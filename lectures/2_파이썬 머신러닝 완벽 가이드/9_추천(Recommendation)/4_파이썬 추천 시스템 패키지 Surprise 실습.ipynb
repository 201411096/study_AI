{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "438801b1",
   "metadata": {},
   "source": [
    "## Surprise - 파이썬 추천 패키지\n",
    "\n",
    "* R은 recommenderlab, Spark는 MLlib에서 쉽게 Recommendation을 수행할 수 있는 패키지를 가지고 있는 방면에 사이킷런에서는 Recommendation을 쉽게 수행할 수 있는 package를 가지고 있지 않습니다.\n",
    "* Python에서 recommendation을 쉽게 제공하는 대표적인 패키지로서 surprise가 있습니다. Surprise는 Scikit learn의 API와 유사하게 작성되어 있으며, 이를 이용해 Recommendation Process를 쉽게 적용할 수 있습니다.\n",
    "* pip 또는 conda로 설치할 수 있으며, 윈도우 운영체제에 설치시에는 Visual studio build tools이 미리 설치되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb399ed6",
   "metadata": {},
   "source": [
    "### Surprise 패키지를 이용한 추천 수행 프로세스\n",
    "\n",
    "1. 데이터 로딩\n",
    "    * 데이터 컬럼 format, rating scaling\n",
    "        * Reader\n",
    "    * Built-in, OS, DataFrame에서 데이터 로딩\n",
    "        * Dataset\n",
    "2. 모델 설정 및 학습\n",
    "    * 추천 Algorithm 설정\n",
    "        * SVD, KNNBasic 등\n",
    "    * Train 데이터로 학습\n",
    "        * train() 메소드\n",
    "3. 예측 및 평가\n",
    "    * 예측\n",
    "        * test(), predict()\n",
    "    * 평가\n",
    "        * accuracy.rmse 등\n",
    "        \n",
    "\n",
    "* cross_validate, GridSearchCV\n",
    "    * Train 데이터로 학습 ~ 예측&평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775fb1af",
   "metadata": {},
   "source": [
    "### Surprise를 이용한 추천 구현 기본\n",
    "\n",
    "1. 필요한 라이브러리 로딩\n",
    "    * from surprise import SVD, Dataset, accuracy\n",
    "    * from surprise.model_selection import train_test_split\n",
    "2. 필요한 데이터 세트를 로딩, 데이터는 Dataset 패키지를 이용, CSV파일 및 Pandas Dataframe에서도 Loading가능, 로딩한 데이터 세트를 학습용과 테스트용 데이터 세트로 분리\n",
    "    * data = Dataset.load_builtin('ml-100k')\n",
    "    * trainset, testset = train_test_split(data, test_size=.25)\n",
    "3. 행렬 분해를 수행할 알고리즘으로 SVD 생성하고 학습용 데이터로 학습\n",
    "    * algo = SVD()\n",
    "    * algo.fit(trainset)\n",
    "4. 테스트 데이터 세트에 대해서 prediction을 수행. 일반적인 scikit learn의 predict() 메소드는 surprise에서 test()메소드, 특정 사용자와 item에 대한 predict는 predict() 메소드.\n",
    "    * predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05742c8e",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개 - Dataset\n",
    "\n",
    "* Surprise는 무비렌즈 데이터 세트와 같이 userid, itemid, rating 컬럼들이 사용자(userid)를 기준으로 한 로우 레벨의 평점 데이터로 구성된 데이터 세트만 입력 가능합니다.\n",
    "* 입력받은 데이터의 첫번째 컬럼을 사용자 ID, 두번째 컬럼을 itemID, 세번째 컬럼을 Rating으로 가정합니다. 네번쨰부터는 Recommendation 알고리즘에 아예 사용하지 않습니다.\n",
    "    * 사용자ID, 아이템ID, 평점의 컬럼순은 반드시 지켜야 합니다.\n",
    "* 이렇게 로우 레벨로 입력 받은 사용자-아이템 데이터는 Dataset 객체로 로딩 후 사용자-아이템 평점 행렬로 변환됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "839b712c",
   "metadata": {},
   "source": [
    "### Dataset 클래스의 주요 메소드\n",
    "\n",
    "* Dataset.load_builtin(name='ml-100k')\n",
    "    * 무비렌즈 아카이브 FTP 서버에서 무비렌즈 데이터를 내려받습니다.\n",
    "    * ml-100k, ml-1M를 내려받을 수 있습니다. 일단 내려받은 데이터는 .surprise_data 디렉토리 밑에 저장되고, 해당 디렉토리에 데이터가 있으면 FTP에서 내려받지 않고 해당 데이터를 이용합니다.\n",
    "    * 입력 파라미터인 name으로 대상 데이터가 ml-100k인지 ml-1m인지를 입력합니다.(name='ml-100k')\n",
    "    * 디폴트는 ml-100k입니다.\n",
    "* Dataset.load_from_file(file_path, reader)\n",
    "    * OS, 파일에서 데이터를 로딩할 때 사용합니다.\n",
    "    * 콤마, 탭 등으로 컬럼이 분리된 포맷의 OS 파일에서 데이터를 로딩합니다.\n",
    "    * 입력 파라미터로 OS 파일명, Reader로 파일의 포맷을 지정합니다.\n",
    "* Dataset.load_from_df(df, reader)\n",
    "    * 판다스의 DataFrame에서 데이터를 로딩합니다.\n",
    "    * 파라미터로 DataFrame을 입력받으며 DataFrame 역시 반드시 3개의 컬럼인 사용자 아이디, 아이템 아이디, 평점 순으로 컬럼 순서가 정해져 있어야 합니다.\n",
    "    * 입력 파라미터로 DataFrame 객체, Reader로 파일의 포맷을 지정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef4d379",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개 - Reader\n",
    "\n",
    "* Raw 데이터 소스에서 Dataset로 로딩 규칙을 지정하기 위해 사용됩니다.\n",
    "* Surprise 데이터 세트는 기본적으로 무비렌즈 데이터와 같은 로우 레벨의 사용자-아이템 평점 데이터 형식을 따르므로, 무비렌즈 데이터 형식이 아닌 경우 이를 변환하여 Dataset로 로딩해야 합니다.\n",
    "\n",
    "\n",
    "* 예시\n",
    "    * from surprise import Reader\n",
    "    * reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "    * data = Dataset.load_from_file('./ml-latest-small/rating_noh.csv', reader=reader)\n",
    "    \n",
    "    \n",
    "* line_format(string) : 컬럼을 순서대로 나열합니다. 입력된 문자열을 공백으로 분리해 컬럼으로 인식합니다.\n",
    "* sep(char) : 컬럼을 분리하는 분리자이며, 디폴트는 '\\t'입니다. 판다스 DataFrame에서 입력받을 경우에는 기재할 필요가 없습니다.\n",
    "* rating_scale(tupe, optional) : 평점 간의 최소~최대 평점을 설정합니다. 디폴트는 (1, 5)이지만 ratings.csv 파일의 경우 최소 평점이 0.5, 최대 평점이 5이므로 (0.5, 5)로 설정했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a1ed09",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7efafb7",
   "metadata": {},
   "source": [
    "## Surprise를 이용한 추천 시스템 기본 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3121ebfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
