{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "717843c7",
   "metadata": {},
   "source": [
    "## Surprise - 파이썬 추천 패키지\n",
    "\n",
    "* R은 recommenderlab, Spark는 MLlib에서 쉽게 Recommendation을 수행할 수 있는 패키지를 가지고 있는 방면에 사이킷런에서는 Recommendation을 쉽게 수행할 수 있는 package를 가지고 있지 않습니다.\n",
    "* Python에서 recommendation을 쉽게 제공하는 대표적인 패키지로서 surprise가 있습니다. Surprise는 Scikit learn의 API와 유사하게 작성되어 있으며, 이를 이용해 Recommendation Process를 쉽게 적용할 수 있습니다.\n",
    "* pip 또는 conda로 설치할 수 있으며, 윈도우 운영체제에 설치시에는 Visual studio build tools이 미리 설치되어 있어야 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20db28d",
   "metadata": {},
   "source": [
    "### Surprise 패키지를 이용한 추천 수행 프로세스\n",
    "\n",
    "1. 데이터 로딩\n",
    "    * 데이터 컬럼 format, rating scaling\n",
    "        * Reader\n",
    "    * Built-in, OS, DataFrame에서 데이터 로딩\n",
    "        * Dataset\n",
    "2. 모델 설정 및 학습\n",
    "    * 추천 Algorithm 설정\n",
    "        * SVD, KNNBasic 등\n",
    "    * Train 데이터로 학습\n",
    "        * train() 메소드\n",
    "3. 예측 및 평가\n",
    "    * 예측\n",
    "        * test(), predict()\n",
    "    * 평가\n",
    "        * accuracy.rmse 등\n",
    "        \n",
    "\n",
    "* cross_validate, GridSearchCV\n",
    "    * Train 데이터로 학습 ~ 예측&평가"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5f2cfe",
   "metadata": {},
   "source": [
    "### Surprise를 이용한 추천 구현 기본\n",
    "\n",
    "1. 필요한 라이브러리 로딩\n",
    "    * from surprise import SVD, Dataset, accuracy\n",
    "    * from surprise.model_selection import train_test_split\n",
    "2. 필요한 데이터 세트를 로딩, 데이터는 Dataset 패키지를 이용, CSV파일 및 Pandas Dataframe에서도 Loading가능, 로딩한 데이터 세트를 학습용과 테스트용 데이터 세트로 분리\n",
    "    * data = Dataset.load_builtin('ml-100k')\n",
    "    * trainset, testset = train_test_split(data, test_size=.25)\n",
    "3. 행렬 분해를 수행할 알고리즘으로 SVD 생성하고 학습용 데이터로 학습\n",
    "    * algo = SVD()\n",
    "    * algo.fit(trainset)\n",
    "4. 테스트 데이터 세트에 대해서 prediction을 수행. 일반적인 scikit learn의 predict() 메소드는 surprise에서 test()메소드, 특정 사용자와 item에 대한 predict는 predict() 메소드.\n",
    "    * predictions = algo.test(testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96add2f",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개 - Dataset\n",
    "\n",
    "* Surprise는 무비렌즈 데이터 세트와 같이 userid, itemid, rating 컬럼들이 사용자(userid)를 기준으로 한 로우 레벨의 평점 데이터로 구성된 데이터 세트만 입력 가능합니다.\n",
    "* 입력받은 데이터의 첫번째 컬럼을 사용자 ID, 두번째 컬럼을 itemID, 세번째 컬럼을 Rating으로 가정합니다. 네번쨰부터는 Recommendation 알고리즘에 아예 사용하지 않습니다.\n",
    "    * 사용자ID, 아이템ID, 평점의 컬럼순은 반드시 지켜야 합니다.\n",
    "* 이렇게 로우 레벨로 입력 받은 사용자-아이템 데이터는 Dataset 객체로 로딩 후 사용자-아이템 평점 행렬로 변환됩니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ff445d",
   "metadata": {},
   "source": [
    "### Dataset 클래스의 주요 메소드\n",
    "\n",
    "* Dataset.load_builtin(name='ml-100k')\n",
    "    * 무비렌즈 아카이브 FTP 서버에서 무비렌즈 데이터를 내려받습니다.\n",
    "    * ml-100k, ml-1M를 내려받을 수 있습니다. 일단 내려받은 데이터는 .surprise_data 디렉토리 밑에 저장되고, 해당 디렉토리에 데이터가 있으면 FTP에서 내려받지 않고 해당 데이터를 이용합니다.\n",
    "    * 입력 파라미터인 name으로 대상 데이터가 ml-100k인지 ml-1m인지를 입력합니다.(name='ml-100k')\n",
    "    * 디폴트는 ml-100k입니다.\n",
    "* Dataset.load_from_file(file_path, reader)\n",
    "    * OS, 파일에서 데이터를 로딩할 때 사용합니다.\n",
    "    * 콤마, 탭 등으로 컬럼이 분리된 포맷의 OS 파일에서 데이터를 로딩합니다.\n",
    "    * 입력 파라미터로 OS 파일명, Reader로 파일의 포맷을 지정합니다.\n",
    "* Dataset.load_from_df(df, reader)\n",
    "    * 판다스의 DataFrame에서 데이터를 로딩합니다.\n",
    "    * 파라미터로 DataFrame을 입력받으며 DataFrame 역시 반드시 3개의 컬럼인 사용자 아이디, 아이템 아이디, 평점 순으로 컬럼 순서가 정해져 있어야 합니다.\n",
    "    * 입력 파라미터로 DataFrame 객체, Reader로 파일의 포맷을 지정합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677d90d",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개 - Reader\n",
    "\n",
    "* Raw 데이터 소스에서 Dataset로 로딩 규칙을 지정하기 위해 사용됩니다.\n",
    "* Surprise 데이터 세트는 기본적으로 무비렌즈 데이터와 같은 로우 레벨의 사용자-아이템 평점 데이터 형식을 따르므로, 무비렌즈 데이터 형식이 아닌 경우 이를 변환하여 Dataset로 로딩해야 합니다.\n",
    "\n",
    "\n",
    "* 예시\n",
    "    * from surprise import Reader\n",
    "    * reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "    * data = Dataset.load_from_file('./ml-latest-small/rating_noh.csv', reader=reader)\n",
    "    \n",
    "    \n",
    "* line_format(string) : 컬럼을 순서대로 나열합니다. 입력된 문자열을 공백으로 분리해 컬럼으로 인식합니다.\n",
    "* sep(char) : 컬럼을 분리하는 분리자이며, 디폴트는 '\\t'입니다. 판다스 DataFrame에서 입력받을 경우에는 기재할 필요가 없습니다.\n",
    "* rating_scale(tupe, optional) : 평점 간의 최소~최대 평점을 설정합니다. 디폴트는 (1, 5)이지만 ratings.csv 파일의 경우 최소 평점이 0.5, 최대 평점이 5이므로 (0.5, 5)로 설정했습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2437d021",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1f2e19",
   "metadata": {},
   "source": [
    "## Surprise를 이용한 추천 시스템 기본 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21738d79",
   "metadata": {},
   "source": [
    "#### surprise 모듈 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc562451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9624f13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1.1\n"
     ]
    }
   ],
   "source": [
    "import surprise\n",
    "\n",
    "print(surprise.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503e82ef",
   "metadata": {},
   "source": [
    "### Surprise를 이용한 추천 시스템 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7303a2c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset\n",
    "from surprise import accuracy\n",
    "from surprise.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74069aa4",
   "metadata": {},
   "source": [
    "#### 내장 데이터를 로드하고 학습과 테스트 데이터로 분리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d4426ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
      "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\user/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin('ml-100k')\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fcb5b68",
   "metadata": {},
   "source": [
    "#### 추천 행렬 분해 알고리즘으로 SVD 객체를 생성하고 학습 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5d5ffb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x22cf9f6d8b0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "algo = SVD()\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499cd90f",
   "metadata": {},
   "source": [
    "#### 테스트 데이터 세트에 예상 평점 데이터 예측, test()메소드 호출 시에는 Prediction 객체의 리스트로 펑점 예측 데이터 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dc5e8317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction type :  <class 'list'>  size :  25000\n",
      "prediction 결과의 최초 5개 추출\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Prediction(uid='120', iid='282', r_ui=4.0, est=3.7003202036929483, details={'was_impossible': False}),\n",
       " Prediction(uid='882', iid='291', r_ui=4.0, est=3.8554527445158033, details={'was_impossible': False}),\n",
       " Prediction(uid='535', iid='507', r_ui=5.0, est=4.09690441053254, details={'was_impossible': False}),\n",
       " Prediction(uid='697', iid='244', r_ui=5.0, est=3.6699218842520316, details={'was_impossible': False}),\n",
       " Prediction(uid='751', iid='385', r_ui=4.0, est=3.3095363428270637, details={'was_impossible': False})]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = algo.test(testset)\n",
    "print('prediction type : ', type(predictions), ' size : ', len(predictions))\n",
    "print('prediction 결과의 최초 5개 추출')\n",
    "predictions[:5]\n",
    "\n",
    "# Prediction 객체가 들어있는 리스트 반환\n",
    "# r_ui : 실제 평점\n",
    "# est : 예측한 평점"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e666e07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('120', '282', 3.7003202036929483),\n",
       " ('882', '291', 3.8554527445158033),\n",
       " ('535', '507', 4.09690441053254)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[ (pred.uid, pred.iid, pred.est) for pred in predictions[:3] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9500f32c",
   "metadata": {},
   "source": [
    "#### predict()메소드는 개별 사용자,아이템에 대한 예측 평점 정보를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e339a599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user: 196        item: 302        r_ui = None   est = 4.29   {'was_impossible': False}\n"
     ]
    }
   ],
   "source": [
    "# 사용자 아이디, 아이템 아이디는 문자열로 입력해야 함. \n",
    "uid = str(196)\n",
    "iid = str(302)\n",
    "pred = algo.predict(uid, iid)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5349f4fe",
   "metadata": {},
   "source": [
    "#### 반환된 Prediction의 리스트 객체를 기반으로 RMSE 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6e2ea997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9482\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9481848514192347"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4cbdcd3",
   "metadata": {},
   "source": [
    "### Surprise 주요 모듈 소개"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2cbbbe8",
   "metadata": {},
   "source": [
    "#### csv 파일로 사용자 평점 데이터 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb9fa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv')\n",
    "# ratings_noh.csv 파일로 unload 시 index 와 header를 모두 제거한 새로운 파일 생성.  \n",
    "ratings.to_csv('./ml-latest-small/ratings_noh.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcba4be",
   "metadata": {},
   "source": [
    "#### Reader클래스로 파일의 포맷팅 지정하고 Dataset의 load_from_file()을 이용하여 데이터셋 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50df17aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import Reader\n",
    "\n",
    "reader = Reader(line_format='user item rating timestamp', sep=',', rating_scale=(0.5, 5))\n",
    "data=Dataset.load_from_file('./ml-latest-small/ratings_noh.csv',reader=reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b382c9cd",
   "metadata": {},
   "source": [
    "#### 학습과 테스트 데이터 세트로 분할하고 SVD로 학습후 테스트데이터 평점 예측 후 RMSE평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a4724cd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "# 수행시마다 동일한 결과 도출을 위해 random_state 설정 \n",
    "algo = SVD(n_factors=50, random_state=0) # latent factor : 50개\n",
    "\n",
    "# 학습 데이터 세트로 학습 후 테스트 데이터 세트로 평점 예측 후 RMSE 평가\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "004ed76d",
   "metadata": {},
   "source": [
    "#### 판다스 DataFrame기반에서 동일하게 재 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a5fab53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.8682\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8681952927143516"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Reader, Dataset\n",
    "\n",
    "ratings = pd.read_csv('./ml-latest-small/ratings.csv') \n",
    "reader = Reader(rating_scale=(0.5, 5.0))\n",
    "\n",
    "# ratings DataFrame 에서 컬럼은 사용자 아이디, 아이템 아이디, 평점 순서를 지켜야 합니다. \n",
    "data = Dataset.load_from_df(ratings[['userId', 'movieId', 'rating']], reader)\n",
    "trainset, testset = train_test_split(data, test_size=.25, random_state=0)\n",
    "\n",
    "algo = SVD(n_factors=50, random_state=0)\n",
    "algo.fit(trainset) \n",
    "predictions = algo.test( testset )\n",
    "accuracy.rmse(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b43bf98",
   "metadata": {},
   "source": [
    "### 교차 검증(Cross Validation)과 하이퍼 파라미터 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d647992",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
