{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5ee64c8",
   "metadata": {},
   "source": [
    "## 텍스트 분석 이해 - NLP와 텍스트 분석"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968f66b9",
   "metadata": {},
   "source": [
    "### NLP(Natural Language Processing)\n",
    "\n",
    "* 인간의 언어를 이해하고 해석하는데 더 중점을 두고 기술이 발전해 옴\n",
    "* NLP 기술의 발전으로 텍스트 분석도 더욱 정교하게 발전"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "946a8ee5",
   "metadata": {},
   "source": [
    "### 텍스트 분석\n",
    "* 텍스트 분석은 머신러닝, 언어 이해, 통계 등을 활용해 모델을 수립하고 정보를 추출해 비즈니스 인텔리전스(Business Intelligence)나 예측 분석 등의 분석 작업을 주로 수행합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6696a17",
   "metadata": {},
   "source": [
    "### 텍스트 분석 주요 영역\n",
    "\n",
    "1. 텍스트 분류(Text Classification)\n",
    "    * 문서가 특정 분류 또는 카테고리에 속하는 것을 예측하는 기법을 통칭합니다. 예를 들어 특정 신문 기사 내용이 연애/정치/사회/문화 중 어떤 카테고리에 속하는지 자동으로 분류하거나 스팸 메일 검출 같은 프로그램이 이에 속합니다. 지도학습을 적용합니다.\n",
    "    \n",
    "    \n",
    "2. 감성 분석(Sentiment Analysis)\n",
    "    * 텍스트에서 나타나는 감정/판단/믿음/의견/기분 등의 주관적인 요소를 분석하는 기법을 총칭합니다. 소셜 미디어 감정 분석, 영화나 제품에 대한 긍정 또는 리뷰, 여론조사 의견 분석 등의 다양한 영역에서 활용됩니다. 지도학습 뿐만 아니라 비지도학습을 이용해 적용할 수 있습니다.\n",
    "    \n",
    "    \n",
    "3. 텍스트 요약(Summarization)\n",
    "    * 텍스트 내에서 중요한 주제나 중심 사상을 추출하는 기법을 말합니다. 대표적으로 토픽 모델링(Topic Modeling)이 있습니다.\n",
    "    \n",
    "    \n",
    "4. 텍스트 군집화와 유사도 측정\n",
    "    * 비슷한 유형의 문서에 대해 군집화를 수행하는 기법을 말합니다. 텍스트 분류를 비지도학습으로 수행하는 방법의 일환으로 사용될 수 있습니다. 유사도 측정 역시 문서들간의 유사도를 측정해 비슷한 문서끼리 모을 수 있는 방법입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5335792a",
   "metadata": {},
   "source": [
    "### 텍스트 분석 머신러닝 수행 프로세스\n",
    "\n",
    "* Text 문서 -> (데이터 사전 가공 후 Feature Vectorization 수행) -> Feature Vectorization -> (Feature 기반의 데이터 셋 제공) -> ML학습/예측/평가\n",
    "    * Feature Vectorization : **Bag of Words** OR **Word2Vec**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f92f2",
   "metadata": {},
   "source": [
    "### 파이썬 기반의 NLP, 텍스트 분석 패키지\n",
    "\n",
    "* NLTK(National Language Toolkit for Python) : 파이썬의 가장 대표적인 NLP 패키지입니다. 방대한 데이터 세트와 서브 모듈을 가지고 있으며 NLP의 거의 모든 영역을 커버하고 있습니다. 많은 NLP 패키지가 NLTK의 영향을 받아 작성되고 있습니다. 수행속도 측면에서 아쉬운 부분이 있어서 실제 대량의 데이터 기반에서는 제대로 활용되지 못하고 있습니다.\n",
    "* Gensim : 토픽 모델링 분야에서 가장 두각을 나타내는 패키지입니다. 오래전부터 토픽 모델링을 쉽게 구현할 수 있는 기능을 제공해 왔으며, Word2Vec 구현 등의 다양한 신기능도 제공합니다. SpaCy와 함께 가장 많이 사용되는 NLP 패키지입니다.\n",
    "* SpaCy : 뛰어난 수행 성능으로 최근 가장 주목을 받는 NLP 패키지입니다. 많은 NLP 어플리케이션에서 SpaCy를 사용하는 사례가 늘고 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f573a9",
   "metadata": {},
   "source": [
    "### 텍스트 전처리 - 텍스트 정규화\n",
    "\n",
    "* 클렌징(Cleansing) : 텍스트에서 분석에 오히려 방해가 되는 불필요한 문자, 기호 등을 사전에 제거하는 작업입니다. 예를 들어 HTML, XML 태그나 특정 기호 등을 사전에 제거합니다.\n",
    "* 토큰화(Tokenization) : 문장 토큰화, 단어 토큰화, n-gram\n",
    "* 필터링/스톱워드 제거/절차 수정 : 불필요한 단어나 분석에 큰 의미가 없는 단어(a, the, is, will등) 그리고 잘못된 철자 수정\n",
    "* Stemming/Lemmatization : 어근(단어 원형) 추출, Lemmatization이 Stemming보다 정교하고 의미론적 기반에서 단어원형을 찾아줌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58f6394f",
   "metadata": {},
   "source": [
    "### N-gram\n",
    "\n",
    "* 문장을 개별 단어 별로 하나씩 토큰화 할 경우 문맥적인 의미는 무시될 수 밖에 없습니다. 이러한 문제를 조금이라도 해결해보고자 도입된 것이 n-gram입니다.\n",
    "* n-gram은 연속된 n개의 단어를 하나의 토큰화 단위로 분리해 내는 것입니다. n개 단어 크기 윈도우를 만들어 문장의 처음부터 오른쪽으로 움직이면서 토큰화를 수행합니다.\n",
    "* 예를 들어 \"Agent Smith knocks the door\"를 2-gram(bigram)으로 만들면 (Agent, Smith), (Smith, knocks), (knocks, the), (the, door)와 같이 연속적으로 2개의 단어들을 순차적으로 이동하면서 단어들을 토큰화합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4653660a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
