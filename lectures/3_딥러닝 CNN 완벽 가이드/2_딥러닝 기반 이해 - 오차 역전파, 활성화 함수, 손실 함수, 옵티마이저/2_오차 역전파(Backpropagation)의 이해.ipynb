{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bdd673",
   "metadata": {},
   "source": [
    "### Backpropagation 개요\n",
    "\n",
    "* 출력층부터 역순으로 Gradient를 전달하여 전체 Layer의 가중치를 Update하는 방식\n",
    "* Feed Forward와 Backpropagation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecb65b7",
   "metadata": {},
   "source": [
    "### 퍼셉트론 회귀 손실 함수의 편미분\n",
    "\n",
    "Loss(w)는 MSE이고 $ Loss(w) = \\frac{1}{N}\\sum_{i=1}^{N}{(y_i - (w_0 + w_1 * x_i))^2} $\n",
    "\n",
    "$ \\frac{dLoss(w)}{dw_1} = \\frac{2}{N}\\sum_{i=1}^{N}{-x_i * (y_i - (w_0 + w_1x_i))} = -\\frac{2}{N}\\sum_{i=1}^{N}{x_i * (실제값_i - 예측값_i)} $\n",
    "$ \\frac{dLoss(w)}{dw_0} = \\frac{2}{N}\\sum_{i=1}^{N}{-(y_i - (w_0 + w_1x_i))} = -\\frac{2}{N}\\sum_{i=1}^{N}{(실제값_i - 예측값_i)} $\n",
    "\n",
    "\n",
    "$ Z = y_i - (w_0 + w_1*x_i )일 경우 Loss(w) = \\frac{1}{N}\\sum_{i=1}^{N}{z^2} $\n",
    "\n",
    "$ \\frac{dLoss(w)}{dw_1} = \\frac{dLoss(w)}{dz}*\\frac{dz}{dw_1} = \\frac{2}{N}\\sum_{i=1}^{N}{z*(-x_i)} = \\frac{2}{N}\\sum_{i=1}^{N}{x_i*(실제값_i - 예측값_i)} $\n",
    "\n",
    "$ \\frac{dLoss(w)}{dw_0} = \\frac{dLoss(w)}{dz}*\\frac{dz}{dw_0} = \\frac{2}{N}\\sum_{i=1}^{N}{z*(-1)} = \\frac{2}{N}\\sum_{i=1}^{N}{(실제값_i - 예측값_i)} $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7032f6",
   "metadata": {},
   "source": [
    "### 미분의 연쇄 법칙 - 의존 변수들의 순차적인 변화율\n",
    "\n",
    "* Chain Rule은 변수가 여러 개일때 어떤 변수에 대한 다른 변수의 변화율을 알아내기 위해 사용됨\n",
    "* 변수 y가 변수 u에 의존하고, 다시 변수 u가 변수 x에 의존한다고 하면 x에 대한 y의 변화율은 u에 대한 y의 변화율과 x에 대한 u의 변화율을 곱하여 계산할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ce8472",
   "metadata": {},
   "source": [
    "### 미분의 연쇄 법칙 의의\n",
    "\n",
    "* 아무리 개별 변수가 복잡하게 구성된 함수의 미분이라도 해당 함수가 (미분 가능한) 내포 함수의 연속적인 결합으로 되어 있다면 연쇄 법칙으로 쉽게 미분 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeb2822e",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "506aca14",
   "metadata": {},
   "source": [
    "## 합성 함수의 연쇄 결합이 적용된 심층 신경망"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4933a5fc",
   "metadata": {},
   "source": [
    "### 심층 신경망은 합성 함수의 연쇄 결합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea82e05",
   "metadata": {},
   "source": [
    "X ->$W^1$->   $F_1$  ->$W^2$->  $F_2$  ->$W^3$->  $F_3$\n",
    "\n",
    "$x_1$   $f_{11}$   $f_{21}$   $f_{31}$\n",
    "\n",
    "$x_2$   $f_{12}$   $f_{22}$\n",
    "\n",
    "$x_3$   $f_{13}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c01271f",
   "metadata": {},
   "source": [
    "입력(Input) = X\n",
    "첫번째 은닉층 출력 = $O_1 = F_1(W^1X)$ \n",
    "\n",
    "두번째 은닉층 출력 = $O_2 = F_2(W^2O_1)$\n",
    "\n",
    "최종 출력 Output = $F_3(W^3O_2)$\n",
    "\n",
    "$=F_3(W^3F_2(W^2O_1)$\n",
    "\n",
    "$=F_3(W^3F_2(W^2F_1(W^1X))$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4608066c",
   "metadata": {},
   "source": [
    "**Loss = $\\frac{1}{N}\\sum_{i=1}^{N}{(실제값 - Output)^2}$**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2fe1b06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
