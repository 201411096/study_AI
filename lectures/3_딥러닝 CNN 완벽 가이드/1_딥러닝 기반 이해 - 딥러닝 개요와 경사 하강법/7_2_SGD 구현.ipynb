{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic Gradient Descent와 Mini Batch Gradient Descent 구현\n",
    "* SGD 는 전체 데이터에서 한건만 임의로 선택하여 Gradient Descent 로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용\n",
    "* Mini Batch GD는 전체 데이터에서 Batch 건수만큼 데이터를 선택하여 Gradient Descent로 Weight/Bias Update 계산한 뒤 Weight/Bias 적용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:55:29.902075Z",
     "iopub.status.busy": "2022-05-29T11:55:29.901743Z",
     "iopub.status.idle": "2022-05-29T11:55:31.125875Z",
     "shell.execute_reply": "2022-05-29T11:55:31.124813Z",
     "shell.execute_reply.started": "2022-05-29T11:55:29.902040Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "from sklearn.datasets import load_boston\n",
    "\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "bostonDF['PRICE'] = boston.target\n",
    "print(bostonDF.shape)\n",
    "bostonDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD 기반으로 Weight/Bias update 값 구하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:55:32.266594Z",
     "iopub.status.busy": "2022-05-29T11:55:32.266283Z",
     "iopub.status.idle": "2022-05-29T11:55:32.275250Z",
     "shell.execute_reply": "2022-05-29T11:55:32.274460Z",
     "shell.execute_reply.started": "2022-05-29T11:55:32.266563Z"
    }
   },
   "outputs": [],
   "source": [
    "# rm_sgd, lstat_sgd가 1건씩만 들어오게 됨\n",
    "def get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate=0.01):\n",
    "    \n",
    "    # 데이터 건수\n",
    "    N = target_sgd.shape[0]\n",
    "    # 예측 값. \n",
    "    predicted_sgd = w1 * rm_sgd + w2*lstat_sgd + bias\n",
    "    # 실제값과 예측값의 차이 \n",
    "    diff_sgd = target_sgd - predicted_sgd\n",
    "    # bias 를 array 기반으로 구하기 위해서 설정. \n",
    "    bias_factors = np.ones((N,))\n",
    "    \n",
    "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(rm_sgd.T, diff_sgd))\n",
    "    w2_update = -(2/N)*learning_rate*(np.dot(lstat_sgd.T, diff_sgd))\n",
    "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_sgd))\n",
    "    \n",
    "    # Mean Squared Error값을 계산. \n",
    "    #mse_loss = np.mean(np.square(diff))\n",
    "    \n",
    "    # weight와 bias가 update되어야 할 값 반환 \n",
    "    return bias_update, w1_update, w2_update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD 수행하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:55:33.404256Z",
     "iopub.status.busy": "2022-05-29T11:55:33.403496Z",
     "iopub.status.idle": "2022-05-29T11:55:33.412768Z",
     "shell.execute_reply": "2022-05-29T11:55:33.412153Z",
     "shell.execute_reply.started": "2022-05-29T11:55:33.404220Z"
    }
   },
   "outputs": [],
   "source": [
    "print(bostonDF['PRICE'].values.shape)\n",
    "print(np.random.choice(bostonDF['PRICE'].values.shape[0], 1))\n",
    "print(np.random.choice(506, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:55:34.160460Z",
     "iopub.status.busy": "2022-05-29T11:55:34.159561Z",
     "iopub.status.idle": "2022-05-29T11:55:34.171486Z",
     "shell.execute_reply": "2022-05-29T11:55:34.170674Z",
     "shell.execute_reply.started": "2022-05-29T11:55:34.160420Z"
    }
   },
   "outputs": [],
   "source": [
    "# RM, LSTAT feature array와 PRICE target array를 입력 받아서 iter_epochs수만큼 반복적으로 Weight와 Bias를 update적용. \n",
    "def st_gradient_descent(features, target, iter_epochs=1000, verbose=True):\n",
    "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
    "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
    "    np.random.seed = 2021\n",
    "    w1 = np.zeros((1,))\n",
    "    w2 = np.zeros((1,))\n",
    "    bias = np.zeros((1, ))\n",
    "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
    "    \n",
    "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
    "    learning_rate = 0.01\n",
    "    rm = features[:, 0]\n",
    "    lstat = features[:, 1]\n",
    "    \n",
    "    \n",
    "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
    "    for i in range(iter_epochs):\n",
    "        # iteration 시마다 stochastic gradient descent 를 수행할 데이터를 한개만 추출. 추출할 데이터의 인덱스를 random.choice() 로 선택. \n",
    "        stochastic_index = np.random.choice(target.shape[0], 1) # 506개 중 1개를 랜덤으로 선택\n",
    "        rm_sgd = rm[stochastic_index]\n",
    "        lstat_sgd = lstat[stochastic_index]\n",
    "        target_sgd = target[stochastic_index]\n",
    "        # SGD 기반으로 Weight/Bias의 Update를 구함.  \n",
    "        bias_update, w1_update, w2_update = get_update_weights_value_sgd(bias, w1, w2, rm_sgd, lstat_sgd, target_sgd, learning_rate)\n",
    "        \n",
    "        # SGD로 구한 weight/bias의 update 적용. \n",
    "        w1 = w1 - w1_update\n",
    "        w2 = w2 - w2_update\n",
    "        bias = bias - bias_update\n",
    "        if verbose:\n",
    "            print('Epoch:', i+1,'/', iter_epochs)\n",
    "            # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
    "            predicted = w1 * rm + w2*lstat + bias\n",
    "            diff = target - predicted\n",
    "            mse_loss = np.mean(np.square(diff))\n",
    "            print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
    "        \n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:55:35.501873Z",
     "iopub.status.busy": "2022-05-29T11:55:35.501560Z",
     "iopub.status.idle": "2022-05-29T11:55:46.476483Z",
     "shell.execute_reply": "2022-05-29T11:55:46.475630Z",
     "shell.execute_reply.started": "2022-05-29T11:55:35.501837Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])\n",
    "\n",
    "w1, w2, bias = st_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=5000, verbose=True)\n",
    "print('##### 최종 w1, w2, bias #######')\n",
    "print(w1, w2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-29T11:56:08.721271Z",
     "iopub.status.busy": "2022-05-29T11:56:08.720669Z",
     "iopub.status.idle": "2022-05-29T11:56:08.755829Z",
     "shell.execute_reply": "2022-05-29T11:56:08.754918Z",
     "shell.execute_reply.started": "2022-05-29T11:56:08.721236Z"
    }
   },
   "outputs": [],
   "source": [
    "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
    "bostonDF['PREDICTED_PRICE_SGD'] = predicted\n",
    "bostonDF.head(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
