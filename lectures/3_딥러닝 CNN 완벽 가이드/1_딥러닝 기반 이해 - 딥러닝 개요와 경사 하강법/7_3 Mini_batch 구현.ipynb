{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ku8CAEic1REX"
   },
   "source": [
    "### iteration시마다 일정한 batch 크기만큼의 데이터를 random하게 가져와서 GD를 수행하는 Mini-Batch GD 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:42:59.661828Z",
     "iopub.status.busy": "2022-06-04T12:42:59.661574Z",
     "iopub.status.idle": "2022-06-04T12:42:59.681049Z",
     "shell.execute_reply": "2022-06-04T12:42:59.680362Z",
     "shell.execute_reply.started": "2022-06-04T12:42:59.661801Z"
    },
    "id": "uPtgS5011REX",
    "outputId": "e0bea017-53df-43eb-f50c-1a140dcd2225"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "boston = load_boston()\n",
    "bostonDF = pd.DataFrame(boston.data, columns=boston.feature_names)\n",
    "bostonDF['PRICE'] = boston.target\n",
    "print(bostonDF.shape)\n",
    "bostonDF.head()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaled_features = scaler.fit_transform(bostonDF[['RM', 'LSTAT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:00.118210Z",
     "iopub.status.busy": "2022-06-04T12:43:00.117539Z",
     "iopub.status.idle": "2022-06-04T12:43:00.124671Z",
     "shell.execute_reply": "2022-06-04T12:43:00.123694Z",
     "shell.execute_reply.started": "2022-06-04T12:43:00.118176Z"
    },
    "id": "TrzYkKA41REX"
   },
   "outputs": [],
   "source": [
    "def get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate=0.01):\n",
    "    \n",
    "    # 데이터 건수\n",
    "    N = target_batch.shape[0]\n",
    "    # 예측 값. \n",
    "    predicted_batch = w1 * rm_batch+ w2 * lstat_batch + bias\n",
    "    # 실제값과 예측값의 차이 \n",
    "    diff_batch = target_batch - predicted_batch\n",
    "    # bias 를 array 기반으로 구하기 위해서 설정. \n",
    "    bias_factors = np.ones((N,))\n",
    "    \n",
    "    # weight와 bias를 얼마나 update할 것인지를 계산.  \n",
    "    w1_update = -(2/N)*learning_rate*(np.dot(rm_batch.T, diff_batch))\n",
    "    w2_update = -(2/N)*learning_rate*(np.dot(lstat_batch.T, diff_batch))\n",
    "    bias_update = -(2/N)*learning_rate*(np.dot(bias_factors.T, diff_batch))\n",
    "    \n",
    "    # Mean Squared Error값을 계산. \n",
    "    #mse_loss = np.mean(np.square(diff))\n",
    "    \n",
    "    # weight와 bias가 update되어야 할 값 반환 \n",
    "    return bias_update, w1_update, w2_update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:00.873782Z",
     "iopub.status.busy": "2022-06-04T12:43:00.873110Z",
     "iopub.status.idle": "2022-06-04T12:43:00.881178Z",
     "shell.execute_reply": "2022-06-04T12:43:00.880367Z",
     "shell.execute_reply.started": "2022-06-04T12:43:00.873745Z"
    },
    "id": "5GBujwnA1REX",
    "outputId": "49b70117-0756-4c5f-9a17-5a7e1112ec30"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178 398 158 222 106 335  82 260  69  30 477 394 110 406  73 350 362  45\n",
      " 235 167 110  79  67 372  89  58 148 224 318 238]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([6.86 , 5.453, 6.066, 6.879, 5.836, 6.037, 6.302, 7.203, 5.885,\n",
       "       5.713, 5.304, 5.887, 6.195, 4.138, 6.245, 6.49 , 5.362, 5.682,\n",
       "       6.086, 5.877, 6.195, 5.874, 5.878, 5.875, 7.079, 6.145, 5.186,\n",
       "       8.266, 6.382, 6.481])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_indexes = np.random.choice(506, 30)\n",
    "print(batch_indexes)\n",
    "\n",
    "bostonDF['RM'].values[batch_indexes]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:01.404297Z",
     "iopub.status.busy": "2022-06-04T12:43:01.403388Z",
     "iopub.status.idle": "2022-06-04T12:43:01.426065Z",
     "shell.execute_reply": "2022-06-04T12:43:01.424743Z",
     "shell.execute_reply.started": "2022-06-04T12:43:01.404246Z"
    },
    "id": "onrv880r1REY"
   },
   "outputs": [],
   "source": [
    "# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음. \n",
    "def batch_random_gradient_descent(features, target, iter_epochs=1000, batch_size=30, verbose=True):\n",
    "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
    "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
    "    np.random.seed = 2021\n",
    "    w1 = np.zeros((1,))\n",
    "    w2 = np.zeros((1,))\n",
    "    bias = np.zeros((1, ))\n",
    "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
    "    \n",
    "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
    "    learning_rate = 0.01\n",
    "    rm = features[:, 0]\n",
    "    lstat = features[:, 1]\n",
    "    \n",
    "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
    "    for i in range(iter_epochs):\n",
    "        # batch_size 갯수만큼 데이터를 임의로 선택. \n",
    "        batch_indexes = np.random.choice(target.shape[0], batch_size)\n",
    "        rm_batch = rm[batch_indexes]\n",
    "        lstat_batch = lstat[batch_indexes]\n",
    "        target_batch = target[batch_indexes]\n",
    "        # Batch GD 기반으로 Weight/Bias의 Update를 구함. \n",
    "        bias_update, w1_update, w2_update = get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n",
    "        \n",
    "        # Batch GD로 구한 weight/bias의 update 적용. \n",
    "        w1 = w1 - w1_update\n",
    "        w2 = w2 - w2_update\n",
    "        bias = bias - bias_update\n",
    "        if verbose:\n",
    "            print('Epoch:', i+1,'/', iter_epochs)\n",
    "            # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
    "            predicted = w1 * rm + w2*lstat + bias\n",
    "            diff = target - predicted\n",
    "            mse_loss = np.mean(np.square(diff))\n",
    "            print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
    "        \n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:02.072282Z",
     "iopub.status.busy": "2022-06-04T12:43:02.071906Z",
     "iopub.status.idle": "2022-06-04T12:43:13.803527Z",
     "shell.execute_reply": "2022-06-04T12:43:13.802837Z",
     "shell.execute_reply.started": "2022-06-04T12:43:02.072249Z"
    },
    "id": "Lr8RDLNo1REY",
    "outputId": "e5a69da3-1dfe-407d-c3ea-bdd28f0096fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "Epoch: 2502 / 5000\n",
      "w1: [23.76443299] w2: [-21.13388005] bias: [16.4769649] loss: 31.032736734415614\n",
      "Epoch: 2503 / 5000\n",
      "w1: [23.7679683] w2: [-21.13181794] bias: [16.49283236] loss: 31.03212240190123\n",
      "Epoch: 2504 / 5000\n",
      "w1: [23.76896053] w2: [-21.11597839] bias: [16.51409916] loss: 31.036461475439086\n",
      "Epoch: 2505 / 5000\n",
      "w1: [23.77571684] w2: [-21.11750201] bias: [16.52125677] loss: 31.035437731088606\n",
      "Epoch: 2506 / 5000\n",
      "w1: [23.78138763] w2: [-21.11791294] bias: [16.52844769] loss: 31.035083546446028\n",
      "Epoch: 2507 / 5000\n",
      "w1: [23.75847249] w2: [-21.1295699] bias: [16.48941585] loss: 31.03448155491036\n",
      "Epoch: 2508 / 5000\n",
      "w1: [23.77478815] w2: [-21.12552915] bias: [16.50997924] loss: 31.032835490861796\n",
      "Epoch: 2509 / 5000\n",
      "w1: [23.80653801] w2: [-21.12118479] bias: [16.56835172] loss: 31.036934883791016\n",
      "Epoch: 2510 / 5000\n",
      "w1: [23.84036013] w2: [-21.1219363] bias: [16.60595289] loss: 31.04428337746538\n",
      "Epoch: 2511 / 5000\n",
      "w1: [23.84377723] w2: [-21.12367101] bias: [16.61936321] loss: 31.047827438675423\n",
      "Epoch: 2512 / 5000\n",
      "w1: [23.83801272] w2: [-21.13078177] bias: [16.61483421] loss: 31.043920123228336\n",
      "Epoch: 2513 / 5000\n",
      "w1: [23.83187777] w2: [-21.12992119] bias: [16.61497743] loss: 31.04432977229778\n",
      "Epoch: 2514 / 5000\n",
      "w1: [23.82248053] w2: [-21.14339] bias: [16.58780561] loss: 31.032903581834383\n",
      "Epoch: 2515 / 5000\n",
      "w1: [23.82149962] w2: [-21.15310512] bias: [16.57563765] loss: 31.02726371522556\n",
      "Epoch: 2516 / 5000\n",
      "w1: [23.81666971] w2: [-21.16495945] bias: [16.55896293] loss: 31.021084887624685\n",
      "Epoch: 2517 / 5000\n",
      "w1: [23.82404628] w2: [-21.17016974] bias: [16.57267465] loss: 31.021205228722444\n",
      "Epoch: 2518 / 5000\n",
      "w1: [23.82870269] w2: [-21.18375165] bias: [16.56414527] loss: 31.015216966862145\n",
      "Epoch: 2519 / 5000\n",
      "w1: [23.82427986] w2: [-21.17543142] bias: [16.5623575] loss: 31.017804589587545\n",
      "Epoch: 2520 / 5000\n",
      "w1: [23.81811867] w2: [-21.17989108] bias: [16.55138965] loss: 31.015464184443772\n",
      "Epoch: 2521 / 5000\n",
      "w1: [23.82805331] w2: [-21.18144037] bias: [16.5628568] loss: 31.015757615220043\n",
      "Epoch: 2522 / 5000\n",
      "w1: [23.8380095] w2: [-21.18302078] bias: [16.57924896] loss: 31.017549127628232\n",
      "Epoch: 2523 / 5000\n",
      "w1: [23.84254299] w2: [-21.1785073] bias: [16.58620134] loss: 31.02021899857683\n",
      "Epoch: 2524 / 5000\n",
      "w1: [23.84629233] w2: [-21.1877791] bias: [16.5821012] loss: 31.016169277542055\n",
      "Epoch: 2525 / 5000\n",
      "w1: [23.84867243] w2: [-21.19721851] bias: [16.57477848] loss: 31.011560141525674\n",
      "Epoch: 2526 / 5000\n",
      "w1: [23.84477695] w2: [-21.205167] bias: [16.5546237] loss: 31.00596667890879\n",
      "Epoch: 2527 / 5000\n",
      "w1: [23.85668696] w2: [-21.18873024] bias: [16.58728393] loss: 31.01652501797595\n",
      "Epoch: 2528 / 5000\n",
      "w1: [23.85089093] w2: [-21.19279707] bias: [16.57446729] loss: 31.012733331881613\n",
      "Epoch: 2529 / 5000\n",
      "w1: [23.85777073] w2: [-21.1970366] bias: [16.58342897] loss: 31.01292930093821\n",
      "Epoch: 2530 / 5000\n",
      "w1: [23.85557453] w2: [-21.19938658] bias: [16.58684498] loss: 31.013060337589266\n",
      "Epoch: 2531 / 5000\n",
      "w1: [23.853575] w2: [-21.19171088] bias: [16.58719641] loss: 31.01568720450748\n",
      "Epoch: 2532 / 5000\n",
      "w1: [23.88492962] w2: [-21.18654299] bias: [16.62141551] loss: 31.02652407833711\n",
      "Epoch: 2533 / 5000\n",
      "w1: [23.88037245] w2: [-21.1956231] bias: [16.60672373] loss: 31.018764455758888\n",
      "Epoch: 2534 / 5000\n",
      "w1: [23.88946427] w2: [-21.20194517] bias: [16.60724868] loss: 31.016690715027334\n",
      "Epoch: 2535 / 5000\n",
      "w1: [23.88654958] w2: [-21.20792964] bias: [16.60362624] loss: 31.013632587782784\n",
      "Epoch: 2536 / 5000\n",
      "w1: [23.87720648] w2: [-21.22340014] bias: [16.57577328] loss: 31.00195255860334\n",
      "Epoch: 2537 / 5000\n",
      "w1: [23.8886086] w2: [-21.21287691] bias: [16.59367522] loss: 31.00918247592896\n",
      "Epoch: 2538 / 5000\n",
      "w1: [23.87581978] w2: [-21.21113831] bias: [16.58918044] loss: 31.008989732799993\n",
      "Epoch: 2539 / 5000\n",
      "w1: [23.88645678] w2: [-21.21586704] bias: [16.59157273] loss: 31.007708523716833\n",
      "Epoch: 2540 / 5000\n",
      "w1: [23.88641436] w2: [-21.22022887] bias: [16.59496015] loss: 31.00717172284543\n",
      "Epoch: 2541 / 5000\n",
      "w1: [23.87931753] w2: [-21.22653838] bias: [16.58158303] loss: 31.002138400994276\n",
      "Epoch: 2542 / 5000\n",
      "w1: [23.85638793] w2: [-21.23822106] bias: [16.53741839] loss: 30.99313784370265\n",
      "Epoch: 2543 / 5000\n",
      "w1: [23.86234636] w2: [-21.23037457] bias: [16.54946104] loss: 30.996261326005243\n",
      "Epoch: 2544 / 5000\n",
      "w1: [23.85596005] w2: [-21.23563701] bias: [16.53738773] loss: 30.99390317385754\n",
      "Epoch: 2545 / 5000\n",
      "w1: [23.8538476] w2: [-21.2352487] bias: [16.53504314] loss: 30.994002253460092\n",
      "Epoch: 2546 / 5000\n",
      "w1: [23.84828773] w2: [-21.2388667] bias: [16.52195266] loss: 30.992599924880025\n",
      "Epoch: 2547 / 5000\n",
      "w1: [23.85868879] w2: [-21.23797705] bias: [16.54183456] loss: 30.993455111461106\n",
      "Epoch: 2548 / 5000\n",
      "w1: [23.86207492] w2: [-21.23872887] bias: [16.54457436] loss: 30.99323243774417\n",
      "Epoch: 2549 / 5000\n",
      "w1: [23.86200232] w2: [-21.24238912] bias: [16.540398] loss: 30.9916988292387\n",
      "Epoch: 2550 / 5000\n",
      "w1: [23.8567417] w2: [-21.25401572] bias: [16.5213719] loss: 30.98742173956469\n",
      "Epoch: 2551 / 5000\n",
      "w1: [23.8824707] w2: [-21.23845397] bias: [16.56495272] loss: 30.99483552937577\n",
      "Epoch: 2552 / 5000\n",
      "w1: [23.88115553] w2: [-21.24314195] bias: [16.55683798] loss: 30.992078195442197\n",
      "Epoch: 2553 / 5000\n",
      "w1: [23.89705004] w2: [-21.23927274] bias: [16.58757661] loss: 30.998792188728828\n",
      "Epoch: 2554 / 5000\n",
      "w1: [23.89015111] w2: [-21.2430677] bias: [16.57356314] loss: 30.994682870125263\n",
      "Epoch: 2555 / 5000\n",
      "w1: [23.89729917] w2: [-21.245925] bias: [16.58087086] loss: 30.995061635886604\n",
      "Epoch: 2556 / 5000\n",
      "w1: [23.88450792] w2: [-21.26424306] bias: [16.54969105] loss: 30.984523646431768\n",
      "Epoch: 2557 / 5000\n",
      "w1: [23.88863131] w2: [-21.2616874] bias: [16.55679973] loss: 30.98602384917128\n",
      "Epoch: 2558 / 5000\n",
      "w1: [23.87340808] w2: [-21.25327609] bias: [16.54315503] loss: 30.987802334209643\n",
      "Epoch: 2559 / 5000\n",
      "w1: [23.87453917] w2: [-21.25101548] bias: [16.54810143] loss: 30.988996122055532\n",
      "Epoch: 2560 / 5000\n",
      "w1: [23.86578283] w2: [-21.25885623] bias: [16.52676021] loss: 30.98538391339834\n",
      "Epoch: 2561 / 5000\n",
      "w1: [23.87682617] w2: [-21.26494775] bias: [16.53789244] loss: 30.983549642716145\n",
      "Epoch: 2562 / 5000\n",
      "w1: [23.87395051] w2: [-21.26598953] bias: [16.5330512] loss: 30.983061713138458\n",
      "Epoch: 2563 / 5000\n",
      "w1: [23.87849211] w2: [-21.26611787] bias: [16.53490281] loss: 30.982719508743173\n",
      "Epoch: 2564 / 5000\n",
      "w1: [23.88691684] w2: [-21.27007599] bias: [16.54315365] loss: 30.981741040396802\n",
      "Epoch: 2565 / 5000\n",
      "w1: [23.89332532] w2: [-21.27327157] bias: [16.54683034] loss: 30.980746103935925\n",
      "Epoch: 2566 / 5000\n",
      "w1: [23.89546342] w2: [-21.27538833] bias: [16.54526671] loss: 30.979730422943867\n",
      "Epoch: 2567 / 5000\n",
      "w1: [23.91044442] w2: [-21.28592037] bias: [16.54903257] loss: 30.976001181266287\n",
      "Epoch: 2568 / 5000\n",
      "w1: [23.90882636] w2: [-21.28418137] bias: [16.54813424] loss: 30.97649313193958\n",
      "Epoch: 2569 / 5000\n",
      "w1: [23.91824791] w2: [-21.28765645] bias: [16.56768073] loss: 30.978302730315157\n",
      "Epoch: 2570 / 5000\n",
      "w1: [23.91870277] w2: [-21.29200766] bias: [16.56379223] loss: 30.976205167477673\n",
      "Epoch: 2571 / 5000\n",
      "w1: [23.91625408] w2: [-21.30445742] bias: [16.547242] loss: 30.969937294018884\n",
      "Epoch: 2572 / 5000\n",
      "w1: [23.91634062] w2: [-21.31348341] bias: [16.53611596] loss: 30.965902413376266\n",
      "Epoch: 2573 / 5000\n",
      "w1: [23.93280709] w2: [-21.30989656] bias: [16.55123986] loss: 30.96773157189958\n",
      "Epoch: 2574 / 5000\n",
      "w1: [23.94291443] w2: [-21.29586289] bias: [16.57892167] loss: 30.977193219338332\n",
      "Epoch: 2575 / 5000\n",
      "w1: [23.95187306] w2: [-21.30298208] bias: [16.58630031] loss: 30.976580719307613\n",
      "Epoch: 2576 / 5000\n",
      "w1: [23.95982656] w2: [-21.30218344] bias: [16.60098244] loss: 30.980914187571596\n",
      "Epoch: 2577 / 5000\n",
      "w1: [23.95687451] w2: [-21.31669658] bias: [16.58646225] loss: 30.97215746148719\n",
      "Epoch: 2578 / 5000\n",
      "w1: [23.9350374] w2: [-21.33389007] bias: [16.55787285] loss: 30.9617614703229\n",
      "Epoch: 2579 / 5000\n",
      "w1: [23.91149688] w2: [-21.34961996] bias: [16.51220831] loss: 30.954962682881895\n",
      "Epoch: 2580 / 5000\n",
      "w1: [23.88037652] w2: [-21.37025614] bias: [16.45506394] loss: 30.9577191596135\n",
      "Epoch: 2581 / 5000\n",
      "w1: [23.88189583] w2: [-21.37254591] bias: [16.46417606] loss: 30.95597956263998\n",
      "Epoch: 2582 / 5000\n",
      "w1: [23.88349685] w2: [-21.39058506] bias: [16.44081561] loss: 30.954910391193156\n",
      "Epoch: 2583 / 5000\n",
      "w1: [23.89363957] w2: [-21.39492366] bias: [16.45027519] loss: 30.95043954471725\n",
      "Epoch: 2584 / 5000\n",
      "w1: [23.88834187] w2: [-21.39426501] bias: [16.44172512] loss: 30.952932847336715\n",
      "Epoch: 2585 / 5000\n",
      "w1: [23.8984305] w2: [-21.36616116] bias: [16.48497652] loss: 30.952861464391255\n",
      "Epoch: 2586 / 5000\n",
      "w1: [23.89257251] w2: [-21.37323823] bias: [16.47339625] loss: 30.95294464081311\n",
      "Epoch: 2587 / 5000\n",
      "w1: [23.88652771] w2: [-21.37941826] bias: [16.46243849] loss: 30.95375532007743\n",
      "Epoch: 2588 / 5000\n",
      "w1: [23.88538908] w2: [-21.37535918] bias: [16.46700872] loss: 30.954412846621636\n",
      "Epoch: 2589 / 5000\n",
      "w1: [23.9010619] w2: [-21.37875283] bias: [16.48068648] loss: 30.949739742398805\n",
      "Epoch: 2590 / 5000\n",
      "w1: [23.89843544] w2: [-21.37383384] bias: [16.48881257] loss: 30.951007994252453\n",
      "Epoch: 2591 / 5000\n",
      "w1: [23.91330298] w2: [-21.3756337] bias: [16.50927326] loss: 30.948190109599317\n",
      "Epoch: 2592 / 5000\n",
      "w1: [23.9175192] w2: [-21.37858151] bias: [16.5161789] loss: 30.947116423650805\n",
      "Epoch: 2593 / 5000\n",
      "w1: [23.90760516] w2: [-21.3851207] bias: [16.50200389] loss: 30.946695753580627\n",
      "Epoch: 2594 / 5000\n",
      "w1: [23.90698845] w2: [-21.38082461] bias: [16.50252056] loss: 30.947802195993575\n",
      "Epoch: 2595 / 5000\n",
      "w1: [23.91880142] w2: [-21.38248209] bias: [16.51269001] loss: 30.945845011760266\n",
      "Epoch: 2596 / 5000\n",
      "w1: [23.92442124] w2: [-21.37920119] bias: [16.52143653] loss: 30.946326703763265\n",
      "Epoch: 2597 / 5000\n",
      "w1: [23.91175309] w2: [-21.3934472] bias: [16.49427839] loss: 30.94415642425286\n",
      "Epoch: 2598 / 5000\n",
      "w1: [23.89526509] w2: [-21.39727471] bias: [16.46667532] loss: 30.947861615171913\n",
      "Epoch: 2599 / 5000\n",
      "w1: [23.9009599] w2: [-21.40705237] bias: [16.47138013] loss: 30.94427620180501\n",
      "Epoch: 2600 / 5000\n",
      "w1: [23.91027559] w2: [-21.40153531] bias: [16.48751418] loss: 30.942763415549226\n",
      "Epoch: 2601 / 5000\n",
      "w1: [23.89528939] w2: [-21.40050657] bias: [16.4694089] loss: 30.946946499077626\n",
      "Epoch: 2602 / 5000\n",
      "w1: [23.91247572] w2: [-21.40791487] bias: [16.48462531] loss: 30.94107851533145\n",
      "Epoch: 2603 / 5000\n",
      "w1: [23.91035892] w2: [-21.41377625] bias: [16.47828139] loss: 30.940535147568497\n",
      "Epoch: 2604 / 5000\n",
      "w1: [23.89349753] w2: [-21.42525837] bias: [16.44086744] loss: 30.94605887945828\n",
      "Epoch: 2605 / 5000\n",
      "w1: [23.89662951] w2: [-21.42787053] bias: [16.44193037] loss: 30.94465756569921\n",
      "Epoch: 2606 / 5000\n",
      "w1: [23.90516173] w2: [-21.42569901] bias: [16.45301258] loss: 30.941535194867956\n",
      "Epoch: 2607 / 5000\n",
      "w1: [23.90475926] w2: [-21.43033313] bias: [16.45567991] loss: 30.940398228842543\n",
      "Epoch: 2608 / 5000\n",
      "w1: [23.89442246] w2: [-21.43358138] bias: [16.43860454] loss: 30.944698993122927\n",
      "Epoch: 2609 / 5000\n",
      "w1: [23.90220038] w2: [-21.43517498] bias: [16.45899376] loss: 30.93962154070553\n",
      "Epoch: 2610 / 5000\n",
      "w1: [23.91176082] w2: [-21.43592877] bias: [16.47276056] loss: 30.936039462796508\n",
      "Epoch: 2611 / 5000\n",
      "w1: [23.94242735] w2: [-21.42831791] bias: [16.52819001] loss: 30.93220270868067\n",
      "Epoch: 2612 / 5000\n",
      "w1: [23.92983971] w2: [-21.42692183] bias: [16.52686965] loss: 30.934074466629692\n",
      "Epoch: 2613 / 5000\n",
      "w1: [23.93317879] w2: [-21.42610222] bias: [16.53369353] loss: 30.934242185813392\n",
      "Epoch: 2614 / 5000\n",
      "w1: [23.92459741] w2: [-21.43248836] bias: [16.51695852] loss: 30.933131487668252\n",
      "Epoch: 2615 / 5000\n",
      "w1: [23.93540285] w2: [-21.42486906] bias: [16.53967669] loss: 30.93472839207078\n",
      "Epoch: 2616 / 5000\n",
      "w1: [23.93029622] w2: [-21.41567445] bias: [16.5407026] loss: 30.937739014814248\n",
      "Epoch: 2617 / 5000\n",
      "w1: [23.9236444] w2: [-21.4182694] bias: [16.52564156] loss: 30.936953280956168\n",
      "Epoch: 2618 / 5000\n",
      "w1: [23.93934114] w2: [-21.41577651] bias: [16.54923528] loss: 30.937571195846004\n",
      "Epoch: 2619 / 5000\n",
      "w1: [23.97235325] w2: [-21.40628368] bias: [16.60850204] loss: 30.94959053901646\n",
      "Epoch: 2620 / 5000\n",
      "w1: [23.9772883] w2: [-21.41188839] bias: [16.60688358] loss: 30.94733928427783\n",
      "Epoch: 2621 / 5000\n",
      "w1: [23.99237398] w2: [-21.41246585] bias: [16.63154506] loss: 30.954547146329368\n",
      "Epoch: 2622 / 5000\n",
      "w1: [23.99651167] w2: [-21.41306858] bias: [16.63764502] loss: 30.95651190533387\n",
      "Epoch: 2623 / 5000\n",
      "w1: [23.99473647] w2: [-21.41104889] bias: [16.63439492] loss: 30.956021454077938\n",
      "Epoch: 2624 / 5000\n",
      "w1: [23.99095359] w2: [-21.41879266] bias: [16.61901028] loss: 30.948517432085758\n",
      "Epoch: 2625 / 5000\n",
      "w1: [23.99594448] w2: [-21.41592726] bias: [16.62334124] loss: 30.950810632264947\n",
      "Epoch: 2626 / 5000\n",
      "w1: [24.01551445] w2: [-21.40277833] bias: [16.6593042] loss: 30.969191750074938\n",
      "Epoch: 2627 / 5000\n",
      "w1: [24.03338132] w2: [-21.40442419] bias: [16.67502453] loss: 30.976905441506798\n",
      "Epoch: 2628 / 5000\n",
      "w1: [24.04393109] w2: [-21.41360192] bias: [16.67437859] loss: 30.974179399619995\n",
      "Epoch: 2629 / 5000\n",
      "w1: [24.05393359] w2: [-21.41541801] bias: [16.6882697] loss: 30.9813147522986\n",
      "Epoch: 2630 / 5000\n",
      "w1: [24.05407677] w2: [-21.42218573] bias: [16.6801033] loss: 30.974722061856813\n",
      "Epoch: 2631 / 5000\n",
      "w1: [24.02908175] w2: [-21.43908566] bias: [16.63386583] loss: 30.947496110154347\n",
      "Epoch: 2632 / 5000\n",
      "w1: [24.01821644] w2: [-21.44173286] bias: [16.61523524] loss: 30.940192687694918\n",
      "Epoch: 2633 / 5000\n",
      "w1: [24.01833199] w2: [-21.45128221] bias: [16.60824185] loss: 30.93509386283849\n",
      "Epoch: 2634 / 5000\n",
      "w1: [24.01818788] w2: [-21.45815339] bias: [16.60785052] loss: 30.932844359043415\n",
      "Epoch: 2635 / 5000\n",
      "w1: [23.9923926] w2: [-21.46770249] bias: [16.56474774] loss: 30.921318621300518\n",
      "Epoch: 2636 / 5000\n",
      "w1: [23.98602107] w2: [-21.47581728] bias: [16.54801085] loss: 30.91727302115209\n",
      "Epoch: 2637 / 5000\n",
      "w1: [23.97260444] w2: [-21.48883059] bias: [16.52251485] loss: 30.913380769081506\n",
      "Epoch: 2638 / 5000\n",
      "w1: [23.97221106] w2: [-21.49365343] bias: [16.51071199] loss: 30.91191515677895\n",
      "Epoch: 2639 / 5000\n",
      "w1: [23.96178487] w2: [-21.50714521] bias: [16.48448771] loss: 30.911068007397162\n",
      "Epoch: 2640 / 5000\n",
      "w1: [23.96104838] w2: [-21.50044406] bias: [16.48624351] loss: 30.91251112893604\n",
      "Epoch: 2641 / 5000\n",
      "w1: [23.952159] w2: [-21.51293859] bias: [16.4677894] loss: 30.913012430297762\n",
      "Epoch: 2642 / 5000\n",
      "w1: [23.97412009] w2: [-21.50807578] bias: [16.50129526] loss: 30.90832072962972\n",
      "Epoch: 2643 / 5000\n",
      "w1: [23.99435085] w2: [-21.50994935] bias: [16.522943] loss: 30.905652581768805\n",
      "Epoch: 2644 / 5000\n",
      "w1: [24.01382401] w2: [-21.4972867] bias: [16.55855092] loss: 30.910824226036482\n",
      "Epoch: 2645 / 5000\n",
      "w1: [24.0238162] w2: [-21.48800571] bias: [16.59740455] loss: 30.920914397751144\n",
      "Epoch: 2646 / 5000\n",
      "w1: [24.03800658] w2: [-21.48324212] bias: [16.61838549] loss: 30.928189059874875\n",
      "Epoch: 2647 / 5000\n",
      "w1: [24.03208367] w2: [-21.49342004] bias: [16.59994375] loss: 30.91980125597975\n",
      "Epoch: 2648 / 5000\n",
      "w1: [24.02161506] w2: [-21.50597376] bias: [16.57902125] loss: 30.911640750532264\n",
      "Epoch: 2649 / 5000\n",
      "w1: [24.03534668] w2: [-21.4916257] bias: [16.60601862] loss: 30.921946692491495\n",
      "Epoch: 2650 / 5000\n",
      "w1: [24.04325107] w2: [-21.48889474] bias: [16.62391851] loss: 30.928224965389703\n",
      "Epoch: 2651 / 5000\n",
      "w1: [24.02188553] w2: [-21.51212868] bias: [16.57876706] loss: 30.90985123572255\n",
      "Epoch: 2652 / 5000\n",
      "w1: [24.02274325] w2: [-21.51953077] bias: [16.57085237] loss: 30.906280823374257\n",
      "Epoch: 2653 / 5000\n",
      "w1: [24.02295997] w2: [-21.52301822] bias: [16.5622558] loss: 30.903883813881357\n",
      "Epoch: 2654 / 5000\n",
      "w1: [24.0332405] w2: [-21.52256481] bias: [16.57758667] loss: 30.90617161346542\n",
      "Epoch: 2655 / 5000\n",
      "w1: [24.03944187] w2: [-21.53576338] bias: [16.57305751] loss: 30.901335454126166\n",
      "Epoch: 2656 / 5000\n",
      "w1: [24.03840048] w2: [-21.53976614] bias: [16.56695068] loss: 30.899193398337104\n",
      "Epoch: 2657 / 5000\n",
      "w1: [24.04972137] w2: [-21.54212069] bias: [16.57515472] loss: 30.899504499567765\n",
      "Epoch: 2658 / 5000\n",
      "w1: [24.05872114] w2: [-21.53875406] bias: [16.59990014] loss: 30.90593043137654\n",
      "Epoch: 2659 / 5000\n",
      "w1: [24.05521849] w2: [-21.54547266] bias: [16.58632185] loss: 30.900741696714615\n",
      "Epoch: 2660 / 5000\n",
      "w1: [24.05070354] w2: [-21.55095952] bias: [16.57307268] loss: 30.896612398087484\n",
      "Epoch: 2661 / 5000\n",
      "w1: [24.06868626] w2: [-21.54658505] bias: [16.59702235] loss: 30.902750772811938\n",
      "Epoch: 2662 / 5000\n",
      "w1: [24.05364759] w2: [-21.55284001] bias: [16.58501234] loss: 30.898413457957126\n",
      "Epoch: 2663 / 5000\n",
      "w1: [24.07303445] w2: [-21.55352658] bias: [16.60462145] loss: 30.902703013270745\n",
      "Epoch: 2664 / 5000\n",
      "w1: [24.05958374] w2: [-21.56335511] bias: [16.57993537] loss: 30.894175023169392\n",
      "Epoch: 2665 / 5000\n",
      "w1: [24.07685091] w2: [-21.5666816] bias: [16.59484858] loss: 30.896202382341762\n",
      "Epoch: 2666 / 5000\n",
      "w1: [24.08566184] w2: [-21.56838222] bias: [16.60845864] loss: 30.899342533226793\n",
      "Epoch: 2667 / 5000\n",
      "w1: [24.08763753] w2: [-21.57241916] bias: [16.60329805] loss: 30.896676440161905\n",
      "Epoch: 2668 / 5000\n",
      "w1: [24.09243827] w2: [-21.57622575] bias: [16.61262642] loss: 30.89824830035141\n",
      "Epoch: 2669 / 5000\n",
      "w1: [24.08166275] w2: [-21.58597739] bias: [16.58964762] loss: 30.88929671203942\n",
      "Epoch: 2670 / 5000\n",
      "w1: [24.08789811] w2: [-21.58779697] bias: [16.59722877] loss: 30.890537625007553\n",
      "Epoch: 2671 / 5000\n",
      "w1: [24.08970904] w2: [-21.57275157] bias: [16.61106516] loss: 30.898810922337255\n",
      "Epoch: 2672 / 5000\n",
      "w1: [24.0975167] w2: [-21.56625196] bias: [16.62678351] loss: 30.905959621242996\n",
      "Epoch: 2673 / 5000\n",
      "w1: [24.09521228] w2: [-21.57259261] bias: [16.62405169] loss: 30.902994521702087\n",
      "Epoch: 2674 / 5000\n",
      "w1: [24.09577143] w2: [-21.57443438] bias: [16.61970248] loss: 30.901032217247916\n",
      "Epoch: 2675 / 5000\n",
      "w1: [24.10152222] w2: [-21.57473566] bias: [16.62579013] loss: 30.903073568914504\n",
      "Epoch: 2676 / 5000\n",
      "w1: [24.10781359] w2: [-21.57535603] bias: [16.63551729] loss: 30.906500641897665\n",
      "Epoch: 2677 / 5000\n",
      "w1: [24.11196827] w2: [-21.57237509] bias: [16.64288717] loss: 30.91041516897785\n",
      "Epoch: 2678 / 5000\n",
      "w1: [24.14407054] w2: [-21.55883798] bias: [16.69912079] loss: 30.944068461190305\n",
      "Epoch: 2679 / 5000\n",
      "w1: [24.15219775] w2: [-21.55414775] bias: [16.71044767] loss: 30.95329577451422\n",
      "Epoch: 2680 / 5000\n",
      "w1: [24.16939492] w2: [-21.5534229] bias: [16.73528081] loss: 30.971548344766642\n",
      "Epoch: 2681 / 5000\n",
      "w1: [24.18414073] w2: [-21.54765522] bias: [16.75018135] loss: 30.986791577884517\n",
      "Epoch: 2682 / 5000\n",
      "w1: [24.17607249] w2: [-21.55163915] bias: [16.73402253] loss: 30.972741603519665\n",
      "Epoch: 2683 / 5000\n",
      "w1: [24.18074143] w2: [-21.55974318] bias: [16.7314622] loss: 30.968708554844216\n",
      "Epoch: 2684 / 5000\n",
      "w1: [24.17056117] w2: [-21.55994503] bias: [16.71529473] loss: 30.956821544691042\n",
      "Epoch: 2685 / 5000\n",
      "w1: [24.16861217] w2: [-21.56485052] bias: [16.70484374] loss: 30.948513989519785\n",
      "Epoch: 2686 / 5000\n",
      "w1: [24.16510364] w2: [-21.57448258] bias: [16.69609101] loss: 30.93947495346695\n",
      "Epoch: 2687 / 5000\n",
      "w1: [24.15710794] w2: [-21.58589872] bias: [16.69079404] loss: 30.93136936940258\n",
      "Epoch: 2688 / 5000\n",
      "w1: [24.15721669] w2: [-21.58272751] bias: [16.71286815] loss: 30.94449676163335\n",
      "Epoch: 2689 / 5000\n",
      "w1: [24.15704528] w2: [-21.57220014] bias: [16.72634904] loss: 30.956350000151847\n",
      "Epoch: 2690 / 5000\n",
      "w1: [24.1714377] w2: [-21.58425889] bias: [16.72912568] loss: 30.955764727035735\n",
      "Epoch: 2691 / 5000\n",
      "w1: [24.17821268] w2: [-21.59642159] bias: [16.7488402] loss: 30.964582566305403\n",
      "Epoch: 2692 / 5000\n",
      "w1: [24.15925108] w2: [-21.60771622] bias: [16.71602799] loss: 30.93711626382762\n",
      "Epoch: 2693 / 5000\n",
      "w1: [24.14549894] w2: [-21.6083897] bias: [16.69269798] loss: 30.922777491316644\n",
      "Epoch: 2694 / 5000\n",
      "w1: [24.14743569] w2: [-21.61582499] bias: [16.68498471] loss: 30.91659938542014\n",
      "Epoch: 2695 / 5000\n",
      "w1: [24.14192708] w2: [-21.62649285] bias: [16.66688408] loss: 30.90419799722341\n",
      "Epoch: 2696 / 5000\n",
      "w1: [24.14024421] w2: [-21.63499652] bias: [16.65893517] loss: 30.89791559853427\n",
      "Epoch: 2697 / 5000\n",
      "w1: [24.14764644] w2: [-21.63882795] bias: [16.65409543] loss: 30.89521167901479\n",
      "Epoch: 2698 / 5000\n",
      "w1: [24.1454982] w2: [-21.64286135] bias: [16.64754532] loss: 30.891188927188285\n",
      "Epoch: 2699 / 5000\n",
      "w1: [24.14971804] w2: [-21.64818708] bias: [16.64100557] loss: 30.88724633291312\n",
      "Epoch: 2700 / 5000\n",
      "w1: [24.14615345] w2: [-21.65720753] bias: [16.62644137] loss: 30.879133101597507\n",
      "Epoch: 2701 / 5000\n",
      "w1: [24.13411908] w2: [-21.65890058] bias: [16.60860106] loss: 30.872861791373527\n",
      "Epoch: 2702 / 5000\n",
      "w1: [24.13956045] w2: [-21.66744649] bias: [16.60303148] loss: 30.868858087236514\n",
      "Epoch: 2703 / 5000\n",
      "w1: [24.13881616] w2: [-21.67585166] bias: [16.59626233] loss: 30.864682083965917\n",
      "Epoch: 2704 / 5000\n",
      "w1: [24.13111354] w2: [-21.68519153] bias: [16.57644111] loss: 30.857779445848692\n",
      "Epoch: 2705 / 5000\n",
      "w1: [24.13028963] w2: [-21.69062181] bias: [16.57155347] loss: 30.85543801484778\n",
      "Epoch: 2706 / 5000\n",
      "w1: [24.13267148] w2: [-21.68392516] bias: [16.58416414] loss: 30.859695232929674\n",
      "Epoch: 2707 / 5000\n",
      "w1: [24.11744027] w2: [-21.69392851] bias: [16.55491462] loss: 30.852599009987777\n",
      "Epoch: 2708 / 5000\n",
      "w1: [24.12292204] w2: [-21.68800127] bias: [16.5632893] loss: 30.855011418430287\n",
      "Epoch: 2709 / 5000\n",
      "w1: [24.13098381] w2: [-21.68116747] bias: [16.57476351] loss: 30.85850994695863\n",
      "Epoch: 2710 / 5000\n",
      "w1: [24.13822234] w2: [-21.68257186] bias: [16.59733798] loss: 30.863077420505967\n",
      "Epoch: 2711 / 5000\n",
      "w1: [24.15087428] w2: [-21.68345028] bias: [16.61438903] loss: 30.867573825735597\n",
      "Epoch: 2712 / 5000\n",
      "w1: [24.14523466] w2: [-21.69377121] bias: [16.596688] loss: 30.859729621921396\n",
      "Epoch: 2713 / 5000\n",
      "w1: [24.15392684] w2: [-21.68978987] bias: [16.6099869] loss: 30.864472236813082\n",
      "Epoch: 2714 / 5000\n",
      "w1: [24.15115309] w2: [-21.6956186] bias: [16.60247266] loss: 30.86069079200098\n",
      "Epoch: 2715 / 5000\n",
      "w1: [24.14712296] w2: [-21.69644771] bias: [16.59765674] loss: 30.859214442188343\n",
      "Epoch: 2716 / 5000\n",
      "w1: [24.13100259] w2: [-21.70903727] bias: [16.57591153] loss: 30.85145885455602\n",
      "Epoch: 2717 / 5000\n",
      "w1: [24.10827813] w2: [-21.70369892] bias: [16.55528617] loss: 30.850939067706623\n",
      "Epoch: 2718 / 5000\n",
      "w1: [24.09987748] w2: [-21.69966901] bias: [16.54588956] loss: 30.85153928387208\n",
      "Epoch: 2719 / 5000\n",
      "w1: [24.09493864] w2: [-21.70374766] bias: [16.53536272] loss: 30.850192733509026\n",
      "Epoch: 2720 / 5000\n",
      "w1: [24.11073848] w2: [-21.70300616] bias: [16.55533406] loss: 30.85092663767763\n",
      "Epoch: 2721 / 5000\n",
      "w1: [24.11637178] w2: [-21.70509137] bias: [16.56306798] loss: 30.85109181295838\n",
      "Epoch: 2722 / 5000\n",
      "w1: [24.10731869] w2: [-21.71164703] bias: [16.54251738] loss: 30.84776322899253\n",
      "Epoch: 2723 / 5000\n",
      "w1: [24.12279647] w2: [-21.70206378] bias: [16.56951033] loss: 30.852495254193173\n",
      "Epoch: 2724 / 5000\n",
      "w1: [24.12117193] w2: [-21.70456451] bias: [16.56030013] loss: 30.850508385523476\n",
      "Epoch: 2725 / 5000\n",
      "w1: [24.11204728] w2: [-21.70926801] bias: [16.54314644] loss: 30.847948023679766\n",
      "Epoch: 2726 / 5000\n",
      "w1: [24.10197329] w2: [-21.71558261] bias: [16.51919199] loss: 30.84592743918395\n",
      "Epoch: 2727 / 5000\n",
      "w1: [24.10422871] w2: [-21.70868995] bias: [16.52543536] loss: 30.847458467485904\n",
      "Epoch: 2728 / 5000\n",
      "w1: [24.10698923] w2: [-21.71038856] bias: [16.52928699] loss: 30.84702288497069\n",
      "Epoch: 2729 / 5000\n",
      "w1: [24.10145929] w2: [-21.7041085] bias: [16.52831752] loss: 30.84894749910808\n",
      "Epoch: 2730 / 5000\n",
      "w1: [24.09174901] w2: [-21.70993895] bias: [16.50604408] loss: 30.84815003975691\n",
      "Epoch: 2731 / 5000\n",
      "w1: [24.08701585] w2: [-21.71086367] bias: [16.49737139] loss: 30.848707470001283\n",
      "Epoch: 2732 / 5000\n",
      "w1: [24.09333267] w2: [-21.69503969] bias: [16.52301846] loss: 30.851559690964496\n",
      "Epoch: 2733 / 5000\n",
      "w1: [24.08576736] w2: [-21.6935528] bias: [16.52021744] loss: 30.85266558380185\n",
      "Epoch: 2734 / 5000\n",
      "w1: [24.08825413] w2: [-21.68422192] bias: [16.52563291] loss: 30.854662044270363\n",
      "Epoch: 2735 / 5000\n",
      "w1: [24.08924644] w2: [-21.69773746] bias: [16.51162419] loss: 30.851086623370048\n",
      "Epoch: 2736 / 5000\n",
      "w1: [24.08700462] w2: [-21.7097251] bias: [16.49444799] loss: 30.848993436941353\n",
      "Epoch: 2737 / 5000\n",
      "w1: [24.07558456] w2: [-21.71900004] bias: [16.47103284] loss: 30.850511173350093\n",
      "Epoch: 2738 / 5000\n",
      "w1: [24.08208863] w2: [-21.71835423] bias: [16.47650053] loss: 30.849010439085767\n",
      "Epoch: 2739 / 5000\n",
      "w1: [24.07308119] w2: [-21.72485586] bias: [16.45689729] loss: 30.851482773326456\n",
      "Epoch: 2740 / 5000\n",
      "w1: [24.07415333] w2: [-21.72891936] bias: [16.46069401] loss: 30.850137838820366\n",
      "Epoch: 2741 / 5000\n",
      "w1: [24.07357716] w2: [-21.72114879] bias: [16.46866058] loss: 30.85073291403746\n",
      "Epoch: 2742 / 5000\n",
      "w1: [24.07339746] w2: [-21.73297207] bias: [16.45423914] loss: 30.8504259456926\n",
      "Epoch: 2743 / 5000\n",
      "w1: [24.06002253] w2: [-21.74604949] bias: [16.42522758] loss: 30.856542745054877\n",
      "Epoch: 2744 / 5000\n",
      "w1: [24.04937288] w2: [-21.75367488] bias: [16.4037886] loss: 30.86357690918819\n",
      "Epoch: 2745 / 5000\n",
      "w1: [24.04921776] w2: [-21.75207051] bias: [16.39782623] loss: 30.865454807541145\n",
      "Epoch: 2746 / 5000\n",
      "w1: [24.04399219] w2: [-21.75968152] bias: [16.3906681] loss: 30.86824246515497\n",
      "Epoch: 2747 / 5000\n",
      "w1: [24.03500185] w2: [-21.76621241] bias: [16.37080896] loss: 30.87701847216555\n",
      "Epoch: 2748 / 5000\n",
      "w1: [24.04985703] w2: [-21.75607205] bias: [16.39669416] loss: 30.865129192917642\n",
      "Epoch: 2749 / 5000\n",
      "w1: [24.03948123] w2: [-21.76013063] bias: [16.39495361] loss: 30.868244985615387\n",
      "Epoch: 2750 / 5000\n",
      "w1: [24.04994299] w2: [-21.74990719] bias: [16.42048278] loss: 30.859682060071208\n",
      "Epoch: 2751 / 5000\n",
      "w1: [24.06726474] w2: [-21.75579974] bias: [16.43621774] loss: 30.851201200461237\n",
      "Epoch: 2752 / 5000\n",
      "w1: [24.06816607] w2: [-21.75045289] bias: [16.44114319] loss: 30.850876269276664\n",
      "Epoch: 2753 / 5000\n",
      "w1: [24.07321627] w2: [-21.75042604] bias: [16.45380116] loss: 30.847741684357935\n",
      "Epoch: 2754 / 5000\n",
      "w1: [24.08333158] w2: [-21.75128572] bias: [16.46273817] loss: 30.844341218865605\n",
      "Epoch: 2755 / 5000\n",
      "w1: [24.07707136] w2: [-21.76171991] bias: [16.43587108] loss: 30.848088763594557\n",
      "Epoch: 2756 / 5000\n",
      "w1: [24.07184569] w2: [-21.76978871] bias: [16.41825674] loss: 30.85188037846595\n",
      "Epoch: 2757 / 5000\n",
      "w1: [24.08311601] w2: [-21.76153793] bias: [16.44655169] loss: 30.844942034844383\n",
      "Epoch: 2758 / 5000\n",
      "w1: [24.10110995] w2: [-21.76391195] bias: [16.46714982] loss: 30.838297931722185\n",
      "Epoch: 2759 / 5000\n",
      "w1: [24.09290388] w2: [-21.78053583] bias: [16.44066982] loss: 30.840856476959015\n",
      "Epoch: 2760 / 5000\n",
      "w1: [24.09806774] w2: [-21.76964136] bias: [16.45177044] loss: 30.839725642559383\n",
      "Epoch: 2761 / 5000\n",
      "w1: [24.11571157] w2: [-21.76514994] bias: [16.47700543] loss: 30.834678251926533\n",
      "Epoch: 2762 / 5000\n",
      "w1: [24.10480824] w2: [-21.77569784] bias: [16.44767746] loss: 30.837917344673084\n",
      "Epoch: 2763 / 5000\n",
      "w1: [24.1067308] w2: [-21.77884328] bias: [16.44972454] loss: 30.83674511852931\n",
      "Epoch: 2764 / 5000\n",
      "w1: [24.10350949] w2: [-21.77876701] bias: [16.44703401] loss: 30.837807230530917\n",
      "Epoch: 2765 / 5000\n",
      "w1: [24.11227764] w2: [-21.78337697] bias: [16.44945667] loss: 30.834918591240445\n",
      "Epoch: 2766 / 5000\n",
      "w1: [24.08507198] w2: [-21.80013638] bias: [16.40528622] loss: 30.847740098958056\n",
      "Epoch: 2767 / 5000\n",
      "w1: [24.09156524] w2: [-21.80118985] bias: [16.42183931] loss: 30.841955219127772\n",
      "Epoch: 2768 / 5000\n",
      "w1: [24.08036838] w2: [-21.79948034] bias: [16.40925869] loss: 30.84808175102387\n",
      "Epoch: 2769 / 5000\n",
      "w1: [24.08276536] w2: [-21.79957175] bias: [16.43262947] loss: 30.842073780356873\n",
      "Epoch: 2770 / 5000\n",
      "w1: [24.09211888] w2: [-21.7923127] bias: [16.45724368] loss: 30.836696019158236\n",
      "Epoch: 2771 / 5000\n",
      "w1: [24.08596854] w2: [-21.78986662] bias: [16.44662675] loss: 30.840061617360384\n",
      "Epoch: 2772 / 5000\n",
      "w1: [24.08581394] w2: [-21.79302376] bias: [16.44299774] loss: 30.840268123302298\n",
      "Epoch: 2773 / 5000\n",
      "w1: [24.09760318] w2: [-21.77817407] bias: [16.46663308] loss: 30.836644903052225\n",
      "Epoch: 2774 / 5000\n",
      "w1: [24.10168746] w2: [-21.77197614] bias: [16.47346082] loss: 30.836238034660063\n",
      "Epoch: 2775 / 5000\n",
      "w1: [24.09598969] w2: [-21.77301762] bias: [16.46681486] loss: 30.837791234022113\n",
      "Epoch: 2776 / 5000\n",
      "w1: [24.08191686] w2: [-21.78756124] bias: [16.43321745] loss: 30.84379396126159\n",
      "Epoch: 2777 / 5000\n",
      "w1: [24.07814487] w2: [-21.79004097] bias: [16.43154105] loss: 30.844718982580392\n",
      "Epoch: 2778 / 5000\n",
      "w1: [24.07042449] w2: [-21.80241206] bias: [16.41412973] loss: 30.84919603725802\n",
      "Epoch: 2779 / 5000\n",
      "w1: [24.07471161] w2: [-21.81344573] bias: [16.41017253] loss: 30.847762210768938\n",
      "Epoch: 2780 / 5000\n",
      "w1: [24.08178382] w2: [-21.80720677] bias: [16.42470382] loss: 30.843035941748347\n",
      "Epoch: 2781 / 5000\n",
      "w1: [24.08129602] w2: [-21.80392939] bias: [16.43769914] loss: 30.840818343952172\n",
      "Epoch: 2782 / 5000\n",
      "w1: [24.05455477] w2: [-21.81766915] bias: [16.39372118] loss: 30.85807863161556\n",
      "Epoch: 2783 / 5000\n",
      "w1: [24.07472318] w2: [-21.81130097] bias: [16.42160542] loss: 30.845097602702484\n",
      "Epoch: 2784 / 5000\n",
      "w1: [24.0732115] w2: [-21.81300647] bias: [16.41526769] loss: 30.84688854322507\n",
      "Epoch: 2785 / 5000\n",
      "w1: [24.08237323] w2: [-21.81349238] bias: [16.43131391] loss: 30.840611981842883\n",
      "Epoch: 2786 / 5000\n",
      "w1: [24.09298879] w2: [-21.80838661] bias: [16.44902738] loss: 30.835378839434874\n",
      "Epoch: 2787 / 5000\n",
      "w1: [24.09775854] w2: [-21.80885746] bias: [16.4603307] loss: 30.83253152931861\n",
      "Epoch: 2788 / 5000\n",
      "w1: [24.08091942] w2: [-21.81531601] bias: [16.43082317] loss: 30.840850823813366\n",
      "Epoch: 2789 / 5000\n",
      "w1: [24.07551448] w2: [-21.8291703] bias: [16.40992227] loss: 30.845831222629272\n",
      "Epoch: 2790 / 5000\n",
      "w1: [24.07653781] w2: [-21.83102662] bias: [16.40823003] loss: 30.845807322564372\n",
      "Epoch: 2791 / 5000\n",
      "w1: [24.08089478] w2: [-21.83277457] bias: [16.41513802] loss: 30.842522099683467\n",
      "Epoch: 2792 / 5000\n",
      "w1: [24.07809453] w2: [-21.83432213] bias: [16.41499985] loss: 30.843154667999723\n",
      "Epoch: 2793 / 5000\n",
      "w1: [24.0731955] w2: [-21.83892646] bias: [16.41510126] loss: 30.843977941333478\n",
      "Epoch: 2794 / 5000\n",
      "w1: [24.07512873] w2: [-21.84451459] bias: [16.41116838] loss: 30.843917128216574\n",
      "Epoch: 2795 / 5000\n",
      "w1: [24.0920336] w2: [-21.84151395] bias: [16.43918837] loss: 30.832900631972166\n",
      "Epoch: 2796 / 5000\n",
      "w1: [24.09976481] w2: [-21.84571348] bias: [16.44488031] loss: 30.829347220486284\n",
      "Epoch: 2797 / 5000\n",
      "w1: [24.10807575] w2: [-21.85076073] bias: [16.45201111] loss: 30.825444939887596\n",
      "Epoch: 2798 / 5000\n",
      "w1: [24.12938987] w2: [-21.84724086] bias: [16.48629655] loss: 30.81742985230827\n",
      "Epoch: 2799 / 5000\n",
      "w1: [24.10803273] w2: [-21.84848737] bias: [16.45932562] loss: 30.824584683912303\n",
      "Epoch: 2800 / 5000\n",
      "w1: [24.12613159] w2: [-21.8490081] bias: [16.48038173] loss: 30.81823748797459\n",
      "Epoch: 2801 / 5000\n",
      "w1: [24.12427539] w2: [-21.84906593] bias: [16.47457218] loss: 30.819166348346712\n",
      "Epoch: 2802 / 5000\n",
      "w1: [24.13418542] w2: [-21.85373348] bias: [16.48503061] loss: 30.815600049458773\n",
      "Epoch: 2803 / 5000\n",
      "w1: [24.13644169] w2: [-21.85134485] bias: [16.48553968] loss: 30.815563943398708\n",
      "Epoch: 2804 / 5000\n",
      "w1: [24.12967303] w2: [-21.86286903] bias: [16.46780513] loss: 30.816750711511936\n",
      "Epoch: 2805 / 5000\n",
      "w1: [24.12761339] w2: [-21.86776805] bias: [16.45618095] loss: 30.8180627375411\n",
      "Epoch: 2806 / 5000\n",
      "w1: [24.14582049] w2: [-21.86264014] bias: [16.48485796] loss: 30.812096025682038\n",
      "Epoch: 2807 / 5000\n",
      "w1: [24.14604987] w2: [-21.86445252] bias: [16.48485062] loss: 30.81175435101537\n",
      "Epoch: 2808 / 5000\n",
      "w1: [24.15855749] w2: [-21.86556957] bias: [16.4972156] loss: 30.808836005227846\n",
      "Epoch: 2809 / 5000\n",
      "w1: [24.14327574] w2: [-21.87641767] bias: [16.46679625] loss: 30.812114750103763\n",
      "Epoch: 2810 / 5000\n",
      "w1: [24.13892079] w2: [-21.87833024] bias: [16.45968437] loss: 30.81363613101738\n",
      "Epoch: 2811 / 5000\n",
      "w1: [24.16975057] w2: [-21.87324842] bias: [16.49581118] loss: 30.80582280208855\n",
      "Epoch: 2812 / 5000\n",
      "w1: [24.1711447] w2: [-21.86989515] bias: [16.50285762] loss: 30.80605645673911\n",
      "Epoch: 2813 / 5000\n",
      "w1: [24.16914248] w2: [-21.86627436] bias: [16.50262132] loss: 30.807007138525176\n",
      "Epoch: 2814 / 5000\n",
      "w1: [24.15884892] w2: [-21.85721148] bias: [16.50671038] loss: 30.81007432097308\n",
      "Epoch: 2815 / 5000\n",
      "w1: [24.14834481] w2: [-21.86958959] bias: [16.49023717] loss: 30.81012870302433\n",
      "Epoch: 2816 / 5000\n",
      "w1: [24.17692202] w2: [-21.86165371] bias: [16.52794847] loss: 30.807309132950113\n",
      "Epoch: 2817 / 5000\n",
      "w1: [24.17724125] w2: [-21.87653432] bias: [16.51181482] loss: 30.803949979326674\n",
      "Epoch: 2818 / 5000\n",
      "w1: [24.17547719] w2: [-21.88265516] bias: [16.51232511] loss: 30.803033702794405\n",
      "Epoch: 2819 / 5000\n",
      "w1: [24.19282616] w2: [-21.87807483] bias: [16.53214754] loss: 30.80252476879052\n",
      "Epoch: 2820 / 5000\n",
      "w1: [24.20589663] w2: [-21.88483465] bias: [16.5341149] loss: 30.800001811508345\n",
      "Epoch: 2821 / 5000\n",
      "w1: [24.20763434] w2: [-21.88500691] bias: [16.53157424] loss: 30.79961830265757\n",
      "Epoch: 2822 / 5000\n",
      "w1: [24.21539092] w2: [-21.89032822] bias: [16.54344969] loss: 30.798840867213936\n",
      "Epoch: 2823 / 5000\n",
      "w1: [24.21681922] w2: [-21.88960852] bias: [16.54196508] loss: 30.798734819892612\n",
      "Epoch: 2824 / 5000\n",
      "w1: [24.19971722] w2: [-21.8880054] bias: [16.51940742] loss: 30.799173503484162\n",
      "Epoch: 2825 / 5000\n",
      "w1: [24.19316943] w2: [-21.89434979] bias: [16.50381669] loss: 30.79852590832971\n",
      "Epoch: 2826 / 5000\n",
      "w1: [24.1887223] w2: [-21.89282386] bias: [16.50144045] loss: 30.79943386750735\n",
      "Epoch: 2827 / 5000\n",
      "w1: [24.18704027] w2: [-21.88522032] bias: [16.50224852] loss: 30.801043817989278\n",
      "Epoch: 2828 / 5000\n",
      "w1: [24.18265341] w2: [-21.8749684] bias: [16.51670575] loss: 30.803633488871185\n",
      "Epoch: 2829 / 5000\n",
      "w1: [24.18298786] w2: [-21.87955571] bias: [16.52539693] loss: 30.80294897555772\n",
      "Epoch: 2830 / 5000\n",
      "w1: [24.19108702] w2: [-21.87766096] bias: [16.5376709] loss: 30.80314441324861\n",
      "Epoch: 2831 / 5000\n",
      "w1: [24.20032335] w2: [-21.86734484] bias: [16.5591978] loss: 30.806797924260053\n",
      "Epoch: 2832 / 5000\n",
      "w1: [24.21062397] w2: [-21.87131623] bias: [16.56387468] loss: 30.8059214668304\n",
      "Epoch: 2833 / 5000\n",
      "w1: [24.22215114] w2: [-21.88243356] bias: [16.56014166] loss: 30.80218451767202\n",
      "Epoch: 2834 / 5000\n",
      "w1: [24.21949951] w2: [-21.88696173] bias: [16.5548215] loss: 30.800588064013816\n",
      "Epoch: 2835 / 5000\n",
      "w1: [24.22400477] w2: [-21.88950097] bias: [16.55776522] loss: 30.800134085086\n",
      "Epoch: 2836 / 5000\n",
      "w1: [24.22319657] w2: [-21.89087516] bias: [16.5544723] loss: 30.799433218026838\n",
      "Epoch: 2837 / 5000\n",
      "w1: [24.23164066] w2: [-21.89464111] bias: [16.56452114] loss: 30.799543615918655\n",
      "Epoch: 2838 / 5000\n",
      "w1: [24.23266101] w2: [-21.90928807] bias: [16.55415199] loss: 30.794699096177247\n",
      "Epoch: 2839 / 5000\n",
      "w1: [24.25576236] w2: [-21.91062526] bias: [16.57631092] loss: 30.79693573366014\n",
      "Epoch: 2840 / 5000\n",
      "w1: [24.23081629] w2: [-21.92053] bias: [16.54053957] loss: 30.790912788811255\n",
      "Epoch: 2841 / 5000\n",
      "w1: [24.23127422] w2: [-21.9118805] bias: [16.55756284] loss: 30.794652876474693\n",
      "Epoch: 2842 / 5000\n",
      "w1: [24.23101119] w2: [-21.9112274] bias: [16.55201416] loss: 30.79411330070061\n",
      "Epoch: 2843 / 5000\n",
      "w1: [24.23155041] w2: [-21.91926714] bias: [16.55729463] loss: 30.79296618966201\n",
      "Epoch: 2844 / 5000\n",
      "w1: [24.21923658] w2: [-21.92784467] bias: [16.53016141] loss: 30.789716395447037\n",
      "Epoch: 2845 / 5000\n",
      "w1: [24.2213954] w2: [-21.93223253] bias: [16.53815686] loss: 30.78912785426158\n",
      "Epoch: 2846 / 5000\n",
      "w1: [24.22328814] w2: [-21.93803552] bias: [16.53551956] loss: 30.78760460843524\n",
      "Epoch: 2847 / 5000\n",
      "w1: [24.22323316] w2: [-21.93349274] bias: [16.53226084] loss: 30.788315850009255\n",
      "Epoch: 2848 / 5000\n",
      "w1: [24.21460359] w2: [-21.93461847] bias: [16.51065096] loss: 30.788349315278012\n",
      "Epoch: 2849 / 5000\n",
      "w1: [24.21449853] w2: [-21.92262452] bias: [16.52116559] loss: 30.79083810424151\n",
      "Epoch: 2850 / 5000\n",
      "w1: [24.21752563] w2: [-21.92256735] bias: [16.51744451] loss: 30.790385378033154\n",
      "Epoch: 2851 / 5000\n",
      "w1: [24.21824331] w2: [-21.92499489] bias: [16.51670038] loss: 30.789817454742284\n",
      "Epoch: 2852 / 5000\n",
      "w1: [24.22483848] w2: [-21.92824503] bias: [16.51593397] loss: 30.78842289999423\n",
      "Epoch: 2853 / 5000\n",
      "w1: [24.22662949] w2: [-21.93327915] bias: [16.51501097] loss: 30.787232638604046\n",
      "Epoch: 2854 / 5000\n",
      "w1: [24.23370248] w2: [-21.93500219] bias: [16.51893344] loss: 30.786263221928483\n",
      "Epoch: 2855 / 5000\n",
      "w1: [24.24598505] w2: [-21.93691344] bias: [16.53256173] loss: 30.78555508305814\n",
      "Epoch: 2856 / 5000\n",
      "w1: [24.25313474] w2: [-21.94301848] bias: [16.52565513] loss: 30.783154547348136\n",
      "Epoch: 2857 / 5000\n",
      "w1: [24.24388878] w2: [-21.93537744] bias: [16.52331406] loss: 30.785388863055903\n",
      "Epoch: 2858 / 5000\n",
      "w1: [24.26029004] w2: [-21.93958173] bias: [16.54469332] loss: 30.78513672232818\n",
      "Epoch: 2859 / 5000\n",
      "w1: [24.27020385] w2: [-21.94319176] bias: [16.55396795] loss: 30.785001208896595\n",
      "Epoch: 2860 / 5000\n",
      "w1: [24.27932197] w2: [-21.95004066] bias: [16.56953657] loss: 30.785625590797395\n",
      "Epoch: 2861 / 5000\n",
      "w1: [24.27946182] w2: [-21.9461933] bias: [16.57065652] loss: 30.78672926993416\n",
      "Epoch: 2862 / 5000\n",
      "w1: [24.27568883] w2: [-21.94350231] bias: [16.56372394] loss: 30.786237163767158\n",
      "Epoch: 2863 / 5000\n",
      "w1: [24.27373285] w2: [-21.94796094] bias: [16.56126263] loss: 30.784885857053062\n",
      "Epoch: 2864 / 5000\n",
      "w1: [24.29483868] w2: [-21.94032097] bias: [16.59724915] loss: 30.793976187376167\n",
      "Epoch: 2865 / 5000\n",
      "w1: [24.29564455] w2: [-21.94998091] bias: [16.58917374] loss: 30.789516388153512\n",
      "Epoch: 2866 / 5000\n",
      "w1: [24.30669316] w2: [-21.95744375] bias: [16.58639248] loss: 30.786980442726268\n",
      "Epoch: 2867 / 5000\n",
      "w1: [24.30494483] w2: [-21.96324725] bias: [16.57713012] loss: 30.783448578939133\n",
      "Epoch: 2868 / 5000\n",
      "w1: [24.31541737] w2: [-21.96606233] bias: [16.59456476] loss: 30.786909243313858\n",
      "Epoch: 2869 / 5000\n",
      "w1: [24.2944062] w2: [-21.9746238] bias: [16.56686991] loss: 30.778976522296993\n",
      "Epoch: 2870 / 5000\n",
      "w1: [24.33009011] w2: [-21.97560286] bias: [16.60701926] loss: 30.78820579714664\n",
      "Epoch: 2871 / 5000\n",
      "w1: [24.31454089] w2: [-22.00286124] bias: [16.56624248] loss: 30.77179251584243\n",
      "Epoch: 2872 / 5000\n",
      "w1: [24.3261561] w2: [-21.98691566] bias: [16.59183639] loss: 30.781052166980853\n",
      "Epoch: 2873 / 5000\n",
      "w1: [24.33790769] w2: [-21.98864487] bias: [16.60097847] loss: 30.783265546023483\n",
      "Epoch: 2874 / 5000\n",
      "w1: [24.34269434] w2: [-21.97376606] bias: [16.61783545] loss: 30.792587573465557\n",
      "Epoch: 2875 / 5000\n",
      "w1: [24.33673616] w2: [-21.97623211] bias: [16.60601604] loss: 30.787949416272532\n",
      "Epoch: 2876 / 5000\n",
      "w1: [24.34511056] w2: [-21.98323971] bias: [16.61155976] loss: 30.7880974732496\n",
      "Epoch: 2877 / 5000\n",
      "w1: [24.33015675] w2: [-21.99871122] bias: [16.58175207] loss: 30.77571299888441\n",
      "Epoch: 2878 / 5000\n",
      "w1: [24.34617112] w2: [-21.97867519] bias: [16.62017996] loss: 30.792198742277975\n",
      "Epoch: 2879 / 5000\n",
      "w1: [24.3346544] w2: [-21.98711081] bias: [16.59497671] loss: 30.781933134106\n",
      "Epoch: 2880 / 5000\n",
      "w1: [24.31709546] w2: [-22.00482614] bias: [16.55573864] loss: 30.76946372562345\n",
      "Epoch: 2881 / 5000\n",
      "w1: [24.31657379] w2: [-22.00199889] bias: [16.5578952] loss: 30.77046642894057\n",
      "Epoch: 2882 / 5000\n",
      "w1: [24.31642455] w2: [-22.00104075] bias: [16.55392755] loss: 30.770036887651894\n",
      "Epoch: 2883 / 5000\n",
      "w1: [24.31767267] w2: [-21.99646747] bias: [16.56547017] loss: 30.773024233960655\n",
      "Epoch: 2884 / 5000\n",
      "w1: [24.29040679] w2: [-22.0134158] bias: [16.51595536] loss: 30.76535842260363\n",
      "Epoch: 2885 / 5000\n",
      "w1: [24.28796417] w2: [-22.01840894] bias: [16.51162066] loss: 30.764501590289598\n",
      "Epoch: 2886 / 5000\n",
      "w1: [24.27886915] w2: [-22.0244749] bias: [16.49702843] loss: 30.764297550532895\n",
      "Epoch: 2887 / 5000\n",
      "w1: [24.30030764] w2: [-22.01824597] bias: [16.53525976] loss: 30.764955308612507\n",
      "Epoch: 2888 / 5000\n",
      "w1: [24.30933134] w2: [-22.0212782] bias: [16.55067566] loss: 30.765514329594545\n",
      "Epoch: 2889 / 5000\n",
      "w1: [24.29382485] w2: [-22.02968204] bias: [16.52483254] loss: 30.762450087516346\n",
      "Epoch: 2890 / 5000\n",
      "w1: [24.28937988] w2: [-22.03689365] bias: [16.51627562] loss: 30.761144766334485\n",
      "Epoch: 2891 / 5000\n",
      "w1: [24.30581495] w2: [-22.03372782] bias: [16.53654237] loss: 30.761573054365677\n",
      "Epoch: 2892 / 5000\n",
      "w1: [24.28093417] w2: [-22.04454215] bias: [16.49908993] loss: 30.760629687631827\n",
      "Epoch: 2893 / 5000\n",
      "w1: [24.27480133] w2: [-22.04694645] bias: [16.49720572] loss: 30.76108925647766\n",
      "Epoch: 2894 / 5000\n",
      "w1: [24.27976349] w2: [-22.0393808] bias: [16.50633903] loss: 30.76161461525657\n",
      "Epoch: 2895 / 5000\n",
      "w1: [24.27542921] w2: [-22.03411148] bias: [16.5094068] loss: 30.763068505206384\n",
      "Epoch: 2896 / 5000\n",
      "w1: [24.27445166] w2: [-22.04071007] bias: [16.49861819] loss: 30.76213090860496\n",
      "Epoch: 2897 / 5000\n",
      "w1: [24.26863433] w2: [-22.04622021] bias: [16.48559718] loss: 30.762555619323038\n",
      "Epoch: 2898 / 5000\n",
      "w1: [24.26272849] w2: [-22.05140359] bias: [16.4733669] loss: 30.76360160113483\n",
      "Epoch: 2899 / 5000\n",
      "w1: [24.24626891] w2: [-22.06021299] bias: [16.44098008] loss: 30.76988302524827\n",
      "Epoch: 2900 / 5000\n",
      "w1: [24.23882354] w2: [-22.05849319] bias: [16.42891425] loss: 30.774046115399216\n",
      "Epoch: 2901 / 5000\n",
      "w1: [24.23399831] w2: [-22.05836677] bias: [16.41774522] loss: 30.777668797147587\n",
      "Epoch: 2902 / 5000\n",
      "w1: [24.23507189] w2: [-22.05001056] bias: [16.42131824] loss: 30.77745947012419\n",
      "Epoch: 2903 / 5000\n",
      "w1: [24.23667285] w2: [-22.04696519] bias: [16.42674975] loss: 30.776253092590398\n",
      "Epoch: 2904 / 5000\n",
      "w1: [24.23025089] w2: [-22.05698554] bias: [16.41300755] loss: 30.779877965412748\n",
      "Epoch: 2905 / 5000\n",
      "w1: [24.24241756] w2: [-22.05794473] bias: [16.43070643] loss: 30.772916686792623\n",
      "Epoch: 2906 / 5000\n",
      "w1: [24.25010301] w2: [-22.05703371] bias: [16.43987254] loss: 30.7696278706082\n",
      "Epoch: 2907 / 5000\n",
      "w1: [24.23875909] w2: [-22.06264056] bias: [16.42318557] loss: 30.774839727652672\n",
      "Epoch: 2908 / 5000\n",
      "w1: [24.24906535] w2: [-22.05915431] bias: [16.44397113] loss: 30.76890305420511\n",
      "Epoch: 2909 / 5000\n",
      "w1: [24.23311097] w2: [-22.06933083] bias: [16.41595921] loss: 30.777234088848733\n",
      "Epoch: 2910 / 5000\n",
      "w1: [24.2225875] w2: [-22.07594753] bias: [16.39655985] loss: 30.78471473837947\n",
      "Epoch: 2911 / 5000\n",
      "w1: [24.2333832] w2: [-22.06969962] bias: [16.42102402] loss: 30.77591759867677\n",
      "Epoch: 2912 / 5000\n",
      "w1: [24.21003961] w2: [-22.08766049] bias: [16.38023893] loss: 30.7928603091778\n",
      "Epoch: 2913 / 5000\n",
      "w1: [24.21908015] w2: [-22.09528338] bias: [16.37657441] loss: 30.790882736044388\n",
      "Epoch: 2914 / 5000\n",
      "w1: [24.2178817] w2: [-22.10193399] bias: [16.37947032] loss: 30.789816568144964\n",
      "Epoch: 2915 / 5000\n",
      "w1: [24.23123856] w2: [-22.09193399] bias: [16.40531072] loss: 30.778482877106644\n",
      "Epoch: 2916 / 5000\n",
      "w1: [24.24888036] w2: [-22.09300378] bias: [16.43113674] loss: 30.76756211450474\n",
      "Epoch: 2917 / 5000\n",
      "w1: [24.25527981] w2: [-22.08685974] bias: [16.43967328] loss: 30.76508581833263\n",
      "Epoch: 2918 / 5000\n",
      "w1: [24.2591052] w2: [-22.09054766] bias: [16.43847088] loss: 30.764053887683094\n",
      "Epoch: 2919 / 5000\n",
      "w1: [24.26386179] w2: [-22.0831825] bias: [16.45500964] loss: 30.761226249242977\n",
      "Epoch: 2920 / 5000\n",
      "w1: [24.25210682] w2: [-22.09346242] bias: [16.42575324] loss: 30.76791577600145\n",
      "Epoch: 2921 / 5000\n",
      "w1: [24.24903172] w2: [-22.09276981] bias: [16.41837871] loss: 30.77041377330025\n",
      "Epoch: 2922 / 5000\n",
      "w1: [24.24196944] w2: [-22.0880439] bias: [16.41121419] loss: 30.77440502676698\n",
      "Epoch: 2923 / 5000\n",
      "w1: [24.23078289] w2: [-22.1005576] bias: [16.38367881] loss: 30.78457051575749\n",
      "Epoch: 2924 / 5000\n",
      "w1: [24.21460007] w2: [-22.1097364] bias: [16.35679198] loss: 30.79906724972073\n",
      "Epoch: 2925 / 5000\n",
      "w1: [24.23199137] w2: [-22.12208358] bias: [16.36852203] loss: 30.78820558818526\n",
      "Epoch: 2926 / 5000\n",
      "w1: [24.24189201] w2: [-22.11958147] bias: [16.40565696] loss: 30.773229817165955\n",
      "Epoch: 2927 / 5000\n",
      "w1: [24.24106149] w2: [-22.12407303] bias: [16.40760943] loss: 30.772538691992594\n",
      "Epoch: 2928 / 5000\n",
      "w1: [24.26529116] w2: [-22.1291322] bias: [16.42969999] loss: 30.760356108172772\n",
      "Epoch: 2929 / 5000\n",
      "w1: [24.2617538] w2: [-22.13930906] bias: [16.4133775] loss: 30.764224110490083\n",
      "Epoch: 2930 / 5000\n",
      "w1: [24.29670252] w2: [-22.14100801] bias: [16.46173034] loss: 30.746790759248196\n",
      "Epoch: 2931 / 5000\n",
      "w1: [24.29343985] w2: [-22.14209342] bias: [16.45391762] loss: 30.748379625415378\n",
      "Epoch: 2932 / 5000\n",
      "w1: [24.30143968] w2: [-22.14280143] bias: [16.457895] loss: 30.746182180512413\n",
      "Epoch: 2933 / 5000\n",
      "w1: [24.3026368] w2: [-22.13748286] bias: [16.45839634] loss: 30.746546644664267\n",
      "Epoch: 2934 / 5000\n",
      "w1: [24.3037185] w2: [-22.14360704] bias: [16.45831209] loss: 30.745598432141904\n",
      "Epoch: 2935 / 5000\n",
      "w1: [24.30729888] w2: [-22.14879582] bias: [16.45871377] loss: 30.74423803440544\n",
      "Epoch: 2936 / 5000\n",
      "w1: [24.31254167] w2: [-22.14545124] bias: [16.47946722] loss: 30.741583471990047\n",
      "Epoch: 2937 / 5000\n",
      "w1: [24.33149995] w2: [-22.13817831] bias: [16.50578133] loss: 30.738890483973872\n",
      "Epoch: 2938 / 5000\n",
      "w1: [24.30983279] w2: [-22.14808565] bias: [16.47903456] loss: 30.741699517270455\n",
      "Epoch: 2939 / 5000\n",
      "w1: [24.31653445] w2: [-22.15261803] bias: [16.48787846] loss: 30.739349630604654\n",
      "Epoch: 2940 / 5000\n",
      "w1: [24.29926305] w2: [-22.15063341] bias: [16.47358847] loss: 30.743692120853993\n",
      "Epoch: 2941 / 5000\n",
      "w1: [24.27845765] w2: [-22.15484666] bias: [16.450946] loss: 30.75050758752416\n",
      "Epoch: 2942 / 5000\n",
      "w1: [24.26895625] w2: [-22.15193915] bias: [16.43705351] loss: 30.755659198763023\n",
      "Epoch: 2943 / 5000\n",
      "w1: [24.27409784] w2: [-22.14722921] bias: [16.44446591] loss: 30.75346713558095\n",
      "Epoch: 2944 / 5000\n",
      "w1: [24.28761105] w2: [-22.14651057] bias: [16.4564228] loss: 30.748643526813336\n",
      "Epoch: 2945 / 5000\n",
      "w1: [24.30068679] w2: [-22.14849157] bias: [16.48438853] loss: 30.74268671010327\n",
      "Epoch: 2946 / 5000\n",
      "w1: [24.30890378] w2: [-22.13930605] bias: [16.49917387] loss: 30.741819571443052\n",
      "Epoch: 2947 / 5000\n",
      "w1: [24.32310417] w2: [-22.13512352] bias: [16.51598345] loss: 30.74040545507057\n",
      "Epoch: 2948 / 5000\n",
      "w1: [24.32608413] w2: [-22.14399363] bias: [16.51145846] loss: 30.738590762165494\n",
      "Epoch: 2949 / 5000\n",
      "w1: [24.31324172] w2: [-22.15047523] bias: [16.48991404] loss: 30.74002647670301\n",
      "Epoch: 2950 / 5000\n",
      "w1: [24.31574579] w2: [-22.14535566] bias: [16.49802084] loss: 30.739998243034055\n",
      "Epoch: 2951 / 5000\n",
      "w1: [24.3335184] w2: [-22.13101902] bias: [16.53714846] loss: 30.740880914127228\n",
      "Epoch: 2952 / 5000\n",
      "w1: [24.34882007] w2: [-22.12580142] bias: [16.55898388] loss: 30.742953157572764\n",
      "Epoch: 2953 / 5000\n",
      "w1: [24.35318529] w2: [-22.12327067] bias: [16.56046669] loss: 30.743447317710896\n",
      "Epoch: 2954 / 5000\n",
      "w1: [24.34722014] w2: [-22.12796157] bias: [16.55087806] loss: 30.741653792596882\n",
      "Epoch: 2955 / 5000\n",
      "w1: [24.34963765] w2: [-22.1346413] bias: [16.54328762] loss: 30.739446030237826\n",
      "Epoch: 2956 / 5000\n",
      "w1: [24.35299722] w2: [-22.1331297] bias: [16.55111506] loss: 30.740321591274608\n",
      "Epoch: 2957 / 5000\n",
      "w1: [24.35076967] w2: [-22.14159269] bias: [16.5362758] loss: 30.737476918047072\n",
      "Epoch: 2958 / 5000\n",
      "w1: [24.35191041] w2: [-22.14437405] bias: [16.53720596] loss: 30.736947467508806\n",
      "Epoch: 2959 / 5000\n",
      "w1: [24.33888652] w2: [-22.14810114] bias: [16.51835905] loss: 30.736546483346945\n",
      "Epoch: 2960 / 5000\n",
      "w1: [24.33591986] w2: [-22.15778805] bias: [16.50308102] loss: 30.735272997467497\n",
      "Epoch: 2961 / 5000\n",
      "w1: [24.35850788] w2: [-22.14067226] bias: [16.54562621] loss: 30.737930411340123\n",
      "Epoch: 2962 / 5000\n",
      "w1: [24.34767116] w2: [-22.12319914] bias: [16.54634079] loss: 30.742068533992903\n",
      "Epoch: 2963 / 5000\n",
      "w1: [24.34072665] w2: [-22.11557394] bias: [16.5417395] loss: 30.743558579612785\n",
      "Epoch: 2964 / 5000\n",
      "w1: [24.36266992] w2: [-22.10883371] bias: [16.57418837] loss: 30.748363991599\n",
      "Epoch: 2965 / 5000\n",
      "w1: [24.37347756] w2: [-22.10956727] bias: [16.58760671] loss: 30.750774664059964\n",
      "Epoch: 2966 / 5000\n",
      "w1: [24.38452025] w2: [-22.10032021] bias: [16.60486345] loss: 30.757347321248538\n",
      "Epoch: 2967 / 5000\n",
      "w1: [24.38742857] w2: [-22.09982249] bias: [16.60300809] loss: 30.757034026249766\n",
      "Epoch: 2968 / 5000\n",
      "w1: [24.38757099] w2: [-22.10057277] bias: [16.61230802] loss: 30.759469857268403\n",
      "Epoch: 2969 / 5000\n",
      "w1: [24.4138268] w2: [-22.10321708] bias: [16.64079348] loss: 30.769698526835832\n",
      "Epoch: 2970 / 5000\n",
      "w1: [24.41162461] w2: [-22.10263541] bias: [16.63675215] loss: 30.768202800181925\n",
      "Epoch: 2971 / 5000\n",
      "w1: [24.3944137] w2: [-22.10779887] bias: [16.60674963] loss: 30.75629671536398\n",
      "Epoch: 2972 / 5000\n",
      "w1: [24.38851906] w2: [-22.10388086] bias: [16.60177718] loss: 30.75573496697137\n",
      "Epoch: 2973 / 5000\n",
      "w1: [24.37356992] w2: [-22.10689696] bias: [16.57864489] loss: 30.74947146890167\n",
      "Epoch: 2974 / 5000\n",
      "w1: [24.37539488] w2: [-22.1107384] bias: [16.57703327] loss: 30.748261863533827\n",
      "Epoch: 2975 / 5000\n",
      "w1: [24.354185] w2: [-22.13067209] bias: [16.53463772] loss: 30.739105968838572\n",
      "Epoch: 2976 / 5000\n",
      "w1: [24.37171557] w2: [-22.13269166] bias: [16.55992426] loss: 30.740641821354526\n",
      "Epoch: 2977 / 5000\n",
      "w1: [24.37565838] w2: [-22.13693281] bias: [16.55539677] loss: 30.73894956871118\n",
      "Epoch: 2978 / 5000\n",
      "w1: [24.37601507] w2: [-22.1479377] bias: [16.54474739] loss: 30.7353735661079\n",
      "Epoch: 2979 / 5000\n",
      "w1: [24.36217541] w2: [-22.15937806] bias: [16.51362078] loss: 30.732113417177192\n",
      "Epoch: 2980 / 5000\n",
      "w1: [24.37593448] w2: [-22.1698556] bias: [16.51926459] loss: 30.729244322593853\n",
      "Epoch: 2981 / 5000\n",
      "w1: [24.37105207] w2: [-22.17246656] bias: [16.50852271] loss: 30.728884951701488\n",
      "Epoch: 2982 / 5000\n",
      "w1: [24.38027294] w2: [-22.16023751] bias: [16.52791572] loss: 30.731151974676653\n",
      "Epoch: 2983 / 5000\n",
      "w1: [24.37315197] w2: [-22.16864272] bias: [16.5101593] loss: 30.72934731812517\n",
      "Epoch: 2984 / 5000\n",
      "w1: [24.36626685] w2: [-22.17250836] bias: [16.50320098] loss: 30.729320360219376\n",
      "Epoch: 2985 / 5000\n",
      "w1: [24.3680926] w2: [-22.1684516] bias: [16.50829744] loss: 30.72985170859003\n",
      "Epoch: 2986 / 5000\n",
      "w1: [24.38373694] w2: [-22.16621371] bias: [16.52987964] loss: 30.72996209084466\n",
      "Epoch: 2987 / 5000\n",
      "w1: [24.38559674] w2: [-22.17269768] bias: [16.52293365] loss: 30.728135520251882\n",
      "Epoch: 2988 / 5000\n",
      "w1: [24.37786318] w2: [-22.17368514] bias: [16.52884495] loss: 30.72898286925479\n",
      "Epoch: 2989 / 5000\n",
      "w1: [24.38560207] w2: [-22.15601859] bias: [16.55224003] loss: 30.734227126451277\n",
      "Epoch: 2990 / 5000\n",
      "w1: [24.40668218] w2: [-22.15696955] bias: [16.57191581] loss: 30.73666085015484\n",
      "Epoch: 2991 / 5000\n",
      "w1: [24.4303785] w2: [-22.15936139] bias: [16.61234206] loss: 30.746465778968954\n",
      "Epoch: 2992 / 5000\n",
      "w1: [24.41247211] w2: [-22.17478154] bias: [16.5764071] loss: 30.733620223977063\n",
      "Epoch: 2993 / 5000\n",
      "w1: [24.41509361] w2: [-22.18078172] bias: [16.5741208] loss: 30.73184545724053\n",
      "Epoch: 2994 / 5000\n",
      "w1: [24.41252996] w2: [-22.18048142] bias: [16.57132468] loss: 30.731415014308464\n",
      "Epoch: 2995 / 5000\n",
      "w1: [24.40392513] w2: [-22.18547564] bias: [16.55204209] loss: 30.72754614771076\n",
      "Epoch: 2996 / 5000\n",
      "w1: [24.41015219] w2: [-22.17123109] bias: [16.56769131] loss: 30.732748747102377\n",
      "Epoch: 2997 / 5000\n",
      "w1: [24.40334153] w2: [-22.1821132] bias: [16.54511917] loss: 30.727331100397162\n",
      "Epoch: 2998 / 5000\n",
      "w1: [24.39624417] w2: [-22.17693623] bias: [16.54302549] loss: 30.72845115401611\n",
      "Epoch: 2999 / 5000\n",
      "w1: [24.40813327] w2: [-22.17544938] bias: [16.55426744] loss: 30.72969623786484\n",
      "Epoch: 3000 / 5000\n",
      "w1: [24.41071009] w2: [-22.18423049] bias: [16.54588167] loss: 30.7266629582517\n",
      "Epoch: 3001 / 5000\n",
      "w1: [24.40586869] w2: [-22.1912291] bias: [16.53518396] loss: 30.724347601824586\n",
      "Epoch: 3002 / 5000\n",
      "w1: [24.36742999] w2: [-22.21296243] bias: [16.47401483] loss: 30.724242199577986\n",
      "Epoch: 3003 / 5000\n",
      "w1: [24.36477651] w2: [-22.2298525] bias: [16.44717672] loss: 30.72554151284723\n",
      "Epoch: 3004 / 5000\n",
      "w1: [24.35973758] w2: [-22.23391629] bias: [16.4393431] loss: 30.7272840319104\n",
      "Epoch: 3005 / 5000\n",
      "w1: [24.38253205] w2: [-22.22287197] bias: [16.47813341] loss: 30.72039058939297\n",
      "Epoch: 3006 / 5000\n",
      "w1: [24.38482667] w2: [-22.22637613] bias: [16.46983425] loss: 30.720120456080906\n",
      "Epoch: 3007 / 5000\n",
      "w1: [24.37214051] w2: [-22.23819232] bias: [16.4415867] loss: 30.724042555925006\n",
      "Epoch: 3008 / 5000\n",
      "w1: [24.40898799] w2: [-22.21370681] bias: [16.50332567] loss: 30.71816105651273\n",
      "Epoch: 3009 / 5000\n",
      "w1: [24.43052588] w2: [-22.21762996] bias: [16.53819861] loss: 30.71834891920133\n",
      "Epoch: 3010 / 5000\n",
      "w1: [24.44760903] w2: [-22.20865981] bias: [16.57022998] loss: 30.724793799993897\n",
      "Epoch: 3011 / 5000\n",
      "w1: [24.45313018] w2: [-22.21656619] bias: [16.56775097] loss: 30.72257179768692\n",
      "Epoch: 3012 / 5000\n",
      "w1: [24.45866042] w2: [-22.22006153] bias: [16.57158594] loss: 30.722590101371505\n",
      "Epoch: 3013 / 5000\n",
      "w1: [24.45799528] w2: [-22.22738035] bias: [16.55970464] loss: 30.718716382255778\n",
      "Epoch: 3014 / 5000\n",
      "w1: [24.46445366] w2: [-22.22511248] bias: [16.57861251] loss: 30.723057118328953\n",
      "Epoch: 3015 / 5000\n",
      "w1: [24.4431628] w2: [-22.23682978] bias: [16.53695115] loss: 30.71397296007402\n",
      "Epoch: 3016 / 5000\n",
      "w1: [24.43772953] w2: [-22.24366525] bias: [16.52127868] loss: 30.71159258552489\n",
      "Epoch: 3017 / 5000\n",
      "w1: [24.42133034] w2: [-22.25686507] bias: [16.48941935] loss: 30.710100145581762\n",
      "Epoch: 3018 / 5000\n",
      "w1: [24.43115242] w2: [-22.26462307] bias: [16.4903098] loss: 30.707810017005013\n",
      "Epoch: 3019 / 5000\n",
      "w1: [24.41544397] w2: [-22.26550778] bias: [16.4683596] loss: 30.710558506397216\n",
      "Epoch: 3020 / 5000\n",
      "w1: [24.40995615] w2: [-22.25616047] bias: [16.46525863] loss: 30.712794101641823\n",
      "Epoch: 3021 / 5000\n",
      "w1: [24.4027441] w2: [-22.26757591] bias: [16.44744555] loss: 30.71436713086108\n",
      "Epoch: 3022 / 5000\n",
      "w1: [24.39582981] w2: [-22.27179477] bias: [16.43246665] loss: 30.717367287751223\n",
      "Epoch: 3023 / 5000\n",
      "w1: [24.39458875] w2: [-22.26799609] bias: [16.43006205] loss: 30.718390372354207\n",
      "Epoch: 3024 / 5000\n",
      "w1: [24.39430393] w2: [-22.27412752] bias: [16.42452308] loss: 30.718824688113678\n",
      "Epoch: 3025 / 5000\n",
      "w1: [24.38783023] w2: [-22.27321814] bias: [16.42035502] loss: 30.721067456652882\n",
      "Epoch: 3026 / 5000\n",
      "w1: [24.392171] w2: [-22.27902286] bias: [16.43584418] loss: 30.716815985975522\n",
      "Epoch: 3027 / 5000\n",
      "w1: [24.39148461] w2: [-22.28326931] bias: [16.43006683] loss: 30.717540222948898\n",
      "Epoch: 3028 / 5000\n",
      "w1: [24.40728772] w2: [-22.28714324] bias: [16.45696278] loss: 30.710244938580413\n",
      "Epoch: 3029 / 5000\n",
      "w1: [24.42107052] w2: [-22.29110285] bias: [16.46615292] loss: 30.706662966263966\n",
      "Epoch: 3030 / 5000\n",
      "w1: [24.42820183] w2: [-22.28696774] bias: [16.47344623] loss: 30.705633190636988\n",
      "Epoch: 3031 / 5000\n",
      "w1: [24.42744629] w2: [-22.29198281] bias: [16.46452279] loss: 30.705714794033714\n",
      "Epoch: 3032 / 5000\n",
      "w1: [24.42455649] w2: [-22.29844475] bias: [16.45433909] loss: 30.70634600458645\n",
      "Epoch: 3033 / 5000\n",
      "w1: [24.4395633] w2: [-22.29871415] bias: [16.47031564] loss: 30.702704901770772\n",
      "Epoch: 3034 / 5000\n",
      "w1: [24.442421] w2: [-22.27980054] bias: [16.49734293] loss: 30.704330140476678\n",
      "Epoch: 3035 / 5000\n",
      "w1: [24.41946323] w2: [-22.29972345] bias: [16.44912968] loss: 30.707663359160613\n",
      "Epoch: 3036 / 5000\n",
      "w1: [24.43714166] w2: [-22.29751603] bias: [16.47935652] loss: 30.702735209558348\n",
      "Epoch: 3037 / 5000\n",
      "w1: [24.45704232] w2: [-22.28949342] bias: [16.50998362] loss: 30.701777032582676\n",
      "Epoch: 3038 / 5000\n",
      "w1: [24.44025592] w2: [-22.29504786] bias: [16.4803074] loss: 30.702624625048227\n",
      "Epoch: 3039 / 5000\n",
      "w1: [24.43864372] w2: [-22.29786373] bias: [16.48517291] loss: 30.702287228028172\n",
      "Epoch: 3040 / 5000\n",
      "w1: [24.42498206] w2: [-22.31641512] bias: [16.4512954] loss: 30.704622607023808\n",
      "Epoch: 3041 / 5000\n",
      "w1: [24.40769161] w2: [-22.31774473] bias: [16.42707189] loss: 30.7115828707186\n",
      "Epoch: 3042 / 5000\n",
      "w1: [24.3921067] w2: [-22.332176] bias: [16.39609537] loss: 30.72134270921708\n",
      "Epoch: 3043 / 5000\n",
      "w1: [24.4072683] w2: [-22.32847211] bias: [16.41892197] loss: 30.712410606310105\n",
      "Epoch: 3044 / 5000\n",
      "w1: [24.3988867] w2: [-22.31614576] bias: [16.41084934] loss: 30.717060194920645\n",
      "Epoch: 3045 / 5000\n",
      "w1: [24.39412458] w2: [-22.31778655] bias: [16.40297934] loss: 30.71996561597098\n",
      "Epoch: 3046 / 5000\n",
      "w1: [24.40187672] w2: [-22.32124789] bias: [16.4093808] loss: 30.716322538682956\n",
      "Epoch: 3047 / 5000\n",
      "w1: [24.41862896] w2: [-22.32525275] bias: [16.42521035] loss: 30.708994950064877\n",
      "Epoch: 3048 / 5000\n",
      "w1: [24.40199686] w2: [-22.3387559] bias: [16.39165399] loss: 30.7196558720622\n",
      "Epoch: 3049 / 5000\n",
      "w1: [24.40703783] w2: [-22.32727388] bias: [16.40572669] loss: 30.715536116070428\n",
      "Epoch: 3050 / 5000\n",
      "w1: [24.42270806] w2: [-22.3244693] bias: [16.43066137] loss: 30.707264123943396\n",
      "Epoch: 3051 / 5000\n",
      "w1: [24.42377911] w2: [-22.32074939] bias: [16.43894564] loss: 30.706080200945873\n",
      "Epoch: 3052 / 5000\n",
      "w1: [24.42866939] w2: [-22.3288559] bias: [16.44144734] loss: 30.703988725299354\n",
      "Epoch: 3053 / 5000\n",
      "w1: [24.43355147] w2: [-22.3219715] bias: [16.45242081] loss: 30.702416911129216\n",
      "Epoch: 3054 / 5000\n",
      "w1: [24.43377981] w2: [-22.32045624] bias: [16.45332107] loss: 30.702443629991816\n",
      "Epoch: 3055 / 5000\n",
      "w1: [24.44959908] w2: [-22.30870871] bias: [16.47896117] loss: 30.699637325464792\n",
      "Epoch: 3056 / 5000\n",
      "w1: [24.48378296] w2: [-22.31059884] bias: [16.52055656] loss: 30.696960859321916\n",
      "Epoch: 3057 / 5000\n",
      "w1: [24.46568055] w2: [-22.31320987] bias: [16.49215441] loss: 30.696905937844175\n",
      "Epoch: 3058 / 5000\n",
      "w1: [24.46026358] w2: [-22.33077454] bias: [16.46584731] loss: 30.696033801094597\n",
      "Epoch: 3059 / 5000\n",
      "w1: [24.46266749] w2: [-22.32596995] bias: [16.46812384] loss: 30.696160914295042\n",
      "Epoch: 3060 / 5000\n",
      "w1: [24.45181047] w2: [-22.33006021] bias: [16.44911481] loss: 30.69885164005508\n",
      "Epoch: 3061 / 5000\n",
      "w1: [24.44978835] w2: [-22.3382789] bias: [16.43459359] loss: 30.700155786650285\n",
      "Epoch: 3062 / 5000\n",
      "w1: [24.44358846] w2: [-22.35097197] bias: [16.41146514] loss: 30.70425507307301\n",
      "Epoch: 3063 / 5000\n",
      "w1: [24.44808926] w2: [-22.35460338] bias: [16.4076452] loss: 30.703785583123388\n",
      "Epoch: 3064 / 5000\n",
      "w1: [24.45319422] w2: [-22.35835925] bias: [16.40810236] loss: 30.70229662426824\n",
      "Epoch: 3065 / 5000\n",
      "w1: [24.44811529] w2: [-22.36002438] bias: [16.39749033] loss: 30.705614095325455\n",
      "Epoch: 3066 / 5000\n",
      "w1: [24.44693582] w2: [-22.35244061] bias: [16.40234969] loss: 30.70533755772274\n",
      "Epoch: 3067 / 5000\n",
      "w1: [24.45299074] w2: [-22.34820981] bias: [16.42590682] loss: 30.69993331493466\n",
      "Epoch: 3068 / 5000\n",
      "w1: [24.46397074] w2: [-22.36000201] bias: [16.42300179] loss: 30.69721399246708\n",
      "Epoch: 3069 / 5000\n",
      "w1: [24.44332865] w2: [-22.3773614] bias: [16.38329399] loss: 30.709266593639143\n",
      "Epoch: 3070 / 5000\n",
      "w1: [24.46380988] w2: [-22.37040227] bias: [16.41641803] loss: 30.69748594709011\n",
      "Epoch: 3071 / 5000\n",
      "w1: [24.44080333] w2: [-22.37981528] bias: [16.38192467] loss: 30.710151954321123\n",
      "Epoch: 3072 / 5000\n",
      "w1: [24.45386682] w2: [-22.37001985] bias: [16.40335269] loss: 30.70227073130709\n",
      "Epoch: 3073 / 5000\n",
      "w1: [24.44591452] w2: [-22.37131134] bias: [16.39097683] loss: 30.706956780555377\n",
      "Epoch: 3074 / 5000\n",
      "w1: [24.45312772] w2: [-22.3627425] bias: [16.40508052] loss: 30.702602621684182\n",
      "Epoch: 3075 / 5000\n",
      "w1: [24.45217155] w2: [-22.36181759] bias: [16.40247722] loss: 30.70344567065553\n",
      "Epoch: 3076 / 5000\n",
      "w1: [24.4632222] w2: [-22.36425031] bias: [16.41118403] loss: 30.69910123111509\n",
      "Epoch: 3077 / 5000\n",
      "w1: [24.48957496] w2: [-22.35061682] bias: [16.45038718] loss: 30.69052878439463\n",
      "Epoch: 3078 / 5000\n",
      "w1: [24.46958805] w2: [-22.35665911] bias: [16.42068294] loss: 30.69681954274699\n",
      "Epoch: 3079 / 5000\n",
      "w1: [24.49194361] w2: [-22.34213366] bias: [16.4554916] loss: 30.690858729920297\n",
      "Epoch: 3080 / 5000\n",
      "w1: [24.5009599] w2: [-22.3495746] bias: [16.46993115] loss: 30.688134708260307\n",
      "Epoch: 3081 / 5000\n",
      "w1: [24.50591112] w2: [-22.34200702] bias: [16.48684135] loss: 30.688581656105093\n",
      "Epoch: 3082 / 5000\n",
      "w1: [24.50675436] w2: [-22.33787065] bias: [16.49295005] loss: 30.68927192632364\n",
      "Epoch: 3083 / 5000\n",
      "w1: [24.4791141] w2: [-22.35342613] bias: [16.44373749] loss: 30.692418473780855\n",
      "Epoch: 3084 / 5000\n",
      "w1: [24.45995808] w2: [-22.35533615] bias: [16.4156941] loss: 30.699679239191827\n",
      "Epoch: 3085 / 5000\n",
      "w1: [24.47352706] w2: [-22.35759849] bias: [16.42641277] loss: 30.69511324993438\n",
      "Epoch: 3086 / 5000\n",
      "w1: [24.46804034] w2: [-22.36067301] bias: [16.41362126] loss: 30.697969437329355\n",
      "Epoch: 3087 / 5000\n",
      "w1: [24.46275838] w2: [-22.36359104] bias: [16.41158853] loss: 30.699173965780012\n",
      "Epoch: 3088 / 5000\n",
      "w1: [24.45997224] w2: [-22.3644922] bias: [16.40746144] loss: 30.700496647395525\n",
      "Epoch: 3089 / 5000\n",
      "w1: [24.48468531] w2: [-22.35813622] bias: [16.44472347] loss: 30.69091706506164\n",
      "Epoch: 3090 / 5000\n",
      "w1: [24.50041609] w2: [-22.34704772] bias: [16.46902726] loss: 30.688557319930176\n",
      "Epoch: 3091 / 5000\n",
      "w1: [24.49903162] w2: [-22.36303946] bias: [16.44457517] loss: 30.68817395884839\n",
      "Epoch: 3092 / 5000\n",
      "w1: [24.50024499] w2: [-22.35944693] bias: [16.46648242] loss: 30.687054698221527\n",
      "Epoch: 3093 / 5000\n",
      "w1: [24.50203864] w2: [-22.36736017] bias: [16.4630756] loss: 30.68598238083321\n",
      "Epoch: 3094 / 5000\n",
      "w1: [24.54503544] w2: [-22.35530257] bias: [16.52357443] loss: 30.68638859049108\n",
      "Epoch: 3095 / 5000\n",
      "w1: [24.55207081] w2: [-22.36901189] bias: [16.51941981] loss: 30.683224970476065\n",
      "Epoch: 3096 / 5000\n",
      "w1: [24.53339524] w2: [-22.38020907] bias: [16.48308067] loss: 30.68039970087538\n",
      "Epoch: 3097 / 5000\n",
      "w1: [24.55296859] w2: [-22.38411259] bias: [16.50378789] loss: 30.679203500257437\n",
      "Epoch: 3098 / 5000\n",
      "w1: [24.54890643] w2: [-22.38322666] bias: [16.50047369] loss: 30.679379219622785\n",
      "Epoch: 3099 / 5000\n",
      "w1: [24.53820074] w2: [-22.3921345] bias: [16.48635896] loss: 30.678321229918456\n",
      "Epoch: 3100 / 5000\n",
      "w1: [24.53406933] w2: [-22.39717705] bias: [16.47894237] loss: 30.67796396110941\n",
      "Epoch: 3101 / 5000\n",
      "w1: [24.54212621] w2: [-22.4038692] bias: [16.48821746] loss: 30.676342362629338\n",
      "Epoch: 3102 / 5000\n",
      "w1: [24.5362136] w2: [-22.4084653] bias: [16.48045102] loss: 30.67622526916499\n",
      "Epoch: 3103 / 5000\n",
      "w1: [24.53750412] w2: [-22.40845984] bias: [16.48609585] loss: 30.676111092461046\n",
      "Epoch: 3104 / 5000\n",
      "w1: [24.54968157] w2: [-22.38814255] bias: [16.52370251] loss: 30.680562526078567\n",
      "Epoch: 3105 / 5000\n",
      "w1: [24.52602641] w2: [-22.40025041] bias: [16.48015674] loss: 30.678401094116815\n",
      "Epoch: 3106 / 5000\n",
      "w1: [24.52494557] w2: [-22.39500374] bias: [16.48112433] loss: 30.679207631670298\n",
      "Epoch: 3107 / 5000\n",
      "w1: [24.55316826] w2: [-22.38151124] bias: [16.52389226] loss: 30.681556941080114\n",
      "Epoch: 3108 / 5000\n",
      "w1: [24.55529574] w2: [-22.38463197] bias: [16.52068112] loss: 30.680567736826273\n",
      "Epoch: 3109 / 5000\n",
      "w1: [24.55149218] w2: [-22.39083964] bias: [16.52195363] loss: 30.679837872130634\n",
      "Epoch: 3110 / 5000\n",
      "w1: [24.55926021] w2: [-22.38380934] bias: [16.53931216] loss: 30.683040243815118\n",
      "Epoch: 3111 / 5000\n",
      "w1: [24.57973591] w2: [-22.3736642] bias: [16.56529142] loss: 30.689977345136235\n",
      "Epoch: 3112 / 5000\n",
      "w1: [24.56545857] w2: [-22.38294543] bias: [16.53717309] loss: 30.68273151368366\n",
      "Epoch: 3113 / 5000\n",
      "w1: [24.56117216] w2: [-22.38767162] bias: [16.52482181] loss: 30.680293339346186\n",
      "Epoch: 3114 / 5000\n",
      "w1: [24.56336192] w2: [-22.38827028] bias: [16.52652796] loss: 30.680325904869708\n",
      "Epoch: 3115 / 5000\n",
      "w1: [24.55651749] w2: [-22.40211764] bias: [16.49588327] loss: 30.675680459811808\n",
      "Epoch: 3116 / 5000\n",
      "w1: [24.54435208] w2: [-22.41104331] bias: [16.47419416] loss: 30.675064187387733\n",
      "Epoch: 3117 / 5000\n",
      "w1: [24.54356319] w2: [-22.41731408] bias: [16.46550013] loss: 30.67452878647211\n",
      "Epoch: 3118 / 5000\n",
      "w1: [24.52788835] w2: [-22.42799658] bias: [16.43397698] loss: 30.677885986439875\n",
      "Epoch: 3119 / 5000\n",
      "w1: [24.52853547] w2: [-22.42797811] bias: [16.42849589] loss: 30.678449647432824\n",
      "Epoch: 3120 / 5000\n",
      "w1: [24.51504852] w2: [-22.44221197] bias: [16.39864667] loss: 30.684876185081794\n",
      "Epoch: 3121 / 5000\n",
      "w1: [24.51296813] w2: [-22.44139854] bias: [16.4093885] loss: 30.683219384929746\n",
      "Epoch: 3122 / 5000\n",
      "w1: [24.50620574] w2: [-22.43861713] bias: [16.40389456] loss: 30.685902040794634\n",
      "Epoch: 3123 / 5000\n",
      "w1: [24.50916816] w2: [-22.44398249] bias: [16.40076451] loss: 30.68555704193286\n",
      "Epoch: 3124 / 5000\n",
      "w1: [24.50952636] w2: [-22.44263561] bias: [16.40107424] loss: 30.68550760938486\n",
      "Epoch: 3125 / 5000\n",
      "w1: [24.4927861] w2: [-22.44941839] bias: [16.37507139] loss: 30.695433071254897\n",
      "Epoch: 3126 / 5000\n",
      "w1: [24.49023627] w2: [-22.45631778] bias: [16.35978069] loss: 30.70044979475957\n",
      "Epoch: 3127 / 5000\n",
      "w1: [24.49145479] w2: [-22.46101829] bias: [16.3582863] loss: 30.70044245950661\n",
      "Epoch: 3128 / 5000\n",
      "w1: [24.50400139] w2: [-22.46439261] bias: [16.37319509] loss: 30.69246578270487\n",
      "Epoch: 3129 / 5000\n",
      "w1: [24.50658826] w2: [-22.45367132] bias: [16.39109598] loss: 30.68769834930615\n",
      "Epoch: 3130 / 5000\n",
      "w1: [24.48803186] w2: [-22.46812226] bias: [16.35391775] loss: 30.702635508543164\n",
      "Epoch: 3131 / 5000\n",
      "w1: [24.48551148] w2: [-22.4701811] bias: [16.34844547] loss: 30.705218605835412\n",
      "Epoch: 3132 / 5000\n",
      "w1: [24.47839465] w2: [-22.4763791] bias: [16.33703855] loss: 30.711501512777904\n",
      "Epoch: 3133 / 5000\n",
      "w1: [24.47496993] w2: [-22.46953427] bias: [16.3400577] loss: 30.711471060941456\n",
      "Epoch: 3134 / 5000\n",
      "w1: [24.49001565] w2: [-22.45659179] bias: [16.36285559] loss: 30.699518876026833\n",
      "Epoch: 3135 / 5000\n",
      "w1: [24.48489632] w2: [-22.4623056] bias: [16.34762476] loss: 30.705877346143666\n",
      "Epoch: 3136 / 5000\n",
      "w1: [24.48802892] w2: [-22.45911194] bias: [16.3504051] loss: 30.70409512817331\n",
      "Epoch: 3137 / 5000\n",
      "w1: [24.4841727] w2: [-22.46741168] bias: [16.34029471] loss: 30.708650224356603\n",
      "Epoch: 3138 / 5000\n",
      "w1: [24.48118244] w2: [-22.46388953] bias: [16.33386792] loss: 30.71205672408968\n",
      "Epoch: 3139 / 5000\n",
      "w1: [24.49657721] w2: [-22.46475347] bias: [16.34461544] loss: 30.703530192795608\n",
      "Epoch: 3140 / 5000\n",
      "w1: [24.50296971] w2: [-22.46575443] bias: [16.34634834] loss: 30.7010983177724\n",
      "Epoch: 3141 / 5000\n",
      "w1: [24.50474225] w2: [-22.47197747] bias: [16.34502101] loss: 30.700887211838907\n",
      "Epoch: 3142 / 5000\n",
      "w1: [24.49687867] w2: [-22.47195079] bias: [16.33898066] loss: 30.705296512271307\n",
      "Epoch: 3143 / 5000\n",
      "w1: [24.50747412] w2: [-22.4777205] bias: [16.35356665] loss: 30.69708343212613\n",
      "Epoch: 3144 / 5000\n",
      "w1: [24.51493174] w2: [-22.46787598] bias: [16.36906298] loss: 30.690750651874133\n",
      "Epoch: 3145 / 5000\n",
      "w1: [24.51446273] w2: [-22.4679391] bias: [16.37919834] loss: 30.688080350753523\n",
      "Epoch: 3146 / 5000\n",
      "w1: [24.52156265] w2: [-22.45976815] bias: [16.39668767] loss: 30.682726045600692\n",
      "Epoch: 3147 / 5000\n",
      "w1: [24.52978863] w2: [-22.46247532] bias: [16.39938036] loss: 30.680237280986624\n",
      "Epoch: 3148 / 5000\n",
      "w1: [24.55517775] w2: [-22.453905] bias: [16.43633585] loss: 30.670761888971086\n",
      "Epoch: 3149 / 5000\n",
      "w1: [24.55788392] w2: [-22.45785421] bias: [16.44877035] loss: 30.668879798985223\n",
      "Epoch: 3150 / 5000\n",
      "w1: [24.54547108] w2: [-22.45920438] bias: [16.43725257] loss: 30.67165255691086\n",
      "Epoch: 3151 / 5000\n",
      "w1: [24.53538999] w2: [-22.47052596] bias: [16.4124794] loss: 30.6760254392264\n",
      "Epoch: 3152 / 5000\n",
      "w1: [24.54554241] w2: [-22.47733278] bias: [16.41746157] loss: 30.672733858546987\n",
      "Epoch: 3153 / 5000\n",
      "w1: [24.54811774] w2: [-22.47168347] bias: [16.42256684] loss: 30.67195496001988\n",
      "Epoch: 3154 / 5000\n",
      "w1: [24.53278086] w2: [-22.47623869] bias: [16.3945983] loss: 30.67971585127017\n",
      "Epoch: 3155 / 5000\n",
      "w1: [24.53577705] w2: [-22.4819635] bias: [16.38669777] loss: 30.680514103642423\n",
      "Epoch: 3156 / 5000\n",
      "w1: [24.57039667] w2: [-22.48119233] bias: [16.42737114] loss: 30.666735163325363\n",
      "Epoch: 3157 / 5000\n",
      "w1: [24.56404787] w2: [-22.47690238] bias: [16.42333927] loss: 30.668662820183048\n",
      "Epoch: 3158 / 5000\n",
      "w1: [24.57440947] w2: [-22.4737837] bias: [16.43406888] loss: 30.666105692307195\n",
      "Epoch: 3159 / 5000\n",
      "w1: [24.58142261] w2: [-22.4788024] bias: [16.44565312] loss: 30.663644519456355\n",
      "Epoch: 3160 / 5000\n",
      "w1: [24.58599277] w2: [-22.48855863] bias: [16.43560014] loss: 30.66279503519352\n",
      "Epoch: 3161 / 5000\n",
      "w1: [24.58299014] w2: [-22.49556] bias: [16.42088495] loss: 30.664192291555732\n",
      "Epoch: 3162 / 5000\n",
      "w1: [24.58224199] w2: [-22.50507177] bias: [16.40787038] loss: 30.66539204666138\n",
      "Epoch: 3163 / 5000\n",
      "w1: [24.58704536] w2: [-22.50745854] bias: [16.40921289] loss: 30.664136896753014\n",
      "Epoch: 3164 / 5000\n",
      "w1: [24.58063112] w2: [-22.50365583] bias: [16.39876428] loss: 30.66733057521192\n",
      "Epoch: 3165 / 5000\n",
      "w1: [24.58913263] w2: [-22.49830086] bias: [16.41452556] loss: 30.663765053651712\n",
      "Epoch: 3166 / 5000\n",
      "w1: [24.57802622] w2: [-22.51289196] bias: [16.38882172] loss: 30.66913508371888\n",
      "Epoch: 3167 / 5000\n",
      "w1: [24.59136394] w2: [-22.51238198] bias: [16.40049622] loss: 30.664379067621855\n",
      "Epoch: 3168 / 5000\n",
      "w1: [24.60475051] w2: [-22.49861557] bias: [16.43564684] loss: 30.659135392429686\n",
      "Epoch: 3169 / 5000\n",
      "w1: [24.59177027] w2: [-22.51226253] bias: [16.40868754] loss: 30.663003200090586\n",
      "Epoch: 3170 / 5000\n",
      "w1: [24.58974047] w2: [-22.51530673] bias: [16.41796819] loss: 30.661767712620154\n",
      "Epoch: 3171 / 5000\n",
      "w1: [24.57523819] w2: [-22.5260422] bias: [16.39250291] loss: 30.66813352825732\n",
      "Epoch: 3172 / 5000\n",
      "w1: [24.58470779] w2: [-22.52904244] bias: [16.39897726] loss: 30.664750184099294\n",
      "Epoch: 3173 / 5000\n",
      "w1: [24.58092249] w2: [-22.52349185] bias: [16.39971208] loss: 30.665722170687218\n",
      "Epoch: 3174 / 5000\n",
      "w1: [24.57298924] w2: [-22.52801971] bias: [16.38285838] loss: 30.670630399494446\n",
      "Epoch: 3175 / 5000\n",
      "w1: [24.55498888] w2: [-22.53856964] bias: [16.35999652] loss: 30.680573414820856\n",
      "Epoch: 3176 / 5000\n",
      "w1: [24.54715403] w2: [-22.54752231] bias: [16.34039024] loss: 30.688936550530546\n",
      "Epoch: 3177 / 5000\n",
      "w1: [24.5593188] w2: [-22.55024418] bias: [16.34982149] loss: 30.682314410260744\n",
      "Epoch: 3178 / 5000\n",
      "w1: [24.57189111] w2: [-22.55255159] bias: [16.37311426] loss: 30.672154163877064\n",
      "Epoch: 3179 / 5000\n",
      "w1: [24.56924182] w2: [-22.5544901] bias: [16.36449323] loss: 30.675122031663427\n",
      "Epoch: 3180 / 5000\n",
      "w1: [24.56082063] w2: [-22.55407766] bias: [16.3589418] loss: 30.678922811254257\n",
      "Epoch: 3181 / 5000\n",
      "w1: [24.56411678] w2: [-22.55224018] bias: [16.37569967] loss: 30.67331536246425\n",
      "Epoch: 3182 / 5000\n",
      "w1: [24.55966376] w2: [-22.56075622] bias: [16.36553684] loss: 30.67700864903931\n",
      "Epoch: 3183 / 5000\n",
      "w1: [24.56296187] w2: [-22.55295842] bias: [16.37768532] loss: 30.673025258833047\n",
      "Epoch: 3184 / 5000\n",
      "w1: [24.54940367] w2: [-22.56360124] bias: [16.35093662] loss: 30.68434854135574\n",
      "Epoch: 3185 / 5000\n",
      "w1: [24.56729511] w2: [-22.55992263] bias: [16.37686033] loss: 30.67193602608444\n",
      "Epoch: 3186 / 5000\n",
      "w1: [24.5605941] w2: [-22.56997055] bias: [16.36592858] loss: 30.67637623056963\n",
      "Epoch: 3187 / 5000\n",
      "w1: [24.58167963] w2: [-22.57374717] bias: [16.38069255] loss: 30.667003547555808\n",
      "Epoch: 3188 / 5000\n",
      "w1: [24.57620432] w2: [-22.55938898] bias: [16.38374736] loss: 30.668125283838926\n",
      "Epoch: 3189 / 5000\n",
      "w1: [24.58658602] w2: [-22.56084397] bias: [16.39135714] loss: 30.664011335539982\n",
      "Epoch: 3190 / 5000\n",
      "w1: [24.5840443] w2: [-22.56216876] bias: [16.38013186] loss: 30.667125206486997\n",
      "Epoch: 3191 / 5000\n",
      "w1: [24.56247582] w2: [-22.56914118] bias: [16.34045299] loss: 30.684265345680057\n",
      "Epoch: 3192 / 5000\n",
      "w1: [24.58055248] w2: [-22.56084545] bias: [16.38620691] loss: 30.666493167300533\n",
      "Epoch: 3193 / 5000\n",
      "w1: [24.57644841] w2: [-22.56459536] bias: [16.37401754] loss: 30.670347111480535\n",
      "Epoch: 3194 / 5000\n",
      "w1: [24.57495394] w2: [-22.55576758] bias: [16.39103348] loss: 30.666842990124078\n",
      "Epoch: 3195 / 5000\n",
      "w1: [24.57170297] w2: [-22.55982913] bias: [16.38329551] loss: 30.669236301302394\n",
      "Epoch: 3196 / 5000\n",
      "w1: [24.59467663] w2: [-22.55643907] bias: [16.41050393] loss: 30.658920197246513\n",
      "Epoch: 3197 / 5000\n",
      "w1: [24.58519874] w2: [-22.54854742] bias: [16.4044267] loss: 30.662345502966296\n",
      "Epoch: 3198 / 5000\n",
      "w1: [24.5795137] w2: [-22.55508702] bias: [16.38696081] loss: 30.66683202081691\n",
      "Epoch: 3199 / 5000\n",
      "w1: [24.58352006] w2: [-22.56172285] bias: [16.3826861] loss: 30.666638805274093\n",
      "Epoch: 3200 / 5000\n",
      "w1: [24.59052288] w2: [-22.56339141] bias: [16.38748485] loss: 30.663905519911914\n",
      "Epoch: 3201 / 5000\n",
      "w1: [24.60396384] w2: [-22.55539621] bias: [16.41395693] loss: 30.656754829117677\n",
      "Epoch: 3202 / 5000\n",
      "w1: [24.60166255] w2: [-22.56408283] bias: [16.40352286] loss: 30.658332752533102\n",
      "Epoch: 3203 / 5000\n",
      "w1: [24.59948868] w2: [-22.56945906] bias: [16.40226137] loss: 30.658645927889097\n",
      "Epoch: 3204 / 5000\n",
      "w1: [24.59313819] w2: [-22.57172672] bias: [16.39394414] loss: 30.661481810647164\n",
      "Epoch: 3205 / 5000\n",
      "w1: [24.59840759] w2: [-22.5746987] bias: [16.40454952] loss: 30.65809489942659\n",
      "Epoch: 3206 / 5000\n",
      "w1: [24.58184047] w2: [-22.57661899] bias: [16.38029896] loss: 30.666945466065968\n",
      "Epoch: 3207 / 5000\n",
      "w1: [24.58086154] w2: [-22.57786038] bias: [16.36841821] loss: 30.670341884326113\n",
      "Epoch: 3208 / 5000\n",
      "w1: [24.59044935] w2: [-22.58238499] bias: [16.38172948] loss: 30.66437698183954\n",
      "Epoch: 3209 / 5000\n",
      "w1: [24.58577096] w2: [-22.57514081] bias: [16.38469055] loss: 30.665020311687595\n",
      "Epoch: 3210 / 5000\n",
      "w1: [24.58248584] w2: [-22.57866607] bias: [16.37444434] loss: 30.668257038786166\n",
      "Epoch: 3211 / 5000\n",
      "w1: [24.58038026] w2: [-22.58286211] bias: [16.36621678] loss: 30.67092729069485\n",
      "Epoch: 3212 / 5000\n",
      "w1: [24.57993784] w2: [-22.57499155] bias: [16.36977387] loss: 30.670284543439333\n",
      "Epoch: 3213 / 5000\n",
      "w1: [24.59220288] w2: [-22.57643762] bias: [16.38401557] loss: 30.663699425642644\n",
      "Epoch: 3214 / 5000\n",
      "w1: [24.60748636] w2: [-22.56837768] bias: [16.41767291] loss: 30.654610479909387\n",
      "Epoch: 3215 / 5000\n",
      "w1: [24.61449138] w2: [-22.56858969] bias: [16.43407169] loss: 30.651300521980076\n",
      "Epoch: 3216 / 5000\n",
      "w1: [24.62863894] w2: [-22.56678808] bias: [16.45614362] loss: 30.647746500782528\n",
      "Epoch: 3217 / 5000\n",
      "w1: [24.64557702] w2: [-22.56002154] bias: [16.47927233] loss: 30.646377937258933\n",
      "Epoch: 3218 / 5000\n",
      "w1: [24.64043026] w2: [-22.56241577] bias: [16.46761161] loss: 30.646548650555776\n",
      "Epoch: 3219 / 5000\n",
      "w1: [24.62740586] w2: [-22.56885692] bias: [16.44366706] loss: 30.6485083834472\n",
      "Epoch: 3220 / 5000\n",
      "w1: [24.62169465] w2: [-22.57863014] bias: [16.42377564] loss: 30.650583530227532\n",
      "Epoch: 3221 / 5000\n",
      "w1: [24.6306315] w2: [-22.577838] bias: [16.43937213] loss: 30.64758854286455\n",
      "Epoch: 3222 / 5000\n",
      "w1: [24.61690329] w2: [-22.59407222] bias: [16.40603468] loss: 30.65307789885163\n",
      "Epoch: 3223 / 5000\n",
      "w1: [24.60347928] w2: [-22.60034768] bias: [16.37722844] loss: 30.66181173729613\n",
      "Epoch: 3224 / 5000\n",
      "w1: [24.60334654] w2: [-22.60043555] bias: [16.37228827] loss: 30.66312578012798\n",
      "Epoch: 3225 / 5000\n",
      "w1: [24.60801511] w2: [-22.6031193] bias: [16.37940273] loss: 30.660129083436424\n",
      "Epoch: 3226 / 5000\n",
      "w1: [24.61248354] w2: [-22.60592438] bias: [16.38890627] loss: 30.656778676602677\n",
      "Epoch: 3227 / 5000\n",
      "w1: [24.6332965] w2: [-22.61182053] bias: [16.40676684] loss: 30.648795676516215\n",
      "Epoch: 3228 / 5000\n",
      "w1: [24.6259636] w2: [-22.61427109] bias: [16.39181056] loss: 30.652934206715763\n",
      "Epoch: 3229 / 5000\n",
      "w1: [24.61373777] w2: [-22.62909935] bias: [16.360172] loss: 30.663141768263593\n",
      "Epoch: 3230 / 5000\n",
      "w1: [24.59003948] w2: [-22.6390642] bias: [16.32396192] loss: 30.682139952708336\n",
      "Epoch: 3231 / 5000\n",
      "w1: [24.5887434] w2: [-22.63727893] bias: [16.31960728] loss: 30.684279994121084\n",
      "Epoch: 3232 / 5000\n",
      "w1: [24.60443957] w2: [-22.63387135] bias: [16.33717054] loss: 30.672991537974298\n",
      "Epoch: 3233 / 5000\n",
      "w1: [24.60044959] w2: [-22.64335978] bias: [16.32232504] loss: 30.679689596269792\n",
      "Epoch: 3234 / 5000\n",
      "w1: [24.59916648] w2: [-22.64144696] bias: [16.32392607] loss: 30.679434204940577\n",
      "Epoch: 3235 / 5000\n",
      "w1: [24.59865153] w2: [-22.64145764] bias: [16.31888162] loss: 30.681589572659213\n",
      "Epoch: 3236 / 5000\n",
      "w1: [24.60479014] w2: [-22.63918608] bias: [16.32537659] loss: 30.677213844000295\n",
      "Epoch: 3237 / 5000\n",
      "w1: [24.61370078] w2: [-22.62962681] bias: [16.34415604] loss: 30.668143815898034\n",
      "Epoch: 3238 / 5000\n",
      "w1: [24.62447363] w2: [-22.62113833] bias: [16.36405359] loss: 30.659682784919095\n",
      "Epoch: 3239 / 5000\n",
      "w1: [24.62651179] w2: [-22.61745441] bias: [16.36776225] loss: 30.658349753657458\n",
      "Epoch: 3240 / 5000\n",
      "w1: [24.60323138] w2: [-22.62455598] bias: [16.33799205] loss: 30.673119361939015\n",
      "Epoch: 3241 / 5000\n",
      "w1: [24.62840434] w2: [-22.59307731] bias: [16.40135248] loss: 30.651830660773765\n",
      "Epoch: 3242 / 5000\n",
      "w1: [24.61921232] w2: [-22.59909306] bias: [16.38031161] loss: 30.657639500041213\n",
      "Epoch: 3243 / 5000\n",
      "w1: [24.63458715] w2: [-22.58757482] bias: [16.41620758] loss: 30.648797382946142\n",
      "Epoch: 3244 / 5000\n",
      "w1: [24.62285014] w2: [-22.59232547] bias: [16.39686642] loss: 30.65375412454186\n",
      "Epoch: 3245 / 5000\n",
      "w1: [24.60017938] w2: [-22.58442276] bias: [16.39031152] loss: 30.66013173545846\n",
      "Epoch: 3246 / 5000\n",
      "w1: [24.61312957] w2: [-22.54929794] bias: [16.44858942] loss: 30.651949580983338\n",
      "Epoch: 3247 / 5000\n",
      "w1: [24.60203503] w2: [-22.54617164] bias: [16.45122966] loss: 30.653551037645865\n",
      "Epoch: 3248 / 5000\n",
      "w1: [24.61244267] w2: [-22.54356318] bias: [16.4910069] loss: 30.651478262953468\n",
      "Epoch: 3249 / 5000\n",
      "w1: [24.61130026] w2: [-22.54967422] bias: [16.47871913] loss: 30.65083345877526\n",
      "Epoch: 3250 / 5000\n",
      "w1: [24.61260432] w2: [-22.55163778] bias: [16.48172612] loss: 30.650439149714817\n",
      "Epoch: 3251 / 5000\n",
      "w1: [24.5980634] w2: [-22.55690377] bias: [16.45557101] loss: 30.652706326542827\n",
      "Epoch: 3252 / 5000\n",
      "w1: [24.59308373] w2: [-22.55480192] bias: [16.44616704] loss: 30.65445550255121\n",
      "Epoch: 3253 / 5000\n",
      "w1: [24.58509339] w2: [-22.56656034] bias: [16.43021966] loss: 30.656750404564736\n",
      "Epoch: 3254 / 5000\n",
      "w1: [24.59646622] w2: [-22.56506126] bias: [16.44298869] loss: 30.653370583967565\n",
      "Epoch: 3255 / 5000\n",
      "w1: [24.57497607] w2: [-22.57080472] bias: [16.41122816] loss: 30.66165082686266\n",
      "Epoch: 3256 / 5000\n",
      "w1: [24.58107716] w2: [-22.57264093] bias: [16.41167786] loss: 30.66024109420318\n",
      "Epoch: 3257 / 5000\n",
      "w1: [24.59424283] w2: [-22.56228664] bias: [16.4418793] loss: 30.65407611196267\n",
      "Epoch: 3258 / 5000\n",
      "w1: [24.60515208] w2: [-22.55476345] bias: [16.46136494] loss: 30.651597630530624\n",
      "Epoch: 3259 / 5000\n",
      "w1: [24.61622167] w2: [-22.55255058] bias: [16.47645836] loss: 30.65002622989869\n",
      "Epoch: 3260 / 5000\n",
      "w1: [24.61960788] w2: [-22.56172375] bias: [16.4724199] loss: 30.648704462254692\n",
      "Epoch: 3261 / 5000\n",
      "w1: [24.63361461] w2: [-22.56216679] bias: [16.4841898] loss: 30.647216301658407\n",
      "Epoch: 3262 / 5000\n",
      "w1: [24.63814756] w2: [-22.57054697] bias: [16.47888944] loss: 30.64575506565378\n",
      "Epoch: 3263 / 5000\n",
      "w1: [24.64226929] w2: [-22.57673698] bias: [16.47028186] loss: 30.644691811776582\n",
      "Epoch: 3264 / 5000\n",
      "w1: [24.6413487] w2: [-22.5781612] bias: [16.45969916] loss: 30.64491039120188\n",
      "Epoch: 3265 / 5000\n",
      "w1: [24.65416281] w2: [-22.57555175] bias: [16.47495852] loss: 30.643685870478098\n",
      "Epoch: 3266 / 5000\n",
      "w1: [24.66700986] w2: [-22.57432239] bias: [16.49068682] loss: 30.643338236805324\n",
      "Epoch: 3267 / 5000\n",
      "w1: [24.67812666] w2: [-22.58326625] bias: [16.49576192] loss: 30.641775665381292\n",
      "Epoch: 3268 / 5000\n",
      "w1: [24.67547317] w2: [-22.58805751] bias: [16.478489] loss: 30.64046450223552\n",
      "Epoch: 3269 / 5000\n",
      "w1: [24.65320261] w2: [-22.60038974] bias: [16.43763867] loss: 30.642578884189312\n",
      "Epoch: 3270 / 5000\n",
      "w1: [24.66483827] w2: [-22.60066287] bias: [16.46490607] loss: 30.639831291652417\n",
      "Epoch: 3271 / 5000\n",
      "w1: [24.65301667] w2: [-22.60270662] bias: [16.44616036] loss: 30.64174867709996\n",
      "Epoch: 3272 / 5000\n",
      "w1: [24.64386804] w2: [-22.61493285] bias: [16.42066457] loss: 30.644622808488204\n",
      "Epoch: 3273 / 5000\n",
      "w1: [24.65248685] w2: [-22.60877776] bias: [16.4413578] loss: 30.641611219153226\n",
      "Epoch: 3274 / 5000\n",
      "w1: [24.6373548] w2: [-22.61813063] bias: [16.41512389] loss: 30.646292899855844\n",
      "Epoch: 3275 / 5000\n",
      "w1: [24.63494314] w2: [-22.61709552] bias: [16.41088231] loss: 30.64746525750625\n",
      "Epoch: 3276 / 5000\n",
      "w1: [24.63934822] w2: [-22.61722211] bias: [16.41341729] loss: 30.6462745174702\n",
      "Epoch: 3277 / 5000\n",
      "w1: [24.64995061] w2: [-22.61207169] bias: [16.42603344] loss: 30.643208513189098\n",
      "Epoch: 3278 / 5000\n",
      "w1: [24.65601571] w2: [-22.60427543] bias: [16.44015692] loss: 30.64164679347475\n",
      "Epoch: 3279 / 5000\n",
      "w1: [24.65103634] w2: [-22.61789001] bias: [16.41763066] loss: 30.64365115006267\n",
      "Epoch: 3280 / 5000\n",
      "w1: [24.65058409] w2: [-22.6072891] bias: [16.42933654] loss: 30.643134776203713\n",
      "Epoch: 3281 / 5000\n",
      "w1: [24.66461445] w2: [-22.59838394] bias: [16.46931379] loss: 30.640058274884197\n",
      "Epoch: 3282 / 5000\n",
      "w1: [24.68526569] w2: [-22.59058717] bias: [16.51154402] loss: 30.64178269105805\n",
      "Epoch: 3283 / 5000\n",
      "w1: [24.70170493] w2: [-22.57758376] bias: [16.54407668] loss: 30.648515043670148\n",
      "Epoch: 3284 / 5000\n",
      "w1: [24.70085527] w2: [-22.57328041] bias: [16.54282204] loss: 30.649013509327965\n",
      "Epoch: 3285 / 5000\n",
      "w1: [24.70201297] w2: [-22.56480191] bias: [16.55013513] loss: 30.652032578567955\n",
      "Epoch: 3286 / 5000\n",
      "w1: [24.69443169] w2: [-22.57917801] bias: [16.52511418] loss: 30.645014530655814\n",
      "Epoch: 3287 / 5000\n",
      "w1: [24.68483921] w2: [-22.57973081] bias: [16.50811683] loss: 30.643038332808356\n",
      "Epoch: 3288 / 5000\n",
      "w1: [24.71491632] w2: [-22.5697147] bias: [16.55057479] loss: 30.65153865075604\n",
      "Epoch: 3289 / 5000\n",
      "w1: [24.71523088] w2: [-22.55516019] bias: [16.55830249] loss: 30.656130955832218\n",
      "Epoch: 3290 / 5000\n",
      "w1: [24.71247324] w2: [-22.56232993] bias: [16.55962317] loss: 30.654979309383315\n",
      "Epoch: 3291 / 5000\n",
      "w1: [24.72231498] w2: [-22.55217322] bias: [16.57155198] loss: 30.660624217983948\n",
      "Epoch: 3292 / 5000\n",
      "w1: [24.72308462] w2: [-22.54308957] bias: [16.57921929] loss: 30.66483038044227\n",
      "Epoch: 3293 / 5000\n",
      "w1: [24.74108303] w2: [-22.5398775] bias: [16.59929284] loss: 30.673862979435984\n",
      "Epoch: 3294 / 5000\n",
      "w1: [24.73440979] w2: [-22.52265407] bias: [16.59979327] loss: 30.677326684544106\n",
      "Epoch: 3295 / 5000\n",
      "w1: [24.7359093] w2: [-22.52385092] bias: [16.61024037] loss: 30.68122091635437\n",
      "Epoch: 3296 / 5000\n",
      "w1: [24.74544672] w2: [-22.51885545] bias: [16.6235213] loss: 30.689136868206088\n",
      "Epoch: 3297 / 5000\n",
      "w1: [24.73931097] w2: [-22.51693365] bias: [16.61654005] loss: 30.685847512992787\n",
      "Epoch: 3298 / 5000\n",
      "w1: [24.75110365] w2: [-22.51296745] bias: [16.63844299] loss: 30.698242172136506\n",
      "Epoch: 3299 / 5000\n",
      "w1: [24.74511994] w2: [-22.51888877] bias: [16.62860369] loss: 30.69131626496398\n",
      "Epoch: 3300 / 5000\n",
      "w1: [24.75529096] w2: [-22.52174065] bias: [16.64751215] loss: 30.70097158321657\n",
      "Epoch: 3301 / 5000\n",
      "w1: [24.74837748] w2: [-22.53218827] bias: [16.62479891] loss: 30.68676762892195\n",
      "Epoch: 3302 / 5000\n",
      "w1: [24.7437393] w2: [-22.54355519] bias: [16.6204822] loss: 30.681567372519623\n",
      "Epoch: 3303 / 5000\n",
      "w1: [24.75196027] w2: [-22.54953633] bias: [16.6213856] loss: 30.681533678283706\n",
      "Epoch: 3304 / 5000\n",
      "w1: [24.77313125] w2: [-22.54271249] bias: [16.6533444] loss: 30.70131074259863\n",
      "Epoch: 3305 / 5000\n",
      "w1: [24.76823654] w2: [-22.54367125] bias: [16.64924317] loss: 30.69815488293112\n",
      "Epoch: 3306 / 5000\n",
      "w1: [24.76148806] w2: [-22.55387268] bias: [16.63200899] loss: 30.686357123120057\n",
      "Epoch: 3307 / 5000\n",
      "w1: [24.75633832] w2: [-22.55475851] bias: [16.62531583] loss: 30.682497330849085\n",
      "Epoch: 3308 / 5000\n",
      "w1: [24.75886002] w2: [-22.56767566] bias: [16.61676143] loss: 30.676146004114216\n",
      "Epoch: 3309 / 5000\n",
      "w1: [24.74368786] w2: [-22.58049492] bias: [16.58338512] loss: 30.65976527808859\n",
      "Epoch: 3310 / 5000\n",
      "w1: [24.72632427] w2: [-22.6043329] bias: [16.541796] loss: 30.643730005373772\n",
      "Epoch: 3311 / 5000\n",
      "w1: [24.73818968] w2: [-22.58640029] bias: [16.56795984] loss: 30.65366048841222\n",
      "Epoch: 3312 / 5000\n",
      "w1: [24.7508352] w2: [-22.5860279] bias: [16.59543848] loss: 30.66314540904854\n",
      "Epoch: 3313 / 5000\n",
      "w1: [24.73843941] w2: [-22.58602441] bias: [16.57655676] loss: 30.65619030006306\n",
      "Epoch: 3314 / 5000\n",
      "w1: [24.76143879] w2: [-22.58547523] bias: [16.60508204] loss: 30.66777002939205\n",
      "Epoch: 3315 / 5000\n",
      "w1: [24.74419643] w2: [-22.59350049] bias: [16.57726231] loss: 30.655256276012246\n",
      "Epoch: 3316 / 5000\n",
      "w1: [24.73883895] w2: [-22.59641035] bias: [16.55942642] loss: 30.649509133202343\n",
      "Epoch: 3317 / 5000\n",
      "w1: [24.7329457] w2: [-22.60300633] bias: [16.54415076] loss: 30.644566109862286\n",
      "Epoch: 3318 / 5000\n",
      "w1: [24.73386136] w2: [-22.61029309] bias: [16.53471462] loss: 30.641425948455225\n",
      "Epoch: 3319 / 5000\n",
      "w1: [24.74704178] w2: [-22.61604362] bias: [16.54501913] loss: 30.642784381669006\n",
      "Epoch: 3320 / 5000\n",
      "w1: [24.74977797] w2: [-22.62288018] bias: [16.53549843] loss: 30.63964915205325\n",
      "Epoch: 3321 / 5000\n",
      "w1: [24.72553727] w2: [-22.64282287] bias: [16.49146095] loss: 30.63096278431964\n",
      "Epoch: 3322 / 5000\n",
      "w1: [24.73170214] w2: [-22.64238295] bias: [16.49604198] loss: 30.63112454689362\n",
      "Epoch: 3323 / 5000\n",
      "w1: [24.74452872] w2: [-22.64902107] bias: [16.50763747] loss: 30.63101788350564\n",
      "Epoch: 3324 / 5000\n",
      "w1: [24.74157179] w2: [-22.66068413] bias: [16.48926433] loss: 30.627672746827244\n",
      "Epoch: 3325 / 5000\n",
      "w1: [24.72871057] w2: [-22.66894701] bias: [16.46103893] loss: 30.62644361561031\n",
      "Epoch: 3326 / 5000\n",
      "w1: [24.74702155] w2: [-22.66615258] bias: [16.48363443] loss: 30.62629199460004\n",
      "Epoch: 3327 / 5000\n",
      "w1: [24.74057669] w2: [-22.65406222] bias: [16.49602679] loss: 30.629173402180797\n",
      "Epoch: 3328 / 5000\n",
      "w1: [24.73519945] w2: [-22.66099567] bias: [16.48185182] loss: 30.627484046028446\n",
      "Epoch: 3329 / 5000\n",
      "w1: [24.73039218] w2: [-22.65951723] bias: [16.484832] loss: 30.628114810787586\n",
      "Epoch: 3330 / 5000\n",
      "w1: [24.73058966] w2: [-22.66470709] bias: [16.47879368] loss: 30.627168047497776\n",
      "Epoch: 3331 / 5000\n",
      "w1: [24.73420777] w2: [-22.64892218] bias: [16.49427073] loss: 30.629974229934785\n",
      "Epoch: 3332 / 5000\n",
      "w1: [24.73393302] w2: [-22.64920029] bias: [16.4904223] loss: 30.62963493869319\n",
      "Epoch: 3333 / 5000\n",
      "w1: [24.72195434] w2: [-22.65783522] bias: [16.46935282] loss: 30.62831654970201\n",
      "Epoch: 3334 / 5000\n",
      "w1: [24.72756918] w2: [-22.66102776] bias: [16.47614268] loss: 30.627710271617012\n",
      "Epoch: 3335 / 5000\n",
      "w1: [24.72001263] w2: [-22.66729502] bias: [16.46147864] loss: 30.62738919770068\n",
      "Epoch: 3336 / 5000\n",
      "w1: [24.71425638] w2: [-22.66509899] bias: [16.45226867] loss: 30.6283309908784\n",
      "Epoch: 3337 / 5000\n",
      "w1: [24.70598929] w2: [-22.67417232] bias: [16.43005094] loss: 30.629773384401137\n",
      "Epoch: 3338 / 5000\n",
      "w1: [24.70646455] w2: [-22.68152678] bias: [16.41857767] loss: 30.630293390406464\n",
      "Epoch: 3339 / 5000\n",
      "w1: [24.69882804] w2: [-22.68117873] bias: [16.40520772] loss: 30.63326835391858\n",
      "Epoch: 3340 / 5000\n",
      "w1: [24.68257624] w2: [-22.68726369] bias: [16.37392586] loss: 30.641959435273677\n",
      "Epoch: 3341 / 5000\n",
      "w1: [24.67152355] w2: [-22.68588846] bias: [16.35684435] loss: 30.648791937491566\n",
      "Epoch: 3342 / 5000\n",
      "w1: [24.67346128] w2: [-22.69169235] bias: [16.36561747] loss: 30.64583381909647\n",
      "Epoch: 3343 / 5000\n",
      "w1: [24.67456403] w2: [-22.69695897] bias: [16.36778367] loss: 30.644870237003396\n",
      "Epoch: 3344 / 5000\n",
      "w1: [24.68113187] w2: [-22.69429751] bias: [16.38306778] loss: 30.63991554091164\n",
      "Epoch: 3345 / 5000\n",
      "w1: [24.70112021] w2: [-22.68571215] bias: [16.4176641] loss: 30.630903368406255\n",
      "Epoch: 3346 / 5000\n",
      "w1: [24.69571745] w2: [-22.68911528] bias: [16.40676984] loss: 30.633058744810665\n",
      "Epoch: 3347 / 5000\n",
      "w1: [24.69818319] w2: [-22.70048296] bias: [16.41172165] loss: 30.63120488724654\n",
      "Epoch: 3348 / 5000\n",
      "w1: [24.70302678] w2: [-22.70333763] bias: [16.41578845] loss: 30.629664287860148\n",
      "Epoch: 3349 / 5000\n",
      "w1: [24.71564934] w2: [-22.69705439] bias: [16.43125213] loss: 30.626538221971387\n",
      "Epoch: 3350 / 5000\n",
      "w1: [24.71447433] w2: [-22.70495688] bias: [16.4176478] loss: 30.62755135330983\n",
      "Epoch: 3351 / 5000\n",
      "w1: [24.71980424] w2: [-22.71296075] bias: [16.41765628] loss: 30.62620488313114\n",
      "Epoch: 3352 / 5000\n",
      "w1: [24.73305059] w2: [-22.70556082] bias: [16.43478402] loss: 30.62335077778264\n",
      "Epoch: 3353 / 5000\n",
      "w1: [24.74511627] w2: [-22.70373733] bias: [16.45108469] loss: 30.621457839040115\n",
      "Epoch: 3354 / 5000\n",
      "w1: [24.7443191] w2: [-22.70177419] bias: [16.4504943] loss: 30.621740783418566\n",
      "Epoch: 3355 / 5000\n",
      "w1: [24.7403593] w2: [-22.70426805] bias: [16.44382726] loss: 30.622127342320123\n",
      "Epoch: 3356 / 5000\n",
      "w1: [24.72420145] w2: [-22.71366799] bias: [16.41575275] loss: 30.625731445383106\n",
      "Epoch: 3357 / 5000\n",
      "w1: [24.73048957] w2: [-22.69688626] bias: [16.4388308] loss: 30.62414670802349\n",
      "Epoch: 3358 / 5000\n",
      "w1: [24.70915746] w2: [-22.70239728] bias: [16.40875453] loss: 30.62972870773065\n",
      "Epoch: 3359 / 5000\n",
      "w1: [24.70679506] w2: [-22.69286756] bias: [16.40630759] loss: 30.631063075173966\n",
      "Epoch: 3360 / 5000\n",
      "w1: [24.71757123] w2: [-22.69801791] bias: [16.41202291] loss: 30.62825375494308\n",
      "Epoch: 3361 / 5000\n",
      "w1: [24.68913093] w2: [-22.71089498] bias: [16.37035199] loss: 30.64060017595447\n",
      "Epoch: 3362 / 5000\n",
      "w1: [24.67335996] w2: [-22.72130015] bias: [16.33771712] loss: 30.653658991985925\n",
      "Epoch: 3363 / 5000\n",
      "w1: [24.6857438] w2: [-22.71321914] bias: [16.35732138] loss: 30.644709924781644\n",
      "Epoch: 3364 / 5000\n",
      "w1: [24.6789105] w2: [-22.71154831] bias: [16.34432628] loss: 30.6501974301076\n",
      "Epoch: 3365 / 5000\n",
      "w1: [24.67980838] w2: [-22.7158512] bias: [16.34143896] loss: 30.6508272520368\n",
      "Epoch: 3366 / 5000\n",
      "w1: [24.68640852] w2: [-22.71671224] bias: [16.34597221] loss: 30.647773246846274\n",
      "Epoch: 3367 / 5000\n",
      "w1: [24.69437814] w2: [-22.71756459] bias: [16.35308802] loss: 30.64378905706766\n",
      "Epoch: 3368 / 5000\n",
      "w1: [24.68825524] w2: [-22.7220741] bias: [16.33955768] loss: 30.649229555315046\n",
      "Epoch: 3369 / 5000\n",
      "w1: [24.68585702] w2: [-22.72650898] bias: [16.33255896] loss: 30.652091484857184\n",
      "Epoch: 3370 / 5000\n",
      "w1: [24.69607485] w2: [-22.7199874] bias: [16.34985835] loss: 30.64425634902118\n",
      "Epoch: 3371 / 5000\n",
      "w1: [24.67341199] w2: [-22.71886623] bias: [16.32259219] loss: 30.65892210932313\n",
      "Epoch: 3372 / 5000\n",
      "w1: [24.67152352] w2: [-22.72941483] bias: [16.32005861] loss: 30.660453891443833\n",
      "Epoch: 3373 / 5000\n",
      "w1: [24.68415178] w2: [-22.72679041] bias: [16.33324522] loss: 30.652306821484427\n",
      "Epoch: 3374 / 5000\n",
      "w1: [24.69173667] w2: [-22.72606148] bias: [16.33876633] loss: 30.648565476682666\n",
      "Epoch: 3375 / 5000\n",
      "w1: [24.6988329] w2: [-22.7344718] bias: [16.33738632] loss: 30.647143942408718\n",
      "Epoch: 3376 / 5000\n",
      "w1: [24.73026608] w2: [-22.72515628] bias: [16.38245713] loss: 30.6292029107427\n",
      "Epoch: 3377 / 5000\n",
      "w1: [24.73266597] w2: [-22.71826593] bias: [16.38845292] loss: 30.62804654968769\n",
      "Epoch: 3378 / 5000\n",
      "w1: [24.74464626] w2: [-22.72134448] bias: [16.39971825] loss: 30.624175068005705\n",
      "Epoch: 3379 / 5000\n",
      "w1: [24.74485599] w2: [-22.70116606] bias: [16.42643081] loss: 30.622860129058616\n",
      "Epoch: 3380 / 5000\n",
      "w1: [24.72687788] w2: [-22.72231555] bias: [16.3821227] loss: 30.630022066417876\n",
      "Epoch: 3381 / 5000\n",
      "w1: [24.72795496] w2: [-22.7314419] bias: [16.37854158] loss: 30.630119094680428\n",
      "Epoch: 3382 / 5000\n",
      "w1: [24.71832586] w2: [-22.72823491] bias: [16.36817377] loss: 30.634393733694438\n",
      "Epoch: 3383 / 5000\n",
      "w1: [24.73837287] w2: [-22.72555374] bias: [16.39053487] loss: 30.626329996739607\n",
      "Epoch: 3384 / 5000\n",
      "w1: [24.73967942] w2: [-22.71931196] bias: [16.39461669] loss: 30.62582106096033\n",
      "Epoch: 3385 / 5000\n",
      "w1: [24.76318723] w2: [-22.71212288] bias: [16.42911297] loss: 30.619613226005143\n",
      "Epoch: 3386 / 5000\n",
      "w1: [24.77995524] w2: [-22.71261481] bias: [16.44719347] loss: 30.617465007654978\n",
      "Epoch: 3387 / 5000\n",
      "w1: [24.78674436] w2: [-22.71601068] bias: [16.45411086] loss: 30.616647038760643\n",
      "Epoch: 3388 / 5000\n",
      "w1: [24.78660597] w2: [-22.70170644] bias: [16.46340664] loss: 30.618580968103842\n",
      "Epoch: 3389 / 5000\n",
      "w1: [24.80568459] w2: [-22.69124591] bias: [16.48995956] loss: 30.62149815760596\n",
      "Epoch: 3390 / 5000\n",
      "w1: [24.79601018] w2: [-22.68268999] bias: [16.48073246] loss: 30.621860566759494\n",
      "Epoch: 3391 / 5000\n",
      "w1: [24.80773503] w2: [-22.6784862] bias: [16.50981967] loss: 30.6263951783566\n",
      "Epoch: 3392 / 5000\n",
      "w1: [24.80857756] w2: [-22.6816317] bias: [16.50773334] loss: 30.62554688242829\n",
      "Epoch: 3393 / 5000\n",
      "w1: [24.82222009] w2: [-22.67416593] bias: [16.5357759] loss: 30.632965728526823\n",
      "Epoch: 3394 / 5000\n",
      "w1: [24.81088228] w2: [-22.68188384] bias: [16.52295037] loss: 30.62838304799038\n",
      "Epoch: 3395 / 5000\n",
      "w1: [24.81279643] w2: [-22.68591014] bias: [16.52413549] loss: 30.62800276906589\n",
      "Epoch: 3396 / 5000\n",
      "w1: [24.82537187] w2: [-22.67595428] bias: [16.54622392] loss: 30.63548537176656\n",
      "Epoch: 3397 / 5000\n",
      "w1: [24.83964164] w2: [-22.66181493] bias: [16.58234477] loss: 30.650903486542685\n",
      "Epoch: 3398 / 5000\n",
      "w1: [24.82777402] w2: [-22.66665341] bias: [16.55756013] loss: 30.640626507434064\n",
      "Epoch: 3399 / 5000\n",
      "w1: [24.82017646] w2: [-22.67470526] bias: [16.53705152] loss: 30.63309179207888\n",
      "Epoch: 3400 / 5000\n",
      "w1: [24.81367538] w2: [-22.67117788] bias: [16.52860963] loss: 30.63147706198532\n",
      "Epoch: 3401 / 5000\n",
      "w1: [24.82643774] w2: [-22.67379445] bias: [16.53620688] loss: 30.633333166057774\n",
      "Epoch: 3402 / 5000\n",
      "w1: [24.82316743] w2: [-22.67671167] bias: [16.53419841] loss: 30.632170544479095\n",
      "Epoch: 3403 / 5000\n",
      "w1: [24.82911797] w2: [-22.68267692] bias: [16.53451129] loss: 30.631450261429865\n",
      "Epoch: 3404 / 5000\n",
      "w1: [24.8455277] w2: [-22.68442188] bias: [16.55757217] loss: 30.638498004086586\n",
      "Epoch: 3405 / 5000\n",
      "w1: [24.85378224] w2: [-22.6849755] bias: [16.56285786] loss: 30.64074658730178\n",
      "Epoch: 3406 / 5000\n",
      "w1: [24.84930475] w2: [-22.68639548] bias: [16.55573614] loss: 30.637843472474117\n",
      "Epoch: 3407 / 5000\n",
      "w1: [24.85476791] w2: [-22.67980722] bias: [16.5686529] loss: 30.64382292450893\n",
      "Epoch: 3408 / 5000\n",
      "w1: [24.85167411] w2: [-22.67023775] bias: [16.57357697] loss: 30.647221289537764\n",
      "Epoch: 3409 / 5000\n",
      "w1: [24.83927282] w2: [-22.67295406] bias: [16.55273424] loss: 30.63879487499342\n",
      "Epoch: 3410 / 5000\n",
      "w1: [24.85270727] w2: [-22.68334653] bias: [16.55172276] loss: 30.63747432286708\n",
      "Epoch: 3411 / 5000\n",
      "w1: [24.85377718] w2: [-22.66405584] bias: [16.56273553] loss: 30.644960673025842\n",
      "Epoch: 3412 / 5000\n",
      "w1: [24.85563662] w2: [-22.66845088] bias: [16.55930224] loss: 30.643083002411615\n",
      "Epoch: 3413 / 5000\n",
      "w1: [24.85533408] w2: [-22.66851939] bias: [16.55298612] loss: 30.640994544789496\n",
      "Epoch: 3414 / 5000\n",
      "w1: [24.8469175] w2: [-22.67875427] bias: [16.53166772] loss: 30.632308188020023\n",
      "Epoch: 3415 / 5000\n",
      "w1: [24.83530753] w2: [-22.68968603] bias: [16.50597544] loss: 30.624249904955708\n",
      "Epoch: 3416 / 5000\n",
      "w1: [24.82536887] w2: [-22.69832882] bias: [16.48367516] loss: 30.619369180187615\n",
      "Epoch: 3417 / 5000\n",
      "w1: [24.82382684] w2: [-22.69848049] bias: [16.4760573] loss: 30.618452420864962\n",
      "Epoch: 3418 / 5000\n",
      "w1: [24.82585656] w2: [-22.70560643] bias: [16.47141491] loss: 30.61694245908611\n",
      "Epoch: 3419 / 5000\n",
      "w1: [24.8317056] w2: [-22.7081393] bias: [16.4819293] loss: 30.617667997329125\n",
      "Epoch: 3420 / 5000\n",
      "w1: [24.8619761] w2: [-22.69085179] bias: [16.52974221] loss: 30.630432873534737\n",
      "Epoch: 3421 / 5000\n",
      "w1: [24.84895081] w2: [-22.68215891] bias: [16.5210785] loss: 30.629154631271195\n",
      "Epoch: 3422 / 5000\n",
      "w1: [24.84750972] w2: [-22.68129282] bias: [16.51171085] loss: 30.627102265607615\n",
      "Epoch: 3423 / 5000\n",
      "w1: [24.83568439] w2: [-22.68956611] bias: [16.49357481] loss: 30.622065545229937\n",
      "Epoch: 3424 / 5000\n",
      "w1: [24.85388062] w2: [-22.69519711] bias: [16.50904783] loss: 30.62439468902063\n",
      "Epoch: 3425 / 5000\n",
      "w1: [24.84121248] w2: [-22.69991539] bias: [16.49593778] loss: 30.620910016387693\n",
      "Epoch: 3426 / 5000\n",
      "w1: [24.87128677] w2: [-22.70116621] bias: [16.52557274] loss: 30.62799749697921\n",
      "Epoch: 3427 / 5000\n",
      "w1: [24.85974756] w2: [-22.70014804] bias: [16.51076182] loss: 30.624122117481537\n",
      "Epoch: 3428 / 5000\n",
      "w1: [24.85174223] w2: [-22.70215267] bias: [16.50227316] loss: 30.621842855043926\n",
      "Epoch: 3429 / 5000\n",
      "w1: [24.8565517] w2: [-22.70629955] bias: [16.50732912] loss: 30.622287273473074\n",
      "Epoch: 3430 / 5000\n",
      "w1: [24.82663217] w2: [-22.72683673] bias: [16.45009458] loss: 30.612707914168464\n",
      "Epoch: 3431 / 5000\n",
      "w1: [24.81774293] w2: [-22.73406818] bias: [16.42831296] loss: 30.612187712493924\n",
      "Epoch: 3432 / 5000\n",
      "w1: [24.81954911] w2: [-22.73015611] bias: [16.43460997] loss: 30.61241530588501\n",
      "Epoch: 3433 / 5000\n",
      "w1: [24.81499974] w2: [-22.73829877] bias: [16.41953183] loss: 30.6122402296587\n",
      "Epoch: 3434 / 5000\n",
      "w1: [24.80046695] w2: [-22.74386466] bias: [16.39373947] loss: 30.61527103483902\n",
      "Epoch: 3435 / 5000\n",
      "w1: [24.78455265] w2: [-22.74343489] bias: [16.37244491] loss: 30.62054001895778\n",
      "Epoch: 3436 / 5000\n",
      "w1: [24.80855084] w2: [-22.74088978] bias: [16.39666477] loss: 30.61413789344313\n",
      "Epoch: 3437 / 5000\n",
      "w1: [24.8227662] w2: [-22.74649419] bias: [16.40902635] loss: 30.61117091735987\n",
      "Epoch: 3438 / 5000\n",
      "w1: [24.84279501] w2: [-22.74579741] bias: [16.43326429] loss: 30.609054424891255\n",
      "Epoch: 3439 / 5000\n",
      "w1: [24.83112289] w2: [-22.73358406] bias: [16.42473745] loss: 30.611120491092375\n",
      "Epoch: 3440 / 5000\n",
      "w1: [24.86067479] w2: [-22.70310467] bias: [16.49029977] loss: 30.61961509121969\n",
      "Epoch: 3441 / 5000\n",
      "w1: [24.85764751] w2: [-22.69046646] bias: [16.49301559] loss: 30.62204374113549\n",
      "Epoch: 3442 / 5000\n",
      "w1: [24.87856797] w2: [-22.68607331] bias: [16.52522629] loss: 30.631077697204088\n",
      "Epoch: 3443 / 5000\n",
      "w1: [24.88906323] w2: [-22.68635958] bias: [16.54164365] loss: 30.63669281034186\n",
      "Epoch: 3444 / 5000\n",
      "w1: [24.9125729] w2: [-22.68442145] bias: [16.56857317] loss: 30.649295098213727\n",
      "Epoch: 3445 / 5000\n",
      "w1: [24.89545783] w2: [-22.69867263] bias: [16.54391512] loss: 30.63554913719621\n",
      "Epoch: 3446 / 5000\n",
      "w1: [24.87852027] w2: [-22.70736059] bias: [16.51394756] loss: 30.62436066956517\n",
      "Epoch: 3447 / 5000\n",
      "w1: [24.87934429] w2: [-22.70555451] bias: [16.52296268] loss: 30.626977513039105\n",
      "Epoch: 3448 / 5000\n",
      "w1: [24.88706516] w2: [-22.6979695] bias: [16.54493368] loss: 30.635285154227393\n",
      "Epoch: 3449 / 5000\n",
      "w1: [24.88537836] w2: [-22.70536048] bias: [16.54216333] loss: 30.63285142316324\n",
      "Epoch: 3450 / 5000\n",
      "w1: [24.88921053] w2: [-22.71224308] bias: [16.54228977] loss: 30.631875195942584\n",
      "Epoch: 3451 / 5000\n",
      "w1: [24.91043193] w2: [-22.70665715] bias: [16.57458591] loss: 30.646529380550515\n",
      "Epoch: 3452 / 5000\n",
      "w1: [24.91359767] w2: [-22.7070534] bias: [16.58731238] loss: 30.652082584587717\n",
      "Epoch: 3453 / 5000\n",
      "w1: [24.91373016] w2: [-22.70846605] bias: [16.58800448] loss: 30.65207495767606\n",
      "Epoch: 3454 / 5000\n",
      "w1: [24.90604742] w2: [-22.70676133] bias: [16.57535048] loss: 30.64625470118433\n",
      "Epoch: 3455 / 5000\n",
      "w1: [24.92829154] w2: [-22.68506744] bias: [16.61634224] loss: 30.673352363117136\n",
      "Epoch: 3456 / 5000\n",
      "w1: [24.92969714] w2: [-22.67927105] bias: [16.63151614] loss: 30.683149674201857\n",
      "Epoch: 3457 / 5000\n",
      "w1: [24.93458046] w2: [-22.67325564] bias: [16.64450899] loss: 30.693143272869186\n",
      "Epoch: 3458 / 5000\n",
      "w1: [24.93601809] w2: [-22.67900671] bias: [16.64046728] loss: 30.689558237602974\n",
      "Epoch: 3459 / 5000\n",
      "w1: [24.95297736] w2: [-22.67495965] bias: [16.67669622] loss: 30.717187802112495\n",
      "Epoch: 3460 / 5000\n",
      "w1: [24.94495591] w2: [-22.68496413] bias: [16.65400905] loss: 30.697890928020996\n",
      "Epoch: 3461 / 5000\n",
      "w1: [24.93834063] w2: [-22.67899946] bias: [16.64843786] loss: 30.694700753843744\n",
      "Epoch: 3462 / 5000\n",
      "w1: [24.91757968] w2: [-22.69193642] bias: [16.60930406] loss: 30.666226639471134\n",
      "Epoch: 3463 / 5000\n",
      "w1: [24.91907684] w2: [-22.69973893] bias: [16.60095944] loss: 30.660657266626085\n",
      "Epoch: 3464 / 5000\n",
      "w1: [24.92429558] w2: [-22.68431528] bias: [16.6277978] loss: 30.678738665310995\n",
      "Epoch: 3465 / 5000\n",
      "w1: [24.91387608] w2: [-22.68176829] bias: [16.61571516] loss: 30.671229607070202\n",
      "Epoch: 3466 / 5000\n",
      "w1: [24.90221323] w2: [-22.68735642] bias: [16.59365714] loss: 30.657684383272628\n",
      "Epoch: 3467 / 5000\n",
      "w1: [24.92568923] w2: [-22.68409929] bias: [16.61616184] loss: 30.673020980615856\n",
      "Epoch: 3468 / 5000\n",
      "w1: [24.91081999] w2: [-22.69229121] bias: [16.58573746] loss: 30.654377511865913\n",
      "Epoch: 3469 / 5000\n",
      "w1: [24.89713411] w2: [-22.70246061] bias: [16.56084547] loss: 30.640702955663293\n",
      "Epoch: 3470 / 5000\n",
      "w1: [24.9039165] w2: [-22.70517386] bias: [16.56905098] loss: 30.643909014992897\n",
      "Epoch: 3471 / 5000\n",
      "w1: [24.89396595] w2: [-22.70768253] bias: [16.55352977] loss: 30.63678674679302\n",
      "Epoch: 3472 / 5000\n",
      "w1: [24.89511118] w2: [-22.71770086] bias: [16.54192427] loss: 30.63119250836432\n",
      "Epoch: 3473 / 5000\n",
      "w1: [24.88188738] w2: [-22.71841278] bias: [16.52562017] loss: 30.62552243440784\n",
      "Epoch: 3474 / 5000\n",
      "w1: [24.89272821] w2: [-22.71112272] bias: [16.54193706] loss: 30.632264699505768\n",
      "Epoch: 3475 / 5000\n",
      "w1: [24.8914911] w2: [-22.70760536] bias: [16.53850009] loss: 30.631787943069217\n",
      "Epoch: 3476 / 5000\n",
      "w1: [24.88054006] w2: [-22.69905638] bias: [16.52817394] loss: 30.629623856969133\n",
      "Epoch: 3477 / 5000\n",
      "w1: [24.87864629] w2: [-22.70541846] bias: [16.51601863] loss: 30.62520692834713\n",
      "Epoch: 3478 / 5000\n",
      "w1: [24.88696755] w2: [-22.69872926] bias: [16.53619784] loss: 30.632439284297558\n",
      "Epoch: 3479 / 5000\n",
      "w1: [24.8881685] w2: [-22.70232716] bias: [16.53390196] loss: 30.631166494382764\n",
      "Epoch: 3480 / 5000\n",
      "w1: [24.88537192] w2: [-22.70876005] bias: [16.52242893] loss: 30.626604632948613\n",
      "Epoch: 3481 / 5000\n",
      "w1: [24.8713587] w2: [-22.7142179] bias: [16.49918546] loss: 30.61972910048874\n",
      "Epoch: 3482 / 5000\n",
      "w1: [24.87054361] w2: [-22.71455952] bias: [16.49639594] loss: 30.619110134029036\n",
      "Epoch: 3483 / 5000\n",
      "w1: [24.85898056] w2: [-22.72573997] bias: [16.47255622] loss: 30.6136275196564\n",
      "Epoch: 3484 / 5000\n",
      "w1: [24.85177631] w2: [-22.73549489] bias: [16.46125004] loss: 30.611293903968228\n",
      "Epoch: 3485 / 5000\n",
      "w1: [24.86467837] w2: [-22.73425524] bias: [16.47091295] loss: 30.612174505272108\n",
      "Epoch: 3486 / 5000\n",
      "w1: [24.85443612] w2: [-22.74371088] bias: [16.4541714] loss: 30.609602434630293\n",
      "Epoch: 3487 / 5000\n",
      "w1: [24.85402479] w2: [-22.73813483] bias: [16.453083] loss: 30.61021060231493\n",
      "Epoch: 3488 / 5000\n",
      "w1: [24.86732639] w2: [-22.73023207] bias: [16.4810382] loss: 30.614094766515503\n",
      "Epoch: 3489 / 5000\n",
      "w1: [24.85740536] w2: [-22.73374117] bias: [16.46287255] loss: 30.611499079469503\n",
      "Epoch: 3490 / 5000\n",
      "w1: [24.87620474] w2: [-22.73265955] bias: [16.47972294] loss: 30.613539081674364\n",
      "Epoch: 3491 / 5000\n",
      "w1: [24.87454768] w2: [-22.74036441] bias: [16.47207035] loss: 30.611361453449092\n",
      "Epoch: 3492 / 5000\n",
      "w1: [24.89184303] w2: [-22.72754211] bias: [16.50049103] loss: 30.618430352628838\n",
      "Epoch: 3493 / 5000\n",
      "w1: [24.91020374] w2: [-22.72453931] bias: [16.52463968] loss: 30.625930903457608\n",
      "Epoch: 3494 / 5000\n",
      "w1: [24.91043567] w2: [-22.72908296] bias: [16.52043376] loss: 30.62394743274322\n",
      "Epoch: 3495 / 5000\n",
      "w1: [24.92182519] w2: [-22.72057405] bias: [16.54545119] loss: 30.63418180447316\n",
      "Epoch: 3496 / 5000\n",
      "w1: [24.9380505] w2: [-22.71421621] bias: [16.56974892] loss: 30.646552464774775\n",
      "Epoch: 3497 / 5000\n",
      "w1: [24.92122648] w2: [-22.70905487] bias: [16.55761295] loss: 30.64081306363484\n",
      "Epoch: 3498 / 5000\n",
      "w1: [24.9198722] w2: [-22.71337705] bias: [16.54759828] loss: 30.636173741952874\n",
      "Epoch: 3499 / 5000\n",
      "w1: [24.92044654] w2: [-22.71813514] bias: [16.54877644] loss: 30.635677817402502\n",
      "Epoch: 3500 / 5000\n",
      "w1: [24.91093717] w2: [-22.72177021] bias: [16.54050554] loss: 30.631297787381484\n",
      "Epoch: 3501 / 5000\n",
      "w1: [24.92361875] w2: [-22.72037318] bias: [16.55327508] loss: 30.63714423483039\n",
      "Epoch: 3502 / 5000\n",
      "w1: [24.92206846] w2: [-22.72541901] bias: [16.54550065] loss: 30.633255431593252\n",
      "Epoch: 3503 / 5000\n",
      "w1: [24.91298313] w2: [-22.73339086] bias: [16.5236713] loss: 30.624234934432554\n",
      "Epoch: 3504 / 5000\n",
      "w1: [24.91238398] w2: [-22.72570321] bias: [16.53022974] loss: 30.627501576181235\n",
      "Epoch: 3505 / 5000\n",
      "w1: [24.91632804] w2: [-22.72698429] bias: [16.53032619] loss: 30.627596124471864\n",
      "Epoch: 3506 / 5000\n",
      "w1: [24.91585305] w2: [-22.71549481] bias: [16.53694605] loss: 30.631811505322144\n",
      "Epoch: 3507 / 5000\n",
      "w1: [24.91662463] w2: [-22.72488246] bias: [16.52973599] loss: 30.627836898570994\n",
      "Epoch: 3508 / 5000\n",
      "w1: [24.92098561] w2: [-22.72730512] bias: [16.52534364] loss: 30.626409850517504\n",
      "Epoch: 3509 / 5000\n",
      "w1: [24.94718344] w2: [-22.72200897] bias: [16.57167092] loss: 30.646884361527654\n",
      "Epoch: 3510 / 5000\n",
      "w1: [24.92072854] w2: [-22.72516956] bias: [16.53595753] loss: 30.630049412719572\n",
      "Epoch: 3511 / 5000\n",
      "w1: [24.91602336] w2: [-22.72176264] bias: [16.5332667] loss: 30.629458160367335\n",
      "Epoch: 3512 / 5000\n",
      "w1: [24.94090414] w2: [-22.72085892] bias: [16.56312891] loss: 30.64281003372824\n",
      "Epoch: 3513 / 5000\n",
      "w1: [24.95477853] w2: [-22.71547951] bias: [16.58589124] loss: 30.65577317399518\n",
      "Epoch: 3514 / 5000\n",
      "w1: [24.95325256] w2: [-22.71954551] bias: [16.57823207] loss: 30.65114716005274\n",
      "Epoch: 3515 / 5000\n",
      "w1: [24.95551579] w2: [-22.7269413] bias: [16.57413816] loss: 30.64802591590445\n",
      "Epoch: 3516 / 5000\n",
      "w1: [24.93897671] w2: [-22.73754967] bias: [16.54007058] loss: 30.630681921908995\n",
      "Epoch: 3517 / 5000\n",
      "w1: [24.93445499] w2: [-22.74645607] bias: [16.52749012] loss: 30.624541138898106\n",
      "Epoch: 3518 / 5000\n",
      "w1: [24.92899991] w2: [-22.74385985] bias: [16.51820048] loss: 30.6219054465264\n",
      "Epoch: 3519 / 5000\n",
      "w1: [24.90909493] w2: [-22.75238278] bias: [16.48783471] loss: 30.612396979659163\n",
      "Epoch: 3520 / 5000\n",
      "w1: [24.89217276] w2: [-22.75846776] bias: [16.46953019] loss: 30.608383806338985\n",
      "Epoch: 3521 / 5000\n",
      "w1: [24.91533724] w2: [-22.75987066] bias: [16.49353387] loss: 30.61253882906624\n",
      "Epoch: 3522 / 5000\n",
      "w1: [24.93306121] w2: [-22.75150971] bias: [16.51822575] loss: 30.62081914041277\n",
      "Epoch: 3523 / 5000\n",
      "w1: [24.92178967] w2: [-22.75929916] bias: [16.49225817] loss: 30.612566412328757\n",
      "Epoch: 3524 / 5000\n",
      "w1: [24.93324887] w2: [-22.76048784] bias: [16.50874963] loss: 30.6167270012462\n",
      "Epoch: 3525 / 5000\n",
      "w1: [24.93888065] w2: [-22.76144094] bias: [16.5211273] loss: 30.620267657634596\n",
      "Epoch: 3526 / 5000\n",
      "w1: [24.96257817] w2: [-22.75120079] bias: [16.55606623] loss: 30.636336262151875\n",
      "Epoch: 3527 / 5000\n",
      "w1: [24.94893764] w2: [-22.74983527] bias: [16.538361] loss: 30.62867631012501\n",
      "Epoch: 3528 / 5000\n",
      "w1: [24.95054626] w2: [-22.74723536] bias: [16.54303127] loss: 30.63096068849754\n",
      "Epoch: 3529 / 5000\n",
      "w1: [24.93707237] w2: [-22.7468789] bias: [16.52268425] loss: 30.623232894458155\n",
      "Epoch: 3530 / 5000\n",
      "w1: [24.95393028] w2: [-22.75476518] bias: [16.53512195] loss: 30.627120854797774\n",
      "Epoch: 3531 / 5000\n",
      "w1: [24.95562011] w2: [-22.75908068] bias: [16.52776575] loss: 30.62405951895023\n",
      "Epoch: 3532 / 5000\n",
      "w1: [24.94467649] w2: [-22.76244312] bias: [16.50626119] loss: 30.616413886008264\n",
      "Epoch: 3533 / 5000\n",
      "w1: [24.92332974] w2: [-22.76982657] bias: [16.47702485] loss: 30.60805312744606\n",
      "Epoch: 3534 / 5000\n",
      "w1: [24.9179317] w2: [-22.77244639] bias: [16.47114954] loss: 30.606645891447137\n",
      "Epoch: 3535 / 5000\n",
      "w1: [24.91504723] w2: [-22.77744028] bias: [16.45947462] loss: 30.604313492606455\n",
      "Epoch: 3536 / 5000\n",
      "w1: [24.92560415] w2: [-22.76256772] bias: [16.48191086] loss: 30.610080110916243\n",
      "Epoch: 3537 / 5000\n",
      "w1: [24.91655305] w2: [-22.76551975] bias: [16.47141469] loss: 30.607661362578778\n",
      "Epoch: 3538 / 5000\n",
      "w1: [24.92051057] w2: [-22.77074002] bias: [16.47017428] loss: 30.606746830282084\n",
      "Epoch: 3539 / 5000\n",
      "w1: [24.91907665] w2: [-22.77133624] bias: [16.46687101] loss: 30.60614808983482\n",
      "Epoch: 3540 / 5000\n",
      "w1: [24.92113288] w2: [-22.76027266] bias: [16.4716708] loss: 30.60849729690283\n",
      "Epoch: 3541 / 5000\n",
      "w1: [24.93957356] w2: [-22.77288338] bias: [16.48175443] loss: 30.608836286047087\n",
      "Epoch: 3542 / 5000\n",
      "w1: [24.96007336] w2: [-22.77086053] bias: [16.53228263] loss: 30.62368345787918\n",
      "Epoch: 3543 / 5000\n",
      "w1: [24.96218914] w2: [-22.7795805] bias: [16.52695106] loss: 30.620547534598522\n",
      "Epoch: 3544 / 5000\n",
      "w1: [24.9721293] w2: [-22.77766558] bias: [16.53401409] loss: 30.62412303299306\n",
      "Epoch: 3545 / 5000\n",
      "w1: [24.95949956] w2: [-22.77769171] bias: [16.51963012] loss: 30.61845868464453\n",
      "Epoch: 3546 / 5000\n",
      "w1: [24.9561079] w2: [-22.78322863] bias: [16.50573897] loss: 30.613411149531228\n",
      "Epoch: 3547 / 5000\n",
      "w1: [24.95551894] w2: [-22.7836056] bias: [16.49963775] loss: 30.611771874229063\n",
      "Epoch: 3548 / 5000\n",
      "w1: [24.96604962] w2: [-22.77425411] bias: [16.51856644] loss: 30.619290315322626\n",
      "Epoch: 3549 / 5000\n",
      "w1: [24.95776248] w2: [-22.7797105] bias: [16.50134967] loss: 30.61297567236076\n",
      "Epoch: 3550 / 5000\n",
      "w1: [24.94100602] w2: [-22.78773215] bias: [16.47153386] loss: 30.60475723324051\n",
      "Epoch: 3551 / 5000\n",
      "w1: [24.9263295] w2: [-22.793699] bias: [16.4488847] loss: 30.600815680466685\n",
      "Epoch: 3552 / 5000\n",
      "w1: [24.93172965] w2: [-22.78671228] bias: [16.45916991] loss: 30.602925164551742\n",
      "Epoch: 3553 / 5000\n",
      "w1: [24.94760337] w2: [-22.78358661] bias: [16.48838003] loss: 30.608817737385994\n",
      "Epoch: 3554 / 5000\n",
      "w1: [24.94682371] w2: [-22.80032645] bias: [16.46921861] loss: 30.602651066923105\n",
      "Epoch: 3555 / 5000\n",
      "w1: [24.94680558] w2: [-22.81038822] bias: [16.46420574] loss: 30.600470879592223\n",
      "Epoch: 3556 / 5000\n",
      "w1: [24.97046304] w2: [-22.81413994] bias: [16.48945305] loss: 30.60518810413092\n",
      "Epoch: 3557 / 5000\n",
      "w1: [24.96889034] w2: [-22.81055794] bias: [16.50881355] loss: 30.610385097106406\n",
      "Epoch: 3558 / 5000\n",
      "w1: [24.95341848] w2: [-22.82004954] bias: [16.4791809] loss: 30.60168791783371\n",
      "Epoch: 3559 / 5000\n",
      "w1: [24.9377949] w2: [-22.82034065] bias: [16.46056098] loss: 30.598677419047778\n",
      "Epoch: 3560 / 5000\n",
      "w1: [24.95047765] w2: [-22.81442673] bias: [16.47867584] loss: 30.60234444909522\n",
      "Epoch: 3561 / 5000\n",
      "w1: [24.96078846] w2: [-22.80395323] bias: [16.50642466] loss: 30.61038346582261\n",
      "Epoch: 3562 / 5000\n",
      "w1: [24.94340114] w2: [-22.81144483] bias: [16.47498934] loss: 30.602011041232288\n",
      "Epoch: 3563 / 5000\n",
      "w1: [24.95863724] w2: [-22.80397486] bias: [16.50457205] loss: 30.609795721228043\n",
      "Epoch: 3564 / 5000\n",
      "w1: [24.98344465] w2: [-22.79591239] bias: [16.54490223] loss: 30.625552047470315\n",
      "Epoch: 3565 / 5000\n",
      "w1: [24.96896896] w2: [-22.80624669] bias: [16.52413518] loss: 30.615413066526017\n",
      "Epoch: 3566 / 5000\n",
      "w1: [24.97306204] w2: [-22.81287244] bias: [16.53464047] loss: 30.61778208000806\n",
      "Epoch: 3567 / 5000\n",
      "w1: [24.95838239] w2: [-22.824081] bias: [16.50286307] loss: 30.606133310458045\n",
      "Epoch: 3568 / 5000\n",
      "w1: [24.97926729] w2: [-22.82124778] bias: [16.53464576] loss: 30.616816059932855\n",
      "Epoch: 3569 / 5000\n",
      "w1: [24.97146175] w2: [-22.8306258] bias: [16.52587851] loss: 30.61182199224624\n",
      "Epoch: 3570 / 5000\n",
      "w1: [24.97018433] w2: [-22.83790847] bias: [16.51707607] loss: 30.6080683571336\n",
      "Epoch: 3571 / 5000\n",
      "w1: [24.96334281] w2: [-22.82987677] bias: [16.51539657] loss: 30.608531600358805\n",
      "Epoch: 3572 / 5000\n",
      "w1: [24.97901936] w2: [-22.83067554] bias: [16.53219147] loss: 30.61431143299349\n",
      "Epoch: 3573 / 5000\n",
      "w1: [24.97172637] w2: [-22.84071373] bias: [16.5121097] loss: 30.606417161705625\n",
      "Epoch: 3574 / 5000\n",
      "w1: [24.9550802] w2: [-22.85424596] bias: [16.47723376] loss: 30.596642624491437\n",
      "Epoch: 3575 / 5000\n",
      "w1: [24.94777016] w2: [-22.86363983] bias: [16.45477257] loss: 30.5926042383969\n",
      "Epoch: 3576 / 5000\n",
      "w1: [24.95002187] w2: [-22.86280422] bias: [16.45037561] loss: 30.59222270489905\n",
      "Epoch: 3577 / 5000\n",
      "w1: [24.94780651] w2: [-22.86038684] bias: [16.44828115] loss: 30.59235989956062\n",
      "Epoch: 3578 / 5000\n",
      "w1: [24.95990107] w2: [-22.86173762] bias: [16.45710333] loss: 30.592895789736463\n",
      "Epoch: 3579 / 5000\n",
      "w1: [24.95736636] w2: [-22.86634791] bias: [16.45548841] loss: 30.592191822929266\n",
      "Epoch: 3580 / 5000\n",
      "w1: [24.96943748] w2: [-22.85498864] bias: [16.47938173] loss: 30.59711647907191\n",
      "Epoch: 3581 / 5000\n",
      "w1: [24.97644627] w2: [-22.85783714] bias: [16.47640029] loss: 30.59633497221133\n",
      "Epoch: 3582 / 5000\n",
      "w1: [24.98270171] w2: [-22.85493662] bias: [16.49665048] loss: 30.6010416140713\n",
      "Epoch: 3583 / 5000\n",
      "w1: [24.98143129] w2: [-22.85260274] bias: [16.4925945] loss: 30.600441697378074\n",
      "Epoch: 3584 / 5000\n",
      "w1: [24.98049763] w2: [-22.86022432] bias: [16.48137382] loss: 30.59700813385585\n",
      "Epoch: 3585 / 5000\n",
      "w1: [24.99011364] w2: [-22.86447804] bias: [16.48973105] loss: 30.59840062325553\n",
      "Epoch: 3586 / 5000\n",
      "w1: [24.98178015] w2: [-22.87441028] bias: [16.47304558] loss: 30.593600703306215\n",
      "Epoch: 3587 / 5000\n",
      "w1: [24.99581113] w2: [-22.87425294] bias: [16.48953827] loss: 30.597142560200503\n",
      "Epoch: 3588 / 5000\n",
      "w1: [25.01918535] w2: [-22.86831083] bias: [16.53204713] loss: 30.611244281365327\n",
      "Epoch: 3589 / 5000\n",
      "w1: [25.01682587] w2: [-22.85238244] bias: [16.55355409] loss: 30.621558124237055\n",
      "Epoch: 3590 / 5000\n",
      "w1: [25.00173341] w2: [-22.85584736] bias: [16.53473561] loss: 30.612658097805483\n",
      "Epoch: 3591 / 5000\n",
      "w1: [24.99848685] w2: [-22.86546109] bias: [16.51665983] loss: 30.605313431680727\n",
      "Epoch: 3592 / 5000\n",
      "w1: [24.98704301] w2: [-22.86175876] bias: [16.49972179] loss: 30.600903165289722\n",
      "Epoch: 3593 / 5000\n",
      "w1: [24.97358059] w2: [-22.87389194] bias: [16.47206092] loss: 30.59340945596541\n",
      "Epoch: 3594 / 5000\n",
      "w1: [24.97544386] w2: [-22.87729396] bias: [16.47445474] loss: 30.59336085199707\n",
      "Epoch: 3595 / 5000\n",
      "w1: [24.98877153] w2: [-22.86119612] bias: [16.49917988] loss: 30.600950366524117\n",
      "Epoch: 3596 / 5000\n",
      "w1: [25.01059879] w2: [-22.85792775] bias: [16.53575924] loss: 30.61349210327144\n",
      "Epoch: 3597 / 5000\n",
      "w1: [24.99390514] w2: [-22.86608079] bias: [16.50394417] loss: 30.601602100128197\n",
      "Epoch: 3598 / 5000\n",
      "w1: [24.98947229] w2: [-22.87016758] bias: [16.49279876] loss: 30.598187683677693\n",
      "Epoch: 3599 / 5000\n",
      "w1: [24.99607095] w2: [-22.87623751] bias: [16.49788767] loss: 30.598705530196213\n",
      "Epoch: 3600 / 5000\n",
      "w1: [25.00398156] w2: [-22.87174127] bias: [16.51274774] loss: 30.60359862671932\n",
      "Epoch: 3601 / 5000\n",
      "w1: [25.00978284] w2: [-22.85770147] bias: [16.52908788] loss: 30.61128997786863\n",
      "Epoch: 3602 / 5000\n",
      "w1: [25.00052771] w2: [-22.86524816] bias: [16.50768933] loss: 30.603084763934863\n",
      "Epoch: 3603 / 5000\n",
      "w1: [25.00604072] w2: [-22.86546703] bias: [16.51133769] loss: 30.6043982957406\n",
      "Epoch: 3604 / 5000\n",
      "w1: [25.00676132] w2: [-22.8746345] bias: [16.5033004] loss: 30.600846819225637\n",
      "Epoch: 3605 / 5000\n",
      "w1: [25.01566757] w2: [-22.85987038] bias: [16.52891786] loss: 30.611409928682342\n",
      "Epoch: 3606 / 5000\n",
      "w1: [25.02710326] w2: [-22.86087958] bias: [16.53663203] loss: 30.615003719047728\n",
      "Epoch: 3607 / 5000\n",
      "w1: [25.0326387] w2: [-22.86405431] bias: [16.53798464] loss: 30.615508182463508\n",
      "Epoch: 3608 / 5000\n",
      "w1: [25.02494098] w2: [-22.8600358] bias: [16.5320449] loss: 30.613352631592004\n",
      "Epoch: 3609 / 5000\n",
      "w1: [25.01297918] w2: [-22.85991914] bias: [16.51441334] loss: 30.606727288642432\n",
      "Epoch: 3610 / 5000\n",
      "w1: [25.00140654] w2: [-22.87093106] bias: [16.48583575] loss: 30.597069764123166\n",
      "Epoch: 3611 / 5000\n",
      "w1: [24.98900186] w2: [-22.87127093] bias: [16.47187249] loss: 30.593948559777253\n",
      "Epoch: 3612 / 5000\n",
      "w1: [24.98334896] w2: [-22.87551786] bias: [16.4707368] loss: 30.593097258058485\n",
      "Epoch: 3613 / 5000\n",
      "w1: [24.97439235] w2: [-22.88775822] bias: [16.44701597] loss: 30.588543727089668\n",
      "Epoch: 3614 / 5000\n",
      "w1: [24.96006317] w2: [-22.88368385] bias: [16.44359807] loss: 30.589053188056063\n",
      "Epoch: 3615 / 5000\n",
      "w1: [24.95731295] w2: [-22.87745091] bias: [16.44336838] loss: 30.58979085974126\n",
      "Epoch: 3616 / 5000\n",
      "w1: [24.95850575] w2: [-22.87903526] bias: [16.44311141] loss: 30.58956281313104\n",
      "Epoch: 3617 / 5000\n",
      "w1: [24.96391409] w2: [-22.87507238] bias: [16.45093838] loss: 30.59058098200108\n",
      "Epoch: 3618 / 5000\n",
      "w1: [24.97646534] w2: [-22.86697045] bias: [16.46392251] loss: 30.593098325054584\n",
      "Epoch: 3619 / 5000\n",
      "w1: [25.00690215] w2: [-22.85192953] bias: [16.5091206] loss: 30.606111825720905\n",
      "Epoch: 3620 / 5000\n",
      "w1: [25.01375235] w2: [-22.84760443] bias: [16.51908754] loss: 30.61033415322085\n",
      "Epoch: 3621 / 5000\n",
      "w1: [24.9895407] w2: [-22.86115036] bias: [16.47501005] loss: 30.595920710365956\n",
      "Epoch: 3622 / 5000\n",
      "w1: [24.97793748] w2: [-22.86951007] bias: [16.45365297] loss: 30.591380194825458\n",
      "Epoch: 3623 / 5000\n",
      "w1: [24.97928133] w2: [-22.86693548] bias: [16.45241403] loss: 30.591530801179037\n",
      "Epoch: 3624 / 5000\n",
      "w1: [24.99202875] w2: [-22.86192631] bias: [16.47168293] loss: 30.595262264827554\n",
      "Epoch: 3625 / 5000\n",
      "w1: [24.98942752] w2: [-22.87215187] bias: [16.45330363] loss: 30.590973209298422\n",
      "Epoch: 3626 / 5000\n",
      "w1: [24.96590595] w2: [-22.88005026] bias: [16.41785152] loss: 30.587705465998404\n",
      "Epoch: 3627 / 5000\n",
      "w1: [24.97641781] w2: [-22.88139069] bias: [16.4253822] loss: 30.58744812657752\n",
      "Epoch: 3628 / 5000\n",
      "w1: [24.97602245] w2: [-22.88835413] bias: [16.42458842] loss: 30.5867199356533\n",
      "Epoch: 3629 / 5000\n",
      "w1: [24.98960567] w2: [-22.8828371] bias: [16.45054017] loss: 30.589307775779318\n",
      "Epoch: 3630 / 5000\n",
      "w1: [24.97617068] w2: [-22.8797169] bias: [16.43195674] loss: 30.58807520754143\n",
      "Epoch: 3631 / 5000\n",
      "w1: [24.99452675] w2: [-22.87706518] bias: [16.45715326] loss: 30.590909945422975\n",
      "Epoch: 3632 / 5000\n",
      "w1: [24.99021952] w2: [-22.88038269] bias: [16.44901697] loss: 30.58941039404109\n",
      "Epoch: 3633 / 5000\n",
      "w1: [25.00484907] w2: [-22.85756545] bias: [16.48423792] loss: 30.59886703827032\n",
      "Epoch: 3634 / 5000\n",
      "w1: [24.9969121] w2: [-22.84314045] bias: [16.47989222] loss: 30.599754364480678\n",
      "Epoch: 3635 / 5000\n",
      "w1: [24.98802398] w2: [-22.85016341] bias: [16.45734779] loss: 30.59437710292922\n",
      "Epoch: 3636 / 5000\n",
      "w1: [24.99462419] w2: [-22.85161497] bias: [16.46105577] loss: 30.59486956187058\n",
      "Epoch: 3637 / 5000\n",
      "w1: [25.00997187] w2: [-22.83947238] bias: [16.48279056] loss: 30.601566614069903\n",
      "Epoch: 3638 / 5000\n",
      "w1: [25.00335095] w2: [-22.85405906] bias: [16.45897398] loss: 30.5943356749731\n",
      "Epoch: 3639 / 5000\n",
      "w1: [25.02376922] w2: [-22.85058618] bias: [16.49416355] loss: 30.60346609238348\n",
      "Epoch: 3640 / 5000\n",
      "w1: [25.01823666] w2: [-22.85074322] bias: [16.48228266] loss: 30.600119082130604\n",
      "Epoch: 3641 / 5000\n",
      "w1: [24.98727175] w2: [-22.86585291] bias: [16.42730512] loss: 30.588869031794342\n",
      "Epoch: 3642 / 5000\n",
      "w1: [24.97317372] w2: [-22.87359584] bias: [16.40039572] loss: 30.58744749530057\n",
      "Epoch: 3643 / 5000\n",
      "w1: [24.98489282] w2: [-22.87371973] bias: [16.40990961] loss: 30.5870302745985\n",
      "Epoch: 3644 / 5000\n",
      "w1: [24.96471531] w2: [-22.87882938] bias: [16.38253524] loss: 30.587897483989163\n",
      "Epoch: 3645 / 5000\n",
      "w1: [24.97474013] w2: [-22.88330621] bias: [16.38806482] loss: 30.586559149364483\n",
      "Epoch: 3646 / 5000\n",
      "w1: [24.97090831] w2: [-22.88486255] bias: [16.37966751] loss: 30.587004401606197\n",
      "Epoch: 3647 / 5000\n",
      "w1: [24.97476547] w2: [-22.87119363] bias: [16.39032066] loss: 30.58750551838422\n",
      "Epoch: 3648 / 5000\n",
      "w1: [24.96190733] w2: [-22.87670955] bias: [16.37076997] loss: 30.58888527367655\n",
      "Epoch: 3649 / 5000\n",
      "w1: [24.96376928] w2: [-22.87644211] bias: [16.36999261] loss: 30.588757153127013\n",
      "Epoch: 3650 / 5000\n",
      "w1: [24.95471427] w2: [-22.89278201] bias: [16.34664816] loss: 30.591120992514327\n",
      "Epoch: 3651 / 5000\n",
      "w1: [24.96994517] w2: [-22.89476578] bias: [16.36225677] loss: 30.587496443167183\n",
      "Epoch: 3652 / 5000\n",
      "w1: [24.96660276] w2: [-22.90312712] bias: [16.34833334] loss: 30.58883986597406\n",
      "Epoch: 3653 / 5000\n",
      "w1: [24.97989831] w2: [-22.88822576] bias: [16.38000637] loss: 30.58594700379487\n",
      "Epoch: 3654 / 5000\n",
      "w1: [24.96706056] w2: [-22.89816661] bias: [16.35837285] loss: 30.587978287968387\n",
      "Epoch: 3655 / 5000\n",
      "w1: [24.97301108] w2: [-22.90122942] bias: [16.36128125] loss: 30.586856302835802\n",
      "Epoch: 3656 / 5000\n",
      "w1: [24.96529218] w2: [-22.91490342] bias: [16.34275324] loss: 30.589215624349297\n",
      "Epoch: 3657 / 5000\n",
      "w1: [24.97903062] w2: [-22.91219352] bias: [16.36137425] loss: 30.58554643135826\n",
      "Epoch: 3658 / 5000\n",
      "w1: [24.98546181] w2: [-22.92081725] bias: [16.36075682] loss: 30.584392193598433\n",
      "Epoch: 3659 / 5000\n",
      "w1: [24.98601911] w2: [-22.92050922] bias: [16.35995268] loss: 30.58441301226176\n",
      "Epoch: 3660 / 5000\n",
      "w1: [24.97765565] w2: [-22.93006785] bias: [16.33863746] loss: 30.58744163788236\n",
      "Epoch: 3661 / 5000\n",
      "w1: [24.98113181] w2: [-22.93893849] bias: [16.33718241] loss: 30.58683045519849\n",
      "Epoch: 3662 / 5000\n",
      "w1: [24.97270825] w2: [-22.94312877] bias: [16.33140829] loss: 30.5888792505205\n",
      "Epoch: 3663 / 5000\n",
      "w1: [24.9966375] w2: [-22.94029743] bias: [16.36790989] loss: 30.581541754311196\n",
      "Epoch: 3664 / 5000\n",
      "w1: [24.98097382] w2: [-22.9467131] bias: [16.35347822] loss: 30.584406616182175\n",
      "Epoch: 3665 / 5000\n",
      "w1: [24.99158891] w2: [-22.93077802] bias: [16.37955734] loss: 30.581961829117\n",
      "Epoch: 3666 / 5000\n",
      "w1: [24.98864112] w2: [-22.93389035] bias: [16.37077032] loss: 30.582552932000635\n",
      "Epoch: 3667 / 5000\n",
      "w1: [25.01180562] w2: [-22.92475867] bias: [16.39832724] loss: 30.580615133224807\n",
      "Epoch: 3668 / 5000\n",
      "w1: [25.01593523] w2: [-22.92607579] bias: [16.40556059] loss: 30.580465583023177\n",
      "Epoch: 3669 / 5000\n",
      "w1: [25.02796622] w2: [-22.92269082] bias: [16.41996912] loss: 30.581148392179184\n",
      "Epoch: 3670 / 5000\n",
      "w1: [25.03753873] w2: [-22.92859152] bias: [16.43620124] loss: 30.581948993976617\n",
      "Epoch: 3671 / 5000\n",
      "w1: [25.05238674] w2: [-22.92885595] bias: [16.45778917] loss: 30.585227809165538\n",
      "Epoch: 3672 / 5000\n",
      "w1: [25.05493069] w2: [-22.92319503] bias: [16.46310952] loss: 30.587036284864787\n",
      "Epoch: 3673 / 5000\n",
      "w1: [25.05148654] w2: [-22.9160174] bias: [16.46292865] loss: 30.58786211836432\n",
      "Epoch: 3674 / 5000\n",
      "w1: [25.06746476] w2: [-22.91721141] bias: [16.48038135] loss: 30.592257653349222\n",
      "Epoch: 3675 / 5000\n",
      "w1: [25.06636006] w2: [-22.91260877] bias: [16.48001162] loss: 30.592797141977275\n",
      "Epoch: 3676 / 5000\n",
      "w1: [25.05253451] w2: [-22.92086721] bias: [16.45525777] loss: 30.58582816830523\n",
      "Epoch: 3677 / 5000\n",
      "w1: [25.04755914] w2: [-22.90788522] bias: [16.46444974] loss: 30.589141510667297\n",
      "Epoch: 3678 / 5000\n",
      "w1: [25.0536533] w2: [-22.90010701] bias: [16.47814781] loss: 30.59350124504867\n",
      "Epoch: 3679 / 5000\n",
      "w1: [25.04395058] w2: [-22.88542733] bias: [16.47906821] loss: 30.595405005484363\n",
      "Epoch: 3680 / 5000\n",
      "w1: [25.03332117] w2: [-22.88990651] bias: [16.46156247] loss: 30.590608991241055\n",
      "Epoch: 3681 / 5000\n",
      "w1: [25.02844409] w2: [-22.8987344] bias: [16.4498193] loss: 30.587347334407916\n",
      "Epoch: 3682 / 5000\n",
      "w1: [25.0367624] w2: [-22.90208348] bias: [16.45272635] loss: 30.587504498984714\n",
      "Epoch: 3683 / 5000\n",
      "w1: [25.01923375] w2: [-22.91211656] bias: [16.41782744] loss: 30.58231620784999\n",
      "Epoch: 3684 / 5000\n",
      "w1: [25.01629744] w2: [-22.91282946] bias: [16.41146766] loss: 30.58194570223163\n",
      "Epoch: 3685 / 5000\n",
      "w1: [25.00501743] w2: [-22.9235734] bias: [16.39152618] loss: 30.581101685244544\n",
      "Epoch: 3686 / 5000\n",
      "w1: [24.99897963] w2: [-22.93090276] bias: [16.37771747] loss: 30.581357055370916\n",
      "Epoch: 3687 / 5000\n",
      "w1: [25.01015512] w2: [-22.9235164] bias: [16.39135075] loss: 30.58075252182811\n",
      "Epoch: 3688 / 5000\n",
      "w1: [25.00450176] w2: [-22.92440822] bias: [16.3842341] loss: 30.581152709038168\n",
      "Epoch: 3689 / 5000\n",
      "w1: [24.99443785] w2: [-22.92702299] bias: [16.36849013] loss: 30.58251245256636\n",
      "Epoch: 3690 / 5000\n",
      "w1: [25.00083273] w2: [-22.92377947] bias: [16.37435576] loss: 30.58180174403594\n",
      "Epoch: 3691 / 5000\n",
      "w1: [25.0419756] w2: [-22.9135768] bias: [16.42823486] loss: 30.582690416710076\n",
      "Epoch: 3692 / 5000\n",
      "w1: [25.04850673] w2: [-22.90594078] bias: [16.43531186] loss: 30.584488114440646\n",
      "Epoch: 3693 / 5000\n",
      "w1: [25.05439504] w2: [-22.91138277] bias: [16.4352495] loss: 30.583856298519777\n",
      "Epoch: 3694 / 5000\n",
      "w1: [25.06653418] w2: [-22.91139291] bias: [16.44634697] loss: 30.585847539237925\n",
      "Epoch: 3695 / 5000\n",
      "w1: [25.09431491] w2: [-22.90590869] bias: [16.4796532] loss: 30.59570049581584\n",
      "Epoch: 3696 / 5000\n",
      "w1: [25.09241397] w2: [-22.90321456] bias: [16.47793224] loss: 30.595511876909004\n",
      "Epoch: 3697 / 5000\n",
      "w1: [25.08272432] w2: [-22.88758543] bias: [16.47372151] loss: 30.596160707446575\n",
      "Epoch: 3698 / 5000\n",
      "w1: [25.08247483] w2: [-22.87943739] bias: [16.48318434] loss: 30.60008433590237\n",
      "Epoch: 3699 / 5000\n",
      "w1: [25.0881364] w2: [-22.87725658] bias: [16.49610187] loss: 30.60491302625382\n",
      "Epoch: 3700 / 5000\n",
      "w1: [25.07937708] w2: [-22.86978637] bias: [16.48716775] loss: 30.602617962565645\n",
      "Epoch: 3701 / 5000\n",
      "w1: [25.08182046] w2: [-22.86748064] bias: [16.48674344] loss: 30.603102527381917\n",
      "Epoch: 3702 / 5000\n",
      "w1: [25.10629676] w2: [-22.87040513] bias: [16.50680338] loss: 30.611880586927704\n",
      "Epoch: 3703 / 5000\n",
      "w1: [25.12431263] w2: [-22.85931388] bias: [16.54285454] loss: 30.63179032164696\n",
      "Epoch: 3704 / 5000\n",
      "w1: [25.11806558] w2: [-22.86837366] bias: [16.52370363] loss: 30.620466730742866\n",
      "Epoch: 3705 / 5000\n",
      "w1: [25.12203833] w2: [-22.86489435] bias: [16.52937057] loss: 30.624186777919945\n",
      "Epoch: 3706 / 5000\n",
      "w1: [25.10526098] w2: [-22.87478844] bias: [16.49335906] loss: 30.6062372802375\n",
      "Epoch: 3707 / 5000\n",
      "w1: [25.10146238] w2: [-22.88482501] bias: [16.48140363] loss: 30.600299115237053\n",
      "Epoch: 3708 / 5000\n",
      "w1: [25.08262185] w2: [-22.88984926] bias: [16.44732135] loss: 30.589545114730758\n",
      "Epoch: 3709 / 5000\n",
      "w1: [25.08240697] w2: [-22.89061671] bias: [16.44571335] loss: 30.589092237245577\n",
      "Epoch: 3710 / 5000\n",
      "w1: [25.10380153] w2: [-22.89023262] bias: [16.4710524] loss: 30.596593234824354\n",
      "Epoch: 3711 / 5000\n",
      "w1: [25.10202752] w2: [-22.88097256] bias: [16.47256024] loss: 30.598395828970894\n",
      "Epoch: 3712 / 5000\n",
      "w1: [25.10568988] w2: [-22.86970992] bias: [16.49819985] loss: 30.608867191044432\n",
      "Epoch: 3713 / 5000\n",
      "w1: [25.10251977] w2: [-22.87252218] bias: [16.49973332] loss: 30.608518507429196\n",
      "Epoch: 3714 / 5000\n",
      "w1: [25.10329072] w2: [-22.88343907] bias: [16.48659256] loss: 30.602305585801734\n",
      "Epoch: 3715 / 5000\n",
      "w1: [25.10553054] w2: [-22.89019627] bias: [16.48754088] loss: 30.60165037178538\n",
      "Epoch: 3716 / 5000\n",
      "w1: [25.08257744] w2: [-22.90470704] bias: [16.44395775] loss: 30.586788485878007\n",
      "Epoch: 3717 / 5000\n",
      "w1: [25.07351381] w2: [-22.90465435] bias: [16.44166813] loss: 30.586084872988668\n",
      "Epoch: 3718 / 5000\n",
      "w1: [25.08111908] w2: [-22.89890766] bias: [16.45148895] loss: 30.589069645839736\n",
      "Epoch: 3719 / 5000\n",
      "w1: [25.10241741] w2: [-22.88846543] bias: [16.49345451] loss: 30.603528816364854\n",
      "Epoch: 3720 / 5000\n",
      "w1: [25.10397664] w2: [-22.89413956] bias: [16.49890975] loss: 30.604478748531715\n",
      "Epoch: 3721 / 5000\n",
      "w1: [25.09583475] w2: [-22.90270141] bias: [16.47872492] loss: 30.596080210460894\n",
      "Epoch: 3722 / 5000\n",
      "w1: [25.10243601] w2: [-22.88326429] bias: [16.4995437] loss: 30.60648073495481\n",
      "Epoch: 3723 / 5000\n",
      "w1: [25.12679533] w2: [-22.85841994] bias: [16.54292449] loss: 30.63245673108886\n",
      "Epoch: 3724 / 5000\n",
      "w1: [25.1192411] w2: [-22.85985103] bias: [16.53779305] loss: 30.628501516879716\n",
      "Epoch: 3725 / 5000\n",
      "w1: [25.1326037] w2: [-22.86958471] bias: [16.54873093] loss: 30.633765818899636\n",
      "Epoch: 3726 / 5000\n",
      "w1: [25.11486639] w2: [-22.8733043] bias: [16.51649201] loss: 30.616113306262886\n",
      "Epoch: 3727 / 5000\n",
      "w1: [25.1068583] w2: [-22.88104892] bias: [16.49683272] loss: 30.606451052204037\n",
      "Epoch: 3728 / 5000\n",
      "w1: [25.08424548] w2: [-22.89086652] bias: [16.45504391] loss: 30.591161741057384\n",
      "Epoch: 3729 / 5000\n",
      "w1: [25.08919174] w2: [-22.87219916] bias: [16.47395005] loss: 30.59920130625864\n",
      "Epoch: 3730 / 5000\n",
      "w1: [25.06892412] w2: [-22.87050085] bias: [16.44982703] loss: 30.592274603372342\n",
      "Epoch: 3731 / 5000\n",
      "w1: [25.08621284] w2: [-22.86507408] bias: [16.48720653] loss: 30.604061670447468\n",
      "Epoch: 3732 / 5000\n",
      "w1: [25.06069146] w2: [-22.88074432] bias: [16.43993177] loss: 30.588632388009177\n",
      "Epoch: 3733 / 5000\n",
      "w1: [25.06144757] w2: [-22.8869146] bias: [16.44323178] loss: 30.588415479066754\n",
      "Epoch: 3734 / 5000\n",
      "w1: [25.05271613] w2: [-22.88178956] bias: [16.43432124] loss: 30.587398435295203\n",
      "Epoch: 3735 / 5000\n",
      "w1: [25.05549469] w2: [-22.88553043] bias: [16.43686088] loss: 30.587367280866165\n",
      "Epoch: 3736 / 5000\n",
      "w1: [25.07261731] w2: [-22.88282242] bias: [16.46651805] loss: 30.59442282859232\n",
      "Epoch: 3737 / 5000\n",
      "w1: [25.06009518] w2: [-22.88500418] bias: [16.44966841] loss: 30.58984697593526\n",
      "Epoch: 3738 / 5000\n",
      "w1: [25.06900673] w2: [-22.88015325] bias: [16.46725033] loss: 30.59479776222624\n",
      "Epoch: 3739 / 5000\n",
      "w1: [25.05257394] w2: [-22.8834066] bias: [16.4408312] loss: 30.58825260922893\n",
      "Epoch: 3740 / 5000\n",
      "w1: [25.04910576] w2: [-22.88772544] bias: [16.44362725] loss: 30.588088812774487\n",
      "Epoch: 3741 / 5000\n",
      "w1: [25.04018546] w2: [-22.89659197] bias: [16.42708975] loss: 30.584519735918924\n",
      "Epoch: 3742 / 5000\n",
      "w1: [25.05604168] w2: [-22.87203118] bias: [16.46762716] loss: 30.595403271011737\n",
      "Epoch: 3743 / 5000\n",
      "w1: [25.06574883] w2: [-22.87487554] bias: [16.48550595] loss: 30.600162009853513\n",
      "Epoch: 3744 / 5000\n",
      "w1: [25.0696755] w2: [-22.87456752] bias: [16.48862749] loss: 30.601410526553508\n",
      "Epoch: 3745 / 5000\n",
      "w1: [25.05805877] w2: [-22.87053769] bias: [16.47951994] loss: 30.598699121942907\n",
      "Epoch: 3746 / 5000\n",
      "w1: [25.05054493] w2: [-22.88103577] bias: [16.45922482] loss: 30.591974461959698\n",
      "Epoch: 3747 / 5000\n",
      "w1: [25.04256039] w2: [-22.89102478] bias: [16.44000557] loss: 30.586977494841502\n",
      "Epoch: 3748 / 5000\n",
      "w1: [25.03615101] w2: [-22.89232004] bias: [16.43060856] loss: 30.585474797978577\n",
      "Epoch: 3749 / 5000\n",
      "w1: [25.02755258] w2: [-22.89730118] bias: [16.41284296] loss: 30.58321646941069\n",
      "Epoch: 3750 / 5000\n",
      "w1: [25.02054852] w2: [-22.89947273] bias: [16.3980292] loss: 30.582373052976568\n",
      "Epoch: 3751 / 5000\n",
      "w1: [25.00452727] w2: [-22.89446688] bias: [16.38061188] loss: 30.583481842651473\n",
      "Epoch: 3752 / 5000\n",
      "w1: [24.99479037] w2: [-22.89555682] bias: [16.36621846] loss: 30.58461364293273\n",
      "Epoch: 3753 / 5000\n",
      "w1: [25.00967377] w2: [-22.89065306] bias: [16.3848219] loss: 30.583438056277508\n",
      "Epoch: 3754 / 5000\n",
      "w1: [24.98078506] w2: [-22.90040624] bias: [16.33953628] loss: 30.588126844257573\n",
      "Epoch: 3755 / 5000\n",
      "w1: [24.99613134] w2: [-22.90231782] bias: [16.35509809] loss: 30.58471119514688\n",
      "Epoch: 3756 / 5000\n",
      "w1: [25.02027245] w2: [-22.89156869] bias: [16.40629016] loss: 30.58357231543594\n",
      "Epoch: 3757 / 5000\n",
      "w1: [25.04942788] w2: [-22.89214666] bias: [16.44429619] loss: 30.587628483662577\n",
      "Epoch: 3758 / 5000\n",
      "w1: [25.06861043] w2: [-22.88932655] bias: [16.47719792] loss: 30.59582622689633\n",
      "Epoch: 3759 / 5000\n",
      "w1: [25.0552731] w2: [-22.89601003] bias: [16.45754266] loss: 30.589696518899146\n",
      "Epoch: 3760 / 5000\n",
      "w1: [25.05395513] w2: [-22.8861658] bias: [16.46170517] loss: 30.591893617733916\n",
      "Epoch: 3761 / 5000\n",
      "w1: [25.05600474] w2: [-22.88675512] bias: [16.45815796] loss: 30.59115215572637\n",
      "Epoch: 3762 / 5000\n",
      "w1: [25.05298608] w2: [-22.89703468] bias: [16.44367677] loss: 30.586956291327866\n",
      "Epoch: 3763 / 5000\n",
      "w1: [25.06112781] w2: [-22.89898879] bias: [16.45285236] loss: 30.58856687181677\n",
      "Epoch: 3764 / 5000\n",
      "w1: [25.07786492] w2: [-22.8910754] bias: [16.48628669] loss: 30.59866673427393\n",
      "Epoch: 3765 / 5000\n",
      "w1: [25.06571657] w2: [-22.89226332] bias: [16.46426507] loss: 30.592103263327292\n",
      "Epoch: 3766 / 5000\n",
      "w1: [25.06677166] w2: [-22.89346422] bias: [16.4681953] loss: 30.592880543283545\n",
      "Epoch: 3767 / 5000\n",
      "w1: [25.07840049] w2: [-22.89662108] bias: [16.47879051] loss: 30.59576055008177\n",
      "Epoch: 3768 / 5000\n",
      "w1: [25.09283796] w2: [-22.89929041] bias: [16.49836058] loss: 30.602241448053128\n",
      "Epoch: 3769 / 5000\n",
      "w1: [25.07215204] w2: [-22.90684213] bias: [16.46218929] loss: 30.58982972899674\n",
      "Epoch: 3770 / 5000\n",
      "w1: [25.08166885] w2: [-22.89389258] bias: [16.48528437] loss: 30.598226281842866\n",
      "Epoch: 3771 / 5000\n",
      "w1: [25.05298379] w2: [-22.90848608] bias: [16.43309444] loss: 30.583893123488856\n",
      "Epoch: 3772 / 5000\n",
      "w1: [25.06726273] w2: [-22.9111453] bias: [16.44400441] loss: 30.585484471116317\n",
      "Epoch: 3773 / 5000\n",
      "w1: [25.06405235] w2: [-22.9190137] bias: [16.43183271] loss: 30.582515758688373\n",
      "Epoch: 3774 / 5000\n",
      "w1: [25.0513958] w2: [-22.92577653] bias: [16.41715126] loss: 30.58006372507286\n",
      "Epoch: 3775 / 5000\n",
      "w1: [25.05819314] w2: [-22.9281128] bias: [16.42284249] loss: 30.580317859421484\n",
      "Epoch: 3776 / 5000\n",
      "w1: [25.05677531] w2: [-22.93625739] bias: [16.41038898] loss: 30.57826791256261\n",
      "Epoch: 3777 / 5000\n",
      "w1: [25.03804124] w2: [-22.9546503] bias: [16.36801478] loss: 30.57674622842407\n",
      "Epoch: 3778 / 5000\n",
      "w1: [25.05935789] w2: [-22.9603914] bias: [16.3877609] loss: 30.574765605137024\n",
      "Epoch: 3779 / 5000\n",
      "w1: [25.07441269] w2: [-22.94423823] bias: [16.41207257] loss: 30.5772594297026\n",
      "Epoch: 3780 / 5000\n",
      "w1: [25.06885758] w2: [-22.95647836] bias: [16.39358853] loss: 30.574868367373934\n",
      "Epoch: 3781 / 5000\n",
      "w1: [25.08110689] w2: [-22.94998521] bias: [16.40975347] loss: 30.576336177076392\n",
      "Epoch: 3782 / 5000\n",
      "w1: [25.07192663] w2: [-22.95411518] bias: [16.39982368] loss: 30.575329425389814\n",
      "Epoch: 3783 / 5000\n",
      "w1: [25.07110463] w2: [-22.96068] bias: [16.39680756] loss: 30.5745702553241\n",
      "Epoch: 3784 / 5000\n",
      "w1: [25.06832281] w2: [-22.97254606] bias: [16.38477577] loss: 30.573238241049058\n",
      "Epoch: 3785 / 5000\n",
      "w1: [25.06699137] w2: [-22.97239903] bias: [16.37792025] loss: 30.57323854270217\n",
      "Epoch: 3786 / 5000\n",
      "w1: [25.07290801] w2: [-22.97442904] bias: [16.3792913] loss: 30.57274176727717\n",
      "Epoch: 3787 / 5000\n",
      "w1: [25.08497889] w2: [-22.97308089] bias: [16.39185113] loss: 30.57268421912074\n",
      "Epoch: 3788 / 5000\n",
      "w1: [25.09140343] w2: [-22.97047329] bias: [16.40538894] loss: 30.573685847104393\n",
      "Epoch: 3789 / 5000\n",
      "w1: [25.11134224] w2: [-22.97166592] bias: [16.43574471] loss: 30.577473813231745\n",
      "Epoch: 3790 / 5000\n",
      "w1: [25.1144522] w2: [-22.96159053] bias: [16.44738278] loss: 30.5810041399574\n",
      "Epoch: 3791 / 5000\n",
      "w1: [25.11902186] w2: [-22.96480294] bias: [16.4523661] loss: 30.581804772297215\n",
      "Epoch: 3792 / 5000\n",
      "w1: [25.10417829] w2: [-22.97429253] bias: [16.43301652] loss: 30.576575009465486\n",
      "Epoch: 3793 / 5000\n",
      "w1: [25.10094919] w2: [-22.98155395] bias: [16.42165833] loss: 30.574157020261126\n",
      "Epoch: 3794 / 5000\n",
      "w1: [25.13900197] w2: [-22.96187905] bias: [16.48746042] loss: 30.592800524621715\n",
      "Epoch: 3795 / 5000\n",
      "w1: [25.13054622] w2: [-22.97605296] bias: [16.47743783] loss: 30.586945279875252\n",
      "Epoch: 3796 / 5000\n",
      "w1: [25.12792119] w2: [-22.96786632] bias: [16.4800417] loss: 30.58870151735086\n",
      "Epoch: 3797 / 5000\n",
      "w1: [25.14196129] w2: [-22.97179716] bias: [16.49673893] loss: 30.594366616316123\n",
      "Epoch: 3798 / 5000\n",
      "w1: [25.14130405] w2: [-22.97819204] bias: [16.48709919] loss: 30.590266534239912\n",
      "Epoch: 3799 / 5000\n",
      "w1: [25.13955013] w2: [-22.98192793] bias: [16.4855874] loss: 30.589067303157066\n",
      "Epoch: 3800 / 5000\n",
      "w1: [25.13510447] w2: [-22.98432945] bias: [16.48046888] loss: 30.5868686438128\n",
      "Epoch: 3801 / 5000\n",
      "w1: [25.14791565] w2: [-22.99136689] bias: [16.48953806] loss: 30.58951338315942\n",
      "Epoch: 3802 / 5000\n",
      "w1: [25.14754187] w2: [-22.99650265] bias: [16.49931137] loss: 30.591669280769235\n",
      "Epoch: 3803 / 5000\n",
      "w1: [25.14841223] w2: [-22.99969547] bias: [16.49555366] loss: 30.590059532908604\n",
      "Epoch: 3804 / 5000\n",
      "w1: [25.14999411] w2: [-23.00393504] bias: [16.49022111] loss: 30.587917934603595\n",
      "Epoch: 3805 / 5000\n",
      "w1: [25.15251407] w2: [-23.00487916] bias: [16.48851692] loss: 30.587500005920415\n",
      "Epoch: 3806 / 5000\n",
      "w1: [25.16859771] w2: [-22.98940939] bias: [16.51739219] loss: 30.60176022996324\n",
      "Epoch: 3807 / 5000\n",
      "w1: [25.16740481] w2: [-22.99692295] bias: [16.50533218] loss: 30.595860041385766\n",
      "Epoch: 3808 / 5000\n",
      "w1: [25.17556928] w2: [-22.98583341] bias: [16.5186214] loss: 30.603877715594923\n",
      "Epoch: 3809 / 5000\n",
      "w1: [25.17679378] w2: [-22.98910627] bias: [16.52680213] loss: 30.606711599263278\n",
      "Epoch: 3810 / 5000\n",
      "w1: [25.1667479] w2: [-22.99546956] bias: [16.5040442] loss: 30.595582597071243\n",
      "Epoch: 3811 / 5000\n",
      "w1: [25.16851471] w2: [-22.9961513] bias: [16.50599644] loss: 30.596364512367398\n",
      "Epoch: 3812 / 5000\n",
      "w1: [25.16654311] w2: [-22.9820833] bias: [16.51140106] loss: 30.60056849353036\n",
      "Epoch: 3813 / 5000\n",
      "w1: [25.15601104] w2: [-23.00268106] bias: [16.48251618] loss: 30.586407934425395\n",
      "Epoch: 3814 / 5000\n",
      "w1: [25.16965997] w2: [-23.00290109] bias: [16.49863294] loss: 30.592806359718857\n",
      "Epoch: 3815 / 5000\n",
      "w1: [25.17206778] w2: [-23.0031185] bias: [16.49860354] loss: 30.593037705299885\n",
      "Epoch: 3816 / 5000\n",
      "w1: [25.19102774] w2: [-23.00314803] bias: [16.53622572] loss: 30.610211796061577\n",
      "Epoch: 3817 / 5000\n",
      "w1: [25.19960186] w2: [-23.00373625] bias: [16.55702538] loss: 30.621159056425377\n",
      "Epoch: 3818 / 5000\n",
      "w1: [25.20376269] w2: [-22.99426436] bias: [16.56783222] loss: 30.62944567974889\n",
      "Epoch: 3819 / 5000\n",
      "w1: [25.23154379] w2: [-22.98177293] bias: [16.61580555] loss: 30.6671298303545\n",
      "Epoch: 3820 / 5000\n",
      "w1: [25.24455545] w2: [-22.98499618] bias: [16.63292149] loss: 30.681524600149626\n",
      "Epoch: 3821 / 5000\n",
      "w1: [25.24188842] w2: [-22.98948681] bias: [16.62938194] loss: 30.677064763234196\n",
      "Epoch: 3822 / 5000\n",
      "w1: [25.22936924] w2: [-23.00411136] bias: [16.60283713] loss: 30.652721745801795\n",
      "Epoch: 3823 / 5000\n",
      "w1: [25.23716984] w2: [-23.00856021] bias: [16.61051923] loss: 30.658393805603872\n",
      "Epoch: 3824 / 5000\n",
      "w1: [25.21829327] w2: [-23.00551003] bias: [16.59005723] loss: 30.642140573354236\n",
      "Epoch: 3825 / 5000\n",
      "w1: [25.20209357] w2: [-23.00264391] bias: [16.57475694] loss: 30.63081343598814\n",
      "Epoch: 3826 / 5000\n",
      "w1: [25.19018087] w2: [-23.00025063] bias: [16.55902886] loss: 30.62105576581533\n",
      "Epoch: 3827 / 5000\n",
      "w1: [25.18838701] w2: [-23.00356085] bias: [16.54852231] loss: 30.615131497914412\n",
      "Epoch: 3828 / 5000\n",
      "w1: [25.18791958] w2: [-23.00710198] bias: [16.5429825] loss: 30.61185571810966\n",
      "Epoch: 3829 / 5000\n",
      "w1: [25.19482593] w2: [-23.01700503] bias: [16.53879788] loss: 30.60923236937644\n",
      "Epoch: 3830 / 5000\n",
      "w1: [25.18688216] w2: [-23.02605435] bias: [16.52074415] loss: 30.59891900469122\n",
      "Epoch: 3831 / 5000\n",
      "w1: [25.20063194] w2: [-23.0158581] bias: [16.54917754] loss: 30.615120768723184\n",
      "Epoch: 3832 / 5000\n",
      "w1: [25.18933561] w2: [-23.01282381] bias: [16.5310908] loss: 30.60588058168698\n",
      "Epoch: 3833 / 5000\n",
      "w1: [25.16806726] w2: [-23.02397153] bias: [16.4952758] loss: 30.58806909047641\n",
      "Epoch: 3834 / 5000\n",
      "w1: [25.19807429] w2: [-23.02673185] bias: [16.52959409] loss: 30.6039880094792\n",
      "Epoch: 3835 / 5000\n",
      "w1: [25.19159678] w2: [-23.03451174] bias: [16.52812114] loss: 30.600944790603325\n",
      "Epoch: 3836 / 5000\n",
      "w1: [25.1878366] w2: [-23.03329428] bias: [16.52135724] loss: 30.59798295566502\n",
      "Epoch: 3837 / 5000\n",
      "w1: [25.18975197] w2: [-23.03443691] bias: [16.52119288] loss: 30.59798447092935\n",
      "Epoch: 3838 / 5000\n",
      "w1: [25.18199167] w2: [-23.03233392] bias: [16.51151474] loss: 30.593736871405127\n",
      "Epoch: 3839 / 5000\n",
      "w1: [25.18700872] w2: [-23.04115335] bias: [16.5210809] loss: 30.596360817130385\n",
      "Epoch: 3840 / 5000\n",
      "w1: [25.18157589] w2: [-23.03960248] bias: [16.51514143] loss: 30.593727821516502\n",
      "Epoch: 3841 / 5000\n",
      "w1: [25.17423311] w2: [-23.04055031] bias: [16.50248698] loss: 30.58835978984881\n",
      "Epoch: 3842 / 5000\n",
      "w1: [25.19241713] w2: [-23.02870205] bias: [16.52757995] loss: 30.60192738507641\n",
      "Epoch: 3843 / 5000\n",
      "w1: [25.19734116] w2: [-23.03797167] bias: [16.51996095] loss: 30.597953596765013\n",
      "Epoch: 3844 / 5000\n",
      "w1: [25.20804374] w2: [-23.03875203] bias: [16.53225084] loss: 30.604403799168555\n",
      "Epoch: 3845 / 5000\n",
      "w1: [25.22461327] w2: [-23.04037001] bias: [16.54631124] loss: 30.613204410730493\n",
      "Epoch: 3846 / 5000\n",
      "w1: [25.22589394] w2: [-23.04195951] bias: [16.54696651] loss: 30.613425544150328\n",
      "Epoch: 3847 / 5000\n",
      "w1: [25.21168166] w2: [-23.05247168] bias: [16.51806729] loss: 30.596682722618976\n",
      "Epoch: 3848 / 5000\n",
      "w1: [25.21074589] w2: [-23.05071322] bias: [16.51008802] loss: 30.5938256034438\n",
      "Epoch: 3849 / 5000\n",
      "w1: [25.21125262] w2: [-23.05170438] bias: [16.5079199] loss: 30.592918905700298\n",
      "Epoch: 3850 / 5000\n",
      "w1: [25.20789083] w2: [-23.05994844] bias: [16.49578348] loss: 30.586837571700332\n",
      "Epoch: 3851 / 5000\n",
      "w1: [25.21133515] w2: [-23.06716294] bias: [16.48761697] loss: 30.58340455449461\n",
      "Epoch: 3852 / 5000\n",
      "w1: [25.18933784] w2: [-23.08155209] bias: [16.44685197] loss: 30.568967304486186\n",
      "Epoch: 3853 / 5000\n",
      "w1: [25.16754898] w2: [-23.09052265] bias: [16.40952384] loss: 30.561765940945442\n",
      "Epoch: 3854 / 5000\n",
      "w1: [25.15161458] w2: [-23.10800731] bias: [16.37595701] loss: 30.559023033089606\n",
      "Epoch: 3855 / 5000\n",
      "w1: [25.17610063] w2: [-23.10289079] bias: [16.41172516] loss: 30.560841064586064\n",
      "Epoch: 3856 / 5000\n",
      "w1: [25.17990852] w2: [-23.10884467] bias: [16.40500668] loss: 30.559608210354583\n",
      "Epoch: 3857 / 5000\n",
      "w1: [25.17754422] w2: [-23.10847899] bias: [16.4032548] loss: 30.55949810992937\n",
      "Epoch: 3858 / 5000\n",
      "w1: [25.17441116] w2: [-23.11250572] bias: [16.39574278] loss: 30.558618468628083\n",
      "Epoch: 3859 / 5000\n",
      "w1: [25.18017818] w2: [-23.1082945] bias: [16.40548708] loss: 30.559700978950744\n",
      "Epoch: 3860 / 5000\n",
      "w1: [25.17938757] w2: [-23.10802356] bias: [16.41543124] loss: 30.56078442367074\n",
      "Epoch: 3861 / 5000\n",
      "w1: [25.16519208] w2: [-23.11874705] bias: [16.38507829] loss: 30.557882280901158\n",
      "Epoch: 3862 / 5000\n",
      "w1: [25.1586313] w2: [-23.12184184] bias: [16.370562] loss: 30.55778757433665\n",
      "Epoch: 3863 / 5000\n",
      "w1: [25.15735647] w2: [-23.12339877] bias: [16.37734643] loss: 30.557779593632514\n",
      "Epoch: 3864 / 5000\n",
      "w1: [25.18082286] w2: [-23.11572364] bias: [16.42252398] loss: 30.560921783727682\n",
      "Epoch: 3865 / 5000\n",
      "w1: [25.18773033] w2: [-23.12345489] bias: [16.42144965] loss: 30.560111536911794\n",
      "Epoch: 3866 / 5000\n",
      "w1: [25.19104818] w2: [-23.12918814] bias: [16.41848457] loss: 30.559229510737868\n",
      "Epoch: 3867 / 5000\n",
      "w1: [25.18491943] w2: [-23.12735882] bias: [16.40883575] loss: 30.55833206310533\n",
      "Epoch: 3868 / 5000\n",
      "w1: [25.1652664] w2: [-23.14398725] bias: [16.37120033] loss: 30.55615107545239\n",
      "Epoch: 3869 / 5000\n",
      "w1: [25.17004578] w2: [-23.13552596] bias: [16.38257514] loss: 30.556489780075793\n",
      "Epoch: 3870 / 5000\n",
      "w1: [25.16726158] w2: [-23.12777945] bias: [16.38383127] loss: 30.55714833831558\n",
      "Epoch: 3871 / 5000\n",
      "w1: [25.17185974] w2: [-23.13358515] bias: [16.39498115] loss: 30.557027574499283\n",
      "Epoch: 3872 / 5000\n",
      "w1: [25.13258363] w2: [-23.14747828] bias: [16.3388459] loss: 30.560791277582577\n",
      "Epoch: 3873 / 5000\n",
      "w1: [25.1266036] w2: [-23.1569344] bias: [16.33526838] loss: 30.561729736444263\n",
      "Epoch: 3874 / 5000\n",
      "w1: [25.12126169] w2: [-23.16794482] bias: [16.32550399] loss: 30.56370685676111\n",
      "Epoch: 3875 / 5000\n",
      "w1: [25.1159406] w2: [-23.16788037] bias: [16.32677837] loss: 30.564253358309514\n",
      "Epoch: 3876 / 5000\n",
      "w1: [25.11075864] w2: [-23.17580399] bias: [16.30900699] loss: 30.568365663927068\n",
      "Epoch: 3877 / 5000\n",
      "w1: [25.09742797] w2: [-23.17761211] bias: [16.28732876] loss: 30.57598479880453\n",
      "Epoch: 3878 / 5000\n",
      "w1: [25.10779694] w2: [-23.18321525] bias: [16.28989609] loss: 30.573435866286637\n",
      "Epoch: 3879 / 5000\n",
      "w1: [25.10099555] w2: [-23.18009853] bias: [16.28269327] loss: 30.5765965886484\n",
      "Epoch: 3880 / 5000\n",
      "w1: [25.10660361] w2: [-23.17785339] bias: [16.28912859] loss: 30.57374542605884\n",
      "Epoch: 3881 / 5000\n",
      "w1: [25.1183641] w2: [-23.17518928] bias: [16.31586379] loss: 30.565784789238347\n",
      "Epoch: 3882 / 5000\n",
      "w1: [25.12547455] w2: [-23.18845629] bias: [16.32072794] loss: 30.563815618212157\n",
      "Epoch: 3883 / 5000\n",
      "w1: [25.12049349] w2: [-23.19722236] bias: [16.30979523] loss: 30.566760700815674\n",
      "Epoch: 3884 / 5000\n",
      "w1: [25.11296532] w2: [-23.19767567] bias: [16.29847986] loss: 30.5706316586191\n",
      "Epoch: 3885 / 5000\n",
      "w1: [25.10459027] w2: [-23.19576506] bias: [16.28779421] loss: 30.574910365932503\n",
      "Epoch: 3886 / 5000\n",
      "w1: [25.10440842] w2: [-23.18210445] bias: [16.29616053] loss: 30.572481104513212\n",
      "Epoch: 3887 / 5000\n",
      "w1: [25.09713591] w2: [-23.18767378] bias: [16.2797219] loss: 30.578443689471378\n",
      "Epoch: 3888 / 5000\n",
      "w1: [25.08640098] w2: [-23.19418968] bias: [16.26321204] loss: 30.58623886130036\n",
      "Epoch: 3889 / 5000\n",
      "w1: [25.07936955] w2: [-23.1971265] bias: [16.25416048] loss: 30.591254744527987\n",
      "Epoch: 3890 / 5000\n",
      "w1: [25.10321514] w2: [-23.20217942] bias: [16.27997357] loss: 30.577577738040922\n",
      "Epoch: 3891 / 5000\n",
      "w1: [25.10001875] w2: [-23.19827769] bias: [16.27716419] loss: 30.578942765870856\n",
      "Epoch: 3892 / 5000\n",
      "w1: [25.09143397] w2: [-23.20500575] bias: [16.26075389] loss: 30.586411179253435\n",
      "Epoch: 3893 / 5000\n",
      "w1: [25.11105995] w2: [-23.20343593] bias: [16.29339574] loss: 30.572373223463785\n",
      "Epoch: 3894 / 5000\n",
      "w1: [25.09866204] w2: [-23.21485612] bias: [16.2656035] loss: 30.583562377703043\n",
      "Epoch: 3895 / 5000\n",
      "w1: [25.10194204] w2: [-23.22200303] bias: [16.26521423] loss: 30.583276692031237\n",
      "Epoch: 3896 / 5000\n",
      "w1: [25.10257577] w2: [-23.21826734] bias: [16.26648558] loss: 30.582535381622186\n",
      "Epoch: 3897 / 5000\n",
      "w1: [25.09991724] w2: [-23.22018647] bias: [16.26119742] loss: 30.585017666626655\n",
      "Epoch: 3898 / 5000\n",
      "w1: [25.09793084] w2: [-23.22120353] bias: [16.2615595] loss: 30.58541219616275\n",
      "Epoch: 3899 / 5000\n",
      "w1: [25.11414505] w2: [-23.22703171] bias: [16.27851547] loss: 30.576604124544613\n",
      "Epoch: 3900 / 5000\n",
      "w1: [25.10239573] w2: [-23.23268884] bias: [16.25690337] loss: 30.586591837745203\n",
      "Epoch: 3901 / 5000\n",
      "w1: [25.09108539] w2: [-23.24368537] bias: [16.23114209] loss: 30.6003448196364\n",
      "Epoch: 3902 / 5000\n",
      "w1: [25.08081387] w2: [-23.24968196] bias: [16.21244059] loss: 30.61230932686204\n",
      "Epoch: 3903 / 5000\n",
      "w1: [25.10569529] w2: [-23.23730892] bias: [16.25337554] loss: 30.58732158196376\n",
      "Epoch: 3904 / 5000\n",
      "w1: [25.10302138] w2: [-23.24528735] bias: [16.24471079] loss: 30.59173970330418\n",
      "Epoch: 3905 / 5000\n",
      "w1: [25.10024268] w2: [-23.24426203] bias: [16.24349566] loss: 30.59286420906508\n",
      "Epoch: 3906 / 5000\n",
      "w1: [25.10389797] w2: [-23.22463588] bias: [16.26780843] loss: 30.5820950308129\n",
      "Epoch: 3907 / 5000\n",
      "w1: [25.09784888] w2: [-23.22840166] bias: [16.25782485] loss: 30.58712450102938\n",
      "Epoch: 3908 / 5000\n",
      "w1: [25.10319584] w2: [-23.22491522] bias: [16.271955] loss: 30.580919508430576\n",
      "Epoch: 3909 / 5000\n",
      "w1: [25.10178311] w2: [-23.21171266] bias: [16.27503542] loss: 30.579709461628536\n",
      "Epoch: 3910 / 5000\n",
      "w1: [25.10234032] w2: [-23.2130812] bias: [16.27675561] loss: 30.579114771225157\n",
      "Epoch: 3911 / 5000\n",
      "w1: [25.08256019] w2: [-23.21250001] bias: [16.25308798] loss: 30.59172046572298\n",
      "Epoch: 3912 / 5000\n",
      "w1: [25.07507334] w2: [-23.21742938] bias: [16.264221] loss: 30.58977217774673\n",
      "Epoch: 3913 / 5000\n",
      "w1: [25.06717801] w2: [-23.21913856] bias: [16.25349258] loss: 30.59591535866012\n",
      "Epoch: 3914 / 5000\n",
      "w1: [25.08597194] w2: [-23.20517357] bias: [16.28341178] loss: 30.58031329550743\n",
      "Epoch: 3915 / 5000\n",
      "w1: [25.09113034] w2: [-23.19507972] bias: [16.30375304] loss: 30.57332439152245\n",
      "Epoch: 3916 / 5000\n",
      "w1: [25.09738468] w2: [-23.18834894] bias: [16.31533693] loss: 30.569373713174034\n",
      "Epoch: 3917 / 5000\n",
      "w1: [25.10204412] w2: [-23.20037797] bias: [16.30875709] loss: 30.57020491446083\n",
      "Epoch: 3918 / 5000\n",
      "w1: [25.09989306] w2: [-23.1986239] bias: [16.30487743] loss: 30.5714877095471\n",
      "Epoch: 3919 / 5000\n",
      "w1: [25.09650335] w2: [-23.19140097] bias: [16.30905275] loss: 30.570985713398752\n",
      "Epoch: 3920 / 5000\n",
      "w1: [25.10358489] w2: [-23.17906348] bias: [16.32890333] loss: 30.565645825539814\n",
      "Epoch: 3921 / 5000\n",
      "w1: [25.11288543] w2: [-23.1763512] bias: [16.34181224] loss: 30.562288053141657\n",
      "Epoch: 3922 / 5000\n",
      "w1: [25.10900019] w2: [-23.18154513] bias: [16.32299801] loss: 30.56589889845953\n",
      "Epoch: 3923 / 5000\n",
      "w1: [25.0900828] w2: [-23.18528416] bias: [16.29161504] loss: 30.57647575319472\n",
      "Epoch: 3924 / 5000\n",
      "w1: [25.08346047] w2: [-23.18041228] bias: [16.28195289] loss: 30.580428486752798\n",
      "Epoch: 3925 / 5000\n",
      "w1: [25.06642534] w2: [-23.1872364] bias: [16.25559662] loss: 30.593413797173586\n",
      "Epoch: 3926 / 5000\n",
      "w1: [25.07422923] w2: [-23.18582069] bias: [16.26645745] loss: 30.5876045227757\n",
      "Epoch: 3927 / 5000\n",
      "w1: [25.0844044] w2: [-23.18304762] bias: [16.27901563] loss: 30.581190295676116\n",
      "Epoch: 3928 / 5000\n",
      "w1: [25.09428675] w2: [-23.17602949] bias: [16.29832458] loss: 30.573718660534485\n",
      "Epoch: 3929 / 5000\n",
      "w1: [25.08757925] w2: [-23.17775455] bias: [16.30930714] loss: 30.5723285625816\n",
      "Epoch: 3930 / 5000\n",
      "w1: [25.11341049] w2: [-23.17969747] bias: [16.34170716] loss: 30.562191287127124\n",
      "Epoch: 3931 / 5000\n",
      "w1: [25.11891121] w2: [-23.17624521] bias: [16.34909807] loss: 30.560578059459985\n",
      "Epoch: 3932 / 5000\n",
      "w1: [25.11911795] w2: [-23.17769159] bias: [16.34945276] loss: 30.56048257212588\n",
      "Epoch: 3933 / 5000\n",
      "w1: [25.10669977] w2: [-23.18077972] bias: [16.32911909] loss: 30.565137253551576\n",
      "Epoch: 3934 / 5000\n",
      "w1: [25.09977825] w2: [-23.18759754] bias: [16.31526094] loss: 30.568975792027523\n",
      "Epoch: 3935 / 5000\n",
      "w1: [25.10290344] w2: [-23.18178702] bias: [16.32154333] loss: 30.56713314470532\n",
      "Epoch: 3936 / 5000\n",
      "w1: [25.1079452] w2: [-23.17966023] bias: [16.32973509] loss: 30.5648487913956\n",
      "Epoch: 3937 / 5000\n",
      "w1: [25.11515326] w2: [-23.17541196] bias: [16.34268165] loss: 30.561886058663788\n",
      "Epoch: 3938 / 5000\n",
      "w1: [25.11944384] w2: [-23.17030276] bias: [16.35184475] loss: 30.560321539981146\n",
      "Epoch: 3939 / 5000\n",
      "w1: [25.12410905] w2: [-23.16936215] bias: [16.35943814] loss: 30.559068917811995\n",
      "Epoch: 3940 / 5000\n",
      "w1: [25.13157806] w2: [-23.16502535] bias: [16.37383474] loss: 30.557497590340688\n",
      "Epoch: 3941 / 5000\n",
      "w1: [25.14382979] w2: [-23.1647257] bias: [16.38720777] loss: 30.5561978971463\n",
      "Epoch: 3942 / 5000\n",
      "w1: [25.14880176] w2: [-23.1619001] bias: [16.39402183] loss: 30.556062285472162\n",
      "Epoch: 3943 / 5000\n",
      "w1: [25.13545658] w2: [-23.17050878] bias: [16.3682383] loss: 30.55726857401962\n",
      "Epoch: 3944 / 5000\n",
      "w1: [25.1247224] w2: [-23.16600363] bias: [16.3557266] loss: 30.55944447621976\n",
      "Epoch: 3945 / 5000\n",
      "w1: [25.1573355] w2: [-23.16198033] bias: [16.39298726] loss: 30.555623130431204\n",
      "Epoch: 3946 / 5000\n",
      "w1: [25.1533382] w2: [-23.1662374] bias: [16.38197509] loss: 30.555592009986327\n",
      "Epoch: 3947 / 5000\n",
      "w1: [25.17201427] w2: [-23.15639145] bias: [16.41240626] loss: 30.55639518752631\n",
      "Epoch: 3948 / 5000\n",
      "w1: [25.16554143] w2: [-23.15482841] bias: [16.40410792] loss: 30.556147521118483\n",
      "Epoch: 3949 / 5000\n",
      "w1: [25.15131626] w2: [-23.15598271] bias: [16.38041556] loss: 30.55627166749267\n",
      "Epoch: 3950 / 5000\n",
      "w1: [25.15073595] w2: [-23.15313224] bias: [16.38266042] loss: 30.556438571001458\n",
      "Epoch: 3951 / 5000\n",
      "w1: [25.15389326] w2: [-23.13043176] bias: [16.40252978] loss: 30.558178332128982\n",
      "Epoch: 3952 / 5000\n",
      "w1: [25.13413166] w2: [-23.141577] bias: [16.37325742] loss: 30.558350078661665\n",
      "Epoch: 3953 / 5000\n",
      "w1: [25.15242947] w2: [-23.12876097] bias: [16.40021673] loss: 30.558236629311544\n",
      "Epoch: 3954 / 5000\n",
      "w1: [25.18588716] w2: [-23.11824911] bias: [16.44017372] loss: 30.563353079378423\n",
      "Epoch: 3955 / 5000\n",
      "w1: [25.16967209] w2: [-23.12172304] bias: [16.41412827] loss: 30.559421247691233\n",
      "Epoch: 3956 / 5000\n",
      "w1: [25.17296264] w2: [-23.12384355] bias: [16.42211965] loss: 30.560056060764303\n",
      "Epoch: 3957 / 5000\n",
      "w1: [25.15802698] w2: [-23.12464615] bias: [16.39740996] loss: 30.55822156661199\n",
      "Epoch: 3958 / 5000\n",
      "w1: [25.15522418] w2: [-23.1315921] bias: [16.39821759] loss: 30.557852443399856\n",
      "Epoch: 3959 / 5000\n",
      "w1: [25.14357264] w2: [-23.14067193] bias: [16.38336923] loss: 30.557550721222373\n",
      "Epoch: 3960 / 5000\n",
      "w1: [25.14926166] w2: [-23.14673557] bias: [16.37976895] loss: 30.556899390528287\n",
      "Epoch: 3961 / 5000\n",
      "w1: [25.14742702] w2: [-23.14511565] bias: [16.37839224] loss: 30.557117657448043\n",
      "Epoch: 3962 / 5000\n",
      "w1: [25.11984653] w2: [-23.1449849] bias: [16.34757376] loss: 30.561361920718856\n",
      "Epoch: 3963 / 5000\n",
      "w1: [25.11687818] w2: [-23.14389575] bias: [16.34735055] loss: 30.561748825068978\n",
      "Epoch: 3964 / 5000\n",
      "w1: [25.1408982] w2: [-23.13343465] bias: [16.39201252] loss: 30.55816325514184\n",
      "Epoch: 3965 / 5000\n",
      "w1: [25.15078189] w2: [-23.13709077] bias: [16.40162896] loss: 30.557762327098718\n",
      "Epoch: 3966 / 5000\n",
      "w1: [25.14248644] w2: [-23.13327028] bias: [16.39170932] loss: 30.55809032050286\n",
      "Epoch: 3967 / 5000\n",
      "w1: [25.16180648] w2: [-23.12960751] bias: [16.41249469] loss: 30.558701990697664\n",
      "Epoch: 3968 / 5000\n",
      "w1: [25.17139293] w2: [-23.12724467] bias: [16.42712808] loss: 30.560315208242056\n",
      "Epoch: 3969 / 5000\n",
      "w1: [25.16533039] w2: [-23.13311016] bias: [16.40904055] loss: 30.558097572334994\n",
      "Epoch: 3970 / 5000\n",
      "w1: [25.16046764] w2: [-23.13529184] bias: [16.39915977] loss: 30.55745668655746\n",
      "Epoch: 3971 / 5000\n",
      "w1: [25.17450586] w2: [-23.12700638] bias: [16.43035619] loss: 30.56076660727198\n",
      "Epoch: 3972 / 5000\n",
      "w1: [25.17477911] w2: [-23.12162736] bias: [16.43167903] loss: 30.56147182839602\n",
      "Epoch: 3973 / 5000\n",
      "w1: [25.19024648] w2: [-23.12527558] bias: [16.45874192] loss: 30.56616499561908\n",
      "Epoch: 3974 / 5000\n",
      "w1: [25.19757397] w2: [-23.12739048] bias: [16.46182865] loss: 30.56695395063812\n",
      "Epoch: 3975 / 5000\n",
      "w1: [25.18886594] w2: [-23.13404968] bias: [16.44729641] loss: 30.56294532334359\n",
      "Epoch: 3976 / 5000\n",
      "w1: [25.18899918] w2: [-23.13180942] bias: [16.44833638] loss: 30.563378918869375\n",
      "Epoch: 3977 / 5000\n",
      "w1: [25.19568829] w2: [-23.12352422] bias: [16.46881454] loss: 30.56887968398438\n",
      "Epoch: 3978 / 5000\n",
      "w1: [25.19648064] w2: [-23.12301976] bias: [16.46688264] loss: 30.568551672995504\n",
      "Epoch: 3979 / 5000\n",
      "w1: [25.18269081] w2: [-23.12475541] bias: [16.44279103] loss: 30.562988266168926\n",
      "Epoch: 3980 / 5000\n",
      "w1: [25.16304634] w2: [-23.13716174] bias: [16.4084977] loss: 30.5577848300952\n",
      "Epoch: 3981 / 5000\n",
      "w1: [25.15719541] w2: [-23.12611035] bias: [16.40637829] loss: 30.55863427871197\n",
      "Epoch: 3982 / 5000\n",
      "w1: [25.15520524] w2: [-23.13366693] bias: [16.39421007] loss: 30.557559117410374\n",
      "Epoch: 3983 / 5000\n",
      "w1: [25.14378894] w2: [-23.13676588] bias: [16.37264763] loss: 30.557902349147607\n",
      "Epoch: 3984 / 5000\n",
      "w1: [25.14688029] w2: [-23.12967996] bias: [16.37867963] loss: 30.557999348547938\n",
      "Epoch: 3985 / 5000\n",
      "w1: [25.1592578] w2: [-23.13670343] bias: [16.3874957] loss: 30.55700411974432\n",
      "Epoch: 3986 / 5000\n",
      "w1: [25.1507889] w2: [-23.14420381] bias: [16.36793258] loss: 30.557167330755846\n",
      "Epoch: 3987 / 5000\n",
      "w1: [25.14089807] w2: [-23.13439521] bias: [16.36545604] loss: 30.558460903677993\n",
      "Epoch: 3988 / 5000\n",
      "w1: [25.13017091] w2: [-23.14066265] bias: [16.34515771] loss: 30.56059363621868\n",
      "Epoch: 3989 / 5000\n",
      "w1: [25.12174771] w2: [-23.15415689] bias: [16.32034647] loss: 30.564583973042513\n",
      "Epoch: 3990 / 5000\n",
      "w1: [25.13270128] w2: [-23.15123223] bias: [16.33339941] loss: 30.561327085534405\n",
      "Epoch: 3991 / 5000\n",
      "w1: [25.15214314] w2: [-23.13566382] bias: [16.37217498] loss: 30.557408000664502\n",
      "Epoch: 3992 / 5000\n",
      "w1: [25.16371139] w2: [-23.12847217] bias: [16.38639556] loss: 30.55732295366139\n",
      "Epoch: 3993 / 5000\n",
      "w1: [25.17627728] w2: [-23.13381062] bias: [16.39393044] loss: 30.55683047098472\n",
      "Epoch: 3994 / 5000\n",
      "w1: [25.18106209] w2: [-23.1387473] bias: [16.39341471] loss: 30.556309968766648\n",
      "Epoch: 3995 / 5000\n",
      "w1: [25.16253541] w2: [-23.15494253] bias: [16.34988287] loss: 30.5565953258143\n",
      "Epoch: 3996 / 5000\n",
      "w1: [25.16775487] w2: [-23.15975563] bias: [16.35182621] loss: 30.555851669775738\n",
      "Epoch: 3997 / 5000\n",
      "w1: [25.15525427] w2: [-23.16977355] bias: [16.3298259] loss: 30.558705477069754\n",
      "Epoch: 3998 / 5000\n",
      "w1: [25.14657618] w2: [-23.18217634] bias: [16.3060626] loss: 30.563300640360218\n",
      "Epoch: 3999 / 5000\n",
      "w1: [25.14216742] w2: [-23.18378539] bias: [16.29637157] loss: 30.565879872791662\n",
      "Epoch: 4000 / 5000\n",
      "w1: [25.1471253] w2: [-23.18267446] bias: [16.30333449] loss: 30.563720744844794\n",
      "Epoch: 4001 / 5000\n",
      "w1: [25.13424454] w2: [-23.18874458] bias: [16.27790985] loss: 30.571608710268933\n",
      "Epoch: 4002 / 5000\n",
      "w1: [25.14276698] w2: [-23.18887497] bias: [16.30502242] loss: 30.564090634996102\n",
      "Epoch: 4003 / 5000\n",
      "w1: [25.12494422] w2: [-23.19557547] bias: [16.27996915] loss: 30.573016297121857\n",
      "Epoch: 4004 / 5000\n",
      "w1: [25.11105659] w2: [-23.19953991] bias: [16.25788799] loss: 30.582583802319096\n",
      "Epoch: 4005 / 5000\n",
      "w1: [25.08981463] w2: [-23.20344066] bias: [16.23902062] loss: 30.59467320007923\n",
      "Epoch: 4006 / 5000\n",
      "w1: [25.10368341] w2: [-23.20339201] bias: [16.27856995] loss: 30.577931949259867\n",
      "Epoch: 4007 / 5000\n",
      "w1: [25.08634279] w2: [-23.19912434] bias: [16.25655048] loss: 30.588796420997703\n",
      "Epoch: 4008 / 5000\n",
      "w1: [25.11441817] w2: [-23.19013287] bias: [16.31292453] loss: 30.56705053494832\n",
      "Epoch: 4009 / 5000\n",
      "w1: [25.1376636] w2: [-23.17994513] bias: [16.34615568] loss: 30.558660536157948\n",
      "Epoch: 4010 / 5000\n",
      "w1: [25.12775855] w2: [-23.18202825] bias: [16.33520369] loss: 30.56121351785979\n",
      "Epoch: 4011 / 5000\n",
      "w1: [25.10836104] w2: [-23.18657384] bias: [16.30416651] loss: 30.569943831186205\n",
      "Epoch: 4012 / 5000\n",
      "w1: [25.10540433] w2: [-23.19083845] bias: [16.29623485] loss: 30.57244495126715\n",
      "Epoch: 4013 / 5000\n",
      "w1: [25.10628952] w2: [-23.20368084] bias: [16.28269987] loss: 30.576209449126484\n",
      "Epoch: 4014 / 5000\n",
      "w1: [25.08729876] w2: [-23.21534987] bias: [16.24818543] loss: 30.59253527993194\n",
      "Epoch: 4015 / 5000\n",
      "w1: [25.09480941] w2: [-23.21380349] bias: [16.25513693] loss: 30.588023660631013\n",
      "Epoch: 4016 / 5000\n",
      "w1: [25.10268426] w2: [-23.21942114] bias: [16.25278426] loss: 30.587260769464375\n",
      "Epoch: 4017 / 5000\n",
      "w1: [25.10995751] w2: [-23.22272629] bias: [16.25727531] loss: 30.5841365849045\n",
      "Epoch: 4018 / 5000\n",
      "w1: [25.10810441] w2: [-23.22667264] bias: [16.24985418] loss: 30.587399136859453\n",
      "Epoch: 4019 / 5000\n",
      "w1: [25.10253539] w2: [-23.22789227] bias: [16.23595025] loss: 30.594141460331805\n",
      "Epoch: 4020 / 5000\n",
      "w1: [25.11212998] w2: [-23.22294428] bias: [16.25108477] loss: 30.585782717840832\n",
      "Epoch: 4021 / 5000\n",
      "w1: [25.12263279] w2: [-23.21994163] bias: [16.26145383] loss: 30.579740815722445\n",
      "Epoch: 4022 / 5000\n",
      "w1: [25.13088634] w2: [-23.21963899] bias: [16.27018842] loss: 30.575291391956995\n",
      "Epoch: 4023 / 5000\n",
      "w1: [25.11676859] w2: [-23.2208027] bias: [16.24837893] loss: 30.58551191592774\n",
      "Epoch: 4024 / 5000\n",
      "w1: [25.12800974] w2: [-23.21587165] bias: [16.26773221] loss: 30.57647885768638\n",
      "Epoch: 4025 / 5000\n",
      "w1: [25.1135287] w2: [-23.22347976] bias: [16.24617505] loss: 30.587225091067317\n",
      "Epoch: 4026 / 5000\n",
      "w1: [25.10673259] w2: [-23.22469911] bias: [16.23292832] loss: 30.594024206807024\n",
      "Epoch: 4027 / 5000\n",
      "w1: [25.10519259] w2: [-23.2263273] bias: [16.24123943] loss: 30.59130070601767\n",
      "Epoch: 4028 / 5000\n",
      "w1: [25.09554684] w2: [-23.22357651] bias: [16.24443317] loss: 30.592368412849336\n",
      "Epoch: 4029 / 5000\n",
      "w1: [25.10997599] w2: [-23.21096208] bias: [16.2706676] loss: 30.579250468592573\n",
      "Epoch: 4030 / 5000\n",
      "w1: [25.10788039] w2: [-23.21958904] bias: [16.25645903] loss: 30.584744172658738\n",
      "Epoch: 4031 / 5000\n",
      "w1: [25.11639734] w2: [-23.216594] bias: [16.28731758] loss: 30.573292082865095\n",
      "Epoch: 4032 / 5000\n",
      "w1: [25.13348899] w2: [-23.21189041] bias: [16.32215579] loss: 30.562377194893926\n",
      "Epoch: 4033 / 5000\n",
      "w1: [25.12808616] w2: [-23.21319507] bias: [16.30617802] loss: 30.5664485489981\n",
      "Epoch: 4034 / 5000\n",
      "w1: [25.13471787] w2: [-23.21462423] bias: [16.31397537] loss: 30.563750820264268\n",
      "Epoch: 4035 / 5000\n",
      "w1: [25.15318833] w2: [-23.21106973] bias: [16.35288732] loss: 30.555577551536036\n",
      "Epoch: 4036 / 5000\n",
      "w1: [25.14511082] w2: [-23.20812194] bias: [16.34914466] loss: 30.55691732834489\n",
      "Epoch: 4037 / 5000\n",
      "w1: [25.13194514] w2: [-23.21475782] bias: [16.33115642] loss: 30.561037850272033\n",
      "Epoch: 4038 / 5000\n",
      "w1: [25.14336885] w2: [-23.21719363] bias: [16.34327087] loss: 30.557702363365838\n",
      "Epoch: 4039 / 5000\n",
      "w1: [25.12990988] w2: [-23.21801307] bias: [16.32181361] loss: 30.56300363499906\n",
      "Epoch: 4040 / 5000\n",
      "w1: [25.13511384] w2: [-23.2268342] bias: [16.31857245] loss: 30.562875730351074\n",
      "Epoch: 4041 / 5000\n",
      "w1: [25.11982341] w2: [-23.23454176] bias: [16.28714318] loss: 30.573215617580285\n",
      "Epoch: 4042 / 5000\n",
      "w1: [25.1296161] w2: [-23.23639391] bias: [16.30673729] loss: 30.566434200851184\n",
      "Epoch: 4043 / 5000\n",
      "w1: [25.13178697] w2: [-23.24190169] bias: [16.30200465] loss: 30.567279791762164\n",
      "Epoch: 4044 / 5000\n",
      "w1: [25.15131795] w2: [-23.24313228] bias: [16.32036513] loss: 30.56016753913054\n",
      "Epoch: 4045 / 5000\n",
      "w1: [25.14242146] w2: [-23.24768822] bias: [16.30019775] loss: 30.565942340786403\n",
      "Epoch: 4046 / 5000\n",
      "w1: [25.1404941] w2: [-23.25550855] bias: [16.29064281] loss: 30.568891821612656\n",
      "Epoch: 4047 / 5000\n",
      "w1: [25.15067716] w2: [-23.25831039] bias: [16.300022] loss: 30.564764617271614\n",
      "Epoch: 4048 / 5000\n",
      "w1: [25.15289213] w2: [-23.26817276] bias: [16.28944064] loss: 30.56724720357946\n",
      "Epoch: 4049 / 5000\n",
      "w1: [25.15992798] w2: [-23.25719474] bias: [16.30452161] loss: 30.56215078654158\n",
      "Epoch: 4050 / 5000\n",
      "w1: [25.1545077] w2: [-23.26117545] bias: [16.30180273] loss: 30.563747032650046\n",
      "Epoch: 4051 / 5000\n",
      "w1: [25.14622568] w2: [-23.26043219] bias: [16.29057522] loss: 30.56797185536362\n",
      "Epoch: 4052 / 5000\n",
      "w1: [25.15802693] w2: [-23.26789319] bias: [16.29816316] loss: 30.564135641100897\n",
      "Epoch: 4053 / 5000\n",
      "w1: [25.17741003] w2: [-23.25725154] bias: [16.32389913] loss: 30.555894257878577\n",
      "Epoch: 4054 / 5000\n",
      "w1: [25.16721448] w2: [-23.24969798] bias: [16.31424936] loss: 30.558969022965904\n",
      "Epoch: 4055 / 5000\n",
      "w1: [25.16386238] w2: [-23.24754571] bias: [16.30530382] loss: 30.561203924387097\n",
      "Epoch: 4056 / 5000\n",
      "w1: [25.15627998] w2: [-23.25716164] bias: [16.28650789] loss: 30.56704129783975\n",
      "Epoch: 4057 / 5000\n",
      "w1: [25.14968769] w2: [-23.25782028] bias: [16.28316814] loss: 30.56919099935969\n",
      "Epoch: 4058 / 5000\n",
      "w1: [25.1498291] w2: [-23.25378159] bias: [16.28455411] loss: 30.56866465146839\n",
      "Epoch: 4059 / 5000\n",
      "w1: [25.15938234] w2: [-23.25552864] bias: [16.29068583] loss: 30.5653875324503\n",
      "Epoch: 4060 / 5000\n",
      "w1: [25.18226568] w2: [-23.24654389] bias: [16.32144045] loss: 30.555641009024388\n",
      "Epoch: 4061 / 5000\n",
      "w1: [25.17491425] w2: [-23.24533829] bias: [16.31287106] loss: 30.558063862316267\n",
      "Epoch: 4062 / 5000\n",
      "w1: [25.16505707] w2: [-23.24831006] bias: [16.29376701] loss: 30.56350766436988\n",
      "Epoch: 4063 / 5000\n",
      "w1: [25.1686792] w2: [-23.24919996] bias: [16.30539616] loss: 30.56044392974687\n",
      "Epoch: 4064 / 5000\n",
      "w1: [25.17237031] w2: [-23.2519172] bias: [16.30524744] loss: 30.559928534597947\n",
      "Epoch: 4065 / 5000\n",
      "w1: [25.17285565] w2: [-23.25558751] bias: [16.29950121] loss: 30.561080060235323\n",
      "Epoch: 4066 / 5000\n",
      "w1: [25.18809081] w2: [-23.25382395] bias: [16.31402646] loss: 30.556035609089314\n",
      "Epoch: 4067 / 5000\n",
      "w1: [25.18545865] w2: [-23.25785642] bias: [16.30914163] loss: 30.557273714689458\n",
      "Epoch: 4068 / 5000\n",
      "w1: [25.19899558] w2: [-23.24511387] bias: [16.34400418] loss: 30.55101387796282\n",
      "Epoch: 4069 / 5000\n",
      "w1: [25.20013672] w2: [-23.24886689] bias: [16.3406454] loss: 30.551138284663484\n",
      "Epoch: 4070 / 5000\n",
      "w1: [25.18659877] w2: [-23.25657507] bias: [16.31621565] loss: 30.555886038853167\n",
      "Epoch: 4071 / 5000\n",
      "w1: [25.18026328] w2: [-23.26188834] bias: [16.30181254] loss: 30.559510076731197\n",
      "Epoch: 4072 / 5000\n",
      "w1: [25.16746383] w2: [-23.27343539] bias: [16.27848407] loss: 30.567551023982027\n",
      "Epoch: 4073 / 5000\n",
      "w1: [25.169387] w2: [-23.26259684] bias: [16.28769748] loss: 30.564501865148085\n",
      "Epoch: 4074 / 5000\n",
      "w1: [25.17671997] w2: [-23.26984218] bias: [16.28948001] loss: 30.56296120142989\n",
      "Epoch: 4075 / 5000\n",
      "w1: [25.17579816] w2: [-23.26171389] bias: [16.28991352] loss: 30.562828761656693\n",
      "Epoch: 4076 / 5000\n",
      "w1: [25.16346181] w2: [-23.26642366] bias: [16.26519002] loss: 30.571847401707505\n",
      "Epoch: 4077 / 5000\n",
      "w1: [25.16599643] w2: [-23.25692305] bias: [16.27262001] loss: 30.568857776555966\n",
      "Epoch: 4078 / 5000\n",
      "w1: [25.18075227] w2: [-23.23506653] bias: [16.31045245] loss: 30.557616921535164\n",
      "Epoch: 4079 / 5000\n",
      "w1: [25.19796027] w2: [-23.22662963] bias: [16.33651424] loss: 30.552190088546176\n",
      "Epoch: 4080 / 5000\n",
      "w1: [25.20132541] w2: [-23.21900184] bias: [16.34410011] loss: 30.55143445605182\n",
      "Epoch: 4081 / 5000\n",
      "w1: [25.20261998] w2: [-23.22235937] bias: [16.34037861] loss: 30.551503591153335\n",
      "Epoch: 4082 / 5000\n",
      "w1: [25.20637667] w2: [-23.23092833] bias: [16.33969926] loss: 30.550992563872576\n",
      "Epoch: 4083 / 5000\n",
      "w1: [25.21252034] w2: [-23.21887192] bias: [16.35636945] loss: 30.549905835220574\n",
      "Epoch: 4084 / 5000\n",
      "w1: [25.23055923] w2: [-23.22304083] bias: [16.37611447] loss: 30.548594494611525\n",
      "Epoch: 4085 / 5000\n",
      "w1: [25.221862] w2: [-23.22275484] bias: [16.35919621] loss: 30.54905177849946\n",
      "Epoch: 4086 / 5000\n",
      "w1: [25.22789521] w2: [-23.20655284] bias: [16.37463987] loss: 30.549591930788587\n",
      "Epoch: 4087 / 5000\n",
      "w1: [25.23402263] w2: [-23.21089062] bias: [16.37547138] loss: 30.549138739838256\n",
      "Epoch: 4088 / 5000\n",
      "w1: [25.22451374] w2: [-23.200426] bias: [16.36728346] loss: 30.549940759273557\n",
      "Epoch: 4089 / 5000\n",
      "w1: [25.2232422] w2: [-23.1958233] bias: [16.37502335] loss: 30.550405730704785\n",
      "Epoch: 4090 / 5000\n",
      "w1: [25.21573973] w2: [-23.18744616] bias: [16.36783925] loss: 30.5510619648587\n",
      "Epoch: 4091 / 5000\n",
      "w1: [25.20792336] w2: [-23.1838676] bias: [16.36119928] loss: 30.55164952746266\n",
      "Epoch: 4092 / 5000\n",
      "w1: [25.21971118] w2: [-23.18529672] bias: [16.38524501] loss: 30.551588227690285\n",
      "Epoch: 4093 / 5000\n",
      "w1: [25.21724332] w2: [-23.19040584] bias: [16.38041046] loss: 30.551121056414733\n",
      "Epoch: 4094 / 5000\n",
      "w1: [25.23551953] w2: [-23.19072269] bias: [16.40194422] loss: 30.55221959991447\n",
      "Epoch: 4095 / 5000\n",
      "w1: [25.23846939] w2: [-23.18765785] bias: [16.40364774] loss: 30.55264742597783\n",
      "Epoch: 4096 / 5000\n",
      "w1: [25.25054792] w2: [-23.19087948] bias: [16.41360814] loss: 30.553717442341778\n",
      "Epoch: 4097 / 5000\n",
      "w1: [25.24742101] w2: [-23.19668199] bias: [16.40239755] loss: 30.55180513526452\n",
      "Epoch: 4098 / 5000\n",
      "w1: [25.23936263] w2: [-23.1961903] bias: [16.38871077] loss: 30.55065134968763\n",
      "Epoch: 4099 / 5000\n",
      "w1: [25.24082777] w2: [-23.18201758] bias: [16.40513212] loss: 30.553301618352236\n",
      "Epoch: 4100 / 5000\n",
      "w1: [25.24512848] w2: [-23.17513273] bias: [16.41119313] loss: 30.55473375834602\n",
      "Epoch: 4101 / 5000\n",
      "w1: [25.24618593] w2: [-23.18323091] bias: [16.41029447] loss: 30.55389197906556\n",
      "Epoch: 4102 / 5000\n",
      "w1: [25.25814456] w2: [-23.1826649] bias: [16.41998614] loss: 30.555659278225043\n",
      "Epoch: 4103 / 5000\n",
      "w1: [25.25344332] w2: [-23.18937678] bias: [16.40735615] loss: 30.553076943039258\n",
      "Epoch: 4104 / 5000\n",
      "w1: [25.24533779] w2: [-23.19076736] bias: [16.3924262] loss: 30.551298428885968\n",
      "Epoch: 4105 / 5000\n",
      "w1: [25.2486715] w2: [-23.19384541] bias: [16.39552067] loss: 30.551334794550854\n",
      "Epoch: 4106 / 5000\n",
      "w1: [25.25880253] w2: [-23.19983057] bias: [16.40783497] loss: 30.552298135498326\n",
      "Epoch: 4107 / 5000\n",
      "w1: [25.26722868] w2: [-23.20223503] bias: [16.41220509] loss: 30.552851121694452\n",
      "Epoch: 4108 / 5000\n",
      "w1: [25.25287032] w2: [-23.21223657] bias: [16.39123681] loss: 30.549531798213376\n",
      "Epoch: 4109 / 5000\n",
      "w1: [25.23342746] w2: [-23.22946275] bias: [16.34714966] loss: 30.548373114526996\n",
      "Epoch: 4110 / 5000\n",
      "w1: [25.23002515] w2: [-23.23198201] bias: [16.34277384] loss: 30.548730953572264\n",
      "Epoch: 4111 / 5000\n",
      "w1: [25.20993682] w2: [-23.24438205] bias: [16.30463981] loss: 30.554582666678847\n",
      "Epoch: 4112 / 5000\n",
      "w1: [25.21919784] w2: [-23.24316731] bias: [16.31490198] loss: 30.551997622229944\n",
      "Epoch: 4113 / 5000\n",
      "w1: [25.23100215] w2: [-23.24129556] bias: [16.32485019] loss: 30.549683432522595\n",
      "Epoch: 4114 / 5000\n",
      "w1: [25.23717271] w2: [-23.24754188] bias: [16.32448196] loss: 30.548994005399205\n",
      "Epoch: 4115 / 5000\n",
      "w1: [25.22673673] w2: [-23.24773523] bias: [16.30767992] loss: 30.552006521813663\n",
      "Epoch: 4116 / 5000\n",
      "w1: [25.23714188] w2: [-23.24660861] bias: [16.32977767] loss: 30.54857105292729\n",
      "Epoch: 4117 / 5000\n",
      "w1: [25.24367969] w2: [-23.23345743] bias: [16.35516295] loss: 30.547359463486387\n",
      "Epoch: 4118 / 5000\n",
      "w1: [25.25007227] w2: [-23.23180992] bias: [16.36183696] loss: 30.5470904219196\n",
      "Epoch: 4119 / 5000\n",
      "w1: [25.23877189] w2: [-23.21985418] bias: [16.35453371] loss: 30.548247663523906\n",
      "Epoch: 4120 / 5000\n",
      "w1: [25.24698868] w2: [-23.21890381] bias: [16.37238604] loss: 30.54812855363583\n",
      "Epoch: 4121 / 5000\n",
      "w1: [25.25756776] w2: [-23.20519197] bias: [16.39223064] loss: 30.55012300808212\n",
      "Epoch: 4122 / 5000\n",
      "w1: [25.24635481] w2: [-23.2087593] bias: [16.37078306] loss: 30.54869385803248\n",
      "Epoch: 4123 / 5000\n",
      "w1: [25.23742763] w2: [-23.21272342] bias: [16.34986463] loss: 30.54871062471985\n",
      "Epoch: 4124 / 5000\n",
      "w1: [25.23126488] w2: [-23.22290119] bias: [16.33305746] loss: 30.549469600823233\n",
      "Epoch: 4125 / 5000\n",
      "w1: [25.24215803] w2: [-23.22385588] bias: [16.34445362] loss: 30.54808033743408\n",
      "Epoch: 4126 / 5000\n",
      "w1: [25.24085371] w2: [-23.22465949] bias: [16.33946518] loss: 30.548321500492317\n",
      "Epoch: 4127 / 5000\n",
      "w1: [25.23012569] w2: [-23.23345238] bias: [16.31816249] loss: 30.55056047153345\n",
      "Epoch: 4128 / 5000\n",
      "w1: [25.23391879] w2: [-23.23594759] bias: [16.32362265] loss: 30.54961801312569\n",
      "Epoch: 4129 / 5000\n",
      "w1: [25.24711534] w2: [-23.23281571] bias: [16.35279302] loss: 30.54722272236813\n",
      "Epoch: 4130 / 5000\n",
      "w1: [25.2456966] w2: [-23.23733269] bias: [16.34416385] loss: 30.547344469816935\n",
      "Epoch: 4131 / 5000\n",
      "w1: [25.24871508] w2: [-23.23983272] bias: [16.34927189] loss: 30.54690295730932\n",
      "Epoch: 4132 / 5000\n",
      "w1: [25.26452705] w2: [-23.22960144] bias: [16.37026715] loss: 30.546884304229017\n",
      "Epoch: 4133 / 5000\n",
      "w1: [25.25773185] w2: [-23.23571103] bias: [16.35413605] loss: 30.546510855848762\n",
      "Epoch: 4134 / 5000\n",
      "w1: [25.25664206] w2: [-23.24145823] bias: [16.34424656] loss: 30.546468333219785\n",
      "Epoch: 4135 / 5000\n",
      "w1: [25.25306665] w2: [-23.23383883] bias: [16.34476161] loss: 30.54697697453512\n",
      "Epoch: 4136 / 5000\n",
      "w1: [25.26629724] w2: [-23.21928347] bias: [16.3701525] loss: 30.547461146064133\n",
      "Epoch: 4137 / 5000\n",
      "w1: [25.27192506] w2: [-23.20297962] bias: [16.40053865] loss: 30.55130441582548\n",
      "Epoch: 4138 / 5000\n",
      "w1: [25.30128458] w2: [-23.20360426] bias: [16.44235079] loss: 30.560210755922405\n",
      "Epoch: 4139 / 5000\n",
      "w1: [25.28967599] w2: [-23.19644251] bias: [16.42856127] loss: 30.557206490640276\n",
      "Epoch: 4140 / 5000\n",
      "w1: [25.28041365] w2: [-23.20219264] bias: [16.4067242] loss: 30.5523986333594\n",
      "Epoch: 4141 / 5000\n",
      "w1: [25.26959658] w2: [-23.21514857] bias: [16.37861478] loss: 30.548185909689398\n",
      "Epoch: 4142 / 5000\n",
      "w1: [25.26974622] w2: [-23.22239572] bias: [16.369984] loss: 30.54717648342169\n",
      "Epoch: 4143 / 5000\n",
      "w1: [25.27219335] w2: [-23.20721637] bias: [16.38864114] loss: 30.549618554800357\n",
      "Epoch: 4144 / 5000\n",
      "w1: [25.26926715] w2: [-23.21436839] bias: [16.37492157] loss: 30.54799171777689\n",
      "Epoch: 4145 / 5000\n",
      "w1: [25.26510624] w2: [-23.21338119] bias: [16.37836881] loss: 30.548351280401842\n",
      "Epoch: 4146 / 5000\n",
      "w1: [25.2485656] w2: [-23.22577484] bias: [16.35629322] loss: 30.547436784952176\n",
      "Epoch: 4147 / 5000\n",
      "w1: [25.24671463] w2: [-23.23089316] bias: [16.35769157] loss: 30.54728872542856\n",
      "Epoch: 4148 / 5000\n",
      "w1: [25.26068919] w2: [-23.22980693] bias: [16.3724581] loss: 30.547070287584692\n",
      "Epoch: 4149 / 5000\n",
      "w1: [25.27019436] w2: [-23.23008583] bias: [16.38504947] loss: 30.547616682004747\n",
      "Epoch: 4150 / 5000\n",
      "w1: [25.28141929] w2: [-23.22691534] bias: [16.40865522] loss: 30.550462899343085\n",
      "Epoch: 4151 / 5000\n",
      "w1: [25.2675698] w2: [-23.23599598] bias: [16.38023682] loss: 30.546925943155426\n",
      "Epoch: 4152 / 5000\n",
      "w1: [25.24864845] w2: [-23.24989202] bias: [16.34689871] loss: 30.54659812832695\n",
      "Epoch: 4153 / 5000\n",
      "w1: [25.25519098] w2: [-23.25078517] bias: [16.35052746] loss: 30.546048129632627\n",
      "Epoch: 4154 / 5000\n",
      "w1: [25.27688524] w2: [-23.25202815] bias: [16.37564478] loss: 30.545486012360236\n",
      "Epoch: 4155 / 5000\n",
      "w1: [25.25051129] w2: [-23.26343729] bias: [16.3366489] loss: 30.54652965305644\n",
      "Epoch: 4156 / 5000\n",
      "w1: [25.26255641] w2: [-23.25297785] bias: [16.37526602] loss: 30.545787850008477\n",
      "Epoch: 4157 / 5000\n",
      "w1: [25.24931715] w2: [-23.25786727] bias: [16.35450153] loss: 30.54604255968311\n",
      "Epoch: 4158 / 5000\n",
      "w1: [25.22638858] w2: [-23.26349165] bias: [16.32611777] loss: 30.549665638981903\n",
      "Epoch: 4159 / 5000\n",
      "w1: [25.23195917] w2: [-23.26074283] bias: [16.33386563] loss: 30.548413369210948\n",
      "Epoch: 4160 / 5000\n",
      "w1: [25.23121901] w2: [-23.2539246] bias: [16.33320797] loss: 30.54867846664359\n",
      "Epoch: 4161 / 5000\n",
      "w1: [25.26952612] w2: [-23.25032685] bias: [16.39468534] loss: 30.546973881518618\n",
      "Epoch: 4162 / 5000\n",
      "w1: [25.25671433] w2: [-23.23214639] bias: [16.39447908] loss: 30.548326696828536\n",
      "Epoch: 4163 / 5000\n",
      "w1: [25.24394809] w2: [-23.23902086] bias: [16.36955244] loss: 30.547081704687105\n",
      "Epoch: 4164 / 5000\n",
      "w1: [25.2629077] w2: [-23.23443306] bias: [16.39727754] loss: 30.548368298920614\n",
      "Epoch: 4165 / 5000\n",
      "w1: [25.26058727] w2: [-23.2396328] bias: [16.39015495] loss: 30.547441959100734\n",
      "Epoch: 4166 / 5000\n",
      "w1: [25.25005356] w2: [-23.25257456] bias: [16.37624901] loss: 30.546259102705214\n",
      "Epoch: 4167 / 5000\n",
      "w1: [25.25589764] w2: [-23.25270926] bias: [16.38488081] loss: 30.5463832059104\n",
      "Epoch: 4168 / 5000\n",
      "w1: [25.24263264] w2: [-23.26028349] bias: [16.36183186] loss: 30.54620004171697\n",
      "Epoch: 4169 / 5000\n",
      "w1: [25.24189532] w2: [-23.26328919] bias: [16.36025264] loss: 30.54615768577245\n",
      "Epoch: 4170 / 5000\n",
      "w1: [25.24204971] w2: [-23.26963505] bias: [16.35346493] loss: 30.546136000401773\n",
      "Epoch: 4171 / 5000\n",
      "w1: [25.24502996] w2: [-23.2766849] bias: [16.36155251] loss: 30.545434775256776\n",
      "Epoch: 4172 / 5000\n",
      "w1: [25.24967988] w2: [-23.27507321] bias: [16.37812939] loss: 30.5451734381061\n",
      "Epoch: 4173 / 5000\n",
      "w1: [25.24574282] w2: [-23.28072165] bias: [16.36971292] loss: 30.54509484978097\n",
      "Epoch: 4174 / 5000\n",
      "w1: [25.23124626] w2: [-23.28432908] bias: [16.34432076] loss: 30.547153568291655\n",
      "Epoch: 4175 / 5000\n",
      "w1: [25.22978621] w2: [-23.28557154] bias: [16.34068653] loss: 30.54756741578737\n",
      "Epoch: 4176 / 5000\n",
      "w1: [25.21744917] w2: [-23.28881419] bias: [16.32090557] loss: 30.551162590514647\n",
      "Epoch: 4177 / 5000\n",
      "w1: [25.20555388] w2: [-23.29609143] bias: [16.2982674] loss: 30.55681269100278\n",
      "Epoch: 4178 / 5000\n",
      "w1: [25.20346325] w2: [-23.3007993] bias: [16.2912391] loss: 30.558751749677864\n",
      "Epoch: 4179 / 5000\n",
      "w1: [25.20959783] w2: [-23.30028035] bias: [16.29522373] loss: 30.556884658188277\n",
      "Epoch: 4180 / 5000\n",
      "w1: [25.19904279] w2: [-23.31375309] bias: [16.26636211] loss: 30.5663270834793\n",
      "Epoch: 4181 / 5000\n",
      "w1: [25.21315627] w2: [-23.31855684] bias: [16.27492336] loss: 30.561509354855946\n",
      "Epoch: 4182 / 5000\n",
      "w1: [25.22344996] w2: [-23.31013279] bias: [16.29168584] loss: 30.555638414101303\n",
      "Epoch: 4183 / 5000\n",
      "w1: [25.2295329] w2: [-23.29474321] bias: [16.30916255] loss: 30.55139312315744\n",
      "Epoch: 4184 / 5000\n",
      "w1: [25.22692307] w2: [-23.29864673] bias: [16.29895307] loss: 30.553513622155126\n",
      "Epoch: 4185 / 5000\n",
      "w1: [25.23476644] w2: [-23.29506268] bias: [16.31307277] loss: 30.55014192726646\n",
      "Epoch: 4186 / 5000\n",
      "w1: [25.24393454] w2: [-23.28903743] bias: [16.3307557] loss: 30.547057263881552\n",
      "Epoch: 4187 / 5000\n",
      "w1: [25.26042748] w2: [-23.28232431] bias: [16.35056207] loss: 30.544583030357018\n",
      "Epoch: 4188 / 5000\n",
      "w1: [25.25775337] w2: [-23.2861263] bias: [16.3435978] loss: 30.544964097953105\n",
      "Epoch: 4189 / 5000\n",
      "w1: [25.26120517] w2: [-23.27310609] bias: [16.36145302] loss: 30.544661103898417\n",
      "Epoch: 4190 / 5000\n",
      "w1: [25.25577541] w2: [-23.27736361] bias: [16.35017145] loss: 30.545068453561505\n",
      "Epoch: 4191 / 5000\n",
      "w1: [25.25631116] w2: [-23.2795012] bias: [16.34959781] loss: 30.544985310473486\n",
      "Epoch: 4192 / 5000\n",
      "w1: [25.27121884] w2: [-23.27832762] bias: [16.36583163] loss: 30.54397030306522\n",
      "Epoch: 4193 / 5000\n",
      "w1: [25.2732479] w2: [-23.26804618] bias: [16.39214234] loss: 30.545550749178737\n",
      "Epoch: 4194 / 5000\n",
      "w1: [25.2653833] w2: [-23.27675715] bias: [16.37113802] loss: 30.544351973463872\n",
      "Epoch: 4195 / 5000\n",
      "w1: [25.25755185] w2: [-23.2896953] bias: [16.3484151] loss: 30.544641313704055\n",
      "Epoch: 4196 / 5000\n",
      "w1: [25.27832615] w2: [-23.27590861] bias: [16.39015641] loss: 30.54485005464646\n",
      "Epoch: 4197 / 5000\n",
      "w1: [25.28337925] w2: [-23.27903829] bias: [16.39962901] loss: 30.545355557623086\n",
      "Epoch: 4198 / 5000\n",
      "w1: [25.27351558] w2: [-23.28514094] bias: [16.38397469] loss: 30.544042260554324\n",
      "Epoch: 4199 / 5000\n",
      "w1: [25.2832037] w2: [-23.28770291] bias: [16.38814731] loss: 30.543925581451298\n",
      "Epoch: 4200 / 5000\n",
      "w1: [25.3090113] w2: [-23.29181862] bias: [16.41521785] loss: 30.546517387185162\n",
      "Epoch: 4201 / 5000\n",
      "w1: [25.3227123] w2: [-23.27490946] bias: [16.43950913] loss: 30.553035315047765\n",
      "Epoch: 4202 / 5000\n",
      "w1: [25.34057755] w2: [-23.2682941] bias: [16.46503] loss: 30.561701213236834\n",
      "Epoch: 4203 / 5000\n",
      "w1: [25.32204747] w2: [-23.27989573] bias: [16.42918136] loss: 30.550412462039084\n",
      "Epoch: 4204 / 5000\n",
      "w1: [25.3310794] w2: [-23.27704157] bias: [16.45174635] loss: 30.556221038600395\n",
      "Epoch: 4205 / 5000\n",
      "w1: [25.32474267] w2: [-23.279088] bias: [16.45671229] loss: 30.556682911884085\n",
      "Epoch: 4206 / 5000\n",
      "w1: [25.31686845] w2: [-23.29045517] bias: [16.43072418] loss: 30.549417476045864\n",
      "Epoch: 4207 / 5000\n",
      "w1: [25.32488966] w2: [-23.28279027] bias: [16.4469078] loss: 30.553962051034063\n",
      "Epoch: 4208 / 5000\n",
      "w1: [25.31197668] w2: [-23.2981181] bias: [16.41581207] loss: 30.546161642356136\n",
      "Epoch: 4209 / 5000\n",
      "w1: [25.32237795] w2: [-23.30059773] bias: [16.42583908] loss: 30.54787461620582\n",
      "Epoch: 4210 / 5000\n",
      "w1: [25.32293233] w2: [-23.30763614] bias: [16.41765102] loss: 30.54597070931971\n",
      "Epoch: 4211 / 5000\n",
      "w1: [25.32480429] w2: [-23.30508371] bias: [16.43365485] loss: 30.54896264256776\n",
      "Epoch: 4212 / 5000\n",
      "w1: [25.33588577] w2: [-23.31186537] bias: [16.44278225] loss: 30.550757643474046\n",
      "Epoch: 4213 / 5000\n",
      "w1: [25.3352424] w2: [-23.31613425] bias: [16.44334375] loss: 30.550400748214432\n",
      "Epoch: 4214 / 5000\n",
      "w1: [25.33952143] w2: [-23.30974937] bias: [16.45089532] loss: 30.553039540057416\n",
      "Epoch: 4215 / 5000\n",
      "w1: [25.35120879] w2: [-23.30595901] bias: [16.46895084] loss: 30.559189794980274\n",
      "Epoch: 4216 / 5000\n",
      "w1: [25.34820401] w2: [-23.31029357] bias: [16.45666383] loss: 30.555095104155\n",
      "Epoch: 4217 / 5000\n",
      "w1: [25.35004832] w2: [-23.31207287] bias: [16.45391593] loss: 30.554365558190113\n",
      "Epoch: 4218 / 5000\n",
      "w1: [25.34473779] w2: [-23.30910992] bias: [16.44901901] loss: 30.553076214941555\n",
      "Epoch: 4219 / 5000\n",
      "w1: [25.35245398] w2: [-23.30355436] bias: [16.46068603] loss: 30.557324188133503\n",
      "Epoch: 4220 / 5000\n",
      "w1: [25.34129319] w2: [-23.30237208] bias: [16.44059638] loss: 30.551633992691624\n",
      "Epoch: 4221 / 5000\n",
      "w1: [25.34591411] w2: [-23.29941471] bias: [16.46007382] loss: 30.557032452880822\n",
      "Epoch: 4222 / 5000\n",
      "w1: [25.36214877] w2: [-23.28349982] bias: [16.49460797] loss: 30.57182908962961\n",
      "Epoch: 4223 / 5000\n",
      "w1: [25.35167813] w2: [-23.28168499] bias: [16.48281376] loss: 30.5666414432481\n",
      "Epoch: 4224 / 5000\n",
      "w1: [25.35313044] w2: [-23.28146472] bias: [16.48608363] loss: 30.56793644336689\n",
      "Epoch: 4225 / 5000\n",
      "w1: [25.35667658] w2: [-23.28121419] bias: [16.49084621] loss: 30.570067702150244\n",
      "Epoch: 4226 / 5000\n",
      "w1: [25.35218646] w2: [-23.28992286] bias: [16.48033994] loss: 30.564784707208208\n",
      "Epoch: 4227 / 5000\n",
      "w1: [25.33737187] w2: [-23.29163639] bias: [16.45813724] loss: 30.556667487307568\n",
      "Epoch: 4228 / 5000\n",
      "w1: [25.32076092] w2: [-23.29301113] bias: [16.44306051] loss: 30.551770904675173\n",
      "Epoch: 4229 / 5000\n",
      "w1: [25.33478117] w2: [-23.29437419] bias: [16.4503076] loss: 30.55421739037715\n",
      "Epoch: 4230 / 5000\n",
      "w1: [25.3407443] w2: [-23.29089792] bias: [16.45620481] loss: 30.556558374005288\n",
      "Epoch: 4231 / 5000\n",
      "w1: [25.32883083] w2: [-23.29516361] bias: [16.4430025] loss: 30.552058377596076\n",
      "Epoch: 4232 / 5000\n",
      "w1: [25.3238809] w2: [-23.30467797] bias: [16.42557578] loss: 30.547526416852488\n",
      "Epoch: 4233 / 5000\n",
      "w1: [25.31940676] w2: [-23.3006429] bias: [16.42394466] loss: 30.547431220802604\n",
      "Epoch: 4234 / 5000\n",
      "w1: [25.30451037] w2: [-23.2993506] bias: [16.40346849] loss: 30.544394613710185\n",
      "Epoch: 4235 / 5000\n",
      "w1: [25.30076504] w2: [-23.28758813] bias: [16.40330649] loss: 30.545201563098466\n",
      "Epoch: 4236 / 5000\n",
      "w1: [25.31020358] w2: [-23.28510688] bias: [16.42414303] loss: 30.548491450166225\n",
      "Epoch: 4237 / 5000\n",
      "w1: [25.33192319] w2: [-23.27178985] bias: [16.45551579] loss: 30.557852332630997\n",
      "Epoch: 4238 / 5000\n",
      "w1: [25.36452773] w2: [-23.26966067] bias: [16.49588106] loss: 30.57472474523418\n",
      "Epoch: 4239 / 5000\n",
      "w1: [25.36021629] w2: [-23.26613889] bias: [16.49272881] loss: 30.573462317381072\n",
      "Epoch: 4240 / 5000\n",
      "w1: [25.35627536] w2: [-23.26415796] bias: [16.48273126] loss: 30.569681750916565\n",
      "Epoch: 4241 / 5000\n",
      "w1: [25.36333757] w2: [-23.25209625] bias: [16.50251661] loss: 30.579845312525922\n",
      "Epoch: 4242 / 5000\n",
      "w1: [25.3582275] w2: [-23.23675905] bias: [16.50705636] loss: 30.58334209588528\n",
      "Epoch: 4243 / 5000\n",
      "w1: [25.34084171] w2: [-23.24872875] bias: [16.47147641] loss: 30.566250279875547\n",
      "Epoch: 4244 / 5000\n",
      "w1: [25.33275812] w2: [-23.24755327] bias: [16.46066995] loss: 30.562316576758207\n",
      "Epoch: 4245 / 5000\n",
      "w1: [25.33478645] w2: [-23.24594475] bias: [16.46401318] loss: 30.56369604583212\n",
      "Epoch: 4246 / 5000\n",
      "w1: [25.31851387] w2: [-23.2516342] bias: [16.43336118] loss: 30.553938399397932\n",
      "Epoch: 4247 / 5000\n",
      "w1: [25.31893644] w2: [-23.25346606] bias: [16.44437232] loss: 30.556201264490305\n",
      "Epoch: 4248 / 5000\n",
      "w1: [25.33060525] w2: [-23.25198098] bias: [16.45744904] loss: 30.56065376243602\n",
      "Epoch: 4249 / 5000\n",
      "w1: [25.31924117] w2: [-23.2635228] bias: [16.43095298] loss: 30.55224377578352\n",
      "Epoch: 4250 / 5000\n",
      "w1: [25.33484947] w2: [-23.2573039] bias: [16.4568291] loss: 30.560227310670772\n",
      "Epoch: 4251 / 5000\n",
      "w1: [25.33115216] w2: [-23.26595776] bias: [16.4401874] loss: 30.55473979674255\n",
      "Epoch: 4252 / 5000\n",
      "w1: [25.32838374] w2: [-23.27146076] bias: [16.42866714] loss: 30.551506427450608\n",
      "Epoch: 4253 / 5000\n",
      "w1: [25.33112103] w2: [-23.2870396] bias: [16.41738568] loss: 30.54805370790621\n",
      "Epoch: 4254 / 5000\n",
      "w1: [25.33626481] w2: [-23.27009767] bias: [16.43822059] loss: 30.554208423225464\n",
      "Epoch: 4255 / 5000\n",
      "w1: [25.33988009] w2: [-23.24883161] bias: [16.46038364] loss: 30.562800712270874\n",
      "Epoch: 4256 / 5000\n",
      "w1: [25.35283902] w2: [-23.25242849] bias: [16.47081383] loss: 30.566960052848632\n",
      "Epoch: 4257 / 5000\n",
      "w1: [25.3741941] w2: [-23.24337514] bias: [16.49757618] loss: 30.58105907759392\n",
      "Epoch: 4258 / 5000\n",
      "w1: [25.37176456] w2: [-23.24909446] bias: [16.48548551] loss: 30.5750918537668\n",
      "Epoch: 4259 / 5000\n",
      "w1: [25.37456808] w2: [-23.24915767] bias: [16.48022854] loss: 30.573559747479305\n",
      "Epoch: 4260 / 5000\n",
      "w1: [25.3743991] w2: [-23.25045875] bias: [16.47821584] loss: 30.572611163314132\n",
      "Epoch: 4261 / 5000\n",
      "w1: [25.37947974] w2: [-23.24970616] bias: [16.48275274] loss: 30.575133691054525\n",
      "Epoch: 4262 / 5000\n",
      "w1: [25.39406613] w2: [-23.24359649] bias: [16.5117151] loss: 30.59058417262393\n",
      "Epoch: 4263 / 5000\n",
      "w1: [25.40671812] w2: [-23.22621192] bias: [16.54096833] loss: 30.610972529425617\n",
      "Epoch: 4264 / 5000\n",
      "w1: [25.41429333] w2: [-23.22613838] bias: [16.54830824] loss: 30.61679973703513\n",
      "Epoch: 4265 / 5000\n",
      "w1: [25.41024394] w2: [-23.23074453] bias: [16.5317461] loss: 30.606037028715804\n",
      "Epoch: 4266 / 5000\n",
      "w1: [25.39835712] w2: [-23.23209871] bias: [16.53140101] loss: 30.602969547514224\n",
      "Epoch: 4267 / 5000\n",
      "w1: [25.41055507] w2: [-23.2304901] bias: [16.54755527] loss: 30.61456606709415\n",
      "Epoch: 4268 / 5000\n",
      "w1: [25.40011681] w2: [-23.23572685] bias: [16.52832727] loss: 30.60111867630592\n",
      "Epoch: 4269 / 5000\n",
      "w1: [25.40727788] w2: [-23.2323002] bias: [16.53749192] loss: 30.608039502390117\n",
      "Epoch: 4270 / 5000\n",
      "w1: [25.42563854] w2: [-23.22582479] bias: [16.55815126] loss: 30.62537770619791\n",
      "Epoch: 4271 / 5000\n",
      "w1: [25.43337869] w2: [-23.23975672] bias: [16.55302487] loss: 30.621388413490646\n",
      "Epoch: 4272 / 5000\n",
      "w1: [25.43406405] w2: [-23.23596918] bias: [16.55418633] loss: 30.62305522285712\n",
      "Epoch: 4273 / 5000\n",
      "w1: [25.43080185] w2: [-23.23871042] bias: [16.55166005] loss: 30.620166818443238\n",
      "Epoch: 4274 / 5000\n",
      "w1: [25.41125143] w2: [-23.25330975] bias: [16.51530542] loss: 30.59386681699798\n",
      "Epoch: 4275 / 5000\n",
      "w1: [25.40230164] w2: [-23.25597568] bias: [16.49938358] loss: 30.5845473588569\n",
      "Epoch: 4276 / 5000\n",
      "w1: [25.39374562] w2: [-23.26990942] bias: [16.4724041] loss: 30.570400429078987\n",
      "Epoch: 4277 / 5000\n",
      "w1: [25.37270937] w2: [-23.27985309] bias: [16.43967145] loss: 30.556477621521065\n",
      "Epoch: 4278 / 5000\n",
      "w1: [25.37198963] w2: [-23.28631006] bias: [16.42972406] loss: 30.55318346730886\n",
      "Epoch: 4279 / 5000\n",
      "w1: [25.37593234] w2: [-23.29079936] bias: [16.42589194] loss: 30.55210215572056\n",
      "Epoch: 4280 / 5000\n",
      "w1: [25.36078177] w2: [-23.30518586] bias: [16.39261222] loss: 30.543728699626733\n",
      "Epoch: 4281 / 5000\n",
      "w1: [25.36455473] w2: [-23.31163717] bias: [16.3884867] loss: 30.542761447091927\n",
      "Epoch: 4282 / 5000\n",
      "w1: [25.34543887] w2: [-23.32249226] bias: [16.35049523] loss: 30.539017385659996\n",
      "Epoch: 4283 / 5000\n",
      "w1: [25.35546845] w2: [-23.3270836] bias: [16.37675889] loss: 30.540228965712103\n",
      "Epoch: 4284 / 5000\n",
      "w1: [25.35523968] w2: [-23.3232939] bias: [16.38455396] loss: 30.54125208969072\n",
      "Epoch: 4285 / 5000\n",
      "w1: [25.37775942] w2: [-23.31762447] bias: [16.41686558] loss: 30.54753260036078\n",
      "Epoch: 4286 / 5000\n",
      "w1: [25.36211093] w2: [-23.33316823] bias: [16.38545765] loss: 30.540765371858928\n",
      "Epoch: 4287 / 5000\n",
      "w1: [25.35272305] w2: [-23.3357307] bias: [16.36817423] loss: 30.539053200548675\n",
      "Epoch: 4288 / 5000\n",
      "w1: [25.34257616] w2: [-23.35210519] bias: [16.34203746] loss: 30.53786275169085\n",
      "Epoch: 4289 / 5000\n",
      "w1: [25.33565763] w2: [-23.35701463] bias: [16.33626235] loss: 30.538188573622353\n",
      "Epoch: 4290 / 5000\n",
      "w1: [25.33973421] w2: [-23.3412289] bias: [16.35170551] loss: 30.53841355821585\n",
      "Epoch: 4291 / 5000\n",
      "w1: [25.32065124] w2: [-23.35779247] bias: [16.31132655] loss: 30.540865076809034\n",
      "Epoch: 4292 / 5000\n",
      "w1: [25.31836487] w2: [-23.35621755] bias: [16.30885779] loss: 30.54133385847245\n",
      "Epoch: 4293 / 5000\n",
      "w1: [25.32442335] w2: [-23.3488132] bias: [16.3182103] loss: 30.54005109252121\n",
      "Epoch: 4294 / 5000\n",
      "w1: [25.32438975] w2: [-23.34602231] bias: [16.32744214] loss: 30.539527504517174\n",
      "Epoch: 4295 / 5000\n",
      "w1: [25.33131564] w2: [-23.33836035] bias: [16.33835675] loss: 30.538908489044424\n",
      "Epoch: 4296 / 5000\n",
      "w1: [25.33261749] w2: [-23.33047669] bias: [16.35614273] loss: 30.539190377158864\n",
      "Epoch: 4297 / 5000\n",
      "w1: [25.32952113] w2: [-23.34021561] bias: [16.34249741] loss: 30.538877712179556\n",
      "Epoch: 4298 / 5000\n",
      "w1: [25.32080585] w2: [-23.34716815] bias: [16.32458742] loss: 30.539932628627206\n",
      "Epoch: 4299 / 5000\n",
      "w1: [25.31722012] w2: [-23.34865533] bias: [16.31764514] loss: 30.54069823237995\n",
      "Epoch: 4300 / 5000\n",
      "w1: [25.31137256] w2: [-23.35682077] bias: [16.30539178] loss: 30.542412753068337\n",
      "Epoch: 4301 / 5000\n",
      "w1: [25.30920381] w2: [-23.36187563] bias: [16.29898094] loss: 30.543465330597215\n",
      "Epoch: 4302 / 5000\n",
      "w1: [25.31051177] w2: [-23.35940591] bias: [16.30222638] loss: 30.542889063476558\n",
      "Epoch: 4303 / 5000\n",
      "w1: [25.3084226] w2: [-23.35831037] bias: [16.29403357] loss: 30.5442192666575\n",
      "Epoch: 4304 / 5000\n",
      "w1: [25.31861193] w2: [-23.35437102] bias: [16.30908511] loss: 30.541296486623267\n",
      "Epoch: 4305 / 5000\n",
      "w1: [25.31532357] w2: [-23.35190756] bias: [16.3049497] loss: 30.54206413294862\n",
      "Epoch: 4306 / 5000\n",
      "w1: [25.31935791] w2: [-23.35455887] bias: [16.31015279] loss: 30.541119452391747\n",
      "Epoch: 4307 / 5000\n",
      "w1: [25.3178889] w2: [-23.36239493] bias: [16.3002853] loss: 30.542338260820536\n",
      "Epoch: 4308 / 5000\n",
      "w1: [25.31399334] w2: [-23.37308604] bias: [16.29300891] loss: 30.543836767372987\n",
      "Epoch: 4309 / 5000\n",
      "w1: [25.31951821] w2: [-23.3745727] bias: [16.29414808] loss: 30.543032054933747\n",
      "Epoch: 4310 / 5000\n",
      "w1: [25.30290071] w2: [-23.37016718] bias: [16.27641981] loss: 30.548065000283465\n",
      "Epoch: 4311 / 5000\n",
      "w1: [25.30434125] w2: [-23.35909553] bias: [16.28637984] loss: 30.545903531505587\n",
      "Epoch: 4312 / 5000\n",
      "w1: [25.28930726] w2: [-23.37266232] bias: [16.25544027] loss: 30.554913717884034\n",
      "Epoch: 4313 / 5000\n",
      "w1: [25.28000752] w2: [-23.37817301] bias: [16.2407957] loss: 30.560842718158746\n",
      "Epoch: 4314 / 5000\n",
      "w1: [25.27303505] w2: [-23.38715779] bias: [16.22106391] loss: 30.569110738211556\n",
      "Epoch: 4315 / 5000\n",
      "w1: [25.28276571] w2: [-23.37269446] bias: [16.24210434] loss: 30.559651556352637\n",
      "Epoch: 4316 / 5000\n",
      "w1: [25.28982465] w2: [-23.37175165] bias: [16.25228478] loss: 30.555579247126083\n",
      "Epoch: 4317 / 5000\n",
      "w1: [25.29190409] w2: [-23.36163185] bias: [16.25995339] loss: 30.552986992722026\n",
      "Epoch: 4318 / 5000\n",
      "w1: [25.29236973] w2: [-23.349594] bias: [16.27130286] loss: 30.55012739644562\n",
      "Epoch: 4319 / 5000\n",
      "w1: [25.29306221] w2: [-23.35171505] bias: [16.26945241] loss: 30.550448980689495\n",
      "Epoch: 4320 / 5000\n",
      "w1: [25.284486] w2: [-23.35751126] bias: [16.2570495] loss: 30.554770900692372\n",
      "Epoch: 4321 / 5000\n",
      "w1: [25.2901396] w2: [-23.34925437] bias: [16.26770376] loss: 30.551193162325667\n",
      "Epoch: 4322 / 5000\n",
      "w1: [25.28636242] w2: [-23.34621082] bias: [16.26892142] loss: 30.55144085953259\n",
      "Epoch: 4323 / 5000\n",
      "w1: [25.28800619] w2: [-23.34638117] bias: [16.26597665] loss: 30.551812036760648\n",
      "Epoch: 4324 / 5000\n",
      "w1: [25.29181205] w2: [-23.33240264] bias: [16.28146791] loss: 30.548011186014115\n",
      "Epoch: 4325 / 5000\n",
      "w1: [25.30206443] w2: [-23.33364757] bias: [16.29403889] loss: 30.54483032928342\n",
      "Epoch: 4326 / 5000\n",
      "w1: [25.31119526] w2: [-23.3056599] bias: [16.33620813] loss: 30.541102260012924\n",
      "Epoch: 4327 / 5000\n",
      "w1: [25.31220708] w2: [-23.31722817] bias: [16.32330982] loss: 30.541237263450522\n",
      "Epoch: 4328 / 5000\n",
      "w1: [25.30845455] w2: [-23.31589481] bias: [16.3170835] loss: 30.541952215143564\n",
      "Epoch: 4329 / 5000\n",
      "w1: [25.30596678] w2: [-23.32096768] bias: [16.30913592] loss: 30.542752735531064\n",
      "Epoch: 4330 / 5000\n",
      "w1: [25.29547388] w2: [-23.3225765] bias: [16.29344003] loss: 30.545645050265954\n",
      "Epoch: 4331 / 5000\n",
      "w1: [25.3001254] w2: [-23.3320641] bias: [16.28980256] loss: 30.54564271298757\n",
      "Epoch: 4332 / 5000\n",
      "w1: [25.29035139] w2: [-23.33467046] bias: [16.271299] loss: 30.550098676453608\n",
      "Epoch: 4333 / 5000\n",
      "w1: [25.30348536] w2: [-23.32264865] bias: [16.29952118] loss: 30.543990251654883\n",
      "Epoch: 4334 / 5000\n",
      "w1: [25.29248048] w2: [-23.3139446] bias: [16.29406579] loss: 30.54589488107984\n",
      "Epoch: 4335 / 5000\n",
      "w1: [25.27815322] w2: [-23.31993913] bias: [16.27618905] loss: 30.55066205317024\n",
      "Epoch: 4336 / 5000\n",
      "w1: [25.28672269] w2: [-23.30753567] bias: [16.29795621] loss: 30.546048575400057\n",
      "Epoch: 4337 / 5000\n",
      "w1: [25.31701988] w2: [-23.29599457] bias: [16.34710252] loss: 30.541101299349126\n",
      "Epoch: 4338 / 5000\n",
      "w1: [25.31146274] w2: [-23.2976371] bias: [16.33684644] loss: 30.5413428589144\n",
      "Epoch: 4339 / 5000\n",
      "w1: [25.32867957] w2: [-23.29912303] bias: [16.35004184] loss: 30.54059315572745\n",
      "Epoch: 4340 / 5000\n",
      "w1: [25.33798842] w2: [-23.29601401] bias: [16.36957803] loss: 30.541594508284092\n",
      "Epoch: 4341 / 5000\n",
      "w1: [25.3277791] w2: [-23.30295586] bias: [16.34789546] loss: 30.54039973583934\n",
      "Epoch: 4342 / 5000\n",
      "w1: [25.31649345] w2: [-23.31518946] bias: [16.32115277] loss: 30.541085097912237\n",
      "Epoch: 4343 / 5000\n",
      "w1: [25.31338499] w2: [-23.32620026] bias: [16.30844354] loss: 30.54207416356231\n",
      "Epoch: 4344 / 5000\n",
      "w1: [25.32510621] w2: [-23.32435196] bias: [16.33573368] loss: 30.53973183833471\n",
      "Epoch: 4345 / 5000\n",
      "w1: [25.3189991] w2: [-23.32387127] bias: [16.32479989] loss: 30.54051983445922\n",
      "Epoch: 4346 / 5000\n",
      "w1: [25.31491551] w2: [-23.32502585] bias: [16.31660677] loss: 30.54130203053968\n",
      "Epoch: 4347 / 5000\n",
      "w1: [25.30891184] w2: [-23.32431732] bias: [16.30603676] loss: 30.54273739052908\n",
      "Epoch: 4348 / 5000\n",
      "w1: [25.32514694] w2: [-23.3239097] bias: [16.32310021] loss: 30.54017330052499\n",
      "Epoch: 4349 / 5000\n",
      "w1: [25.3160037] w2: [-23.32706261] bias: [16.30799554] loss: 30.54186625400281\n",
      "Epoch: 4350 / 5000\n",
      "w1: [25.30836279] w2: [-23.33609687] bias: [16.29216512] loss: 30.544366926643317\n",
      "Epoch: 4351 / 5000\n",
      "w1: [25.3081762] w2: [-23.3463737] bias: [16.27999452] loss: 30.54628258933224\n",
      "Epoch: 4352 / 5000\n",
      "w1: [25.30202645] w2: [-23.33996675] bias: [16.27276053] loss: 30.54826084655071\n",
      "Epoch: 4353 / 5000\n",
      "w1: [25.29790831] w2: [-23.33664282] bias: [16.26833636] loss: 30.549609489197895\n",
      "Epoch: 4354 / 5000\n",
      "w1: [25.31429995] w2: [-23.34721722] bias: [16.28210034] loss: 30.545179251499455\n",
      "Epoch: 4355 / 5000\n",
      "w1: [25.29942603] w2: [-23.35277047] bias: [16.26338417] loss: 30.550763309567028\n",
      "Epoch: 4356 / 5000\n",
      "w1: [25.29484877] w2: [-23.36044412] bias: [16.25306763] loss: 30.554074067947216\n",
      "Epoch: 4357 / 5000\n",
      "w1: [25.29881732] w2: [-23.36665634] bias: [16.24773068] loss: 30.554940526650395\n",
      "Epoch: 4358 / 5000\n",
      "w1: [25.29842368] w2: [-23.36793661] bias: [16.24443761] loss: 30.555901547196065\n",
      "Epoch: 4359 / 5000\n",
      "w1: [25.30174423] w2: [-23.35304307] bias: [16.26517576] loss: 30.550045383978556\n",
      "Epoch: 4360 / 5000\n",
      "w1: [25.31073737] w2: [-23.35114219] bias: [16.27651124] loss: 30.54659819712622\n",
      "Epoch: 4361 / 5000\n",
      "w1: [25.31453551] w2: [-23.34980497] bias: [16.27610945] loss: 30.546143817670877\n",
      "Epoch: 4362 / 5000\n",
      "w1: [25.31699157] w2: [-23.34780142] bias: [16.27644808] loss: 30.54574107235763\n",
      "Epoch: 4363 / 5000\n",
      "w1: [25.29497634] w2: [-23.35784391] bias: [16.23828152] loss: 30.557705799409536\n",
      "Epoch: 4364 / 5000\n",
      "w1: [25.28585668] w2: [-23.36008595] bias: [16.22242191] loss: 30.564195756998647\n",
      "Epoch: 4365 / 5000\n",
      "w1: [25.29298545] w2: [-23.36309186] bias: [16.22418522] loss: 30.56236978356589\n",
      "Epoch: 4366 / 5000\n",
      "w1: [25.27832927] w2: [-23.37030449] bias: [16.20002551] loss: 30.57416949371399\n",
      "Epoch: 4367 / 5000\n",
      "w1: [25.30096716] w2: [-23.36284209] bias: [16.23264005] loss: 30.55835826627448\n",
      "Epoch: 4368 / 5000\n",
      "w1: [25.29560308] w2: [-23.36493627] bias: [16.22804249] loss: 30.56080252426427\n",
      "Epoch: 4369 / 5000\n",
      "w1: [25.28585892] w2: [-23.36417313] bias: [16.21032773] loss: 30.568368242295747\n",
      "Epoch: 4370 / 5000\n",
      "w1: [25.2930153] w2: [-23.36983855] bias: [16.2079663] loss: 30.567964198918833\n",
      "Epoch: 4371 / 5000\n",
      "w1: [25.29330861] w2: [-23.37164375] bias: [16.21540957] loss: 30.5655530283917\n",
      "Epoch: 4372 / 5000\n",
      "w1: [25.2915274] w2: [-23.36529979] bias: [16.21416928] loss: 30.565938559493496\n",
      "Epoch: 4373 / 5000\n",
      "w1: [25.30158886] w2: [-23.34819475] bias: [16.23633731] loss: 30.556597625235568\n",
      "Epoch: 4374 / 5000\n",
      "w1: [25.32121301] w2: [-23.32074823] bias: [16.29036904] loss: 30.543190924079955\n",
      "Epoch: 4375 / 5000\n",
      "w1: [25.29803483] w2: [-23.32738215] bias: [16.25750853] loss: 30.551550862488405\n",
      "Epoch: 4376 / 5000\n",
      "w1: [25.30311927] w2: [-23.32717525] bias: [16.27092194] loss: 30.54823098483239\n",
      "Epoch: 4377 / 5000\n",
      "w1: [25.30848253] w2: [-23.31965376] bias: [16.28215889] loss: 30.545674358794884\n",
      "Epoch: 4378 / 5000\n",
      "w1: [25.29695766] w2: [-23.31655419] bias: [16.28095504] loss: 30.547257086789504\n",
      "Epoch: 4379 / 5000\n",
      "w1: [25.2795161] w2: [-23.32568216] bias: [16.24945755] loss: 30.556337788110607\n",
      "Epoch: 4380 / 5000\n",
      "w1: [25.28122682] w2: [-23.31061028] bias: [16.27065004] loss: 30.551102489652784\n",
      "Epoch: 4381 / 5000\n",
      "w1: [25.28627296] w2: [-23.31549818] bias: [16.27258578] loss: 30.55009830772496\n",
      "Epoch: 4382 / 5000\n",
      "w1: [25.30021661] w2: [-23.29506719] bias: [16.30706014] loss: 30.543793935418027\n",
      "Epoch: 4383 / 5000\n",
      "w1: [25.29856703] w2: [-23.30378588] bias: [16.29444146] loss: 30.545184902883587\n",
      "Epoch: 4384 / 5000\n",
      "w1: [25.30946181] w2: [-23.3041705] bias: [16.30380514] loss: 30.543108681056072\n",
      "Epoch: 4385 / 5000\n",
      "w1: [25.3071285] w2: [-23.30967433] bias: [16.290368] loss: 30.54472735159034\n",
      "Epoch: 4386 / 5000\n",
      "w1: [25.28822608] w2: [-23.32300488] bias: [16.25398117] loss: 30.553744510608578\n",
      "Epoch: 4387 / 5000\n",
      "w1: [25.27873867] w2: [-23.3260632] bias: [16.24296361] loss: 30.558109874179195\n",
      "Epoch: 4388 / 5000\n",
      "w1: [25.30154634] w2: [-23.32287861] bias: [16.27804758] loss: 30.54718668029864\n",
      "Epoch: 4389 / 5000\n",
      "w1: [25.31075395] w2: [-23.3297791] bias: [16.29392745] loss: 30.543865414550186\n",
      "Epoch: 4390 / 5000\n",
      "w1: [25.29817759] w2: [-23.33987666] bias: [16.26582692] loss: 30.550130660782298\n",
      "Epoch: 4391 / 5000\n",
      "w1: [25.27263078] w2: [-23.35698633] bias: [16.21639384] loss: 30.56877428856306\n",
      "Epoch: 4392 / 5000\n",
      "w1: [25.26707718] w2: [-23.36867201] bias: [16.19694367] loss: 30.57793051631151\n",
      "Epoch: 4393 / 5000\n",
      "w1: [25.27452173] w2: [-23.36862383] bias: [16.20048715] loss: 30.574776814704922\n",
      "Epoch: 4394 / 5000\n",
      "w1: [25.28986069] w2: [-23.37331529] bias: [16.21466804] loss: 30.566641981644114\n",
      "Epoch: 4395 / 5000\n",
      "w1: [25.27824229] w2: [-23.37406052] bias: [16.19732077] loss: 30.575490507451732\n",
      "Epoch: 4396 / 5000\n",
      "w1: [25.27936155] w2: [-23.37088001] bias: [16.19398028] loss: 30.576235039079926\n",
      "Epoch: 4397 / 5000\n",
      "w1: [25.28312976] w2: [-23.37976437] bias: [16.18596311] loss: 30.57915872736731\n",
      "Epoch: 4398 / 5000\n",
      "w1: [25.28681951] w2: [-23.38672736] bias: [16.18002211] loss: 30.581231672875038\n",
      "Epoch: 4399 / 5000\n",
      "w1: [25.29299459] w2: [-23.38317006] bias: [16.19077844] loss: 30.575128767598468\n",
      "Epoch: 4400 / 5000\n",
      "w1: [25.27998841] w2: [-23.3925432] bias: [16.15901704] loss: 30.592836464707656\n",
      "Epoch: 4401 / 5000\n",
      "w1: [25.29409258] w2: [-23.3941245] bias: [16.18186848] loss: 30.579277810689\n",
      "Epoch: 4402 / 5000\n",
      "w1: [25.2813728] w2: [-23.38501072] bias: [16.16726828] loss: 30.587948862548316\n",
      "Epoch: 4403 / 5000\n",
      "w1: [25.27970518] w2: [-23.37274224] bias: [16.17388776] loss: 30.584374055178458\n",
      "Epoch: 4404 / 5000\n",
      "w1: [25.27449606] w2: [-23.37458112] bias: [16.164376] loss: 30.590098401770383\n",
      "Epoch: 4405 / 5000\n",
      "w1: [25.277552] w2: [-23.36602959] bias: [16.17822243] loss: 30.582527675853566\n",
      "Epoch: 4406 / 5000\n",
      "w1: [25.25527246] w2: [-23.36943032] bias: [16.14678402] loss: 30.603493890539813\n",
      "Epoch: 4407 / 5000\n",
      "w1: [25.25827931] w2: [-23.35806419] bias: [16.15784349] loss: 30.596010768906766\n",
      "Epoch: 4408 / 5000\n",
      "w1: [25.28337892] w2: [-23.35390212] bias: [16.18707156] loss: 30.576551924807163\n",
      "Epoch: 4409 / 5000\n",
      "w1: [25.29658145] w2: [-23.3455437] bias: [16.20125012] loss: 30.567852356867295\n",
      "Epoch: 4410 / 5000\n",
      "w1: [25.26831633] w2: [-23.35802549] bias: [16.15971186] loss: 30.59227887296019\n",
      "Epoch: 4411 / 5000\n",
      "w1: [25.27640195] w2: [-23.34462975] bias: [16.19220587] loss: 30.575598126337287\n",
      "Epoch: 4412 / 5000\n",
      "w1: [25.28260309] w2: [-23.33996246] bias: [16.20105824] loss: 30.570657069328778\n",
      "Epoch: 4413 / 5000\n",
      "w1: [25.2784019] w2: [-23.34273446] bias: [16.18917281] loss: 30.57610801520848\n",
      "Epoch: 4414 / 5000\n",
      "w1: [25.28902774] w2: [-23.33847675] bias: [16.20443669] loss: 30.56799857030179\n",
      "Epoch: 4415 / 5000\n",
      "w1: [25.28493501] w2: [-23.34278965] bias: [16.19652864] loss: 30.571898774046318\n",
      "Epoch: 4416 / 5000\n",
      "w1: [25.28565822] w2: [-23.34712898] bias: [16.19307933] loss: 30.57327034849805\n",
      "Epoch: 4417 / 5000\n",
      "w1: [25.27285068] w2: [-23.3575544] bias: [16.16281352] loss: 30.589579732076952\n",
      "Epoch: 4418 / 5000\n",
      "w1: [25.28403547] w2: [-23.34558277] bias: [16.18423817] loss: 30.57682359928299\n",
      "Epoch: 4419 / 5000\n",
      "w1: [25.26526994] w2: [-23.353917] bias: [16.15022087] loss: 30.597127936590745\n",
      "Epoch: 4420 / 5000\n",
      "w1: [25.28866152] w2: [-23.34767084] bias: [16.18159174] loss: 30.57686657624844\n",
      "Epoch: 4421 / 5000\n",
      "w1: [25.28858535] w2: [-23.34762281] bias: [16.17812037] loss: 30.578220025522842\n",
      "Epoch: 4422 / 5000\n",
      "w1: [25.27810412] w2: [-23.35536422] bias: [16.16637347] loss: 30.58639424342347\n",
      "Epoch: 4423 / 5000\n",
      "w1: [25.29304934] w2: [-23.33979926] bias: [16.21585144] loss: 30.56360567997743\n",
      "Epoch: 4424 / 5000\n",
      "w1: [25.29783676] w2: [-23.3307755] bias: [16.23561987] loss: 30.556752810195306\n",
      "Epoch: 4425 / 5000\n",
      "w1: [25.29720712] w2: [-23.32490797] bias: [16.23850509] loss: 30.555924434348643\n",
      "Epoch: 4426 / 5000\n",
      "w1: [25.30306831] w2: [-23.3253685] bias: [16.24975581] loss: 30.552362301934995\n",
      "Epoch: 4427 / 5000\n",
      "w1: [25.30330198] w2: [-23.31920501] bias: [16.24645721] loss: 30.55287714331988\n",
      "Epoch: 4428 / 5000\n",
      "w1: [25.30353119] w2: [-23.32081035] bias: [16.24313944] loss: 30.553628061272715\n",
      "Epoch: 4429 / 5000\n",
      "w1: [25.2951654] w2: [-23.32825239] bias: [16.22843479] loss: 30.559018794551758\n",
      "Epoch: 4430 / 5000\n",
      "w1: [25.27680887] w2: [-23.33820358] bias: [16.20063579] loss: 30.572001152147514\n",
      "Epoch: 4431 / 5000\n",
      "w1: [25.28164742] w2: [-23.32127944] bias: [16.21524827] loss: 30.565130349199926\n",
      "Epoch: 4432 / 5000\n",
      "w1: [25.27101576] w2: [-23.31399805] bias: [16.2072839] loss: 30.56950476300244\n",
      "Epoch: 4433 / 5000\n",
      "w1: [25.26990567] w2: [-23.3184639] bias: [16.20016191] loss: 30.57243461998268\n",
      "Epoch: 4434 / 5000\n",
      "w1: [25.25873705] w2: [-23.32395048] bias: [16.18495524] loss: 30.581122406759516\n",
      "Epoch: 4435 / 5000\n",
      "w1: [25.25437752] w2: [-23.3246683] bias: [16.17247313] loss: 30.587395954213576\n",
      "Epoch: 4436 / 5000\n",
      "w1: [25.28028888] w2: [-23.29839529] bias: [16.22340275] loss: 30.561926217719762\n",
      "Epoch: 4437 / 5000\n",
      "w1: [25.26718075] w2: [-23.3100089] bias: [16.19534568] loss: 30.574195453656\n",
      "Epoch: 4438 / 5000\n",
      "w1: [25.25634156] w2: [-23.30580603] bias: [16.18771548] loss: 30.579281189530278\n",
      "Epoch: 4439 / 5000\n",
      "w1: [25.25469925] w2: [-23.3073379] bias: [16.17742179] loss: 30.583824121428293\n",
      "Epoch: 4440 / 5000\n",
      "w1: [25.24616448] w2: [-23.30721172] bias: [16.16721899] loss: 30.590319112769233\n",
      "Epoch: 4441 / 5000\n",
      "w1: [25.24817074] w2: [-23.2937222] bias: [16.18799931] loss: 30.580304956525286\n",
      "Epoch: 4442 / 5000\n",
      "w1: [25.24879277] w2: [-23.28337231] bias: [16.18971641] loss: 30.578788975451058\n",
      "Epoch: 4443 / 5000\n",
      "w1: [25.24026893] w2: [-23.2933087] bias: [16.16480041] loss: 30.591751648354926\n",
      "Epoch: 4444 / 5000\n",
      "w1: [25.25926781] w2: [-23.28846377] bias: [16.19081006] loss: 30.57623916967359\n",
      "Epoch: 4445 / 5000\n",
      "w1: [25.27392238] w2: [-23.2782785] bias: [16.21423297] loss: 30.564895739328158\n",
      "Epoch: 4446 / 5000\n",
      "w1: [25.27832976] w2: [-23.27851068] bias: [16.21360457] loss: 30.564213770219112\n",
      "Epoch: 4447 / 5000\n",
      "w1: [25.27325069] w2: [-23.28344817] bias: [16.20369331] loss: 30.568476726877794\n",
      "Epoch: 4448 / 5000\n",
      "w1: [25.2713828] w2: [-23.26818652] bias: [16.20958662] loss: 30.56631308676013\n",
      "Epoch: 4449 / 5000\n",
      "w1: [25.27461431] w2: [-23.25707958] bias: [16.21983778] loss: 30.56235273724579\n",
      "Epoch: 4450 / 5000\n",
      "w1: [25.26212524] w2: [-23.25628894] bias: [16.20243933] loss: 30.569844760451563\n",
      "Epoch: 4451 / 5000\n",
      "w1: [25.25671222] w2: [-23.26371718] bias: [16.18493214] loss: 30.577350745293916\n",
      "Epoch: 4452 / 5000\n",
      "w1: [25.27157336] w2: [-23.25984326] bias: [16.20554949] loss: 30.567094631619018\n",
      "Epoch: 4453 / 5000\n",
      "w1: [25.27209769] w2: [-23.26164703] bias: [16.20409648] loss: 30.567507774198052\n",
      "Epoch: 4454 / 5000\n",
      "w1: [25.28705754] w2: [-23.27202641] bias: [16.22195302] loss: 30.56003166638585\n",
      "Epoch: 4455 / 5000\n",
      "w1: [25.31247216] w2: [-23.26743083] bias: [16.27342887] loss: 30.546383305080475\n",
      "Epoch: 4456 / 5000\n",
      "w1: [25.3420301] w2: [-23.27087718] bias: [16.31570296] loss: 30.540996697944262\n",
      "Epoch: 4457 / 5000\n",
      "w1: [25.35057471] w2: [-23.26535726] bias: [16.32742245] loss: 30.54094360022504\n",
      "Epoch: 4458 / 5000\n",
      "w1: [25.3635408] w2: [-23.25817628] bias: [16.34967036] loss: 30.542370036949627\n",
      "Epoch: 4459 / 5000\n",
      "w1: [25.37807005] w2: [-23.24310335] bias: [16.38612143] loss: 30.548891868664015\n",
      "Epoch: 4460 / 5000\n",
      "w1: [25.36156971] w2: [-23.24873936] bias: [16.36663943] loss: 30.544825882192708\n",
      "Epoch: 4461 / 5000\n",
      "w1: [25.38154824] w2: [-23.24027917] bias: [16.40274998] loss: 30.552764172623668\n",
      "Epoch: 4462 / 5000\n",
      "w1: [25.37879218] w2: [-23.24695869] bias: [16.38905526] loss: 30.54909599536942\n",
      "Epoch: 4463 / 5000\n",
      "w1: [25.3905338] w2: [-23.24952932] bias: [16.40728005] loss: 30.553445107032832\n",
      "Epoch: 4464 / 5000\n",
      "w1: [25.40112147] w2: [-23.24338071] bias: [16.42205216] loss: 30.558921857892233\n",
      "Epoch: 4465 / 5000\n",
      "w1: [25.37955853] w2: [-23.2612589] bias: [16.37940321] loss: 30.546110865885133\n",
      "Epoch: 4466 / 5000\n",
      "w1: [25.38321989] w2: [-23.27073918] bias: [16.37238765] loss: 30.544352825584024\n",
      "Epoch: 4467 / 5000\n",
      "w1: [25.39593157] w2: [-23.2584915] bias: [16.39925239] loss: 30.55104619204154\n",
      "Epoch: 4468 / 5000\n",
      "w1: [25.38276743] w2: [-23.27378912] bias: [16.36907167] loss: 30.54362500310167\n",
      "Epoch: 4469 / 5000\n",
      "w1: [25.38287526] w2: [-23.26942935] bias: [16.37672149] loss: 30.54509857317421\n",
      "Epoch: 4470 / 5000\n",
      "w1: [25.37579484] w2: [-23.27800481] bias: [16.36022459] loss: 30.542087609423625\n",
      "Epoch: 4471 / 5000\n",
      "w1: [25.34371687] w2: [-23.2902489] bias: [16.32145421] loss: 30.540129136288858\n",
      "Epoch: 4472 / 5000\n",
      "w1: [25.31789846] w2: [-23.30147619] bias: [16.27651278] loss: 30.54530092713116\n",
      "Epoch: 4473 / 5000\n",
      "w1: [25.33646407] w2: [-23.28958079] bias: [16.30775612] loss: 30.540957445330683\n",
      "Epoch: 4474 / 5000\n",
      "w1: [25.3368309] w2: [-23.28996412] bias: [16.3084597] loss: 30.540891298426484\n",
      "Epoch: 4475 / 5000\n",
      "w1: [25.34790855] w2: [-23.28786631] bias: [16.32069779] loss: 30.540018864110937\n",
      "Epoch: 4476 / 5000\n",
      "w1: [25.33978277] w2: [-23.28075651] bias: [16.31441861] loss: 30.54078904853454\n",
      "Epoch: 4477 / 5000\n",
      "w1: [25.34686976] w2: [-23.27122756] bias: [16.33114799] loss: 30.540870096264122\n",
      "Epoch: 4478 / 5000\n",
      "w1: [25.33400792] w2: [-23.28538453] bias: [16.31326485] loss: 30.54102045399011\n",
      "Epoch: 4479 / 5000\n",
      "w1: [25.32542866] w2: [-23.28581352] bias: [16.31436844] loss: 30.54152324627133\n",
      "Epoch: 4480 / 5000\n",
      "w1: [25.33545969] w2: [-23.27453292] bias: [16.33505016] loss: 30.541188604767626\n",
      "Epoch: 4481 / 5000\n",
      "w1: [25.31987003] w2: [-23.27716097] bias: [16.3069709] loss: 30.542505773438087\n",
      "Epoch: 4482 / 5000\n",
      "w1: [25.31057618] w2: [-23.27770859] bias: [16.29453883] loss: 30.54419788773517\n",
      "Epoch: 4483 / 5000\n",
      "w1: [25.30854505] w2: [-23.27304841] bias: [16.2954413] loss: 30.544375308526284\n",
      "Epoch: 4484 / 5000\n",
      "w1: [25.32956537] w2: [-23.26498715] bias: [16.33038544] loss: 30.541792672979643\n",
      "Epoch: 4485 / 5000\n",
      "w1: [25.33014292] w2: [-23.25458143] bias: [16.33867476] loss: 30.542439371303516\n",
      "Epoch: 4486 / 5000\n",
      "w1: [25.34653372] w2: [-23.25149438] bias: [16.36100235] loss: 30.543828978077045\n",
      "Epoch: 4487 / 5000\n",
      "w1: [25.34629055] w2: [-23.26014734] bias: [16.34823675] loss: 30.542240820183945\n",
      "Epoch: 4488 / 5000\n",
      "w1: [25.34881708] w2: [-23.24603087] bias: [16.35900837] loss: 30.54403854024265\n",
      "Epoch: 4489 / 5000\n",
      "w1: [25.36033985] w2: [-23.2489071] bias: [16.37664952] loss: 30.54611447165767\n",
      "Epoch: 4490 / 5000\n",
      "w1: [25.35901559] w2: [-23.25280218] bias: [16.3668445] loss: 30.54448502020677\n",
      "Epoch: 4491 / 5000\n",
      "w1: [25.34718163] w2: [-23.25893096] bias: [16.34610089] loss: 30.542169253697946\n",
      "Epoch: 4492 / 5000\n",
      "w1: [25.3451417] w2: [-23.25573166] bias: [16.3455107] loss: 30.54235517376448\n",
      "Epoch: 4493 / 5000\n",
      "w1: [25.36900607] w2: [-23.25272008] bias: [16.38669046] loss: 30.547652104089213\n",
      "Epoch: 4494 / 5000\n",
      "w1: [25.38348734] w2: [-23.24239861] bias: [16.42345447] loss: 30.55770945300405\n",
      "Epoch: 4495 / 5000\n",
      "w1: [25.37041416] w2: [-23.25225143] bias: [16.39597502] loss: 30.54943076182274\n",
      "Epoch: 4496 / 5000\n",
      "w1: [25.3765123] w2: [-23.24479205] bias: [16.40827433] loss: 30.553143588587982\n",
      "Epoch: 4497 / 5000\n",
      "w1: [25.36194699] w2: [-23.25467305] bias: [16.38096705] loss: 30.54629756628156\n",
      "Epoch: 4498 / 5000\n",
      "w1: [25.37794787] w2: [-23.25229596] bias: [16.39413248] loss: 30.549488761147845\n",
      "Epoch: 4499 / 5000\n",
      "w1: [25.37357648] w2: [-23.25517793] bias: [16.39063253] loss: 30.548321255458685\n",
      "Epoch: 4500 / 5000\n",
      "w1: [25.3557969] w2: [-23.25436873] bias: [16.36504215] loss: 30.544110276701346\n",
      "Epoch: 4501 / 5000\n",
      "w1: [25.35721746] w2: [-23.25099004] bias: [16.37260035] loss: 30.54531031635958\n",
      "Epoch: 4502 / 5000\n",
      "w1: [25.35982614] w2: [-23.25612464] bias: [16.38174812] loss: 30.546219536281253\n",
      "Epoch: 4503 / 5000\n",
      "w1: [25.37616401] w2: [-23.25494541] bias: [16.39790459] loss: 30.549858624904555\n",
      "Epoch: 4504 / 5000\n",
      "w1: [25.39520359] w2: [-23.23831511] bias: [16.43842427] loss: 30.56374815403984\n",
      "Epoch: 4505 / 5000\n",
      "w1: [25.39646785] w2: [-23.22714643] bias: [16.44685307] loss: 30.56816508404246\n",
      "Epoch: 4506 / 5000\n",
      "w1: [25.40806054] w2: [-23.22785826] bias: [16.4660747] loss: 30.576604423050465\n",
      "Epoch: 4507 / 5000\n",
      "w1: [25.38761005] w2: [-23.23889869] bias: [16.42460566] loss: 30.558841808495288\n",
      "Epoch: 4508 / 5000\n",
      "w1: [25.38050065] w2: [-23.2465942] bias: [16.40534366] loss: 30.552577555018452\n",
      "Epoch: 4509 / 5000\n",
      "w1: [25.36230425] w2: [-23.26880973] bias: [16.36128417] loss: 30.542717986359822\n",
      "Epoch: 4510 / 5000\n",
      "w1: [25.35082155] w2: [-23.27338362] bias: [16.33779598] loss: 30.540861031033533\n",
      "Epoch: 4511 / 5000\n",
      "w1: [25.35110883] w2: [-23.27042244] bias: [16.33504317] loss: 30.540903500212405\n",
      "Epoch: 4512 / 5000\n",
      "w1: [25.34294544] w2: [-23.27317201] bias: [16.32515473] loss: 30.540836583478626\n",
      "Epoch: 4513 / 5000\n",
      "w1: [25.33681678] w2: [-23.27447071] bias: [16.31550534] loss: 30.541149290823576\n",
      "Epoch: 4514 / 5000\n",
      "w1: [25.32221352] w2: [-23.28181682] bias: [16.29312944] loss: 30.543191795010888\n",
      "Epoch: 4515 / 5000\n",
      "w1: [25.34064936] w2: [-23.28116869] bias: [16.3134803] loss: 30.540747502979013\n",
      "Epoch: 4516 / 5000\n",
      "w1: [25.32344132] w2: [-23.2895541] bias: [16.2804873] loss: 30.544234872544845\n",
      "Epoch: 4517 / 5000\n",
      "w1: [25.30727395] w2: [-23.2961226] bias: [16.25218337] loss: 30.550581293658695\n",
      "Epoch: 4518 / 5000\n",
      "w1: [25.30222174] w2: [-23.30472595] bias: [16.23558302] loss: 30.555100687417873\n",
      "Epoch: 4519 / 5000\n",
      "w1: [25.29582987] w2: [-23.29461808] bias: [16.23188243] loss: 30.5567525065335\n",
      "Epoch: 4520 / 5000\n",
      "w1: [25.2935583] w2: [-23.28772719] bias: [16.23066127] loss: 30.557221505330144\n",
      "Epoch: 4521 / 5000\n",
      "w1: [25.28273505] w2: [-23.29813401] bias: [16.20519692] loss: 30.566782678968863\n",
      "Epoch: 4522 / 5000\n",
      "w1: [25.27163734] w2: [-23.30001723] bias: [16.18802469] loss: 30.57510175944098\n",
      "Epoch: 4523 / 5000\n",
      "w1: [25.29789691] w2: [-23.28986222] bias: [16.25219597] loss: 30.55184786705575\n",
      "Epoch: 4524 / 5000\n",
      "w1: [25.29098633] w2: [-23.30336014] bias: [16.23154837] loss: 30.55798234948396\n",
      "Epoch: 4525 / 5000\n",
      "w1: [25.29565018] w2: [-23.30474946] bias: [16.24919428] loss: 30.55312311580619\n",
      "Epoch: 4526 / 5000\n",
      "w1: [25.30670976] w2: [-23.30505307] bias: [16.26797419] loss: 30.547975547446654\n",
      "Epoch: 4527 / 5000\n",
      "w1: [25.33596889] w2: [-23.30260741] bias: [16.30138021] loss: 30.541051270926676\n",
      "Epoch: 4528 / 5000\n",
      "w1: [25.34165101] w2: [-23.29383697] bias: [16.3259417] loss: 30.540061120260425\n",
      "Epoch: 4529 / 5000\n",
      "w1: [25.33996467] w2: [-23.29875544] bias: [16.32056638] loss: 30.540046725564622\n",
      "Epoch: 4530 / 5000\n",
      "w1: [25.34491961] w2: [-23.29946196] bias: [16.31968349] loss: 30.539769605293504\n",
      "Epoch: 4531 / 5000\n",
      "w1: [25.35621433] w2: [-23.291708] bias: [16.36129129] loss: 30.54115228848994\n",
      "Epoch: 4532 / 5000\n",
      "w1: [25.35338679] w2: [-23.29278145] bias: [16.3534652] loss: 30.540543088376932\n",
      "Epoch: 4533 / 5000\n",
      "w1: [25.36149002] w2: [-23.29232456] bias: [16.36035907] loss: 30.541031570032164\n",
      "Epoch: 4534 / 5000\n",
      "w1: [25.36047677] w2: [-23.29537734] bias: [16.35297711] loss: 30.54028662789238\n",
      "Epoch: 4535 / 5000\n",
      "w1: [25.36391328] w2: [-23.29675918] bias: [16.35529102] loss: 30.540344113616694\n",
      "Epoch: 4536 / 5000\n",
      "w1: [25.40620861] w2: [-23.2791141] bias: [16.41644896] loss: 30.5536334227601\n",
      "Epoch: 4537 / 5000\n",
      "w1: [25.4091757] w2: [-23.27801617] bias: [16.42934183] loss: 30.557484233336567\n",
      "Epoch: 4538 / 5000\n",
      "w1: [25.42425867] w2: [-23.2866282] bias: [16.45467451] loss: 30.56606309619764\n",
      "Epoch: 4539 / 5000\n",
      "w1: [25.40862369] w2: [-23.28739038] bias: [16.44520936] loss: 30.560899524512127\n",
      "Epoch: 4540 / 5000\n",
      "w1: [25.41709163] w2: [-23.2827341] bias: [16.47765368] loss: 30.573917159610833\n",
      "Epoch: 4541 / 5000\n",
      "w1: [25.40053022] w2: [-23.28668322] bias: [16.45096601] loss: 30.561809787941197\n",
      "Epoch: 4542 / 5000\n",
      "w1: [25.39486205] w2: [-23.29118597] bias: [16.43778878] loss: 30.556761477515494\n",
      "Epoch: 4543 / 5000\n",
      "w1: [25.38295549] w2: [-23.29706616] bias: [16.41538991] loss: 30.549611558174423\n",
      "Epoch: 4544 / 5000\n",
      "w1: [25.35352218] w2: [-23.30497006] bias: [16.37123231] loss: 30.541149161326413\n",
      "Epoch: 4545 / 5000\n",
      "w1: [25.35052155] w2: [-23.30381412] bias: [16.37570284] loss: 30.5416306806608\n",
      "Epoch: 4546 / 5000\n",
      "w1: [25.34220654] w2: [-23.29797836] bias: [16.37234869] loss: 30.541683504730365\n",
      "Epoch: 4547 / 5000\n",
      "w1: [25.34132316] w2: [-23.30541781] bias: [16.37802478] loss: 30.541696356518003\n",
      "Epoch: 4548 / 5000\n",
      "w1: [25.33578667] w2: [-23.30339442] bias: [16.37015323] loss: 30.54119784083178\n",
      "Epoch: 4549 / 5000\n",
      "w1: [25.33680543] w2: [-23.27607289] bias: [16.38923033] loss: 30.544992129704433\n",
      "Epoch: 4550 / 5000\n",
      "w1: [25.36864711] w2: [-23.25800165] bias: [16.44487445] loss: 30.560174418126746\n",
      "Epoch: 4551 / 5000\n",
      "w1: [25.36715874] w2: [-23.24808045] bias: [16.44867844] loss: 30.562388717082595\n",
      "Epoch: 4552 / 5000\n",
      "w1: [25.36887824] w2: [-23.25317691] bias: [16.44515837] loss: 30.560891925846114\n",
      "Epoch: 4553 / 5000\n",
      "w1: [25.3617261] w2: [-23.26023529] bias: [16.43938741] loss: 30.557732762893966\n",
      "Epoch: 4554 / 5000\n",
      "w1: [25.38239002] w2: [-23.24256778] bias: [16.47880363] loss: 30.575197777914795\n",
      "Epoch: 4555 / 5000\n",
      "w1: [25.3780741] w2: [-23.24078698] bias: [16.47327546] loss: 30.57281380754552\n",
      "Epoch: 4556 / 5000\n",
      "w1: [25.36463595] w2: [-23.24554282] bias: [16.4511778] loss: 30.563186837172534\n",
      "Epoch: 4557 / 5000\n",
      "w1: [25.35199792] w2: [-23.25100933] bias: [16.43411265] loss: 30.556630702616715\n",
      "Epoch: 4558 / 5000\n",
      "w1: [25.36357934] w2: [-23.24454126] bias: [16.45676413] loss: 30.56489594474881\n",
      "Epoch: 4559 / 5000\n",
      "w1: [25.35869489] w2: [-23.24963233] bias: [16.44617734] loss: 30.56058988761854\n",
      "Epoch: 4560 / 5000\n",
      "w1: [25.35927073] w2: [-23.2412145] bias: [16.45876869] loss: 30.565469345589797\n",
      "Epoch: 4561 / 5000\n",
      "w1: [25.34008662] w2: [-23.25217093] bias: [16.41821478] loss: 30.552076441588913\n",
      "Epoch: 4562 / 5000\n",
      "w1: [25.31916451] w2: [-23.26912471] bias: [16.37514882] loss: 30.543855576970195\n",
      "Epoch: 4563 / 5000\n",
      "w1: [25.32580039] w2: [-23.27172456] bias: [16.37904837] loss: 30.544037983850338\n",
      "Epoch: 4564 / 5000\n",
      "w1: [25.3288724] w2: [-23.26868991] bias: [16.38026214] loss: 30.544400668873678\n",
      "Epoch: 4565 / 5000\n",
      "w1: [25.32706727] w2: [-23.26612377] bias: [16.37516921] loss: 30.54406740749947\n",
      "Epoch: 4566 / 5000\n",
      "w1: [25.32727525] w2: [-23.26997805] bias: [16.37118749] loss: 30.543446896519022\n",
      "Epoch: 4567 / 5000\n",
      "w1: [25.3142599] w2: [-23.26579427] bias: [16.36112717] loss: 30.543154953786363\n",
      "Epoch: 4568 / 5000\n",
      "w1: [25.32467392] w2: [-23.25728618] bias: [16.3822695] loss: 30.545428648432264\n",
      "Epoch: 4569 / 5000\n",
      "w1: [25.31486387] w2: [-23.26682265] bias: [16.36823681] loss: 30.5435113161281\n",
      "Epoch: 4570 / 5000\n",
      "w1: [25.31725792] w2: [-23.26797453] bias: [16.36967292] loss: 30.54351417726425\n",
      "Epoch: 4571 / 5000\n",
      "w1: [25.31684786] w2: [-23.27383762] bias: [16.35509763] loss: 30.54236960592991\n",
      "Epoch: 4572 / 5000\n",
      "w1: [25.3118253] w2: [-23.28642022] bias: [16.33328796] loss: 30.541780716422956\n",
      "Epoch: 4573 / 5000\n",
      "w1: [25.3128196] w2: [-23.28615524] bias: [16.34575618] loss: 30.54168666431954\n",
      "Epoch: 4574 / 5000\n",
      "w1: [25.31602979] w2: [-23.28816644] bias: [16.34240094] loss: 30.541443013284862\n",
      "Epoch: 4575 / 5000\n",
      "w1: [25.30733908] w2: [-23.29440628] bias: [16.32493468] loss: 30.542063771138913\n",
      "Epoch: 4576 / 5000\n",
      "w1: [25.292207] w2: [-23.30263606] bias: [16.29431917] loss: 30.54590364184021\n",
      "Epoch: 4577 / 5000\n",
      "w1: [25.28834207] w2: [-23.31017947] bias: [16.2835416] loss: 30.547901712149685\n",
      "Epoch: 4578 / 5000\n",
      "w1: [25.2741724] w2: [-23.32128305] bias: [16.25953682] loss: 30.554739916029018\n",
      "Epoch: 4579 / 5000\n",
      "w1: [25.27463992] w2: [-23.31835579] bias: [16.26014923] loss: 30.5544452781583\n",
      "Epoch: 4580 / 5000\n",
      "w1: [25.29738768] w2: [-23.31012505] bias: [16.29192344] loss: 30.545615214620895\n",
      "Epoch: 4581 / 5000\n",
      "w1: [25.28493946] w2: [-23.30348874] bias: [16.28134356] loss: 30.548636996558376\n",
      "Epoch: 4582 / 5000\n",
      "w1: [25.28853901] w2: [-23.30188322] bias: [16.28602922] loss: 30.54745827595665\n",
      "Epoch: 4583 / 5000\n",
      "w1: [25.26987669] w2: [-23.30940692] bias: [16.2563154] loss: 30.555843000908265\n",
      "Epoch: 4584 / 5000\n",
      "w1: [25.27545629] w2: [-23.31233242] bias: [16.26480521] loss: 30.55316460757072\n",
      "Epoch: 4585 / 5000\n",
      "w1: [25.28164714] w2: [-23.31205383] bias: [16.27998603] loss: 30.549381147616813\n",
      "Epoch: 4586 / 5000\n",
      "w1: [25.28280187] w2: [-23.31227335] bias: [16.2761515] loss: 30.549894351031586\n",
      "Epoch: 4587 / 5000\n",
      "w1: [25.27414727] w2: [-23.32280922] bias: [16.26101352] loss: 30.554455689813523\n",
      "Epoch: 4588 / 5000\n",
      "w1: [25.26111856] w2: [-23.333028] bias: [16.23313274] loss: 30.564519452109064\n",
      "Epoch: 4589 / 5000\n",
      "w1: [25.2467254] w2: [-23.34459516] bias: [16.20802471] loss: 30.576835077170816\n",
      "Epoch: 4590 / 5000\n",
      "w1: [25.22929487] w2: [-23.34349632] bias: [16.18633429] loss: 30.58992420763218\n",
      "Epoch: 4591 / 5000\n",
      "w1: [25.22851438] w2: [-23.34514156] bias: [16.19259542] loss: 30.587610340308522\n",
      "Epoch: 4592 / 5000\n",
      "w1: [25.22673392] w2: [-23.33497845] bias: [16.19747616] loss: 30.585190039861203\n",
      "Epoch: 4593 / 5000\n",
      "w1: [25.23357536] w2: [-23.32642793] bias: [16.21691959] loss: 30.575440204626616\n",
      "Epoch: 4594 / 5000\n",
      "w1: [25.23430492] w2: [-23.32418481] bias: [16.21875906] loss: 30.574473270494167\n",
      "Epoch: 4595 / 5000\n",
      "w1: [25.22967455] w2: [-23.31456922] bias: [16.2237494] loss: 30.57320180807313\n",
      "Epoch: 4596 / 5000\n",
      "w1: [25.25196119] w2: [-23.30928624] bias: [16.2521233] loss: 30.55996907731384\n",
      "Epoch: 4597 / 5000\n",
      "w1: [25.27462743] w2: [-23.30689002] bias: [16.2801238] loss: 30.550256145372405\n",
      "Epoch: 4598 / 5000\n",
      "w1: [25.2945967] w2: [-23.29261414] bias: [16.31627972] loss: 30.5435896156819\n",
      "Epoch: 4599 / 5000\n",
      "w1: [25.31548625] w2: [-23.2945075] bias: [16.3482261] loss: 30.541238894915345\n",
      "Epoch: 4600 / 5000\n",
      "w1: [25.30434974] w2: [-23.29930837] bias: [16.32985474] loss: 30.541924184045076\n",
      "Epoch: 4601 / 5000\n",
      "w1: [25.28967907] w2: [-23.30968696] bias: [16.30188556] loss: 30.54523587312578\n",
      "Epoch: 4602 / 5000\n",
      "w1: [25.29520872] w2: [-23.31100755] bias: [16.3293857] loss: 30.54230394480765\n",
      "Epoch: 4603 / 5000\n",
      "w1: [25.29569395] w2: [-23.30839953] bias: [16.33670125] loss: 30.541974068703702\n",
      "Epoch: 4604 / 5000\n",
      "w1: [25.30133363] w2: [-23.31998057] bias: [16.33570295] loss: 30.54132812965288\n",
      "Epoch: 4605 / 5000\n",
      "w1: [25.28650309] w2: [-23.32786112] bias: [16.30534127] loss: 30.545114450095614\n",
      "Epoch: 4606 / 5000\n",
      "w1: [25.2771713] w2: [-23.332886] bias: [16.28706066] loss: 30.549035874027098\n",
      "Epoch: 4607 / 5000\n",
      "w1: [25.27021374] w2: [-23.32567179] bias: [16.30420222] loss: 30.547149451318216\n",
      "Epoch: 4608 / 5000\n",
      "w1: [25.27715316] w2: [-23.32762762] bias: [16.30879252] loss: 30.545722528948186\n",
      "Epoch: 4609 / 5000\n",
      "w1: [25.28556583] w2: [-23.31949682] bias: [16.32376743] loss: 30.543346074691353\n",
      "Epoch: 4610 / 5000\n",
      "w1: [25.27392745] w2: [-23.32711081] bias: [16.29765264] loss: 30.547668013433185\n",
      "Epoch: 4611 / 5000\n",
      "w1: [25.27252647] w2: [-23.33166832] bias: [16.29284428] loss: 30.548660388310555\n",
      "Epoch: 4612 / 5000\n",
      "w1: [25.26043669] w2: [-23.33130852] bias: [16.28486074] loss: 30.55179938075686\n",
      "Epoch: 4613 / 5000\n",
      "w1: [25.2651439] w2: [-23.32585714] bias: [16.29348785] loss: 30.54947355792015\n",
      "Epoch: 4614 / 5000\n",
      "w1: [25.27453787] w2: [-23.33236992] bias: [16.29603734] loss: 30.54788486481866\n",
      "Epoch: 4615 / 5000\n",
      "w1: [25.27346763] w2: [-23.34004864] bias: [16.30396374] loss: 30.546862940630326\n",
      "Epoch: 4616 / 5000\n",
      "w1: [25.25812314] w2: [-23.34406881] bias: [16.27900383] loss: 30.553660686533778\n",
      "Epoch: 4617 / 5000\n",
      "w1: [25.25486932] w2: [-23.3300925] bias: [16.2863612] loss: 30.552309836292494\n",
      "Epoch: 4618 / 5000\n",
      "w1: [25.28441123] w2: [-23.32288172] bias: [16.3285957] loss: 30.543007566613817\n",
      "Epoch: 4619 / 5000\n",
      "w1: [25.27508386] w2: [-23.31668023] bias: [16.32029357] loss: 30.544686052241218\n",
      "Epoch: 4620 / 5000\n",
      "w1: [25.27468067] w2: [-23.31921668] bias: [16.31713562] loss: 30.54503506369802\n",
      "Epoch: 4621 / 5000\n",
      "w1: [25.28341797] w2: [-23.31518198] bias: [16.32732225] loss: 30.54331537440145\n",
      "Epoch: 4622 / 5000\n",
      "w1: [25.28616563] w2: [-23.31615733] bias: [16.32654888] loss: 30.543122418508897\n",
      "Epoch: 4623 / 5000\n",
      "w1: [25.29324866] w2: [-23.29912142] bias: [16.35640257] loss: 30.54204282836243\n",
      "Epoch: 4624 / 5000\n",
      "w1: [25.30017264] w2: [-23.2881498] bias: [16.37066944] loss: 30.542653435851786\n",
      "Epoch: 4625 / 5000\n",
      "w1: [25.30120813] w2: [-23.28708005] bias: [16.36987745] loss: 30.542652663577343\n",
      "Epoch: 4626 / 5000\n",
      "w1: [25.30759146] w2: [-23.28956468] bias: [16.37314717] loss: 30.542548098588163\n",
      "Epoch: 4627 / 5000\n",
      "w1: [25.30512911] w2: [-23.29092189] bias: [16.361217] loss: 30.542031379026973\n",
      "Epoch: 4628 / 5000\n",
      "w1: [25.29661032] w2: [-23.28973408] bias: [16.34942149] loss: 30.54227285276289\n",
      "Epoch: 4629 / 5000\n",
      "w1: [25.29990048] w2: [-23.29772216] bias: [16.34669588] loss: 30.541817113800537\n",
      "Epoch: 4630 / 5000\n",
      "w1: [25.29295834] w2: [-23.29791228] bias: [16.34398336] loss: 30.542235019182453\n",
      "Epoch: 4631 / 5000\n",
      "w1: [25.29048244] w2: [-23.29314098] bias: [16.35252526] loss: 30.542422326937164\n",
      "Epoch: 4632 / 5000\n",
      "w1: [25.30704832] w2: [-23.28746543] bias: [16.37445057] loss: 30.542754051566952\n",
      "Epoch: 4633 / 5000\n",
      "w1: [25.30768125] w2: [-23.29641196] bias: [16.36734303] loss: 30.541890735860566\n",
      "Epoch: 4634 / 5000\n",
      "w1: [25.31976586] w2: [-23.27131007] bias: [16.40253131] loss: 30.54674395478709\n",
      "Epoch: 4635 / 5000\n",
      "w1: [25.33068234] w2: [-23.27285589] bias: [16.4174181] loss: 30.549364488694923\n",
      "Epoch: 4636 / 5000\n",
      "w1: [25.31471181] w2: [-23.29064972] bias: [16.37741362] loss: 30.542662971843512\n",
      "Epoch: 4637 / 5000\n",
      "w1: [25.30879814] w2: [-23.29377984] bias: [16.36709358] loss: 30.541992422819668\n",
      "Epoch: 4638 / 5000\n",
      "w1: [25.31060479] w2: [-23.29414146] bias: [16.36417283] loss: 30.541810842783708\n",
      "Epoch: 4639 / 5000\n",
      "w1: [25.32279466] w2: [-23.28988935] bias: [16.38345652] loss: 30.543181111472812\n",
      "Epoch: 4640 / 5000\n",
      "w1: [25.302586] w2: [-23.30238682] bias: [16.34221169] loss: 30.541571226668765\n",
      "Epoch: 4641 / 5000\n",
      "w1: [25.31477062] w2: [-23.30334622] bias: [16.35032118] loss: 30.540909191704785\n",
      "Epoch: 4642 / 5000\n",
      "w1: [25.32431847] w2: [-23.30413847] bias: [16.37482474] loss: 30.541575533818587\n",
      "Epoch: 4643 / 5000\n",
      "w1: [25.31749055] w2: [-23.30449101] bias: [16.3653718] loss: 30.54115152181384\n",
      "Epoch: 4644 / 5000\n",
      "w1: [25.31472419] w2: [-23.3107936] bias: [16.35191781] loss: 30.540613019303308\n",
      "Epoch: 4645 / 5000\n",
      "w1: [25.3153737] w2: [-23.3020371] bias: [16.35608514] loss: 30.54103604960841\n",
      "Epoch: 4646 / 5000\n",
      "w1: [25.31677198] w2: [-23.3152254] bias: [16.34152218] loss: 30.54037749223092\n",
      "Epoch: 4647 / 5000\n",
      "w1: [25.31980262] w2: [-23.31271412] bias: [16.34529947] loss: 30.540294395869818\n",
      "Epoch: 4648 / 5000\n",
      "w1: [25.32567413] w2: [-23.30577412] bias: [16.35571603] loss: 30.540525988399914\n",
      "Epoch: 4649 / 5000\n",
      "w1: [25.32807354] w2: [-23.29328004] bias: [16.37062979] loss: 30.541907130433998\n",
      "Epoch: 4650 / 5000\n",
      "w1: [25.32474727] w2: [-23.29269859] bias: [16.36809701] loss: 30.541811473505735\n",
      "Epoch: 4651 / 5000\n",
      "w1: [25.32121615] w2: [-23.29039337] bias: [16.37217213] loss: 30.54225377941764\n",
      "Epoch: 4652 / 5000\n",
      "w1: [25.32682835] w2: [-23.2718657] bias: [16.39366526] loss: 30.545684547009632\n",
      "Epoch: 4653 / 5000\n",
      "w1: [25.32169229] w2: [-23.26730014] bias: [16.39160167] loss: 30.545694027620915\n",
      "Epoch: 4654 / 5000\n",
      "w1: [25.30301044] w2: [-23.2778472] bias: [16.35923167] loss: 30.542695487661348\n",
      "Epoch: 4655 / 5000\n",
      "w1: [25.31375646] w2: [-23.27593991] bias: [16.37343465] loss: 30.543308780568818\n",
      "Epoch: 4656 / 5000\n",
      "w1: [25.31781954] w2: [-23.26505622] bias: [16.38825506] loss: 30.54542347244081\n",
      "Epoch: 4657 / 5000\n",
      "w1: [25.31298153] w2: [-23.2742463] bias: [16.37777256] loss: 30.543750843962723\n",
      "Epoch: 4658 / 5000\n",
      "w1: [25.33721147] w2: [-23.26055124] bias: [16.41409637] loss: 30.550271020522842\n",
      "Epoch: 4659 / 5000\n",
      "w1: [25.3331468] w2: [-23.26652555] bias: [16.40324112] loss: 30.54767492745277\n",
      "Epoch: 4660 / 5000\n",
      "w1: [25.32149134] w2: [-23.27562412] bias: [16.38618493] loss: 30.544449269248425\n",
      "Epoch: 4661 / 5000\n",
      "w1: [25.32331157] w2: [-23.28160049] bias: [16.38678908] loss: 30.54409356455625\n",
      "Epoch: 4662 / 5000\n",
      "w1: [25.3367798] w2: [-23.28137424] bias: [16.40066552] loss: 30.546117473074453\n",
      "Epoch: 4663 / 5000\n",
      "w1: [25.34319856] w2: [-23.27574962] bias: [16.41942899] loss: 30.550104603268508\n",
      "Epoch: 4664 / 5000\n",
      "w1: [25.34474553] w2: [-23.27412614] bias: [16.42198245] loss: 30.55086214978736\n",
      "Epoch: 4665 / 5000\n",
      "w1: [25.34401794] w2: [-23.28177816] bias: [16.41205343] loss: 30.548200972789548\n",
      "Epoch: 4666 / 5000\n",
      "w1: [25.34474732] w2: [-23.27616009] bias: [16.42255197] loss: 30.55077056657195\n",
      "Epoch: 4667 / 5000\n",
      "w1: [25.3459955] w2: [-23.27175726] bias: [16.43438898] loss: 30.553868356409755\n",
      "Epoch: 4668 / 5000\n",
      "w1: [25.33231841] w2: [-23.2731407] bias: [16.41735664] loss: 30.549404543071187\n",
      "Epoch: 4669 / 5000\n",
      "w1: [25.33951704] w2: [-23.26012516] bias: [16.43442183] loss: 30.554682841890408\n",
      "Epoch: 4670 / 5000\n",
      "w1: [25.33663832] w2: [-23.27148509] bias: [16.41603383] loss: 30.549535303536636\n",
      "Epoch: 4671 / 5000\n",
      "w1: [25.33361413] w2: [-23.27784844] bias: [16.40315698] loss: 30.54668649376856\n",
      "Epoch: 4672 / 5000\n",
      "w1: [25.34136037] w2: [-23.28068744] bias: [16.40597751] loss: 30.547157621732342\n",
      "Epoch: 4673 / 5000\n",
      "w1: [25.32881533] w2: [-23.28128007] bias: [16.38768078] loss: 30.54427304188987\n",
      "Epoch: 4674 / 5000\n",
      "w1: [25.33898931] w2: [-23.28957301] bias: [16.39124308] loss: 30.54423296052021\n",
      "Epoch: 4675 / 5000\n",
      "w1: [25.35898348] w2: [-23.28241869] bias: [16.42202547] loss: 30.55091735237713\n",
      "Epoch: 4676 / 5000\n",
      "w1: [25.34083631] w2: [-23.28303597] bias: [16.40083794] loss: 30.546131924745556\n",
      "Epoch: 4677 / 5000\n",
      "w1: [25.34299727] w2: [-23.27564553] bias: [16.40444823] loss: 30.547426083876058\n",
      "Epoch: 4678 / 5000\n",
      "w1: [25.33507703] w2: [-23.26997564] bias: [16.39476465] loss: 30.546183143831527\n",
      "Epoch: 4679 / 5000\n",
      "w1: [25.33979103] w2: [-23.27400538] bias: [16.39368444] loss: 30.545825366328938\n",
      "Epoch: 4680 / 5000\n",
      "w1: [25.33944967] w2: [-23.27961074] bias: [16.38813402] loss: 30.54462957239249\n",
      "Epoch: 4681 / 5000\n",
      "w1: [25.36548008] w2: [-23.27374267] bias: [16.42492859] loss: 30.55293906334733\n",
      "Epoch: 4682 / 5000\n",
      "w1: [25.36334076] w2: [-23.25121629] bias: [16.43176828] loss: 30.556987236948153\n",
      "Epoch: 4683 / 5000\n",
      "w1: [25.3664556] w2: [-23.25670134] bias: [16.43088033] loss: 30.556385588792526\n",
      "Epoch: 4684 / 5000\n",
      "w1: [25.36526616] w2: [-23.26039734] bias: [16.42818819] loss: 30.555187860857288\n",
      "Epoch: 4685 / 5000\n",
      "w1: [25.36383503] w2: [-23.25227516] bias: [16.4316825] loss: 30.556883068695\n",
      "Epoch: 4686 / 5000\n",
      "w1: [25.36712304] w2: [-23.26195315] bias: [16.42348932] loss: 30.554035086369765\n",
      "Epoch: 4687 / 5000\n",
      "w1: [25.37270818] w2: [-23.25795188] bias: [16.4335453] loss: 30.557486070106577\n",
      "Epoch: 4688 / 5000\n",
      "w1: [25.36469752] w2: [-23.26295062] bias: [16.41823515] loss: 30.552544645794132\n",
      "Epoch: 4689 / 5000\n",
      "w1: [25.36098079] w2: [-23.26626077] bias: [16.4130226] loss: 30.550835807398954\n",
      "Epoch: 4690 / 5000\n",
      "w1: [25.36485264] w2: [-23.27114831] bias: [16.43203683] loss: 30.554863129948643\n",
      "Epoch: 4691 / 5000\n",
      "w1: [25.37402677] w2: [-23.27128696] bias: [16.4389601] loss: 30.557438955396282\n",
      "Epoch: 4692 / 5000\n",
      "w1: [25.39265719] w2: [-23.26766798] bias: [16.47600455] loss: 30.571871002603107\n",
      "Epoch: 4693 / 5000\n",
      "w1: [25.39060359] w2: [-23.26896946] bias: [16.47691312] loss: 30.57170737126892\n",
      "Epoch: 4694 / 5000\n",
      "w1: [25.38526348] w2: [-23.2753191] bias: [16.45905122] loss: 30.564021777589858\n",
      "Epoch: 4695 / 5000\n",
      "w1: [25.35563812] w2: [-23.28676303] bias: [16.40758118] loss: 30.54749862971577\n",
      "Epoch: 4696 / 5000\n",
      "w1: [25.3419638] w2: [-23.28525487] bias: [16.38863572] loss: 30.54430268259259\n",
      "Epoch: 4697 / 5000\n",
      "w1: [25.3357086] w2: [-23.28635263] bias: [16.38027357] loss: 30.543185537838163\n",
      "Epoch: 4698 / 5000\n",
      "w1: [25.33054283] w2: [-23.29471685] bias: [16.36936809] loss: 30.541710312312816\n",
      "Epoch: 4699 / 5000\n",
      "w1: [25.31452485] w2: [-23.31165942] bias: [16.32471055] loss: 30.541128045966058\n",
      "Epoch: 4700 / 5000\n",
      "w1: [25.29756369] w2: [-23.32461122] bias: [16.29285374] loss: 30.54548665375658\n",
      "Epoch: 4701 / 5000\n",
      "w1: [25.30448744] w2: [-23.31540282] bias: [16.30791912] loss: 30.54306406493188\n",
      "Epoch: 4702 / 5000\n",
      "w1: [25.29387621] w2: [-23.30802386] bias: [16.30995913] loss: 30.543959704489968\n",
      "Epoch: 4703 / 5000\n",
      "w1: [25.27950106] w2: [-23.30911877] bias: [16.29244885] loss: 30.547655063908145\n",
      "Epoch: 4704 / 5000\n",
      "w1: [25.27045774] w2: [-23.31051116] bias: [16.27719111] loss: 30.55142813905433\n",
      "Epoch: 4705 / 5000\n",
      "w1: [25.28147592] w2: [-23.31261203] bias: [16.28883785] loss: 30.547969721542636\n",
      "Epoch: 4706 / 5000\n",
      "w1: [25.27464309] w2: [-23.31057878] bias: [16.27911637] loss: 30.55048031684549\n",
      "Epoch: 4707 / 5000\n",
      "w1: [25.27327349] w2: [-23.30963902] bias: [16.27176824] loss: 30.552037556098373\n",
      "Epoch: 4708 / 5000\n",
      "w1: [25.30191657] w2: [-23.30263613] bias: [16.31188823] loss: 30.54312210669259\n",
      "Epoch: 4709 / 5000\n",
      "w1: [25.2960322] w2: [-23.31184006] bias: [16.29263237] loss: 30.54567648400391\n",
      "Epoch: 4710 / 5000\n",
      "w1: [25.29311012] w2: [-23.31439844] bias: [16.28671822] loss: 30.54684982806235\n",
      "Epoch: 4711 / 5000\n",
      "w1: [25.29971483] w2: [-23.30562031] bias: [16.29959653] loss: 30.54446398121613\n",
      "Epoch: 4712 / 5000\n",
      "w1: [25.27754672] w2: [-23.31993307] bias: [16.25342056] loss: 30.55554300820653\n",
      "Epoch: 4713 / 5000\n",
      "w1: [25.28140398] w2: [-23.3286406] bias: [16.25106981] loss: 30.55572546542714\n",
      "Epoch: 4714 / 5000\n",
      "w1: [25.28208173] w2: [-23.3242105] bias: [16.25666603] loss: 30.554176698912247\n",
      "Epoch: 4715 / 5000\n",
      "w1: [25.2752731] w2: [-23.3256201] bias: [16.24391904] loss: 30.558471702712577\n",
      "Epoch: 4716 / 5000\n",
      "w1: [25.28721237] w2: [-23.32648328] bias: [16.25435799] loss: 30.553924926289636\n",
      "Epoch: 4717 / 5000\n",
      "w1: [25.27732477] w2: [-23.33434093] bias: [16.23229352] loss: 30.561616385030224\n",
      "Epoch: 4718 / 5000\n",
      "w1: [25.27428708] w2: [-23.33888214] bias: [16.22554549] loss: 30.564435616724438\n",
      "Epoch: 4719 / 5000\n",
      "w1: [25.2671615] w2: [-23.32965528] bias: [16.22263875] loss: 30.566301926266604\n",
      "Epoch: 4720 / 5000\n",
      "w1: [25.27831985] w2: [-23.32547802] bias: [16.23601686] loss: 30.55999466805863\n",
      "Epoch: 4721 / 5000\n",
      "w1: [25.2637165] w2: [-23.32933856] bias: [16.21358329] loss: 30.56994132281374\n",
      "Epoch: 4722 / 5000\n",
      "w1: [25.26293856] w2: [-23.33764463] bias: [16.1983805] loss: 30.576015340012045\n",
      "Epoch: 4723 / 5000\n",
      "w1: [25.27357498] w2: [-23.33172397] bias: [16.21567178] loss: 30.567266318558616\n",
      "Epoch: 4724 / 5000\n",
      "w1: [25.27350784] w2: [-23.33606772] bias: [16.2072757] loss: 30.570314435675222\n",
      "Epoch: 4725 / 5000\n",
      "w1: [25.26277496] w2: [-23.33115296] bias: [16.205814] loss: 30.572925193634838\n",
      "Epoch: 4726 / 5000\n",
      "w1: [25.2499502] w2: [-23.32182009] bias: [16.19957888] loss: 30.577543879277325\n",
      "Epoch: 4727 / 5000\n",
      "w1: [25.24435783] w2: [-23.33218378] bias: [16.18499542] loss: 30.5854692811754\n",
      "Epoch: 4728 / 5000\n",
      "w1: [25.24142512] w2: [-23.32301767] bias: [16.18710609] loss: 30.584607568983987\n",
      "Epoch: 4729 / 5000\n",
      "w1: [25.24064386] w2: [-23.31777949] bias: [16.19191827] loss: 30.582467029095213\n",
      "Epoch: 4730 / 5000\n",
      "w1: [25.25769684] w2: [-23.30860456] bias: [16.23132773] loss: 30.564543490254135\n",
      "Epoch: 4731 / 5000\n",
      "w1: [25.27931084] w2: [-23.28656813] bias: [16.28032006] loss: 30.54941772919021\n",
      "Epoch: 4732 / 5000\n",
      "w1: [25.28325769] w2: [-23.27424781] bias: [16.29362146] loss: 30.547112212609527\n",
      "Epoch: 4733 / 5000\n",
      "w1: [25.28540666] w2: [-23.261871] bias: [16.30121248] loss: 30.546214650675093\n",
      "Epoch: 4734 / 5000\n",
      "w1: [25.27079813] w2: [-23.2716185] bias: [16.27665107] loss: 30.551042416242176\n",
      "Epoch: 4735 / 5000\n",
      "w1: [25.27629069] w2: [-23.25021565] bias: [16.30254332] loss: 30.547161563215536\n",
      "Epoch: 4736 / 5000\n",
      "w1: [25.26248732] w2: [-23.25621486] bias: [16.28689901] loss: 30.550497241459002\n",
      "Epoch: 4737 / 5000\n",
      "w1: [25.2659447] w2: [-23.25511219] bias: [16.29869768] loss: 30.54857053978201\n",
      "Epoch: 4738 / 5000\n",
      "w1: [25.2637408] w2: [-23.2419458] bias: [16.30591115] loss: 30.548215510599196\n",
      "Epoch: 4739 / 5000\n",
      "w1: [25.25730833] w2: [-23.25339576] bias: [16.28461929] loss: 30.55148842673715\n",
      "Epoch: 4740 / 5000\n",
      "w1: [25.23361919] w2: [-23.26518035] bias: [16.23921665] loss: 30.565198329430736\n",
      "Epoch: 4741 / 5000\n",
      "w1: [25.23900082] w2: [-23.25347554] bias: [16.2526397] loss: 30.56042938536506\n",
      "Epoch: 4742 / 5000\n",
      "w1: [25.22958859] w2: [-23.25854366] bias: [16.23506058] loss: 30.566887958502733\n",
      "Epoch: 4743 / 5000\n",
      "w1: [25.22451083] w2: [-23.26044834] bias: [16.22569463] loss: 30.570776740699248\n",
      "Epoch: 4744 / 5000\n",
      "w1: [25.22170389] w2: [-23.26557762] bias: [16.21235569] loss: 30.575990084324484\n",
      "Epoch: 4745 / 5000\n",
      "w1: [25.21603695] w2: [-23.26863623] bias: [16.20682383] loss: 30.57943161191037\n",
      "Epoch: 4746 / 5000\n",
      "w1: [25.21939459] w2: [-23.26447642] bias: [16.22480692] loss: 30.57234214050146\n",
      "Epoch: 4747 / 5000\n",
      "w1: [25.21856776] w2: [-23.26394624] bias: [16.2271233] loss: 30.571762144369515\n",
      "Epoch: 4748 / 5000\n",
      "w1: [25.19871353] w2: [-23.27945608] bias: [16.18721106] loss: 30.592311254663368\n",
      "Epoch: 4749 / 5000\n",
      "w1: [25.21137734] w2: [-23.26309892] bias: [16.21258012] loss: 30.578147203020276\n",
      "Epoch: 4750 / 5000\n",
      "w1: [25.21471634] w2: [-23.25804333] bias: [16.21639046] loss: 30.57578705427691\n",
      "Epoch: 4751 / 5000\n",
      "w1: [25.22837855] w2: [-23.25259501] bias: [16.2308746] loss: 30.568087686951255\n",
      "Epoch: 4752 / 5000\n",
      "w1: [25.22356681] w2: [-23.26244773] bias: [16.21244502] loss: 30.575360186152793\n",
      "Epoch: 4753 / 5000\n",
      "w1: [25.22833132] w2: [-23.24856282] bias: [16.2301981] loss: 30.56812896594453\n",
      "Epoch: 4754 / 5000\n",
      "w1: [25.24540194] w2: [-23.24140461] bias: [16.25255071] loss: 30.559097068850235\n",
      "Epoch: 4755 / 5000\n",
      "w1: [25.24790155] w2: [-23.24844983] bias: [16.24659893] loss: 30.56019064587248\n",
      "Epoch: 4756 / 5000\n",
      "w1: [25.25300198] w2: [-23.26007446] bias: [16.2446512] loss: 30.560073901188034\n",
      "Epoch: 4757 / 5000\n",
      "w1: [25.25782295] w2: [-23.26198529] bias: [16.24526376] loss: 30.5591457521283\n",
      "Epoch: 4758 / 5000\n",
      "w1: [25.25933418] w2: [-23.25504216] bias: [16.24585115] loss: 30.55857931492035\n",
      "Epoch: 4759 / 5000\n",
      "w1: [25.24580997] w2: [-23.26263428] bias: [16.21864373] loss: 30.568583460240216\n",
      "Epoch: 4760 / 5000\n",
      "w1: [25.27066903] w2: [-23.25489023] bias: [16.25756547] loss: 30.55431043076641\n",
      "Epoch: 4761 / 5000\n",
      "w1: [25.27075798] w2: [-23.25972528] bias: [16.25716836] loss: 30.554442892992835\n",
      "Epoch: 4762 / 5000\n",
      "w1: [25.27798475] w2: [-23.26230337] bias: [16.2623043] loss: 30.55244857312271\n",
      "Epoch: 4763 / 5000\n",
      "w1: [25.29834425] w2: [-23.26444414] bias: [16.2913487] loss: 30.545871393194023\n",
      "Epoch: 4764 / 5000\n",
      "w1: [25.31056506] w2: [-23.26091648] bias: [16.30797878] loss: 30.543565490776494\n",
      "Epoch: 4765 / 5000\n",
      "w1: [25.3003204] w2: [-23.27169175] bias: [16.28199067] loss: 30.546654066763292\n",
      "Epoch: 4766 / 5000\n",
      "w1: [25.29768955] w2: [-23.28043631] bias: [16.26915443] loss: 30.548769372192094\n",
      "Epoch: 4767 / 5000\n",
      "w1: [25.3103586] w2: [-23.27064056] bias: [16.29726831] loss: 30.544094457158216\n",
      "Epoch: 4768 / 5000\n",
      "w1: [25.31740925] w2: [-23.27701668] bias: [16.29585997] loss: 30.543472444674716\n",
      "Epoch: 4769 / 5000\n",
      "w1: [25.31042446] w2: [-23.28254637] bias: [16.28046373] loss: 30.545670941256137\n",
      "Epoch: 4770 / 5000\n",
      "w1: [25.32786709] w2: [-23.28528157] bias: [16.29586847] loss: 30.54242275716684\n",
      "Epoch: 4771 / 5000\n",
      "w1: [25.33152273] w2: [-23.28920092] bias: [16.29396774] loss: 30.542188525205646\n",
      "Epoch: 4772 / 5000\n",
      "w1: [25.34462157] w2: [-23.29464522] bias: [16.31558522] loss: 30.540029676196376\n",
      "Epoch: 4773 / 5000\n",
      "w1: [25.33854612] w2: [-23.29990816] bias: [16.31130321] loss: 30.540390528504552\n",
      "Epoch: 4774 / 5000\n",
      "w1: [25.31642282] w2: [-23.30747076] bias: [16.27340639] loss: 30.545924715585123\n",
      "Epoch: 4775 / 5000\n",
      "w1: [25.31617692] w2: [-23.31419284] bias: [16.2672214] loss: 30.54695497859431\n",
      "Epoch: 4776 / 5000\n",
      "w1: [25.31983941] w2: [-23.30906564] bias: [16.27247455] loss: 30.54565481236291\n",
      "Epoch: 4777 / 5000\n",
      "w1: [25.3239597] w2: [-23.30482548] bias: [16.28508548] loss: 30.54357455736921\n",
      "Epoch: 4778 / 5000\n",
      "w1: [25.30083104] w2: [-23.31919928] bias: [16.24374719] loss: 30.553884415116308\n",
      "Epoch: 4779 / 5000\n",
      "w1: [25.31901048] w2: [-23.30937392] bias: [16.26906383] loss: 30.54626440499009\n",
      "Epoch: 4780 / 5000\n",
      "w1: [25.32646769] w2: [-23.30472623] bias: [16.29093287] loss: 30.54270949604482\n",
      "Epoch: 4781 / 5000\n",
      "w1: [25.29920555] w2: [-23.3105526] bias: [16.25908488] loss: 30.55069275925817\n",
      "Epoch: 4782 / 5000\n",
      "w1: [25.30517239] w2: [-23.30780543] bias: [16.27127079] loss: 30.547665010222666\n",
      "Epoch: 4783 / 5000\n",
      "w1: [25.30509486] w2: [-23.31389847] bias: [16.26492574] loss: 30.548824334115288\n",
      "Epoch: 4784 / 5000\n",
      "w1: [25.30339424] w2: [-23.3180523] bias: [16.25758793] loss: 30.550515645652006\n",
      "Epoch: 4785 / 5000\n",
      "w1: [25.32103724] w2: [-23.31331604] bias: [16.28342222] loss: 30.54405497062823\n",
      "Epoch: 4786 / 5000\n",
      "w1: [25.3121341] w2: [-23.32433469] bias: [16.25930528] loss: 30.54903704675827\n",
      "Epoch: 4787 / 5000\n",
      "w1: [25.30747117] w2: [-23.33497181] bias: [16.24410391] loss: 30.553198922342784\n",
      "Epoch: 4788 / 5000\n",
      "w1: [25.29147118] w2: [-23.34342336] bias: [16.21979569] loss: 30.562928296981916\n",
      "Epoch: 4789 / 5000\n",
      "w1: [25.29202391] w2: [-23.33309873] bias: [16.22710278] loss: 30.56019198357676\n",
      "Epoch: 4790 / 5000\n",
      "w1: [25.304665] w2: [-23.32011623] bias: [16.25260446] loss: 30.551375760182307\n",
      "Epoch: 4791 / 5000\n",
      "w1: [25.3194688] w2: [-23.32182051] bias: [16.27021762] loss: 30.546130138317103\n",
      "Epoch: 4792 / 5000\n",
      "w1: [25.31480749] w2: [-23.32442005] bias: [16.26494891] loss: 30.54764437064163\n",
      "Epoch: 4793 / 5000\n",
      "w1: [25.31216971] w2: [-23.32391866] bias: [16.25973881] loss: 30.54894298052403\n",
      "Epoch: 4794 / 5000\n",
      "w1: [25.32852685] w2: [-23.32698023] bias: [16.27646372] loss: 30.544143722712032\n",
      "Epoch: 4795 / 5000\n",
      "w1: [25.31717974] w2: [-23.3286293] bias: [16.26741558] loss: 30.546961853924465\n",
      "Epoch: 4796 / 5000\n",
      "w1: [25.31517183] w2: [-23.32725594] bias: [16.25996837] loss: 30.54853542723066\n",
      "Epoch: 4797 / 5000\n",
      "w1: [25.30788441] w2: [-23.31679557] bias: [16.26651986] loss: 30.548202924105755\n",
      "Epoch: 4798 / 5000\n",
      "w1: [25.31030037] w2: [-23.30745927] bias: [16.27407634] loss: 30.54657485451053\n",
      "Epoch: 4799 / 5000\n",
      "w1: [25.30947006] w2: [-23.30474669] bias: [16.27046846] loss: 30.547214597582613\n",
      "Epoch: 4800 / 5000\n",
      "w1: [25.3158358] w2: [-23.29235874] bias: [16.29277035] loss: 30.543680297716232\n",
      "Epoch: 4801 / 5000\n",
      "w1: [25.3302] w2: [-23.29360885] bias: [16.3094362] loss: 30.541212606131644\n",
      "Epoch: 4802 / 5000\n",
      "w1: [25.34571146] w2: [-23.28759412] bias: [16.33779441] loss: 30.540288886326667\n",
      "Epoch: 4803 / 5000\n",
      "w1: [25.35088747] w2: [-23.29431318] bias: [16.34381171] loss: 30.540012861376393\n",
      "Epoch: 4804 / 5000\n",
      "w1: [25.36108346] w2: [-23.27854955] bias: [16.36804394] loss: 30.542713898594204\n",
      "Epoch: 4805 / 5000\n",
      "w1: [25.37274895] w2: [-23.28258419] bias: [16.37848223] loss: 30.543927540363914\n",
      "Epoch: 4806 / 5000\n",
      "w1: [25.36845014] w2: [-23.28303678] bias: [16.36905012] loss: 30.542600101433727\n",
      "Epoch: 4807 / 5000\n",
      "w1: [25.33554832] w2: [-23.30797108] bias: [16.31869608] loss: 30.540080708367803\n",
      "Epoch: 4808 / 5000\n",
      "w1: [25.32638191] w2: [-23.31724355] bias: [16.30541402] loss: 30.54129839797426\n",
      "Epoch: 4809 / 5000\n",
      "w1: [25.33573871] w2: [-23.31560918] bias: [16.30990664] loss: 30.540286004077423\n",
      "Epoch: 4810 / 5000\n",
      "w1: [25.3208043] w2: [-23.31788292] bias: [16.31135772] loss: 30.54131262360686\n",
      "Epoch: 4811 / 5000\n",
      "w1: [25.30189292] w2: [-23.32603504] bias: [16.27686862] loss: 30.547367255344106\n",
      "Epoch: 4812 / 5000\n",
      "w1: [25.30317212] w2: [-23.32393503] bias: [16.2808649] loss: 30.546545740593693\n",
      "Epoch: 4813 / 5000\n",
      "w1: [25.31080298] w2: [-23.32907294] bias: [16.2896773] loss: 30.544401658363146\n",
      "Epoch: 4814 / 5000\n",
      "w1: [25.30385453] w2: [-23.33195456] bias: [16.27238126] loss: 30.547946217457323\n",
      "Epoch: 4815 / 5000\n",
      "w1: [25.30237265] w2: [-23.33302602] bias: [16.2701808] loss: 30.54856063703946\n",
      "Epoch: 4816 / 5000\n",
      "w1: [25.31237706] w2: [-23.33136479] bias: [16.27936131] loss: 30.545689469700523\n",
      "Epoch: 4817 / 5000\n",
      "w1: [25.3171182] w2: [-23.336293] bias: [16.27639176] loss: 30.545600852388304\n",
      "Epoch: 4818 / 5000\n",
      "w1: [25.31942102] w2: [-23.32864229] bias: [16.29205662] loss: 30.54316144280164\n",
      "Epoch: 4819 / 5000\n",
      "w1: [25.32019093] w2: [-23.3274926] bias: [16.29325359] loss: 30.542945434817668\n",
      "Epoch: 4820 / 5000\n",
      "w1: [25.29598994] w2: [-23.33682344] bias: [16.26056806] loss: 30.551463529934004\n",
      "Epoch: 4821 / 5000\n",
      "w1: [25.29177163] w2: [-23.34230129] bias: [16.25963713] loss: 30.55247510949429\n",
      "Epoch: 4822 / 5000\n",
      "w1: [25.28449421] w2: [-23.3468141] bias: [16.24391507] loss: 30.557653775103176\n",
      "Epoch: 4823 / 5000\n",
      "w1: [25.28109853] w2: [-23.35082076] bias: [16.23572059] loss: 30.560702508993682\n",
      "Epoch: 4824 / 5000\n",
      "w1: [25.2688206] w2: [-23.36222732] bias: [16.20804136] loss: 30.572887657168366\n",
      "Epoch: 4825 / 5000\n",
      "w1: [25.28364394] w2: [-23.3637539] bias: [16.22373624] loss: 30.564457185316993\n",
      "Epoch: 4826 / 5000\n",
      "w1: [25.27557666] w2: [-23.36015334] bias: [16.21705121] loss: 30.56811207738079\n",
      "Epoch: 4827 / 5000\n",
      "w1: [25.26718909] w2: [-23.36202055] bias: [16.20504725] loss: 30.57434006637315\n",
      "Epoch: 4828 / 5000\n",
      "w1: [25.26672223] w2: [-23.3713813] bias: [16.19654431] loss: 30.578392698799973\n",
      "Epoch: 4829 / 5000\n",
      "w1: [25.26784187] w2: [-23.37277973] bias: [16.20290535] loss: 30.575794827984137\n",
      "Epoch: 4830 / 5000\n",
      "w1: [25.28195557] w2: [-23.38091003] bias: [16.21322387] loss: 30.569381803296846\n",
      "Epoch: 4831 / 5000\n",
      "w1: [25.27241415] w2: [-23.38594972] bias: [16.20453745] loss: 30.57511067884211\n",
      "Epoch: 4832 / 5000\n",
      "w1: [25.27202717] w2: [-23.39070654] bias: [16.2018031] loss: 30.576627586310643\n",
      "Epoch: 4833 / 5000\n",
      "w1: [25.26979321] w2: [-23.39303247] bias: [16.19399104] loss: 30.580466413927066\n",
      "Epoch: 4834 / 5000\n",
      "w1: [25.27002681] w2: [-23.39756033] bias: [16.19036755] loss: 30.582293976608447\n",
      "Epoch: 4835 / 5000\n",
      "w1: [25.25872689] w2: [-23.39891583] bias: [16.17996883] loss: 30.589941798852607\n",
      "Epoch: 4836 / 5000\n",
      "w1: [25.25177414] w2: [-23.40893527] bias: [16.16073613] loss: 30.602162468807975\n",
      "Epoch: 4837 / 5000\n",
      "w1: [25.25369852] w2: [-23.39249098] bias: [16.18641195] loss: 30.58784341106594\n",
      "Epoch: 4838 / 5000\n",
      "w1: [25.26480684] w2: [-23.39701829] bias: [16.19831744] loss: 30.580339566214594\n",
      "Epoch: 4839 / 5000\n",
      "w1: [25.28036373] w2: [-23.39973527] bias: [16.21264028] loss: 30.571314943833055\n",
      "Epoch: 4840 / 5000\n",
      "w1: [25.27052255] w2: [-23.40609162] bias: [16.20427276] loss: 30.577321980962317\n",
      "Epoch: 4841 / 5000\n",
      "w1: [25.28066925] w2: [-23.41282222] bias: [16.21222266] loss: 30.572404699588677\n",
      "Epoch: 4842 / 5000\n",
      "w1: [25.28189491] w2: [-23.40576506] bias: [16.21434441] loss: 30.570803529399335\n",
      "Epoch: 4843 / 5000\n",
      "w1: [25.27784134] w2: [-23.40423563] bias: [16.21188254] loss: 30.57252252943297\n",
      "Epoch: 4844 / 5000\n",
      "w1: [25.27218621] w2: [-23.40735817] bias: [16.20134607] loss: 30.57816757831262\n",
      "Epoch: 4845 / 5000\n",
      "w1: [25.24896418] w2: [-23.41473828] bias: [16.16345449] loss: 30.60234203675696\n",
      "Epoch: 4846 / 5000\n",
      "w1: [25.25539793] w2: [-23.40455796] bias: [16.1775262] loss: 30.592564208023457\n",
      "Epoch: 4847 / 5000\n",
      "w1: [25.26592855] w2: [-23.39166249] bias: [16.20020632] loss: 30.57884058299329\n",
      "Epoch: 4848 / 5000\n",
      "w1: [25.27182181] w2: [-23.37310135] bias: [16.22212919] loss: 30.568075453007044\n",
      "Epoch: 4849 / 5000\n",
      "w1: [25.27514139] w2: [-23.36914474] bias: [16.2404713] loss: 30.561419134369515\n",
      "Epoch: 4850 / 5000\n",
      "w1: [25.26494382] w2: [-23.37555547] bias: [16.21560594] loss: 30.572037257805356\n",
      "Epoch: 4851 / 5000\n",
      "w1: [25.28823013] w2: [-23.37133029] bias: [16.24559804] loss: 30.557596488740128\n",
      "Epoch: 4852 / 5000\n",
      "w1: [25.27413835] w2: [-23.38524765] bias: [16.21749713] loss: 30.56996279040607\n",
      "Epoch: 4853 / 5000\n",
      "w1: [25.26436583] w2: [-23.38635475] bias: [16.21705546] loss: 30.57243702468117\n",
      "Epoch: 4854 / 5000\n",
      "w1: [25.26395199] w2: [-23.3824094] bias: [16.21945901] loss: 30.57138954315274\n",
      "Epoch: 4855 / 5000\n",
      "w1: [25.25324991] w2: [-23.37991115] bias: [16.20515581] loss: 30.579080266686\n",
      "Epoch: 4856 / 5000\n",
      "w1: [25.26349476] w2: [-23.38484298] bias: [16.21744276] loss: 30.57238884683102\n",
      "Epoch: 4857 / 5000\n",
      "w1: [25.27610054] w2: [-23.38696846] bias: [16.23018131] loss: 30.565399893954886\n",
      "Epoch: 4858 / 5000\n",
      "w1: [25.27217061] w2: [-23.3890649] bias: [16.22051884] loss: 30.569625076814212\n",
      "Epoch: 4859 / 5000\n",
      "w1: [25.26653486] w2: [-23.38177342] bias: [16.22156729] loss: 30.57002202267484\n",
      "Epoch: 4860 / 5000\n",
      "w1: [25.27041166] w2: [-23.37489881] bias: [16.23269173] loss: 30.565060369865623\n",
      "Epoch: 4861 / 5000\n",
      "w1: [25.25247735] w2: [-23.37960071] bias: [16.20313206] loss: 30.580044784138277\n",
      "Epoch: 4862 / 5000\n",
      "w1: [25.24386943] w2: [-23.3814284] bias: [16.18919172] loss: 30.588247091578896\n",
      "Epoch: 4863 / 5000\n",
      "w1: [25.24265622] w2: [-23.39028123] bias: [16.17852447] loss: 30.594245237208668\n",
      "Epoch: 4864 / 5000\n",
      "w1: [25.25468021] w2: [-23.39278123] bias: [16.19164691] loss: 30.58535415753715\n",
      "Epoch: 4865 / 5000\n",
      "w1: [25.25680939] w2: [-23.38396564] bias: [16.19737227] loss: 30.581625261212906\n",
      "Epoch: 4866 / 5000\n",
      "w1: [25.24411288] w2: [-23.39331135] bias: [16.1716068] loss: 30.597389696655938\n",
      "Epoch: 4867 / 5000\n",
      "w1: [25.24860935] w2: [-23.40114163] bias: [16.16603921] loss: 30.599606430271862\n",
      "Epoch: 4868 / 5000\n",
      "w1: [25.25655625] w2: [-23.39050877] bias: [16.18005453] loss: 30.589663745721204\n",
      "Epoch: 4869 / 5000\n",
      "w1: [25.24798601] w2: [-23.38477251] bias: [16.17002807] loss: 30.59608855914058\n",
      "Epoch: 4870 / 5000\n",
      "w1: [25.24755101] w2: [-23.39203139] bias: [16.16980906] loss: 30.597098016950522\n",
      "Epoch: 4871 / 5000\n",
      "w1: [25.26998565] w2: [-23.37122298] bias: [16.22248263] loss: 30.56823736532004\n",
      "Epoch: 4872 / 5000\n",
      "w1: [25.26231831] w2: [-23.38316419] bias: [16.21777479] loss: 30.57241963590151\n",
      "Epoch: 4873 / 5000\n",
      "w1: [25.27252361] w2: [-23.38102433] bias: [16.23022985] loss: 30.56577223645427\n",
      "Epoch: 4874 / 5000\n",
      "w1: [25.26013813] w2: [-23.39112277] bias: [16.20323326] loss: 30.579049662803506\n",
      "Epoch: 4875 / 5000\n",
      "w1: [25.25877973] w2: [-23.38782382] bias: [16.20143091] loss: 30.57982569978124\n",
      "Epoch: 4876 / 5000\n",
      "w1: [25.27949638] w2: [-23.38614931] bias: [16.22364381] loss: 30.56675273026537\n",
      "Epoch: 4877 / 5000\n",
      "w1: [25.27510641] w2: [-23.3858073] bias: [16.21882155] loss: 30.56932538727467\n",
      "Epoch: 4878 / 5000\n",
      "w1: [25.28058008] w2: [-23.37637926] bias: [16.22939668] loss: 30.56406550934469\n",
      "Epoch: 4879 / 5000\n",
      "w1: [25.26274052] w2: [-23.39072199] bias: [16.19499534] loss: 30.5816618473962\n",
      "Epoch: 4880 / 5000\n",
      "w1: [25.25572378] w2: [-23.39462378] bias: [16.17592792] loss: 30.592171010704707\n",
      "Epoch: 4881 / 5000\n",
      "w1: [25.27535104] w2: [-23.38521717] bias: [16.20304972] loss: 30.57490641484813\n",
      "Epoch: 4882 / 5000\n",
      "w1: [25.28809225] w2: [-23.38684227] bias: [16.21356135] loss: 30.568306820509722\n",
      "Epoch: 4883 / 5000\n",
      "w1: [25.28780773] w2: [-23.39306151] bias: [16.20369186] loss: 30.572322427513843\n",
      "Epoch: 4884 / 5000\n",
      "w1: [25.30457963] w2: [-23.39814353] bias: [16.22127309] loss: 30.562967366287936\n",
      "Epoch: 4885 / 5000\n",
      "w1: [25.30019318] w2: [-23.40114297] bias: [16.21204141] loss: 30.567144319694965\n",
      "Epoch: 4886 / 5000\n",
      "w1: [25.31633092] w2: [-23.38521647] bias: [16.24468297] loss: 30.5534246877221\n",
      "Epoch: 4887 / 5000\n",
      "w1: [25.29909452] w2: [-23.39786634] bias: [16.22159407] loss: 30.56399485317905\n",
      "Epoch: 4888 / 5000\n",
      "w1: [25.30873794] w2: [-23.39815527] bias: [16.26244963] loss: 30.55094895950346\n",
      "Epoch: 4889 / 5000\n",
      "w1: [25.34489364] w2: [-23.38575171] bias: [16.32646585] loss: 30.537423438209252\n",
      "Epoch: 4890 / 5000\n",
      "w1: [25.36528906] w2: [-23.37448156] bias: [16.36965263] loss: 30.536979062267925\n",
      "Epoch: 4891 / 5000\n",
      "w1: [25.36776842] w2: [-23.37481076] bias: [16.37061785] loss: 30.536996017273914\n",
      "Epoch: 4892 / 5000\n",
      "w1: [25.36586444] w2: [-23.37747571] bias: [16.36066195] loss: 30.536395834241507\n",
      "Epoch: 4893 / 5000\n",
      "w1: [25.35998632] w2: [-23.35820728] bias: [16.36704875] loss: 30.537711639187137\n",
      "Epoch: 4894 / 5000\n",
      "w1: [25.36209795] w2: [-23.35730232] bias: [16.37100072] loss: 30.53798535858433\n",
      "Epoch: 4895 / 5000\n",
      "w1: [25.35814916] w2: [-23.35972912] bias: [16.36295483] loss: 30.53745389388812\n",
      "Epoch: 4896 / 5000\n",
      "w1: [25.35340101] w2: [-23.35978886] bias: [16.35463013] loss: 30.53727184780382\n",
      "Epoch: 4897 / 5000\n",
      "w1: [25.36180356] w2: [-23.36194454] bias: [16.3561516] loss: 30.53700212631553\n",
      "Epoch: 4898 / 5000\n",
      "w1: [25.34826424] w2: [-23.36972703] bias: [16.32952823] loss: 30.537354405212962\n",
      "Epoch: 4899 / 5000\n",
      "w1: [25.35234602] w2: [-23.36021995] bias: [16.34321249] loss: 30.53715459154784\n",
      "Epoch: 4900 / 5000\n",
      "w1: [25.35793582] w2: [-23.34712532] bias: [16.36166359] loss: 30.538010513278685\n",
      "Epoch: 4901 / 5000\n",
      "w1: [25.37665923] w2: [-23.33049389] bias: [16.40067544] loss: 30.543423416735806\n",
      "Epoch: 4902 / 5000\n",
      "w1: [25.36607213] w2: [-23.32829073] bias: [16.38432538] loss: 30.541044012566303\n",
      "Epoch: 4903 / 5000\n",
      "w1: [25.35046312] w2: [-23.34077666] bias: [16.35232495] loss: 30.538105992053865\n",
      "Epoch: 4904 / 5000\n",
      "w1: [25.34662901] w2: [-23.35008482] bias: [16.33724832] loss: 30.537780120415505\n",
      "Epoch: 4905 / 5000\n",
      "w1: [25.35625936] w2: [-23.35470534] bias: [16.34092724] loss: 30.537179679534997\n",
      "Epoch: 4906 / 5000\n",
      "w1: [25.37046288] w2: [-23.35168554] bias: [16.36117425] loss: 30.537585726193306\n",
      "Epoch: 4907 / 5000\n",
      "w1: [25.37070151] w2: [-23.35098712] bias: [16.36147982] loss: 30.537638393322393\n",
      "Epoch: 4908 / 5000\n",
      "w1: [25.39138406] w2: [-23.35679272] bias: [16.38116061] loss: 30.53917631222469\n",
      "Epoch: 4909 / 5000\n",
      "w1: [25.38668485] w2: [-23.35761743] bias: [16.37112989] loss: 30.53799132169275\n",
      "Epoch: 4910 / 5000\n",
      "w1: [25.37851223] w2: [-23.36433874] bias: [16.35651995] loss: 30.53659218551574\n",
      "Epoch: 4911 / 5000\n",
      "w1: [25.37523551] w2: [-23.37370501] bias: [16.34538052] loss: 30.535860954940148\n",
      "Epoch: 4912 / 5000\n",
      "w1: [25.36156675] w2: [-23.3778913] bias: [16.32036296] loss: 30.536730086451147\n",
      "Epoch: 4913 / 5000\n",
      "w1: [25.37701223] w2: [-23.37956433] bias: [16.33990161] loss: 30.535514358313982\n",
      "Epoch: 4914 / 5000\n",
      "w1: [25.36152839] w2: [-23.38202] bias: [16.32058565] loss: 30.53664884527322\n",
      "Epoch: 4915 / 5000\n",
      "w1: [25.37391172] w2: [-23.37049979] bias: [16.34418085] loss: 30.53600084273067\n",
      "Epoch: 4916 / 5000\n",
      "w1: [25.35770803] w2: [-23.38091511] bias: [16.31717815] loss: 30.537114323382937\n",
      "Epoch: 4917 / 5000\n",
      "w1: [25.34694179] w2: [-23.3982777] bias: [16.29049135] loss: 30.540627852908088\n",
      "Epoch: 4918 / 5000\n",
      "w1: [25.37683206] w2: [-23.38247748] bias: [16.33900543] loss: 30.535419297550092\n",
      "Epoch: 4919 / 5000\n",
      "w1: [25.37872514] w2: [-23.39093513] bias: [16.32805237] loss: 30.53518959847276\n",
      "Epoch: 4920 / 5000\n",
      "w1: [25.39403944] w2: [-23.39316767] bias: [16.35498811] loss: 30.53495703736742\n",
      "Epoch: 4921 / 5000\n",
      "w1: [25.38296974] w2: [-23.39503476] bias: [16.3353831] loss: 30.53478731282988\n",
      "Epoch: 4922 / 5000\n",
      "w1: [25.39394044] w2: [-23.39526414] bias: [16.34967932] loss: 30.534650868336247\n",
      "Epoch: 4923 / 5000\n",
      "w1: [25.39272153] w2: [-23.39359271] bias: [16.35310662] loss: 30.534876204215585\n",
      "Epoch: 4924 / 5000\n",
      "w1: [25.40279633] w2: [-23.39144641] bias: [16.36839051] loss: 30.53587930428059\n",
      "Epoch: 4925 / 5000\n",
      "w1: [25.41869569] w2: [-23.38201518] bias: [16.39557555] loss: 30.540237077779164\n",
      "Epoch: 4926 / 5000\n",
      "w1: [25.43226752] w2: [-23.38054085] bias: [16.41215363] loss: 30.54421415865011\n",
      "Epoch: 4927 / 5000\n",
      "w1: [25.45804745] w2: [-23.37630151] bias: [16.4461386] loss: 30.55591528023205\n",
      "Epoch: 4928 / 5000\n",
      "w1: [25.45530853] w2: [-23.37208211] bias: [16.44461401] loss: 30.555630527022988\n",
      "Epoch: 4929 / 5000\n",
      "w1: [25.4682846] w2: [-23.37286672] bias: [16.46141678] loss: 30.56273756819952\n",
      "Epoch: 4930 / 5000\n",
      "w1: [25.46602606] w2: [-23.37584469] bias: [16.45559643] loss: 30.56003535102823\n",
      "Epoch: 4931 / 5000\n",
      "w1: [25.47194125] w2: [-23.37752188] bias: [16.45703871] loss: 30.561126235600213\n",
      "Epoch: 4932 / 5000\n",
      "w1: [25.46465084] w2: [-23.38461872] bias: [16.43952171] loss: 30.553719629827444\n",
      "Epoch: 4933 / 5000\n",
      "w1: [25.46560015] w2: [-23.39003524] bias: [16.43329486] loss: 30.551412299263486\n",
      "Epoch: 4934 / 5000\n",
      "w1: [25.45319271] w2: [-23.39816434] bias: [16.40542588] loss: 30.54268172643947\n",
      "Epoch: 4935 / 5000\n",
      "w1: [25.47397757] w2: [-23.39489724] bias: [16.44130182] loss: 30.554149367443827\n",
      "Epoch: 4936 / 5000\n",
      "w1: [25.44985278] w2: [-23.40316324] bias: [16.39690831] loss: 30.54037242742645\n",
      "Epoch: 4937 / 5000\n",
      "w1: [25.44730279] w2: [-23.40958747] bias: [16.39268955] loss: 30.538975899303914\n",
      "Epoch: 4938 / 5000\n",
      "w1: [25.44090944] w2: [-23.41062714] bias: [16.38541691] loss: 30.537465849816805\n",
      "Epoch: 4939 / 5000\n",
      "w1: [25.44784863] w2: [-23.41435467] bias: [16.38515596] loss: 30.537440956203074\n",
      "Epoch: 4940 / 5000\n",
      "w1: [25.44979823] w2: [-23.40953892] bias: [16.38688035] loss: 30.538148624438872\n",
      "Epoch: 4941 / 5000\n",
      "w1: [25.47332764] w2: [-23.41564198] bias: [16.43114419] loss: 30.54884082190328\n",
      "Epoch: 4942 / 5000\n",
      "w1: [25.46997251] w2: [-23.41760227] bias: [16.42514074] loss: 30.546737765670915\n",
      "Epoch: 4943 / 5000\n",
      "w1: [25.44003087] w2: [-23.41660556] bias: [16.38398019] loss: 30.536809543737725\n",
      "Epoch: 4944 / 5000\n",
      "w1: [25.42744996] w2: [-23.42835603] bias: [16.35406885] loss: 30.533000147701017\n",
      "Epoch: 4945 / 5000\n",
      "w1: [25.42127455] w2: [-23.44056843] bias: [16.33637683] loss: 30.53206553372592\n",
      "Epoch: 4946 / 5000\n",
      "w1: [25.42112881] w2: [-23.43071427] bias: [16.34143395] loss: 30.53246750808641\n",
      "Epoch: 4947 / 5000\n",
      "w1: [25.42995061] w2: [-23.42589881] bias: [16.35721088] loss: 30.53330510339079\n",
      "Epoch: 4948 / 5000\n",
      "w1: [25.43453201] w2: [-23.43006652] bias: [16.37036474] loss: 30.534223411212697\n",
      "Epoch: 4949 / 5000\n",
      "w1: [25.42517231] w2: [-23.42722721] bias: [16.3570558] loss: 30.533245601744834\n",
      "Epoch: 4950 / 5000\n",
      "w1: [25.42689097] w2: [-23.4294614] bias: [16.35235422] loss: 30.532859247871997\n",
      "Epoch: 4951 / 5000\n",
      "w1: [25.42869198] w2: [-23.41843048] bias: [16.35818505] loss: 30.533735917939246\n",
      "Epoch: 4952 / 5000\n",
      "w1: [25.46146332] w2: [-23.41446779] bias: [16.39381316] loss: 30.539560994393785\n",
      "Epoch: 4953 / 5000\n",
      "w1: [25.46299414] w2: [-23.4147053] bias: [16.39224202] loss: 30.53934584351554\n",
      "Epoch: 4954 / 5000\n",
      "w1: [25.47360123] w2: [-23.40645298] bias: [16.41383935] loss: 30.54540900858518\n",
      "Epoch: 4955 / 5000\n",
      "w1: [25.46322327] w2: [-23.41995432] bias: [16.38746969] loss: 30.538113446861\n",
      "Epoch: 4956 / 5000\n",
      "w1: [25.46122067] w2: [-23.42876546] bias: [16.38767986] loss: 30.537386747027526\n",
      "Epoch: 4957 / 5000\n",
      "w1: [25.44734321] w2: [-23.44233163] bias: [16.35808327] loss: 30.532623179133545\n",
      "Epoch: 4958 / 5000\n",
      "w1: [25.44838613] w2: [-23.44234007] bias: [16.36002619] loss: 30.532789011717426\n",
      "Epoch: 4959 / 5000\n",
      "w1: [25.43742493] w2: [-23.44850103] bias: [16.35076463] loss: 30.531896271272128\n",
      "Epoch: 4960 / 5000\n",
      "w1: [25.43520982] w2: [-23.45230913] bias: [16.34116855] loss: 30.53142193138991\n",
      "Epoch: 4961 / 5000\n",
      "w1: [25.44891086] w2: [-23.44419246] bias: [16.36810101] loss: 30.533443392010362\n",
      "Epoch: 4962 / 5000\n",
      "w1: [25.43642105] w2: [-23.45118221] bias: [16.34112474] loss: 30.531431213597077\n",
      "Epoch: 4963 / 5000\n",
      "w1: [25.44053925] w2: [-23.45368735] bias: [16.34072832] loss: 30.531252560324088\n",
      "Epoch: 4964 / 5000\n",
      "w1: [25.42315437] w2: [-23.4655141] bias: [16.31018725] loss: 30.532133826187035\n",
      "Epoch: 4965 / 5000\n",
      "w1: [25.41272017] w2: [-23.47270057] bias: [16.28998161] loss: 30.53466316604547\n",
      "Epoch: 4966 / 5000\n",
      "w1: [25.41645776] w2: [-23.45962802] bias: [16.30670044] loss: 30.532833853964785\n",
      "Epoch: 4967 / 5000\n",
      "w1: [25.41646878] w2: [-23.46443127] bias: [16.29554138] loss: 30.533708553088164\n",
      "Epoch: 4968 / 5000\n",
      "w1: [25.42046451] w2: [-23.46974549] bias: [16.29312594] loss: 30.533618690393524\n",
      "Epoch: 4969 / 5000\n",
      "w1: [25.41871259] w2: [-23.4733101] bias: [16.29542018] loss: 30.533570550735373\n",
      "Epoch: 4970 / 5000\n",
      "w1: [25.43229012] w2: [-23.46298953] bias: [16.3168854] loss: 30.531334050394975\n",
      "Epoch: 4971 / 5000\n",
      "w1: [25.44232727] w2: [-23.46149559] bias: [16.33000184] loss: 30.530778757703832\n",
      "Epoch: 4972 / 5000\n",
      "w1: [25.46086269] w2: [-23.45514261] bias: [16.35514098] loss: 30.531858010036693\n",
      "Epoch: 4973 / 5000\n",
      "w1: [25.48292899] w2: [-23.45282171] bias: [16.39474072] loss: 30.53797171506843\n",
      "Epoch: 4974 / 5000\n",
      "w1: [25.46556555] w2: [-23.46773402] bias: [16.36061922] loss: 30.531759119877417\n",
      "Epoch: 4975 / 5000\n",
      "w1: [25.45715946] w2: [-23.46595638] bias: [16.34176399] loss: 30.53060244604459\n",
      "Epoch: 4976 / 5000\n",
      "w1: [25.46403406] w2: [-23.46442358] bias: [16.36701526] loss: 30.53251052555433\n",
      "Epoch: 4977 / 5000\n",
      "w1: [25.45526632] w2: [-23.47785455] bias: [16.34703863] loss: 30.53043818546006\n",
      "Epoch: 4978 / 5000\n",
      "w1: [25.45987287] w2: [-23.48380976] bias: [16.3607646] loss: 30.53099309705037\n",
      "Epoch: 4979 / 5000\n",
      "w1: [25.46683551] w2: [-23.48431554] bias: [16.3816498] loss: 30.533115062238686\n",
      "Epoch: 4980 / 5000\n",
      "w1: [25.46932364] w2: [-23.4837682] bias: [16.38128104] loss: 30.533176273134902\n",
      "Epoch: 4981 / 5000\n",
      "w1: [25.48018962] w2: [-23.49201618] bias: [16.39270111] loss: 30.534667866576076\n",
      "Epoch: 4982 / 5000\n",
      "w1: [25.48087177] w2: [-23.49234425] bias: [16.39147406] loss: 30.53449132993622\n",
      "Epoch: 4983 / 5000\n",
      "w1: [25.47002083] w2: [-23.50342811] bias: [16.36172162] loss: 30.53028486557911\n",
      "Epoch: 4984 / 5000\n",
      "w1: [25.49636992] w2: [-23.50324727] bias: [16.40218013] loss: 30.536362228045082\n",
      "Epoch: 4985 / 5000\n",
      "w1: [25.49347384] w2: [-23.51056553] bias: [16.39067584] loss: 30.533784227961554\n",
      "Epoch: 4986 / 5000\n",
      "w1: [25.49386431] w2: [-23.49848047] bias: [16.39818457] loss: 30.535841916488028\n",
      "Epoch: 4987 / 5000\n",
      "w1: [25.48620822] w2: [-23.51088465] bias: [16.38710139] loss: 30.532936936114602\n",
      "Epoch: 4988 / 5000\n",
      "w1: [25.49408612] w2: [-23.50292451] bias: [16.40068994] loss: 30.535977908459753\n",
      "Epoch: 4989 / 5000\n",
      "w1: [25.49553784] w2: [-23.51069295] bias: [16.4050906] loss: 30.53629812621057\n",
      "Epoch: 4990 / 5000\n",
      "w1: [25.51209899] w2: [-23.50762348] bias: [16.4364076] loss: 30.54496053566735\n",
      "Epoch: 4991 / 5000\n",
      "w1: [25.49383073] w2: [-23.52278998] bias: [16.3990947] loss: 30.534332906183348\n",
      "Epoch: 4992 / 5000\n",
      "w1: [25.497281] w2: [-23.52258852] bias: [16.41102448] loss: 30.536644398649795\n",
      "Epoch: 4993 / 5000\n",
      "w1: [25.49582871] w2: [-23.53192036] bias: [16.39766363] loss: 30.53362339086072\n",
      "Epoch: 4994 / 5000\n",
      "w1: [25.48443087] w2: [-23.52472029] bias: [16.38452884] loss: 30.531763615791224\n",
      "Epoch: 4995 / 5000\n",
      "w1: [25.48352707] w2: [-23.51682697] bias: [16.38997871] loss: 30.53287569680319\n",
      "Epoch: 4996 / 5000\n",
      "w1: [25.46525559] w2: [-23.5198742] bias: [16.36291684] loss: 30.529718302172846\n",
      "Epoch: 4997 / 5000\n",
      "w1: [25.46910937] w2: [-23.51754047] bias: [16.36348368] loss: 30.529844788416394\n",
      "Epoch: 4998 / 5000\n",
      "w1: [25.46262476] w2: [-23.52284014] bias: [16.35978178] loss: 30.529451176817304\n",
      "Epoch: 4999 / 5000\n",
      "w1: [25.45334175] w2: [-23.51677125] bias: [16.3508355] loss: 30.529410402630788\n",
      "Epoch: 5000 / 5000\n",
      "w1: [25.45522559] w2: [-23.52008808] bias: [16.34634067] loss: 30.529188308895545\n",
      "##### 최종 w1, w2, bias #######\n",
      "[25.45522559] [-23.52008808] [16.34634067]\n"
     ]
    }
   ],
   "source": [
    "w1, w2, bias = batch_random_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=5000, batch_size=30, verbose=True)\n",
    "print('##### 최종 w1, w2, bias #######')\n",
    "print(w1, w2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 407
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:13.807278Z",
     "iopub.status.busy": "2022-06-04T12:43:13.807081Z",
     "iopub.status.idle": "2022-06-04T12:43:13.836108Z",
     "shell.execute_reply": "2022-06-04T12:43:13.835434Z",
     "shell.execute_reply.started": "2022-06-04T12:43:13.807252Z"
    },
    "id": "Rg7K3a7C1REZ",
    "outputId": "8ff09492-a0f2-493d-d290-7311bbb156d1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-de01808b-f81c-4dbc-8546-d38e17ac0736\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.937588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>25.486589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>32.529370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.324713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>31.500316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>28.081091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>21.356486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>17.775532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>8.140533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.286595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-de01808b-f81c-4dbc-8546-d38e17ac0736')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-de01808b-f81c-4dbc-8546-d38e17ac0736 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-de01808b-f81c-4dbc-8546-d38e17ac0736');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE_BATCH_RANDOM  \n",
       "0     15.3  396.90   4.98   24.0                     28.937588  \n",
       "1     17.8  396.90   9.14   21.6                     25.486589  \n",
       "2     17.8  392.83   4.03   34.7                     32.529370  \n",
       "3     18.7  394.63   2.94   33.4                     32.324713  \n",
       "4     18.7  396.90   5.33   36.2                     31.500316  \n",
       "5     18.7  394.12   5.21   28.7                     28.081091  \n",
       "6     15.2  395.60  12.43   22.9                     21.356486  \n",
       "7     15.2  396.90  19.15   27.1                     17.775532  \n",
       "8     15.2  386.63  29.93   16.5                      8.140533  \n",
       "9     15.2  386.71  17.10   18.9                     18.286595  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
    "bostonDF['PREDICTED_PRICE_BATCH_RANDOM'] = predicted\n",
    "bostonDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZSk8_87k1REZ"
   },
   "source": [
    "### iteration 시에 순차적으로 일정한 batch 크기만큼의 데이터를 전체 학습데이터에 걸쳐서 가져오는 Mini-Batch GD 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:22.937250Z",
     "iopub.status.busy": "2022-06-04T12:43:22.936992Z",
     "iopub.status.idle": "2022-06-04T12:43:22.944644Z",
     "shell.execute_reply": "2022-06-04T12:43:22.943775Z",
     "shell.execute_reply.started": "2022-06-04T12:43:22.937222Z"
    },
    "id": "m5xiqjv-1REZ",
    "outputId": "c895c130-fd10-46b0-9978-e04bd2aacba6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "30\n",
      "60\n",
      "90\n",
      "120\n",
      "150\n",
      "180\n",
      "210\n",
      "240\n",
      "270\n",
      "300\n",
      "330\n",
      "360\n",
      "390\n",
      "420\n",
      "450\n",
      "480\n"
     ]
    }
   ],
   "source": [
    "for batch_step in range(0, 506, 30):\n",
    "    print(batch_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:23.415035Z",
     "iopub.status.busy": "2022-06-04T12:43:23.414485Z",
     "iopub.status.idle": "2022-06-04T12:43:23.420965Z",
     "shell.execute_reply": "2022-06-04T12:43:23.419972Z",
     "shell.execute_reply.started": "2022-06-04T12:43:23.414999Z"
    },
    "id": "5dz-cWfS1REa",
    "outputId": "c868632d-50d0-4f08-f263-2f83a996d858"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([23. , 23.7, 25. , 21.8, 20.6, 21.2, 19.1, 20.6, 15.2,  7. ,  8.1,\n",
       "       13.6, 20.1, 21.8, 24.5, 23.1, 19.7, 18.3, 21.2, 17.5, 16.8, 22.4,\n",
       "       20.6, 23.9, 22. , 11.9])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bostonDF['PRICE'].values[480:510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:26.495334Z",
     "iopub.status.busy": "2022-06-04T12:43:26.495014Z",
     "iopub.status.idle": "2022-06-04T12:43:26.505256Z",
     "shell.execute_reply": "2022-06-04T12:43:26.504303Z",
     "shell.execute_reply.started": "2022-06-04T12:43:26.495298Z"
    },
    "id": "SC2-htEj1REb"
   },
   "outputs": [],
   "source": [
    "# batch_gradient_descent()는 인자로 batch_size(배치 크기)를 입력 받음. \n",
    "def batch_gradient_descent(features, target, iter_epochs=1000, batch_size=30, verbose=True):\n",
    "    # w1, w2는 numpy array 연산을 위해 1차원 array로 변환하되 초기 값은 0으로 설정\n",
    "    # bias도 1차원 array로 변환하되 초기 값은 1로 설정. \n",
    "    np.random.seed = 2021\n",
    "    w1 = np.zeros((1,))\n",
    "    w2 = np.zeros((1,))\n",
    "    bias = np.zeros((1, ))\n",
    "    print('최초 w1, w2, bias:', w1, w2, bias)\n",
    "    \n",
    "    # learning_rate와 RM, LSTAT 피처 지정. 호출 시 numpy array형태로 RM과 LSTAT으로 된 2차원 feature가 입력됨.\n",
    "    learning_rate = 0.01\n",
    "    rm = features[:, 0]\n",
    "    lstat = features[:, 1]\n",
    "    \n",
    "    # iter_epochs 수만큼 반복하면서 weight와 bias update 수행. \n",
    "    for i in range(iter_epochs):\n",
    "        # batch_size 만큼 데이터를 가져와서 weight/bias update를 수행하는 로직을 전체 데이터 건수만큼 반복\n",
    "        for batch_step in range(0, target.shape[0], batch_size):\n",
    "            # batch_size만큼 순차적인 데이터를 가져옴. \n",
    "            rm_batch = rm[batch_step:batch_step + batch_size]\n",
    "            lstat_batch = lstat[batch_step:batch_step + batch_size]\n",
    "            target_batch = target[batch_step:batch_step + batch_size]\n",
    "        \n",
    "            bias_update, w1_update, w2_update = get_update_weights_value_batch(bias, w1, w2, rm_batch, lstat_batch, target_batch, learning_rate)\n",
    "\n",
    "            # Batch GD로 구한 weight/bias의 update 적용. \n",
    "            w1 = w1 - w1_update\n",
    "            w2 = w2 - w2_update\n",
    "            bias = bias - bias_update\n",
    "        \n",
    "            if verbose:\n",
    "                print('Epoch:', i+1,'/', iter_epochs, 'batch step:', batch_step)\n",
    "                # Loss는 전체 학습 데이터 기반으로 구해야 함.\n",
    "                predicted = w1 * rm + w2*lstat + bias\n",
    "                diff = target - predicted\n",
    "                mse_loss = np.mean(np.square(diff))\n",
    "                print('w1:', w1, 'w2:', w2, 'bias:', bias, 'loss:', mse_loss)\n",
    "        \n",
    "    return w1, w2, bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2022-06-04T12:43:27.417323Z",
     "iopub.status.busy": "2022-06-04T12:43:27.416688Z"
    },
    "id": "TPgRM2E61REb",
    "outputId": "3ca9c7b4-d4f3-473f-ea39-5a6d275bc0e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;30;43m스트리밍 출력 내용이 길어서 마지막 5000줄이 삭제되었습니다.\u001b[0m\n",
      "Epoch: 4854 / 5000 batch step: 0\n",
      "w1: [26.37113179] w2: [-23.3170506] bias: [15.66459595] loss: 30.53104909105693\n",
      "Epoch: 4854 / 5000 batch step: 30\n",
      "w1: [26.36454546] w2: [-23.31705373] bias: [15.65152313] loss: 30.535788172711857\n",
      "Epoch: 4854 / 5000 batch step: 60\n",
      "w1: [26.34306099] w2: [-23.32405613] bias: [15.61066547] loss: 30.555145882668047\n",
      "Epoch: 4854 / 5000 batch step: 90\n",
      "w1: [26.3364793] w2: [-23.3279927] bias: [15.59539323] loss: 30.563713677921147\n",
      "Epoch: 4854 / 5000 batch step: 120\n",
      "w1: [26.34627759] w2: [-23.29722068] bias: [15.63186706] loss: 30.543555725548774\n",
      "Epoch: 4854 / 5000 batch step: 150\n",
      "w1: [26.38082788] w2: [-23.29572631] bias: [15.67611729] loss: 30.525453203135328\n",
      "Epoch: 4854 / 5000 batch step: 180\n",
      "w1: [26.44824084] w2: [-23.27866953] bias: [15.77842268] loss: 30.513839517658006\n",
      "Epoch: 4854 / 5000 batch step: 210\n",
      "w1: [26.48468782] w2: [-23.25831124] bias: [15.8371246] loss: 30.526117097325006\n",
      "Epoch: 4854 / 5000 batch step: 240\n",
      "w1: [26.52319059] w2: [-23.25246167] bias: [15.87850572] loss: 30.54461347012819\n",
      "Epoch: 4854 / 5000 batch step: 270\n",
      "w1: [26.53951201] w2: [-23.2525642] bias: [15.89556271] loss: 30.55435292101873\n",
      "Epoch: 4854 / 5000 batch step: 300\n",
      "w1: [26.51993319] w2: [-23.25872451] bias: [15.85694273] loss: 30.53623597064614\n",
      "Epoch: 4854 / 5000 batch step: 330\n",
      "w1: [26.48402958] w2: [-23.27127422] bias: [15.78619738] loss: 30.51634963230915\n",
      "Epoch: 4854 / 5000 batch step: 360\n",
      "w1: [26.49521704] w2: [-23.2415861] bias: [15.87624218] loss: 30.54010560736358\n",
      "Epoch: 4854 / 5000 batch step: 390\n",
      "w1: [26.4693301] w2: [-23.25344685] bias: [15.84196035] loss: 30.525824803372217\n",
      "Epoch: 4854 / 5000 batch step: 420\n",
      "w1: [26.419747] w2: [-23.29702775] bias: [15.74668465] loss: 30.513321046094422\n",
      "Epoch: 4854 / 5000 batch step: 450\n",
      "w1: [26.39420947] w2: [-23.3147477] bias: [15.70330949] loss: 30.51978104286643\n",
      "Epoch: 4854 / 5000 batch step: 480\n",
      "w1: [26.37734787] w2: [-23.31615994] bias: [15.67748289] loss: 30.526888946506062\n",
      "Epoch: 4855 / 5000 batch step: 0\n",
      "w1: [26.37113184] w2: [-23.31705057] bias: [15.66459592] loss: 30.531049090902002\n",
      "Epoch: 4855 / 5000 batch step: 30\n",
      "w1: [26.36454551] w2: [-23.3170537] bias: [15.65152309] loss: 30.535788172537792\n",
      "Epoch: 4855 / 5000 batch step: 60\n",
      "w1: [26.34306105] w2: [-23.3240561] bias: [15.61066544] loss: 30.555145882456372\n",
      "Epoch: 4855 / 5000 batch step: 90\n",
      "w1: [26.33647936] w2: [-23.32799267] bias: [15.59539319] loss: 30.563713677704555\n",
      "Epoch: 4855 / 5000 batch step: 120\n",
      "w1: [26.34627765] w2: [-23.29722065] bias: [15.63186702] loss: 30.543555725357162\n",
      "Epoch: 4855 / 5000 batch step: 150\n",
      "w1: [26.38082793] w2: [-23.29572628] bias: [15.67611725] loss: 30.52545320294385\n",
      "Epoch: 4855 / 5000 batch step: 180\n",
      "w1: [26.4482409] w2: [-23.2786695] bias: [15.77842264] loss: 30.513839517504522\n",
      "Epoch: 4855 / 5000 batch step: 210\n",
      "w1: [26.48468788] w2: [-23.25831121] bias: [15.83712456] loss: 30.526117097172325\n",
      "Epoch: 4855 / 5000 batch step: 240\n",
      "w1: [26.52319064] w2: [-23.25246164] bias: [15.87850568] loss: 30.544613469962485\n",
      "Epoch: 4855 / 5000 batch step: 270\n",
      "w1: [26.53951207] w2: [-23.25256417] bias: [15.89556267] loss: 30.554352920859348\n",
      "Epoch: 4855 / 5000 batch step: 300\n",
      "w1: [26.51993325] w2: [-23.25872448] bias: [15.85694269] loss: 30.536235970517932\n",
      "Epoch: 4855 / 5000 batch step: 330\n",
      "w1: [26.48402964] w2: [-23.27127418] bias: [15.78619735] loss: 30.516349632191922\n",
      "Epoch: 4855 / 5000 batch step: 360\n",
      "w1: [26.4952171] w2: [-23.24158607] bias: [15.87624214] loss: 30.540105607249593\n",
      "Epoch: 4855 / 5000 batch step: 390\n",
      "w1: [26.46933016] w2: [-23.25344682] bias: [15.84196031] loss: 30.525824803215414\n",
      "Epoch: 4855 / 5000 batch step: 420\n",
      "w1: [26.41974705] w2: [-23.29702772] bias: [15.74668462] loss: 30.513321045927555\n",
      "Epoch: 4855 / 5000 batch step: 450\n",
      "w1: [26.39420953] w2: [-23.31474767] bias: [15.70330945] loss: 30.51978104272079\n",
      "Epoch: 4855 / 5000 batch step: 480\n",
      "w1: [26.37734792] w2: [-23.31615991] bias: [15.67748285] loss: 30.526888946356976\n",
      "Epoch: 4856 / 5000 batch step: 0\n",
      "w1: [26.3711319] w2: [-23.31705054] bias: [15.66459588] loss: 30.531049090747423\n",
      "Epoch: 4856 / 5000 batch step: 30\n",
      "w1: [26.36454557] w2: [-23.31705367] bias: [15.65152305] loss: 30.535788172364136\n",
      "Epoch: 4856 / 5000 batch step: 60\n",
      "w1: [26.3430611] w2: [-23.32405607] bias: [15.6106654] loss: 30.555145882245192\n",
      "Epoch: 4856 / 5000 batch step: 90\n",
      "w1: [26.33647941] w2: [-23.32799264] bias: [15.59539315] loss: 30.56371367748846\n",
      "Epoch: 4856 / 5000 batch step: 120\n",
      "w1: [26.3462777] w2: [-23.29722062] bias: [15.63186698] loss: 30.543555725165984\n",
      "Epoch: 4856 / 5000 batch step: 150\n",
      "w1: [26.38082799] w2: [-23.29572625] bias: [15.67611721] loss: 30.525453202752814\n",
      "Epoch: 4856 / 5000 batch step: 180\n",
      "w1: [26.44824095] w2: [-23.27866947] bias: [15.77842261] loss: 30.51383951735139\n",
      "Epoch: 4856 / 5000 batch step: 210\n",
      "w1: [26.48468793] w2: [-23.25831118] bias: [15.83712453] loss: 30.52611709702\n",
      "Epoch: 4856 / 5000 batch step: 240\n",
      "w1: [26.5231907] w2: [-23.25246161] bias: [15.87850564] loss: 30.544613469797156\n",
      "Epoch: 4856 / 5000 batch step: 270\n",
      "w1: [26.53951212] w2: [-23.25256414] bias: [15.89556263] loss: 30.554352920700328\n",
      "Epoch: 4856 / 5000 batch step: 300\n",
      "w1: [26.5199333] w2: [-23.25872445] bias: [15.85694265] loss: 30.536235970390013\n",
      "Epoch: 4856 / 5000 batch step: 330\n",
      "w1: [26.48402969] w2: [-23.27127415] bias: [15.78619731] loss: 30.516349632074952\n",
      "Epoch: 4856 / 5000 batch step: 360\n",
      "w1: [26.49521715] w2: [-23.24158604] bias: [15.87624211] loss: 30.540105607135867\n",
      "Epoch: 4856 / 5000 batch step: 390\n",
      "w1: [26.46933021] w2: [-23.25344679] bias: [15.84196027] loss: 30.525824803058974\n",
      "Epoch: 4856 / 5000 batch step: 420\n",
      "w1: [26.41974711] w2: [-23.29702769] bias: [15.74668458] loss: 30.513321045761067\n",
      "Epoch: 4856 / 5000 batch step: 450\n",
      "w1: [26.39420958] w2: [-23.31474763] bias: [15.70330942] loss: 30.51978104257548\n",
      "Epoch: 4856 / 5000 batch step: 480\n",
      "w1: [26.37734798] w2: [-23.31615988] bias: [15.67748281] loss: 30.52688894620823\n",
      "Epoch: 4857 / 5000 batch step: 0\n",
      "w1: [26.37113195] w2: [-23.3170505] bias: [15.66459584] loss: 30.531049090593196\n",
      "Epoch: 4857 / 5000 batch step: 30\n",
      "w1: [26.36454562] w2: [-23.31705364] bias: [15.65152301] loss: 30.53578817219087\n",
      "Epoch: 4857 / 5000 batch step: 60\n",
      "w1: [26.34306116] w2: [-23.32405604] bias: [15.61066536] loss: 30.555145882034484\n",
      "Epoch: 4857 / 5000 batch step: 90\n",
      "w1: [26.33647947] w2: [-23.32799261] bias: [15.59539311] loss: 30.563713677272858\n",
      "Epoch: 4857 / 5000 batch step: 120\n",
      "w1: [26.34627776] w2: [-23.29722059] bias: [15.63186695] loss: 30.543555724975235\n",
      "Epoch: 4857 / 5000 batch step: 150\n",
      "w1: [26.38082804] w2: [-23.29572622] bias: [15.67611718] loss: 30.525453202562208\n",
      "Epoch: 4857 / 5000 batch step: 180\n",
      "w1: [26.44824101] w2: [-23.27866944] bias: [15.77842257] loss: 30.513839517198605\n",
      "Epoch: 4857 / 5000 batch step: 210\n",
      "w1: [26.48468799] w2: [-23.25831114] bias: [15.83712449] loss: 30.526117096868013\n",
      "Epoch: 4857 / 5000 batch step: 240\n",
      "w1: [26.52319075] w2: [-23.25246158] bias: [15.8785056] loss: 30.544613469632207\n",
      "Epoch: 4857 / 5000 batch step: 270\n",
      "w1: [26.53951218] w2: [-23.25256411] bias: [15.89556259] loss: 30.554352920541664\n",
      "Epoch: 4857 / 5000 batch step: 300\n",
      "w1: [26.51993336] w2: [-23.25872442] bias: [15.85694261] loss: 30.53623597026239\n",
      "Epoch: 4857 / 5000 batch step: 330\n",
      "w1: [26.48402975] w2: [-23.27127412] bias: [15.78619727] loss: 30.516349631958256\n",
      "Epoch: 4857 / 5000 batch step: 360\n",
      "w1: [26.49521721] w2: [-23.24158601] bias: [15.87624207] loss: 30.540105607022397\n",
      "Epoch: 4857 / 5000 batch step: 390\n",
      "w1: [26.46933027] w2: [-23.25344676] bias: [15.84196024] loss: 30.52582480290289\n",
      "Epoch: 4857 / 5000 batch step: 420\n",
      "w1: [26.41974716] w2: [-23.29702766] bias: [15.74668454] loss: 30.51332104559496\n",
      "Epoch: 4857 / 5000 batch step: 450\n",
      "w1: [26.39420963] w2: [-23.3147476] bias: [15.70330938] loss: 30.519781042430502\n",
      "Epoch: 4857 / 5000 batch step: 480\n",
      "w1: [26.37734803] w2: [-23.31615985] bias: [15.67748277] loss: 30.526888946059817\n",
      "Epoch: 4858 / 5000 batch step: 0\n",
      "w1: [26.37113201] w2: [-23.31705047] bias: [15.6645958] loss: 30.531049090439325\n",
      "Epoch: 4858 / 5000 batch step: 30\n",
      "w1: [26.36454568] w2: [-23.31705361] bias: [15.65152297] loss: 30.535788172017998\n",
      "Epoch: 4858 / 5000 batch step: 60\n",
      "w1: [26.34306121] w2: [-23.32405601] bias: [15.61066532] loss: 30.555145881824263\n",
      "Epoch: 4858 / 5000 batch step: 90\n",
      "w1: [26.33647952] w2: [-23.32799258] bias: [15.59539307] loss: 30.56371367705774\n",
      "Epoch: 4858 / 5000 batch step: 120\n",
      "w1: [26.34627781] w2: [-23.29722056] bias: [15.63186691] loss: 30.543555724784934\n",
      "Epoch: 4858 / 5000 batch step: 150\n",
      "w1: [26.3808281] w2: [-23.29572619] bias: [15.67611714] loss: 30.525453202372038\n",
      "Epoch: 4858 / 5000 batch step: 180\n",
      "w1: [26.44824106] w2: [-23.27866941] bias: [15.77842253] loss: 30.51383951704617\n",
      "Epoch: 4858 / 5000 batch step: 210\n",
      "w1: [26.48468804] w2: [-23.25831111] bias: [15.83712445] loss: 30.526117096716376\n",
      "Epoch: 4858 / 5000 batch step: 240\n",
      "w1: [26.5231908] w2: [-23.25246155] bias: [15.87850556] loss: 30.544613469467627\n",
      "Epoch: 4858 / 5000 batch step: 270\n",
      "w1: [26.53951223] w2: [-23.25256408] bias: [15.89556256] loss: 30.554352920383366\n",
      "Epoch: 4858 / 5000 batch step: 300\n",
      "w1: [26.51993341] w2: [-23.25872439] bias: [15.85694257] loss: 30.536235970135053\n",
      "Epoch: 4858 / 5000 batch step: 330\n",
      "w1: [26.4840298] w2: [-23.27127409] bias: [15.78619723] loss: 30.516349631841827\n",
      "Epoch: 4858 / 5000 batch step: 360\n",
      "w1: [26.49521726] w2: [-23.24158598] bias: [15.87624203] loss: 30.54010560690919\n",
      "Epoch: 4858 / 5000 batch step: 390\n",
      "w1: [26.46933032] w2: [-23.25344673] bias: [15.8419602] loss: 30.525824802747156\n",
      "Epoch: 4858 / 5000 batch step: 420\n",
      "w1: [26.41974722] w2: [-23.29702763] bias: [15.7466845] loss: 30.51332104542923\n",
      "Epoch: 4858 / 5000 batch step: 450\n",
      "w1: [26.39420969] w2: [-23.31474757] bias: [15.70330934] loss: 30.519781042285846\n",
      "Epoch: 4858 / 5000 batch step: 480\n",
      "w1: [26.37734809] w2: [-23.31615982] bias: [15.67748273] loss: 30.526888945911743\n",
      "Epoch: 4859 / 5000 batch step: 0\n",
      "w1: [26.37113206] w2: [-23.31705044] bias: [15.66459576] loss: 30.531049090285798\n",
      "Epoch: 4859 / 5000 batch step: 30\n",
      "w1: [26.36454573] w2: [-23.31705358] bias: [15.65152294] loss: 30.53578817184552\n",
      "Epoch: 4859 / 5000 batch step: 60\n",
      "w1: [26.34306127] w2: [-23.32405598] bias: [15.61066528] loss: 30.55514588161451\n",
      "Epoch: 4859 / 5000 batch step: 90\n",
      "w1: [26.33647958] w2: [-23.32799255] bias: [15.59539304] loss: 30.563713676843115\n",
      "Epoch: 4859 / 5000 batch step: 120\n",
      "w1: [26.34627787] w2: [-23.29722053] bias: [15.63186687] loss: 30.543555724595056\n",
      "Epoch: 4859 / 5000 batch step: 150\n",
      "w1: [26.38082815] w2: [-23.29572616] bias: [15.6761171] loss: 30.5254532021823\n",
      "Epoch: 4859 / 5000 batch step: 180\n",
      "w1: [26.44824112] w2: [-23.27866938] bias: [15.77842249] loss: 30.51383951689408\n",
      "Epoch: 4859 / 5000 batch step: 210\n",
      "w1: [26.4846881] w2: [-23.25831108] bias: [15.83712441] loss: 30.526117096565084\n",
      "Epoch: 4859 / 5000 batch step: 240\n",
      "w1: [26.52319086] w2: [-23.25246152] bias: [15.87850553] loss: 30.544613469303425\n",
      "Epoch: 4859 / 5000 batch step: 270\n",
      "w1: [26.53951229] w2: [-23.25256405] bias: [15.89556252] loss: 30.554352920225433\n",
      "Epoch: 4859 / 5000 batch step: 300\n",
      "w1: [26.51993346] w2: [-23.25872436] bias: [15.85694254] loss: 30.536235970008004\n",
      "Epoch: 4859 / 5000 batch step: 330\n",
      "w1: [26.48402986] w2: [-23.27127406] bias: [15.78619719] loss: 30.51634963172566\n",
      "Epoch: 4859 / 5000 batch step: 360\n",
      "w1: [26.49521732] w2: [-23.24158595] bias: [15.87624199] loss: 30.54010560679624\n",
      "Epoch: 4859 / 5000 batch step: 390\n",
      "w1: [26.46933038] w2: [-23.2534467] bias: [15.84196016] loss: 30.525824802591774\n",
      "Epoch: 4859 / 5000 batch step: 420\n",
      "w1: [26.41974727] w2: [-23.2970276] bias: [15.74668446] loss: 30.51332104526387\n",
      "Epoch: 4859 / 5000 batch step: 450\n",
      "w1: [26.39420974] w2: [-23.31474754] bias: [15.7033093] loss: 30.519781042141524\n",
      "Epoch: 4859 / 5000 batch step: 480\n",
      "w1: [26.37734814] w2: [-23.31615979] bias: [15.6774827] loss: 30.526888945764004\n",
      "Epoch: 4860 / 5000 batch step: 0\n",
      "w1: [26.37113212] w2: [-23.31705041] bias: [15.66459573] loss: 30.531049090132626\n",
      "Epoch: 4860 / 5000 batch step: 30\n",
      "w1: [26.36454579] w2: [-23.31705355] bias: [15.6515229] loss: 30.53578817167343\n",
      "Epoch: 4860 / 5000 batch step: 60\n",
      "w1: [26.34306132] w2: [-23.32405595] bias: [15.61066525] loss: 30.555145881405238\n",
      "Epoch: 4860 / 5000 batch step: 90\n",
      "w1: [26.33647963] w2: [-23.32799252] bias: [15.595393] loss: 30.56371367662898\n",
      "Epoch: 4860 / 5000 batch step: 120\n",
      "w1: [26.34627792] w2: [-23.2972205] bias: [15.63186683] loss: 30.543555724405614\n",
      "Epoch: 4860 / 5000 batch step: 150\n",
      "w1: [26.3808282] w2: [-23.29572613] bias: [15.67611706] loss: 30.525453201992995\n",
      "Epoch: 4860 / 5000 batch step: 180\n",
      "w1: [26.44824117] w2: [-23.27866935] bias: [15.77842245] loss: 30.51383951674233\n",
      "Epoch: 4860 / 5000 batch step: 210\n",
      "w1: [26.48468815] w2: [-23.25831105] bias: [15.83712437] loss: 30.526117096414136\n",
      "Epoch: 4860 / 5000 batch step: 240\n",
      "w1: [26.52319091] w2: [-23.25246149] bias: [15.87850549] loss: 30.544613469139595\n",
      "Epoch: 4860 / 5000 batch step: 270\n",
      "w1: [26.53951234] w2: [-23.25256402] bias: [15.89556248] loss: 30.554352920067856\n",
      "Epoch: 4860 / 5000 batch step: 300\n",
      "w1: [26.51993352] w2: [-23.25872433] bias: [15.8569425] loss: 30.536235969881247\n",
      "Epoch: 4860 / 5000 batch step: 330\n",
      "w1: [26.48402991] w2: [-23.27127403] bias: [15.78619716] loss: 30.51634963160975\n",
      "Epoch: 4860 / 5000 batch step: 360\n",
      "w1: [26.49521737] w2: [-23.24158592] bias: [15.87624195] loss: 30.540105606683543\n",
      "Epoch: 4860 / 5000 batch step: 390\n",
      "w1: [26.46933043] w2: [-23.25344667] bias: [15.84196012] loss: 30.525824802436755\n",
      "Epoch: 4860 / 5000 batch step: 420\n",
      "w1: [26.41974733] w2: [-23.29702757] bias: [15.74668443] loss: 30.513321045098895\n",
      "Epoch: 4860 / 5000 batch step: 450\n",
      "w1: [26.3942098] w2: [-23.31474751] bias: [15.70330926] loss: 30.519781041997533\n",
      "Epoch: 4860 / 5000 batch step: 480\n",
      "w1: [26.37734819] w2: [-23.31615976] bias: [15.67748266] loss: 30.526888945616605\n",
      "Epoch: 4861 / 5000 batch step: 0\n",
      "w1: [26.37113217] w2: [-23.31705038] bias: [15.66459569] loss: 30.531049089979795\n",
      "Epoch: 4861 / 5000 batch step: 30\n",
      "w1: [26.36454584] w2: [-23.31705352] bias: [15.65152286] loss: 30.535788171501736\n",
      "Epoch: 4861 / 5000 batch step: 60\n",
      "w1: [26.34306138] w2: [-23.32405592] bias: [15.61066521] loss: 30.555145881196438\n",
      "Epoch: 4861 / 5000 batch step: 90\n",
      "w1: [26.33647968] w2: [-23.32799249] bias: [15.59539296] loss: 30.56371367641533\n",
      "Epoch: 4861 / 5000 batch step: 120\n",
      "w1: [26.34627798] w2: [-23.29722047] bias: [15.63186679] loss: 30.5435557242166\n",
      "Epoch: 4861 / 5000 batch step: 150\n",
      "w1: [26.38082826] w2: [-23.2957261] bias: [15.67611703] loss: 30.52545320180412\n",
      "Epoch: 4861 / 5000 batch step: 180\n",
      "w1: [26.44824123] w2: [-23.27866932] bias: [15.77842242] loss: 30.51383951659093\n",
      "Epoch: 4861 / 5000 batch step: 210\n",
      "w1: [26.48468821] w2: [-23.25831102] bias: [15.83712434] loss: 30.52611709626353\n",
      "Epoch: 4861 / 5000 batch step: 240\n",
      "w1: [26.52319097] w2: [-23.25246146] bias: [15.87850545] loss: 30.544613468976138\n",
      "Epoch: 4861 / 5000 batch step: 270\n",
      "w1: [26.53951239] w2: [-23.25256399] bias: [15.89556244] loss: 30.554352919910635\n",
      "Epoch: 4861 / 5000 batch step: 300\n",
      "w1: [26.51993357] w2: [-23.2587243] bias: [15.85694246] loss: 30.536235969754774\n",
      "Epoch: 4861 / 5000 batch step: 330\n",
      "w1: [26.48402997] w2: [-23.271274] bias: [15.78619712] loss: 30.516349631494112\n",
      "Epoch: 4861 / 5000 batch step: 360\n",
      "w1: [26.49521743] w2: [-23.24158589] bias: [15.87624192] loss: 30.5401056065711\n",
      "Epoch: 4861 / 5000 batch step: 390\n",
      "w1: [26.46933048] w2: [-23.25344664] bias: [15.84196009] loss: 30.525824802282074\n",
      "Epoch: 4861 / 5000 batch step: 420\n",
      "w1: [26.41974738] w2: [-23.29702754] bias: [15.74668439] loss: 30.513321044934287\n",
      "Epoch: 4861 / 5000 batch step: 450\n",
      "w1: [26.39420985] w2: [-23.31474749] bias: [15.70330923] loss: 30.519781041853868\n",
      "Epoch: 4861 / 5000 batch step: 480\n",
      "w1: [26.37734825] w2: [-23.31615973] bias: [15.67748262] loss: 30.526888945469533\n",
      "Epoch: 4862 / 5000 batch step: 0\n",
      "w1: [26.37113222] w2: [-23.31705036] bias: [15.66459565] loss: 30.531049089827317\n",
      "Epoch: 4862 / 5000 batch step: 30\n",
      "w1: [26.36454589] w2: [-23.31705349] bias: [15.65152282] loss: 30.535788171330427\n",
      "Epoch: 4862 / 5000 batch step: 60\n",
      "w1: [26.34306143] w2: [-23.32405589] bias: [15.61066517] loss: 30.55514588098812\n",
      "Epoch: 4862 / 5000 batch step: 90\n",
      "w1: [26.33647974] w2: [-23.32799246] bias: [15.59539292] loss: 30.563713676202163\n",
      "Epoch: 4862 / 5000 batch step: 120\n",
      "w1: [26.34627803] w2: [-23.29722044] bias: [15.63186676] loss: 30.543555724028018\n",
      "Epoch: 4862 / 5000 batch step: 150\n",
      "w1: [26.38082831] w2: [-23.29572607] bias: [15.67611699] loss: 30.52545320161567\n",
      "Epoch: 4862 / 5000 batch step: 180\n",
      "w1: [26.44824128] w2: [-23.27866929] bias: [15.77842238] loss: 30.513839516439873\n",
      "Epoch: 4862 / 5000 batch step: 210\n",
      "w1: [26.48468826] w2: [-23.25831099] bias: [15.8371243] loss: 30.52611709611327\n",
      "Epoch: 4862 / 5000 batch step: 240\n",
      "w1: [26.52319102] w2: [-23.25246143] bias: [15.87850541] loss: 30.544613468813054\n",
      "Epoch: 4862 / 5000 batch step: 270\n",
      "w1: [26.53951245] w2: [-23.25256396] bias: [15.89556241] loss: 30.55435291975377\n",
      "Epoch: 4862 / 5000 batch step: 300\n",
      "w1: [26.51993363] w2: [-23.25872427] bias: [15.85694242] loss: 30.536235969628596\n",
      "Epoch: 4862 / 5000 batch step: 330\n",
      "w1: [26.48403002] w2: [-23.27127397] bias: [15.78619708] loss: 30.516349631378734\n",
      "Epoch: 4862 / 5000 batch step: 360\n",
      "w1: [26.49521748] w2: [-23.24158586] bias: [15.87624188] loss: 30.540105606458923\n",
      "Epoch: 4862 / 5000 batch step: 390\n",
      "w1: [26.46933054] w2: [-23.25344661] bias: [15.84196005] loss: 30.525824802127758\n",
      "Epoch: 4862 / 5000 batch step: 420\n",
      "w1: [26.41974744] w2: [-23.29702751] bias: [15.74668435] loss: 30.513321044770063\n",
      "Epoch: 4862 / 5000 batch step: 450\n",
      "w1: [26.39420991] w2: [-23.31474746] bias: [15.70330919] loss: 30.51978104171053\n",
      "Epoch: 4862 / 5000 batch step: 480\n",
      "w1: [26.3773483] w2: [-23.3161597] bias: [15.67748258] loss: 30.526888945322806\n",
      "Epoch: 4863 / 5000 batch step: 0\n",
      "w1: [26.37113228] w2: [-23.31705033] bias: [15.66459561] loss: 30.531049089675186\n",
      "Epoch: 4863 / 5000 batch step: 30\n",
      "w1: [26.36454595] w2: [-23.31705346] bias: [15.65152279] loss: 30.535788171159517\n",
      "Epoch: 4863 / 5000 batch step: 60\n",
      "w1: [26.34306149] w2: [-23.32405586] bias: [15.61066513] loss: 30.555145880780273\n",
      "Epoch: 4863 / 5000 batch step: 90\n",
      "w1: [26.33647979] w2: [-23.32799243] bias: [15.59539289] loss: 30.563713675989483\n",
      "Epoch: 4863 / 5000 batch step: 120\n",
      "w1: [26.34627808] w2: [-23.29722041] bias: [15.63186672] loss: 30.54355572383986\n",
      "Epoch: 4863 / 5000 batch step: 150\n",
      "w1: [26.38082837] w2: [-23.29572604] bias: [15.67611695] loss: 30.52545320142766\n",
      "Epoch: 4863 / 5000 batch step: 180\n",
      "w1: [26.44824134] w2: [-23.27866926] bias: [15.77842234] loss: 30.513839516289163\n",
      "Epoch: 4863 / 5000 batch step: 210\n",
      "w1: [26.48468832] w2: [-23.25831097] bias: [15.83712426] loss: 30.526117095963343\n",
      "Epoch: 4863 / 5000 batch step: 240\n",
      "w1: [26.52319108] w2: [-23.2524614] bias: [15.87850538] loss: 30.544613468650333\n",
      "Epoch: 4863 / 5000 batch step: 270\n",
      "w1: [26.5395125] w2: [-23.25256393] bias: [15.89556237] loss: 30.554352919597264\n",
      "Epoch: 4863 / 5000 batch step: 300\n",
      "w1: [26.51993368] w2: [-23.25872424] bias: [15.85694239] loss: 30.536235969502698\n",
      "Epoch: 4863 / 5000 batch step: 330\n",
      "w1: [26.48403007] w2: [-23.27127394] bias: [15.78619704] loss: 30.51634963126362\n",
      "Epoch: 4863 / 5000 batch step: 360\n",
      "w1: [26.49521754] w2: [-23.24158583] bias: [15.87624184] loss: 30.540105606346994\n",
      "Epoch: 4863 / 5000 batch step: 390\n",
      "w1: [26.46933059] w2: [-23.25344658] bias: [15.84196001] loss: 30.52582480197379\n",
      "Epoch: 4863 / 5000 batch step: 420\n",
      "w1: [26.41974749] w2: [-23.29702748] bias: [15.74668431] loss: 30.513321044606208\n",
      "Epoch: 4863 / 5000 batch step: 450\n",
      "w1: [26.39420996] w2: [-23.31474743] bias: [15.70330915] loss: 30.519781041567516\n",
      "Epoch: 4863 / 5000 batch step: 480\n",
      "w1: [26.37734836] w2: [-23.31615967] bias: [15.67748255] loss: 30.526888945176406\n",
      "Epoch: 4864 / 5000 batch step: 0\n",
      "w1: [26.37113233] w2: [-23.3170503] bias: [15.66459557] loss: 30.531049089523403\n",
      "Epoch: 4864 / 5000 batch step: 30\n",
      "w1: [26.364546] w2: [-23.31705343] bias: [15.65152275] loss: 30.535788170988994\n",
      "Epoch: 4864 / 5000 batch step: 60\n",
      "w1: [26.34306154] w2: [-23.32405583] bias: [15.6106651] loss: 30.5551458805729\n",
      "Epoch: 4864 / 5000 batch step: 90\n",
      "w1: [26.33647985] w2: [-23.3279924] bias: [15.59539285] loss: 30.56371367577729\n",
      "Epoch: 4864 / 5000 batch step: 120\n",
      "w1: [26.34627814] w2: [-23.29722038] bias: [15.63186668] loss: 30.543555723652137\n",
      "Epoch: 4864 / 5000 batch step: 150\n",
      "w1: [26.38082842] w2: [-23.29572601] bias: [15.67611691] loss: 30.525453201240065\n",
      "Epoch: 4864 / 5000 batch step: 180\n",
      "w1: [26.44824139] w2: [-23.27866923] bias: [15.7784223] loss: 30.51383951613879\n",
      "Epoch: 4864 / 5000 batch step: 210\n",
      "w1: [26.48468837] w2: [-23.25831094] bias: [15.83712422] loss: 30.52611709581377\n",
      "Epoch: 4864 / 5000 batch step: 240\n",
      "w1: [26.52319113] w2: [-23.25246137] bias: [15.87850534] loss: 30.544613468487995\n",
      "Epoch: 4864 / 5000 batch step: 270\n",
      "w1: [26.53951256] w2: [-23.2525639] bias: [15.89556233] loss: 30.554352919441115\n",
      "Epoch: 4864 / 5000 batch step: 300\n",
      "w1: [26.51993374] w2: [-23.25872421] bias: [15.85694235] loss: 30.536235969377092\n",
      "Epoch: 4864 / 5000 batch step: 330\n",
      "w1: [26.48403013] w2: [-23.27127391] bias: [15.78619701] loss: 30.516349631148763\n",
      "Epoch: 4864 / 5000 batch step: 360\n",
      "w1: [26.49521759] w2: [-23.2415858] bias: [15.8762418] loss: 30.540105606235315\n",
      "Epoch: 4864 / 5000 batch step: 390\n",
      "w1: [26.46933065] w2: [-23.25344655] bias: [15.84195997] loss: 30.525824801820168\n",
      "Epoch: 4864 / 5000 batch step: 420\n",
      "w1: [26.41974754] w2: [-23.29702745] bias: [15.74668428] loss: 30.513321044442723\n",
      "Epoch: 4864 / 5000 batch step: 450\n",
      "w1: [26.39421001] w2: [-23.3147474] bias: [15.70330911] loss: 30.519781041424828\n",
      "Epoch: 4864 / 5000 batch step: 480\n",
      "w1: [26.37734841] w2: [-23.31615964] bias: [15.67748251] loss: 30.52688894503034\n",
      "Epoch: 4865 / 5000 batch step: 0\n",
      "w1: [26.37113239] w2: [-23.31705027] bias: [15.66459554] loss: 30.531049089371955\n",
      "Epoch: 4865 / 5000 batch step: 30\n",
      "w1: [26.36454606] w2: [-23.3170534] bias: [15.65152271] loss: 30.53578817081885\n",
      "Epoch: 4865 / 5000 batch step: 60\n",
      "w1: [26.34306159] w2: [-23.3240558] bias: [15.61066506] loss: 30.555145880366\n",
      "Epoch: 4865 / 5000 batch step: 90\n",
      "w1: [26.3364799] w2: [-23.32799237] bias: [15.59539281] loss: 30.563713675565577\n",
      "Epoch: 4865 / 5000 batch step: 120\n",
      "w1: [26.34627819] w2: [-23.29722035] bias: [15.63186664] loss: 30.543555723464834\n",
      "Epoch: 4865 / 5000 batch step: 150\n",
      "w1: [26.38082848] w2: [-23.29572598] bias: [15.67611688] loss: 30.5254532010529\n",
      "Epoch: 4865 / 5000 batch step: 180\n",
      "w1: [26.44824145] w2: [-23.2786692] bias: [15.77842227] loss: 30.513839515988764\n",
      "Epoch: 4865 / 5000 batch step: 210\n",
      "w1: [26.48468842] w2: [-23.25831091] bias: [15.83712419] loss: 30.52611709566453\n",
      "Epoch: 4865 / 5000 batch step: 240\n",
      "w1: [26.52319118] w2: [-23.25246134] bias: [15.8785053] loss: 30.544613468326023\n",
      "Epoch: 4865 / 5000 batch step: 270\n",
      "w1: [26.53951261] w2: [-23.25256387] bias: [15.89556229] loss: 30.554352919285325\n",
      "Epoch: 4865 / 5000 batch step: 300\n",
      "w1: [26.51993379] w2: [-23.25872418] bias: [15.85694231] loss: 30.53623596925177\n",
      "Epoch: 4865 / 5000 batch step: 330\n",
      "w1: [26.48403018] w2: [-23.27127388] bias: [15.78619697] loss: 30.516349631034174\n",
      "Epoch: 4865 / 5000 batch step: 360\n",
      "w1: [26.49521764] w2: [-23.24158577] bias: [15.87624177] loss: 30.5401056061239\n",
      "Epoch: 4865 / 5000 batch step: 390\n",
      "w1: [26.4693307] w2: [-23.25344652] bias: [15.84195994] loss: 30.5258248016669\n",
      "Epoch: 4865 / 5000 batch step: 420\n",
      "w1: [26.4197476] w2: [-23.29702742] bias: [15.74668424] loss: 30.51332104427961\n",
      "Epoch: 4865 / 5000 batch step: 450\n",
      "w1: [26.39421007] w2: [-23.31474737] bias: [15.70330908] loss: 30.519781041282474\n",
      "Epoch: 4865 / 5000 batch step: 480\n",
      "w1: [26.37734846] w2: [-23.31615961] bias: [15.67748247] loss: 30.52688894488461\n",
      "Epoch: 4866 / 5000 batch step: 0\n",
      "w1: [26.37113244] w2: [-23.31705024] bias: [15.6645955] loss: 30.531049089220865\n",
      "Epoch: 4866 / 5000 batch step: 30\n",
      "w1: [26.36454611] w2: [-23.31705337] bias: [15.65152267] loss: 30.5357881706491\n",
      "Epoch: 4866 / 5000 batch step: 60\n",
      "w1: [26.34306165] w2: [-23.32405577] bias: [15.61066502] loss: 30.555145880159557\n",
      "Epoch: 4866 / 5000 batch step: 90\n",
      "w1: [26.33647996] w2: [-23.32799234] bias: [15.59539277] loss: 30.563713675354347\n",
      "Epoch: 4866 / 5000 batch step: 120\n",
      "w1: [26.34627825] w2: [-23.29722032] bias: [15.63186661] loss: 30.54355572327796\n",
      "Epoch: 4866 / 5000 batch step: 150\n",
      "w1: [26.38082853] w2: [-23.29572595] bias: [15.67611684] loss: 30.52545320086616\n",
      "Epoch: 4866 / 5000 batch step: 180\n",
      "w1: [26.4482415] w2: [-23.27866917] bias: [15.77842223] loss: 30.51383951583908\n",
      "Epoch: 4866 / 5000 batch step: 210\n",
      "w1: [26.48468848] w2: [-23.25831088] bias: [15.83712415] loss: 30.52611709551563\n",
      "Epoch: 4866 / 5000 batch step: 240\n",
      "w1: [26.52319124] w2: [-23.25246131] bias: [15.87850526] loss: 30.54461346816441\n",
      "Epoch: 4866 / 5000 batch step: 270\n",
      "w1: [26.53951266] w2: [-23.25256385] bias: [15.89556226] loss: 30.554352919129887\n",
      "Epoch: 4866 / 5000 batch step: 300\n",
      "w1: [26.51993384] w2: [-23.25872415] bias: [15.85694227] loss: 30.536235969126736\n",
      "Epoch: 4866 / 5000 batch step: 330\n",
      "w1: [26.48403024] w2: [-23.27127386] bias: [15.78619693] loss: 30.516349630919844\n",
      "Epoch: 4866 / 5000 batch step: 360\n",
      "w1: [26.4952177] w2: [-23.24158574] bias: [15.87624173] loss: 30.54010560601273\n",
      "Epoch: 4866 / 5000 batch step: 390\n",
      "w1: [26.46933075] w2: [-23.2534465] bias: [15.8419599] loss: 30.52582480151398\n",
      "Epoch: 4866 / 5000 batch step: 420\n",
      "w1: [26.41974765] w2: [-23.29702739] bias: [15.7466842] loss: 30.51332104411687\n",
      "Epoch: 4866 / 5000 batch step: 450\n",
      "w1: [26.39421012] w2: [-23.31474734] bias: [15.70330904] loss: 30.519781041140426\n",
      "Epoch: 4866 / 5000 batch step: 480\n",
      "w1: [26.37734852] w2: [-23.31615958] bias: [15.67748243] loss: 30.52688894473921\n",
      "Epoch: 4867 / 5000 batch step: 0\n",
      "w1: [26.37113249] w2: [-23.31705021] bias: [15.66459546] loss: 30.531049089070105\n",
      "Epoch: 4867 / 5000 batch step: 30\n",
      "w1: [26.36454616] w2: [-23.31705334] bias: [15.65152264] loss: 30.53578817047973\n",
      "Epoch: 4867 / 5000 batch step: 60\n",
      "w1: [26.3430617] w2: [-23.32405574] bias: [15.61066499] loss: 30.5551458799536\n",
      "Epoch: 4867 / 5000 batch step: 90\n",
      "w1: [26.33648001] w2: [-23.32799231] bias: [15.59539274] loss: 30.563713675143592\n",
      "Epoch: 4867 / 5000 batch step: 120\n",
      "w1: [26.3462783] w2: [-23.29722029] bias: [15.63186657] loss: 30.54355572309151\n",
      "Epoch: 4867 / 5000 batch step: 150\n",
      "w1: [26.38082858] w2: [-23.29572592] bias: [15.6761168] loss: 30.525453200679852\n",
      "Epoch: 4867 / 5000 batch step: 180\n",
      "w1: [26.44824155] w2: [-23.27866914] bias: [15.77842219] loss: 30.513839515689735\n",
      "Epoch: 4867 / 5000 batch step: 210\n",
      "w1: [26.48468853] w2: [-23.25831085] bias: [15.83712411] loss: 30.526117095367066\n",
      "Epoch: 4867 / 5000 batch step: 240\n",
      "w1: [26.52319129] w2: [-23.25246129] bias: [15.87850523] loss: 30.54461346800317\n",
      "Epoch: 4867 / 5000 batch step: 270\n",
      "w1: [26.53951272] w2: [-23.25256382] bias: [15.89556222] loss: 30.554352918974796\n",
      "Epoch: 4867 / 5000 batch step: 300\n",
      "w1: [26.5199339] w2: [-23.25872412] bias: [15.85694224] loss: 30.536235969001975\n",
      "Epoch: 4867 / 5000 batch step: 330\n",
      "w1: [26.48403029] w2: [-23.27127383] bias: [15.7861969] loss: 30.516349630805767\n",
      "Epoch: 4867 / 5000 batch step: 360\n",
      "w1: [26.49521775] w2: [-23.24158571] bias: [15.87624169] loss: 30.540105605901818\n",
      "Epoch: 4867 / 5000 batch step: 390\n",
      "w1: [26.46933081] w2: [-23.25344647] bias: [15.84195986] loss: 30.5258248013614\n",
      "Epoch: 4867 / 5000 batch step: 420\n",
      "w1: [26.4197477] w2: [-23.29702736] bias: [15.74668416] loss: 30.513321043954498\n",
      "Epoch: 4867 / 5000 batch step: 450\n",
      "w1: [26.39421018] w2: [-23.31474731] bias: [15.703309] loss: 30.519781040998716\n",
      "Epoch: 4867 / 5000 batch step: 480\n",
      "w1: [26.37734857] w2: [-23.31615955] bias: [15.6774824] loss: 30.52688894459414\n",
      "Epoch: 4868 / 5000 batch step: 0\n",
      "w1: [26.37113255] w2: [-23.31705018] bias: [15.66459543] loss: 30.5310490889197\n",
      "Epoch: 4868 / 5000 batch step: 30\n",
      "w1: [26.36454622] w2: [-23.31705331] bias: [15.6515226] loss: 30.53578817031076\n",
      "Epoch: 4868 / 5000 batch step: 60\n",
      "w1: [26.34306176] w2: [-23.32405571] bias: [15.61066495] loss: 30.555145879748107\n",
      "Epoch: 4868 / 5000 batch step: 90\n",
      "w1: [26.33648006] w2: [-23.32799228] bias: [15.5953927] loss: 30.56371367493332\n",
      "Epoch: 4868 / 5000 batch step: 120\n",
      "w1: [26.34627835] w2: [-23.29722026] bias: [15.63186653] loss: 30.543555722905488\n",
      "Epoch: 4868 / 5000 batch step: 150\n",
      "w1: [26.38082864] w2: [-23.29572589] bias: [15.67611677] loss: 30.52545320049396\n",
      "Epoch: 4868 / 5000 batch step: 180\n",
      "w1: [26.44824161] w2: [-23.27866911] bias: [15.77842216] loss: 30.513839515540727\n",
      "Epoch: 4868 / 5000 batch step: 210\n",
      "w1: [26.48468859] w2: [-23.25831082] bias: [15.83712408] loss: 30.52611709521884\n",
      "Epoch: 4868 / 5000 batch step: 240\n",
      "w1: [26.52319135] w2: [-23.25246126] bias: [15.87850519] loss: 30.544613467842296\n",
      "Epoch: 4868 / 5000 batch step: 270\n",
      "w1: [26.53951277] w2: [-23.25256379] bias: [15.89556218] loss: 30.55435291882006\n",
      "Epoch: 4868 / 5000 batch step: 300\n",
      "w1: [26.51993395] w2: [-23.25872409] bias: [15.8569422] loss: 30.53623596887751\n",
      "Epoch: 4868 / 5000 batch step: 330\n",
      "w1: [26.48403034] w2: [-23.2712738] bias: [15.78619686] loss: 30.51634963069196\n",
      "Epoch: 4868 / 5000 batch step: 360\n",
      "w1: [26.49521781] w2: [-23.24158568] bias: [15.87624166] loss: 30.54010560579115\n",
      "Epoch: 4868 / 5000 batch step: 390\n",
      "w1: [26.46933086] w2: [-23.25344644] bias: [15.84195983] loss: 30.525824801209172\n",
      "Epoch: 4868 / 5000 batch step: 420\n",
      "w1: [26.41974776] w2: [-23.29702733] bias: [15.74668413] loss: 30.513321043792505\n",
      "Epoch: 4868 / 5000 batch step: 450\n",
      "w1: [26.39421023] w2: [-23.31474728] bias: [15.70330896] loss: 30.519781040857314\n",
      "Epoch: 4868 / 5000 batch step: 480\n",
      "w1: [26.37734863] w2: [-23.31615952] bias: [15.67748236] loss: 30.526888944449396\n",
      "Epoch: 4869 / 5000 batch step: 0\n",
      "w1: [26.3711326] w2: [-23.31705015] bias: [15.66459539] loss: 30.531049088769635\n",
      "Epoch: 4869 / 5000 batch step: 30\n",
      "w1: [26.36454627] w2: [-23.31705328] bias: [15.65152256] loss: 30.535788170142155\n",
      "Epoch: 4869 / 5000 batch step: 60\n",
      "w1: [26.34306181] w2: [-23.32405568] bias: [15.61066491] loss: 30.555145879543087\n",
      "Epoch: 4869 / 5000 batch step: 90\n",
      "w1: [26.33648012] w2: [-23.32799225] bias: [15.59539266] loss: 30.563713674723534\n",
      "Epoch: 4869 / 5000 batch step: 120\n",
      "w1: [26.34627841] w2: [-23.29722023] bias: [15.6318665] loss: 30.543555722719887\n",
      "Epoch: 4869 / 5000 batch step: 150\n",
      "w1: [26.38082869] w2: [-23.29572586] bias: [15.67611673] loss: 30.525453200308498\n",
      "Epoch: 4869 / 5000 batch step: 180\n",
      "w1: [26.44824166] w2: [-23.27866908] bias: [15.77842212] loss: 30.513839515392057\n",
      "Epoch: 4869 / 5000 batch step: 210\n",
      "w1: [26.48468864] w2: [-23.25831079] bias: [15.83712404] loss: 30.526117095070955\n",
      "Epoch: 4869 / 5000 batch step: 240\n",
      "w1: [26.5231914] w2: [-23.25246123] bias: [15.87850515] loss: 30.54461346768179\n",
      "Epoch: 4869 / 5000 batch step: 270\n",
      "w1: [26.53951282] w2: [-23.25256376] bias: [15.89556214] loss: 30.554352918665675\n",
      "Epoch: 4869 / 5000 batch step: 300\n",
      "w1: [26.519934] w2: [-23.25872406] bias: [15.85694216] loss: 30.53623596875332\n",
      "Epoch: 4869 / 5000 batch step: 330\n",
      "w1: [26.4840304] w2: [-23.27127377] bias: [15.78619682] loss: 30.516349630578404\n",
      "Epoch: 4869 / 5000 batch step: 360\n",
      "w1: [26.49521786] w2: [-23.24158565] bias: [15.87624162] loss: 30.540105605680747\n",
      "Epoch: 4869 / 5000 batch step: 390\n",
      "w1: [26.46933091] w2: [-23.25344641] bias: [15.84195979] loss: 30.52582480105729\n",
      "Epoch: 4869 / 5000 batch step: 420\n",
      "w1: [26.41974781] w2: [-23.2970273] bias: [15.74668409] loss: 30.51332104363087\n",
      "Epoch: 4869 / 5000 batch step: 450\n",
      "w1: [26.39421028] w2: [-23.31474725] bias: [15.70330893] loss: 30.519781040716243\n",
      "Epoch: 4869 / 5000 batch step: 480\n",
      "w1: [26.37734868] w2: [-23.31615949] bias: [15.67748232] loss: 30.526888944304986\n",
      "Epoch: 4870 / 5000 batch step: 0\n",
      "w1: [26.37113265] w2: [-23.31705012] bias: [15.66459535] loss: 30.531049088619902\n",
      "Epoch: 4870 / 5000 batch step: 30\n",
      "w1: [26.36454632] w2: [-23.31705325] bias: [15.65152253] loss: 30.535788169973948\n",
      "Epoch: 4870 / 5000 batch step: 60\n",
      "w1: [26.34306186] w2: [-23.32405565] bias: [15.61066487] loss: 30.555145879338525\n",
      "Epoch: 4870 / 5000 batch step: 90\n",
      "w1: [26.33648017] w2: [-23.32799222] bias: [15.59539263] loss: 30.563713674514215\n",
      "Epoch: 4870 / 5000 batch step: 120\n",
      "w1: [26.34627846] w2: [-23.2972202] bias: [15.63186646] loss: 30.543555722534705\n",
      "Epoch: 4870 / 5000 batch step: 150\n",
      "w1: [26.38082874] w2: [-23.29572583] bias: [15.67611669] loss: 30.52545320012345\n",
      "Epoch: 4870 / 5000 batch step: 180\n",
      "w1: [26.44824171] w2: [-23.27866905] bias: [15.77842208] loss: 30.51383951524373\n",
      "Epoch: 4870 / 5000 batch step: 210\n",
      "w1: [26.48468869] w2: [-23.25831076] bias: [15.837124] loss: 30.526117094923407\n",
      "Epoch: 4870 / 5000 batch step: 240\n",
      "w1: [26.52319145] w2: [-23.2524612] bias: [15.87850512] loss: 30.54461346752164\n",
      "Epoch: 4870 / 5000 batch step: 270\n",
      "w1: [26.53951288] w2: [-23.25256373] bias: [15.89556211] loss: 30.554352918511647\n",
      "Epoch: 4870 / 5000 batch step: 300\n",
      "w1: [26.51993406] w2: [-23.25872403] bias: [15.85694213] loss: 30.536235968629416\n",
      "Epoch: 4870 / 5000 batch step: 330\n",
      "w1: [26.48403045] w2: [-23.27127374] bias: [15.78619678] loss: 30.516349630465108\n",
      "Epoch: 4870 / 5000 batch step: 360\n",
      "w1: [26.49521791] w2: [-23.24158562] bias: [15.87624158] loss: 30.540105605570588\n",
      "Epoch: 4870 / 5000 batch step: 390\n",
      "w1: [26.46933097] w2: [-23.25344638] bias: [15.84195975] loss: 30.525824800905763\n",
      "Epoch: 4870 / 5000 batch step: 420\n",
      "w1: [26.41974786] w2: [-23.29702728] bias: [15.74668405] loss: 30.513321043469606\n",
      "Epoch: 4870 / 5000 batch step: 450\n",
      "w1: [26.39421034] w2: [-23.31474722] bias: [15.70330889] loss: 30.5197810405755\n",
      "Epoch: 4870 / 5000 batch step: 480\n",
      "w1: [26.37734873] w2: [-23.31615946] bias: [15.67748229] loss: 30.526888944160905\n",
      "Epoch: 4871 / 5000 batch step: 0\n",
      "w1: [26.37113271] w2: [-23.31705009] bias: [15.66459531] loss: 30.531049088470514\n",
      "Epoch: 4871 / 5000 batch step: 30\n",
      "w1: [26.36454638] w2: [-23.31705322] bias: [15.65152249] loss: 30.535788169806114\n",
      "Epoch: 4871 / 5000 batch step: 60\n",
      "w1: [26.34306192] w2: [-23.32405563] bias: [15.61066484] loss: 30.555145879134425\n",
      "Epoch: 4871 / 5000 batch step: 90\n",
      "w1: [26.33648022] w2: [-23.32799219] bias: [15.59539259] loss: 30.563713674305372\n",
      "Epoch: 4871 / 5000 batch step: 120\n",
      "w1: [26.34627851] w2: [-23.29722017] bias: [15.63186642] loss: 30.54355572234995\n",
      "Epoch: 4871 / 5000 batch step: 150\n",
      "w1: [26.3808288] w2: [-23.2957258] bias: [15.67611665] loss: 30.52545319993883\n",
      "Epoch: 4871 / 5000 batch step: 180\n",
      "w1: [26.44824177] w2: [-23.27866902] bias: [15.77842205] loss: 30.513839515095743\n",
      "Epoch: 4871 / 5000 batch step: 210\n",
      "w1: [26.48468875] w2: [-23.25831073] bias: [15.83712396] loss: 30.52611709477619\n",
      "Epoch: 4871 / 5000 batch step: 240\n",
      "w1: [26.52319151] w2: [-23.25246117] bias: [15.87850508] loss: 30.544613467361867\n",
      "Epoch: 4871 / 5000 batch step: 270\n",
      "w1: [26.53951293] w2: [-23.2525637] bias: [15.89556207] loss: 30.554352918357964\n",
      "Epoch: 4871 / 5000 batch step: 300\n",
      "w1: [26.51993411] w2: [-23.258724] bias: [15.85694209] loss: 30.536235968505796\n",
      "Epoch: 4871 / 5000 batch step: 330\n",
      "w1: [26.4840305] w2: [-23.27127371] bias: [15.78619675] loss: 30.51634963035207\n",
      "Epoch: 4871 / 5000 batch step: 360\n",
      "w1: [26.49521797] w2: [-23.24158559] bias: [15.87624155] loss: 30.540105605460674\n",
      "Epoch: 4871 / 5000 batch step: 390\n",
      "w1: [26.46933102] w2: [-23.25344635] bias: [15.84195971] loss: 30.52582480075457\n",
      "Epoch: 4871 / 5000 batch step: 420\n",
      "w1: [26.41974792] w2: [-23.29702725] bias: [15.74668402] loss: 30.513321043308707\n",
      "Epoch: 4871 / 5000 batch step: 450\n",
      "w1: [26.39421039] w2: [-23.31474719] bias: [15.70330885] loss: 30.519781040435063\n",
      "Epoch: 4871 / 5000 batch step: 480\n",
      "w1: [26.37734879] w2: [-23.31615944] bias: [15.67748225] loss: 30.526888944017152\n",
      "Epoch: 4872 / 5000 batch step: 0\n",
      "w1: [26.37113276] w2: [-23.31705006] bias: [15.66459528] loss: 30.531049088321474\n",
      "Epoch: 4872 / 5000 batch step: 30\n",
      "w1: [26.36454643] w2: [-23.31705319] bias: [15.65152245] loss: 30.53578816963867\n",
      "Epoch: 4872 / 5000 batch step: 60\n",
      "w1: [26.34306197] w2: [-23.3240556] bias: [15.6106648] loss: 30.55514587893079\n",
      "Epoch: 4872 / 5000 batch step: 90\n",
      "w1: [26.33648028] w2: [-23.32799217] bias: [15.59539255] loss: 30.563713674097006\n",
      "Epoch: 4872 / 5000 batch step: 120\n",
      "w1: [26.34627857] w2: [-23.29722014] bias: [15.63186639] loss: 30.54355572216561\n",
      "Epoch: 4872 / 5000 batch step: 150\n",
      "w1: [26.38082885] w2: [-23.29572577] bias: [15.67611662] loss: 30.52545319975462\n",
      "Epoch: 4872 / 5000 batch step: 180\n",
      "w1: [26.44824182] w2: [-23.27866899] bias: [15.77842201] loss: 30.513839514948085\n",
      "Epoch: 4872 / 5000 batch step: 210\n",
      "w1: [26.4846888] w2: [-23.2583107] bias: [15.83712393] loss: 30.526117094629313\n",
      "Epoch: 4872 / 5000 batch step: 240\n",
      "w1: [26.52319156] w2: [-23.25246114] bias: [15.87850504] loss: 30.544613467202456\n",
      "Epoch: 4872 / 5000 batch step: 270\n",
      "w1: [26.53951298] w2: [-23.25256367] bias: [15.89556203] loss: 30.554352918204636\n",
      "Epoch: 4872 / 5000 batch step: 300\n",
      "w1: [26.51993416] w2: [-23.25872397] bias: [15.85694205] loss: 30.53623596838246\n",
      "Epoch: 4872 / 5000 batch step: 330\n",
      "w1: [26.48403056] w2: [-23.27127368] bias: [15.78619671] loss: 30.516349630239294\n",
      "Epoch: 4872 / 5000 batch step: 360\n",
      "w1: [26.49521802] w2: [-23.24158557] bias: [15.87624151] loss: 30.540105605351027\n",
      "Epoch: 4872 / 5000 batch step: 390\n",
      "w1: [26.46933107] w2: [-23.25344632] bias: [15.84195968] loss: 30.525824800603722\n",
      "Epoch: 4872 / 5000 batch step: 420\n",
      "w1: [26.41974797] w2: [-23.29702722] bias: [15.74668398] loss: 30.513321043148174\n",
      "Epoch: 4872 / 5000 batch step: 450\n",
      "w1: [26.39421044] w2: [-23.31474716] bias: [15.70330882] loss: 30.51978104029495\n",
      "Epoch: 4872 / 5000 batch step: 480\n",
      "w1: [26.37734884] w2: [-23.31615941] bias: [15.67748221] loss: 30.52688894387371\n",
      "Epoch: 4873 / 5000 batch step: 0\n",
      "w1: [26.37113281] w2: [-23.31705003] bias: [15.66459524] loss: 30.53104908817276\n",
      "Epoch: 4873 / 5000 batch step: 30\n",
      "w1: [26.36454648] w2: [-23.31705316] bias: [15.65152242] loss: 30.535788169471594\n",
      "Epoch: 4873 / 5000 batch step: 60\n",
      "w1: [26.34306202] w2: [-23.32405557] bias: [15.61066476] loss: 30.555145878727622\n",
      "Epoch: 4873 / 5000 batch step: 90\n",
      "w1: [26.33648033] w2: [-23.32799214] bias: [15.59539252] loss: 30.56371367388911\n",
      "Epoch: 4873 / 5000 batch step: 120\n",
      "w1: [26.34627862] w2: [-23.29722012] bias: [15.63186635] loss: 30.54355572198169\n",
      "Epoch: 4873 / 5000 batch step: 150\n",
      "w1: [26.3808289] w2: [-23.29572574] bias: [15.67611658] loss: 30.52545319957083\n",
      "Epoch: 4873 / 5000 batch step: 180\n",
      "w1: [26.44824187] w2: [-23.27866896] bias: [15.77842197] loss: 30.513839514800768\n",
      "Epoch: 4873 / 5000 batch step: 210\n",
      "w1: [26.48468885] w2: [-23.25831067] bias: [15.83712389] loss: 30.526117094482768\n",
      "Epoch: 4873 / 5000 batch step: 240\n",
      "w1: [26.52319161] w2: [-23.25246111] bias: [15.87850501] loss: 30.5446134670434\n",
      "Epoch: 4873 / 5000 batch step: 270\n",
      "w1: [26.53951304] w2: [-23.25256364] bias: [15.895562] loss: 30.554352918051656\n",
      "Epoch: 4873 / 5000 batch step: 300\n",
      "w1: [26.51993422] w2: [-23.25872394] bias: [15.85694202] loss: 30.536235968259394\n",
      "Epoch: 4873 / 5000 batch step: 330\n",
      "w1: [26.48403061] w2: [-23.27127365] bias: [15.78619667] loss: 30.51634963012677\n",
      "Epoch: 4873 / 5000 batch step: 360\n",
      "w1: [26.49521807] w2: [-23.24158554] bias: [15.87624147] loss: 30.540105605241614\n",
      "Epoch: 4873 / 5000 batch step: 390\n",
      "w1: [26.46933113] w2: [-23.25344629] bias: [15.84195964] loss: 30.525824800453215\n",
      "Epoch: 4873 / 5000 batch step: 420\n",
      "w1: [26.41974802] w2: [-23.29702719] bias: [15.74668394] loss: 30.513321042988004\n",
      "Epoch: 4873 / 5000 batch step: 450\n",
      "w1: [26.39421049] w2: [-23.31474713] bias: [15.70330878] loss: 30.519781040155156\n",
      "Epoch: 4873 / 5000 batch step: 480\n",
      "w1: [26.37734889] w2: [-23.31615938] bias: [15.67748218] loss: 30.52688894373061\n",
      "Epoch: 4874 / 5000 batch step: 0\n",
      "w1: [26.37113287] w2: [-23.31705] bias: [15.6645952] loss: 30.53104908802439\n",
      "Epoch: 4874 / 5000 batch step: 30\n",
      "w1: [26.36454654] w2: [-23.31705313] bias: [15.65152238] loss: 30.535788169304904\n",
      "Epoch: 4874 / 5000 batch step: 60\n",
      "w1: [26.34306208] w2: [-23.32405554] bias: [15.61066473] loss: 30.55514587852491\n",
      "Epoch: 4874 / 5000 batch step: 90\n",
      "w1: [26.33648038] w2: [-23.32799211] bias: [15.59539248] loss: 30.56371367368169\n",
      "Epoch: 4874 / 5000 batch step: 120\n",
      "w1: [26.34627867] w2: [-23.29722009] bias: [15.63186631] loss: 30.54355572179819\n",
      "Epoch: 4874 / 5000 batch step: 150\n",
      "w1: [26.38082896] w2: [-23.29572571] bias: [15.67611655] loss: 30.525453199387464\n",
      "Epoch: 4874 / 5000 batch step: 180\n",
      "w1: [26.44824193] w2: [-23.27866894] bias: [15.77842194] loss: 30.51383951465378\n",
      "Epoch: 4874 / 5000 batch step: 210\n",
      "w1: [26.4846889] w2: [-23.25831064] bias: [15.83712385] loss: 30.526117094336556\n",
      "Epoch: 4874 / 5000 batch step: 240\n",
      "w1: [26.52319166] w2: [-23.25246108] bias: [15.87850497] loss: 30.54461346688471\n",
      "Epoch: 4874 / 5000 batch step: 270\n",
      "w1: [26.53951309] w2: [-23.25256361] bias: [15.89556196] loss: 30.55435291789902\n",
      "Epoch: 4874 / 5000 batch step: 300\n",
      "w1: [26.51993427] w2: [-23.25872391] bias: [15.85694198] loss: 30.536235968136616\n",
      "Epoch: 4874 / 5000 batch step: 330\n",
      "w1: [26.48403066] w2: [-23.27127362] bias: [15.78619664] loss: 30.516349630014496\n",
      "Epoch: 4874 / 5000 batch step: 360\n",
      "w1: [26.49521812] w2: [-23.24158551] bias: [15.87624144] loss: 30.540105605132457\n",
      "Epoch: 4874 / 5000 batch step: 390\n",
      "w1: [26.46933118] w2: [-23.25344626] bias: [15.84195961] loss: 30.52582480030306\n",
      "Epoch: 4874 / 5000 batch step: 420\n",
      "w1: [26.41974808] w2: [-23.29702716] bias: [15.74668391] loss: 30.51332104282821\n",
      "Epoch: 4874 / 5000 batch step: 450\n",
      "w1: [26.39421055] w2: [-23.3147471] bias: [15.70330874] loss: 30.519781040015683\n",
      "Epoch: 4874 / 5000 batch step: 480\n",
      "w1: [26.37734894] w2: [-23.31615935] bias: [15.67748214] loss: 30.526888943587842\n",
      "Epoch: 4875 / 5000 batch step: 0\n",
      "w1: [26.37113292] w2: [-23.31704997] bias: [15.66459517] loss: 30.531049087876358\n",
      "Epoch: 4875 / 5000 batch step: 30\n",
      "w1: [26.36454659] w2: [-23.31705311] bias: [15.65152234] loss: 30.535788169138595\n",
      "Epoch: 4875 / 5000 batch step: 60\n",
      "w1: [26.34306213] w2: [-23.32405551] bias: [15.61066469] loss: 30.555145878322666\n",
      "Epoch: 4875 / 5000 batch step: 90\n",
      "w1: [26.33648043] w2: [-23.32799208] bias: [15.59539244] loss: 30.56371367347474\n",
      "Epoch: 4875 / 5000 batch step: 120\n",
      "w1: [26.34627873] w2: [-23.29722006] bias: [15.63186628] loss: 30.543555721615096\n",
      "Epoch: 4875 / 5000 batch step: 150\n",
      "w1: [26.38082901] w2: [-23.29572568] bias: [15.67611651] loss: 30.52545319920451\n",
      "Epoch: 4875 / 5000 batch step: 180\n",
      "w1: [26.44824198] w2: [-23.27866891] bias: [15.7784219] loss: 30.51383951450713\n",
      "Epoch: 4875 / 5000 batch step: 210\n",
      "w1: [26.48468896] w2: [-23.25831061] bias: [15.83712382] loss: 30.526117094190678\n",
      "Epoch: 4875 / 5000 batch step: 240\n",
      "w1: [26.52319172] w2: [-23.25246105] bias: [15.87850493] loss: 30.544613466726382\n",
      "Epoch: 4875 / 5000 batch step: 270\n",
      "w1: [26.53951314] w2: [-23.25256358] bias: [15.89556192] loss: 30.554352917746726\n",
      "Epoch: 4875 / 5000 batch step: 300\n",
      "w1: [26.51993432] w2: [-23.25872389] bias: [15.85694194] loss: 30.536235968014115\n",
      "Epoch: 4875 / 5000 batch step: 330\n",
      "w1: [26.48403071] w2: [-23.27127359] bias: [15.7861966] loss: 30.51634962990249\n",
      "Epoch: 4875 / 5000 batch step: 360\n",
      "w1: [26.49521818] w2: [-23.24158548] bias: [15.8762414] loss: 30.54010560502354\n",
      "Epoch: 4875 / 5000 batch step: 390\n",
      "w1: [26.46933123] w2: [-23.25344623] bias: [15.84195957] loss: 30.525824800153238\n",
      "Epoch: 4875 / 5000 batch step: 420\n",
      "w1: [26.41974813] w2: [-23.29702713] bias: [15.74668387] loss: 30.513321042668768\n",
      "Epoch: 4875 / 5000 batch step: 450\n",
      "w1: [26.3942106] w2: [-23.31474707] bias: [15.70330871] loss: 30.519781039876523\n",
      "Epoch: 4875 / 5000 batch step: 480\n",
      "w1: [26.377349] w2: [-23.31615932] bias: [15.6774821] loss: 30.526888943445385\n",
      "Epoch: 4876 / 5000 batch step: 0\n",
      "w1: [26.37113297] w2: [-23.31704994] bias: [15.66459513] loss: 30.531049087728665\n",
      "Epoch: 4876 / 5000 batch step: 30\n",
      "w1: [26.36454664] w2: [-23.31705308] bias: [15.65152231] loss: 30.53578816897267\n",
      "Epoch: 4876 / 5000 batch step: 60\n",
      "w1: [26.34306218] w2: [-23.32405548] bias: [15.61066466] loss: 30.555145878120882\n",
      "Epoch: 4876 / 5000 batch step: 90\n",
      "w1: [26.33648049] w2: [-23.32799205] bias: [15.59539241] loss: 30.56371367326827\n",
      "Epoch: 4876 / 5000 batch step: 120\n",
      "w1: [26.34627878] w2: [-23.29722003] bias: [15.63186624] loss: 30.54355572143243\n",
      "Epoch: 4876 / 5000 batch step: 150\n",
      "w1: [26.38082906] w2: [-23.29572565] bias: [15.67611647] loss: 30.525453199021978\n",
      "Epoch: 4876 / 5000 batch step: 180\n",
      "w1: [26.44824203] w2: [-23.27866888] bias: [15.77842186] loss: 30.51383951436081\n",
      "Epoch: 4876 / 5000 batch step: 210\n",
      "w1: [26.48468901] w2: [-23.25831058] bias: [15.83712378] loss: 30.526117094045123\n",
      "Epoch: 4876 / 5000 batch step: 240\n",
      "w1: [26.52319177] w2: [-23.25246102] bias: [15.8785049] loss: 30.544613466568414\n",
      "Epoch: 4876 / 5000 batch step: 270\n",
      "w1: [26.53951319] w2: [-23.25256355] bias: [15.89556189] loss: 30.55435291759479\n",
      "Epoch: 4876 / 5000 batch step: 300\n",
      "w1: [26.51993437] w2: [-23.25872386] bias: [15.85694191] loss: 30.536235967891894\n",
      "Epoch: 4876 / 5000 batch step: 330\n",
      "w1: [26.48403077] w2: [-23.27127356] bias: [15.78619657] loss: 30.51634962979073\n",
      "Epoch: 4876 / 5000 batch step: 360\n",
      "w1: [26.49521823] w2: [-23.24158545] bias: [15.87624136] loss: 30.54010560491488\n",
      "Epoch: 4876 / 5000 batch step: 390\n",
      "w1: [26.46933129] w2: [-23.2534462] bias: [15.84195953] loss: 30.525824800003758\n",
      "Epoch: 4876 / 5000 batch step: 420\n",
      "w1: [26.41974818] w2: [-23.2970271] bias: [15.74668383] loss: 30.513321042509695\n",
      "Epoch: 4876 / 5000 batch step: 450\n",
      "w1: [26.39421065] w2: [-23.31474705] bias: [15.70330867] loss: 30.519781039737683\n",
      "Epoch: 4876 / 5000 batch step: 480\n",
      "w1: [26.37734905] w2: [-23.31615929] bias: [15.67748207] loss: 30.52688894330326\n",
      "Epoch: 4877 / 5000 batch step: 0\n",
      "w1: [26.37113302] w2: [-23.31704992] bias: [15.6645951] loss: 30.5310490875813\n",
      "Epoch: 4877 / 5000 batch step: 30\n",
      "w1: [26.36454669] w2: [-23.31705305] bias: [15.65152227] loss: 30.535788168807112\n",
      "Epoch: 4877 / 5000 batch step: 60\n",
      "w1: [26.34306223] w2: [-23.32405545] bias: [15.61066462] loss: 30.555145877919553\n",
      "Epoch: 4877 / 5000 batch step: 90\n",
      "w1: [26.33648054] w2: [-23.32799202] bias: [15.59539237] loss: 30.563713673062257\n",
      "Epoch: 4877 / 5000 batch step: 120\n",
      "w1: [26.34627883] w2: [-23.29722] bias: [15.6318662] loss: 30.543555721250183\n",
      "Epoch: 4877 / 5000 batch step: 150\n",
      "w1: [26.38082911] w2: [-23.29572563] bias: [15.67611644] loss: 30.52545319883986\n",
      "Epoch: 4877 / 5000 batch step: 180\n",
      "w1: [26.44824208] w2: [-23.27866885] bias: [15.77842183] loss: 30.513839514214826\n",
      "Epoch: 4877 / 5000 batch step: 210\n",
      "w1: [26.48468906] w2: [-23.25831056] bias: [15.83712375] loss: 30.52611709389991\n",
      "Epoch: 4877 / 5000 batch step: 240\n",
      "w1: [26.52319182] w2: [-23.25246099] bias: [15.87850486] loss: 30.5446134664108\n",
      "Epoch: 4877 / 5000 batch step: 270\n",
      "w1: [26.53951325] w2: [-23.25256352] bias: [15.89556185] loss: 30.554352917443193\n",
      "Epoch: 4877 / 5000 batch step: 300\n",
      "w1: [26.51993443] w2: [-23.25872383] bias: [15.85694187] loss: 30.536235967769947\n",
      "Epoch: 4877 / 5000 batch step: 330\n",
      "w1: [26.48403082] w2: [-23.27127353] bias: [15.78619653] loss: 30.516349629679226\n",
      "Epoch: 4877 / 5000 batch step: 360\n",
      "w1: [26.49521828] w2: [-23.24158542] bias: [15.87624133] loss: 30.540105604806467\n",
      "Epoch: 4877 / 5000 batch step: 390\n",
      "w1: [26.46933134] w2: [-23.25344617] bias: [15.8419595] loss: 30.525824799854618\n",
      "Epoch: 4877 / 5000 batch step: 420\n",
      "w1: [26.41974823] w2: [-23.29702707] bias: [15.7466838] loss: 30.513321042350977\n",
      "Epoch: 4877 / 5000 batch step: 450\n",
      "w1: [26.3942107] w2: [-23.31474702] bias: [15.70330863] loss: 30.519781039599152\n",
      "Epoch: 4877 / 5000 batch step: 480\n",
      "w1: [26.3773491] w2: [-23.31615926] bias: [15.67748203] loss: 30.526888943161445\n",
      "Epoch: 4878 / 5000 batch step: 0\n",
      "w1: [26.37113308] w2: [-23.31704989] bias: [15.66459506] loss: 30.531049087434276\n",
      "Epoch: 4878 / 5000 batch step: 30\n",
      "w1: [26.36454675] w2: [-23.31705302] bias: [15.65152223] loss: 30.53578816864193\n",
      "Epoch: 4878 / 5000 batch step: 60\n",
      "w1: [26.34306229] w2: [-23.32405542] bias: [15.61066458] loss: 30.555145877718683\n",
      "Epoch: 4878 / 5000 batch step: 90\n",
      "w1: [26.33648059] w2: [-23.32799199] bias: [15.59539234] loss: 30.563713672856718\n",
      "Epoch: 4878 / 5000 batch step: 120\n",
      "w1: [26.34627888] w2: [-23.29721997] bias: [15.63186617] loss: 30.543555721068344\n",
      "Epoch: 4878 / 5000 batch step: 150\n",
      "w1: [26.38082917] w2: [-23.2957256] bias: [15.6761164] loss: 30.52545319865815\n",
      "Epoch: 4878 / 5000 batch step: 180\n",
      "w1: [26.44824214] w2: [-23.27866882] bias: [15.77842179] loss: 30.513839514069183\n",
      "Epoch: 4878 / 5000 batch step: 210\n",
      "w1: [26.48468911] w2: [-23.25831053] bias: [15.83712371] loss: 30.526117093755026\n",
      "Epoch: 4878 / 5000 batch step: 240\n",
      "w1: [26.52319187] w2: [-23.25246096] bias: [15.87850482] loss: 30.54461346625356\n",
      "Epoch: 4878 / 5000 batch step: 270\n",
      "w1: [26.5395133] w2: [-23.2525635] bias: [15.89556182] loss: 30.554352917291943\n",
      "Epoch: 4878 / 5000 batch step: 300\n",
      "w1: [26.51993448] w2: [-23.2587238] bias: [15.85694183] loss: 30.53623596764828\n",
      "Epoch: 4878 / 5000 batch step: 330\n",
      "w1: [26.48403087] w2: [-23.2712735] bias: [15.78619649] loss: 30.516349629567973\n",
      "Epoch: 4878 / 5000 batch step: 360\n",
      "w1: [26.49521833] w2: [-23.24158539] bias: [15.87624129] loss: 30.540105604698297\n",
      "Epoch: 4878 / 5000 batch step: 390\n",
      "w1: [26.46933139] w2: [-23.25344615] bias: [15.84195946] loss: 30.52582479970582\n",
      "Epoch: 4878 / 5000 batch step: 420\n",
      "w1: [26.41974829] w2: [-23.29702704] bias: [15.74668376] loss: 30.513321042192622\n",
      "Epoch: 4878 / 5000 batch step: 450\n",
      "w1: [26.39421076] w2: [-23.31474699] bias: [15.7033086] loss: 30.51978103946094\n",
      "Epoch: 4878 / 5000 batch step: 480\n",
      "w1: [26.37734915] w2: [-23.31615923] bias: [15.67748199] loss: 30.526888943019966\n",
      "Epoch: 4879 / 5000 batch step: 0\n",
      "w1: [26.37113313] w2: [-23.31704986] bias: [15.66459502] loss: 30.53104908728759\n",
      "Epoch: 4879 / 5000 batch step: 30\n",
      "w1: [26.3645468] w2: [-23.31705299] bias: [15.6515222] loss: 30.535788168477133\n",
      "Epoch: 4879 / 5000 batch step: 60\n",
      "w1: [26.34306234] w2: [-23.32405539] bias: [15.61066455] loss: 30.555145877518274\n",
      "Epoch: 4879 / 5000 batch step: 90\n",
      "w1: [26.33648064] w2: [-23.32799196] bias: [15.5953923] loss: 30.563713672651645\n",
      "Epoch: 4879 / 5000 batch step: 120\n",
      "w1: [26.34627894] w2: [-23.29721994] bias: [15.63186613] loss: 30.543555720886925\n",
      "Epoch: 4879 / 5000 batch step: 150\n",
      "w1: [26.38082922] w2: [-23.29572557] bias: [15.67611636] loss: 30.525453198476864\n",
      "Epoch: 4879 / 5000 batch step: 180\n",
      "w1: [26.44824219] w2: [-23.27866879] bias: [15.77842175] loss: 30.513839513923863\n",
      "Epoch: 4879 / 5000 batch step: 210\n",
      "w1: [26.48468917] w2: [-23.2583105] bias: [15.83712367] loss: 30.526117093610463\n",
      "Epoch: 4879 / 5000 batch step: 240\n",
      "w1: [26.52319193] w2: [-23.25246094] bias: [15.87850479] loss: 30.54461346609666\n",
      "Epoch: 4879 / 5000 batch step: 270\n",
      "w1: [26.53951335] w2: [-23.25256347] bias: [15.89556178] loss: 30.55435291714104\n",
      "Epoch: 4879 / 5000 batch step: 300\n",
      "w1: [26.51993453] w2: [-23.25872377] bias: [15.8569418] loss: 30.53623596752689\n",
      "Epoch: 4879 / 5000 batch step: 330\n",
      "w1: [26.48403092] w2: [-23.27127348] bias: [15.78619646] loss: 30.516349629456982\n",
      "Epoch: 4879 / 5000 batch step: 360\n",
      "w1: [26.49521839] w2: [-23.24158536] bias: [15.87624126] loss: 30.540105604590366\n",
      "Epoch: 4879 / 5000 batch step: 390\n",
      "w1: [26.46933144] w2: [-23.25344612] bias: [15.84195942] loss: 30.52582479955736\n",
      "Epoch: 4879 / 5000 batch step: 420\n",
      "w1: [26.41974834] w2: [-23.29702702] bias: [15.74668372] loss: 30.513321042034626\n",
      "Epoch: 4879 / 5000 batch step: 450\n",
      "w1: [26.39421081] w2: [-23.31474696] bias: [15.70330856] loss: 30.519781039323053\n",
      "Epoch: 4879 / 5000 batch step: 480\n",
      "w1: [26.37734921] w2: [-23.3161592] bias: [15.67748196] loss: 30.526888942878813\n",
      "Epoch: 4880 / 5000 batch step: 0\n",
      "w1: [26.37113318] w2: [-23.31704983] bias: [15.66459499] loss: 30.531049087141234\n",
      "Epoch: 4880 / 5000 batch step: 30\n",
      "w1: [26.36454685] w2: [-23.31705296] bias: [15.65152216] loss: 30.535788168312706\n",
      "Epoch: 4880 / 5000 batch step: 60\n",
      "w1: [26.34306239] w2: [-23.32405537] bias: [15.61066451] loss: 30.555145877318317\n",
      "Epoch: 4880 / 5000 batch step: 90\n",
      "w1: [26.3364807] w2: [-23.32799193] bias: [15.59539226] loss: 30.563713672447037\n",
      "Epoch: 4880 / 5000 batch step: 120\n",
      "w1: [26.34627899] w2: [-23.29721991] bias: [15.6318661] loss: 30.543555720705914\n",
      "Epoch: 4880 / 5000 batch step: 150\n",
      "w1: [26.38082927] w2: [-23.29572554] bias: [15.67611633] loss: 30.52545319829598\n",
      "Epoch: 4880 / 5000 batch step: 180\n",
      "w1: [26.44824224] w2: [-23.27866876] bias: [15.77842172] loss: 30.51383951377887\n",
      "Epoch: 4880 / 5000 batch step: 210\n",
      "w1: [26.48468922] w2: [-23.25831047] bias: [15.83712364] loss: 30.52611709346624\n",
      "Epoch: 4880 / 5000 batch step: 240\n",
      "w1: [26.52319198] w2: [-23.25246091] bias: [15.87850475] loss: 30.544613465940124\n",
      "Epoch: 4880 / 5000 batch step: 270\n",
      "w1: [26.5395134] w2: [-23.25256344] bias: [15.89556174] loss: 30.554352916990474\n",
      "Epoch: 4880 / 5000 batch step: 300\n",
      "w1: [26.51993458] w2: [-23.25872374] bias: [15.85694176] loss: 30.536235967405776\n",
      "Epoch: 4880 / 5000 batch step: 330\n",
      "w1: [26.48403098] w2: [-23.27127345] bias: [15.78619642] loss: 30.516349629346234\n",
      "Epoch: 4880 / 5000 batch step: 360\n",
      "w1: [26.49521844] w2: [-23.24158533] bias: [15.87624122] loss: 30.540105604482694\n",
      "Epoch: 4880 / 5000 batch step: 390\n",
      "w1: [26.46933149] w2: [-23.25344609] bias: [15.84195939] loss: 30.525824799409232\n",
      "Epoch: 4880 / 5000 batch step: 420\n",
      "w1: [26.41974839] w2: [-23.29702699] bias: [15.74668369] loss: 30.513321041877\n",
      "Epoch: 4880 / 5000 batch step: 450\n",
      "w1: [26.39421086] w2: [-23.31474693] bias: [15.70330853] loss: 30.519781039185467\n",
      "Epoch: 4880 / 5000 batch step: 480\n",
      "w1: [26.37734926] w2: [-23.31615918] bias: [15.67748192] loss: 30.52688894273797\n",
      "Epoch: 4881 / 5000 batch step: 0\n",
      "w1: [26.37113323] w2: [-23.3170498] bias: [15.66459495] loss: 30.531049086995207\n",
      "Epoch: 4881 / 5000 batch step: 30\n",
      "w1: [26.3645469] w2: [-23.31705293] bias: [15.65152213] loss: 30.53578816814866\n",
      "Epoch: 4881 / 5000 batch step: 60\n",
      "w1: [26.34306244] w2: [-23.32405534] bias: [15.61066447] loss: 30.555145877118814\n",
      "Epoch: 4881 / 5000 batch step: 90\n",
      "w1: [26.33648075] w2: [-23.32799191] bias: [15.59539223] loss: 30.563713672242905\n",
      "Epoch: 4881 / 5000 batch step: 120\n",
      "w1: [26.34627904] w2: [-23.29721989] bias: [15.63186606] loss: 30.543555720525312\n",
      "Epoch: 4881 / 5000 batch step: 150\n",
      "w1: [26.38082932] w2: [-23.29572551] bias: [15.67611629] loss: 30.525453198115514\n",
      "Epoch: 4881 / 5000 batch step: 180\n",
      "w1: [26.44824229] w2: [-23.27866873] bias: [15.77842168] loss: 30.513839513634206\n",
      "Epoch: 4881 / 5000 batch step: 210\n",
      "w1: [26.48468927] w2: [-23.25831044] bias: [15.8371236] loss: 30.526117093322334\n",
      "Epoch: 4881 / 5000 batch step: 240\n",
      "w1: [26.52319203] w2: [-23.25246088] bias: [15.87850471] loss: 30.54461346578394\n",
      "Epoch: 4881 / 5000 batch step: 270\n",
      "w1: [26.53951346] w2: [-23.25256341] bias: [15.89556171] loss: 30.55435291684025\n",
      "Epoch: 4881 / 5000 batch step: 300\n",
      "w1: [26.51993464] w2: [-23.25872371] bias: [15.85694173] loss: 30.536235967284934\n",
      "Epoch: 4881 / 5000 batch step: 330\n",
      "w1: [26.48403103] w2: [-23.27127342] bias: [15.78619639] loss: 30.516349629235744\n",
      "Epoch: 4881 / 5000 batch step: 360\n",
      "w1: [26.49521849] w2: [-23.24158531] bias: [15.87624118] loss: 30.54010560437526\n",
      "Epoch: 4881 / 5000 batch step: 390\n",
      "w1: [26.46933155] w2: [-23.25344606] bias: [15.84195935] loss: 30.525824799261446\n",
      "Epoch: 4881 / 5000 batch step: 420\n",
      "w1: [26.41974844] w2: [-23.29702696] bias: [15.74668365] loss: 30.513321041719717\n",
      "Epoch: 4881 / 5000 batch step: 450\n",
      "w1: [26.39421091] w2: [-23.3147469] bias: [15.70330849] loss: 30.519781039048194\n",
      "Epoch: 4881 / 5000 batch step: 480\n",
      "w1: [26.37734931] w2: [-23.31615915] bias: [15.67748188] loss: 30.52688894259745\n",
      "Epoch: 4882 / 5000 batch step: 0\n",
      "w1: [26.37113328] w2: [-23.31704977] bias: [15.66459491] loss: 30.531049086849517\n",
      "Epoch: 4882 / 5000 batch step: 30\n",
      "w1: [26.36454696] w2: [-23.3170529] bias: [15.65152209] loss: 30.535788167984975\n",
      "Epoch: 4882 / 5000 batch step: 60\n",
      "w1: [26.34306249] w2: [-23.32405531] bias: [15.61066444] loss: 30.555145876919767\n",
      "Epoch: 4882 / 5000 batch step: 90\n",
      "w1: [26.3364808] w2: [-23.32799188] bias: [15.59539219] loss: 30.563713672039228\n",
      "Epoch: 4882 / 5000 batch step: 120\n",
      "w1: [26.34627909] w2: [-23.29721986] bias: [15.63186602] loss: 30.543555720345122\n",
      "Epoch: 4882 / 5000 batch step: 150\n",
      "w1: [26.38082937] w2: [-23.29572548] bias: [15.67611626] loss: 30.525453197935455\n",
      "Epoch: 4882 / 5000 batch step: 180\n",
      "w1: [26.44824234] w2: [-23.2786687] bias: [15.77842165] loss: 30.513839513489877\n",
      "Epoch: 4882 / 5000 batch step: 210\n",
      "w1: [26.48468932] w2: [-23.25831041] bias: [15.83712357] loss: 30.52611709317876\n",
      "Epoch: 4882 / 5000 batch step: 240\n",
      "w1: [26.52319208] w2: [-23.25246085] bias: [15.87850468] loss: 30.54461346562811\n",
      "Epoch: 4882 / 5000 batch step: 270\n",
      "w1: [26.53951351] w2: [-23.25256338] bias: [15.89556167] loss: 30.55435291669037\n",
      "Epoch: 4882 / 5000 batch step: 300\n",
      "w1: [26.51993469] w2: [-23.25872368] bias: [15.85694169] loss: 30.53623596716437\n",
      "Epoch: 4882 / 5000 batch step: 330\n",
      "w1: [26.48403108] w2: [-23.27127339] bias: [15.78619635] loss: 30.516349629125504\n",
      "Epoch: 4882 / 5000 batch step: 360\n",
      "w1: [26.49521854] w2: [-23.24158528] bias: [15.87624115] loss: 30.54010560426807\n",
      "Epoch: 4882 / 5000 batch step: 390\n",
      "w1: [26.4693316] w2: [-23.25344603] bias: [15.84195932] loss: 30.525824799113995\n",
      "Epoch: 4882 / 5000 batch step: 420\n",
      "w1: [26.41974849] w2: [-23.29702693] bias: [15.74668362] loss: 30.513321041562797\n",
      "Epoch: 4882 / 5000 batch step: 450\n",
      "w1: [26.39421096] w2: [-23.31474687] bias: [15.70330845] loss: 30.519781038911237\n",
      "Epoch: 4882 / 5000 batch step: 480\n",
      "w1: [26.37734936] w2: [-23.31615912] bias: [15.67748185] loss: 30.526888942457244\n",
      "Epoch: 4883 / 5000 batch step: 0\n",
      "w1: [26.37113334] w2: [-23.31704974] bias: [15.66459488] loss: 30.531049086704158\n",
      "Epoch: 4883 / 5000 batch step: 30\n",
      "w1: [26.36454701] w2: [-23.31705288] bias: [15.65152205] loss: 30.535788167821664\n",
      "Epoch: 4883 / 5000 batch step: 60\n",
      "w1: [26.34306255] w2: [-23.32405528] bias: [15.6106644] loss: 30.55514587672117\n",
      "Epoch: 4883 / 5000 batch step: 90\n",
      "w1: [26.33648085] w2: [-23.32799185] bias: [15.59539216] loss: 30.563713671836016\n",
      "Epoch: 4883 / 5000 batch step: 120\n",
      "w1: [26.34627914] w2: [-23.29721983] bias: [15.63186599] loss: 30.543555720165344\n",
      "Epoch: 4883 / 5000 batch step: 150\n",
      "w1: [26.38082943] w2: [-23.29572545] bias: [15.67611622] loss: 30.52545319775581\n",
      "Epoch: 4883 / 5000 batch step: 180\n",
      "w1: [26.4482424] w2: [-23.27866868] bias: [15.77842161] loss: 30.51383951334588\n",
      "Epoch: 4883 / 5000 batch step: 210\n",
      "w1: [26.48468937] w2: [-23.25831038] bias: [15.83712353] loss: 30.526117093035513\n",
      "Epoch: 4883 / 5000 batch step: 240\n",
      "w1: [26.52319213] w2: [-23.25246082] bias: [15.87850464] loss: 30.54461346547264\n",
      "Epoch: 4883 / 5000 batch step: 270\n",
      "w1: [26.53951356] w2: [-23.25256335] bias: [15.89556164] loss: 30.554352916540832\n",
      "Epoch: 4883 / 5000 batch step: 300\n",
      "w1: [26.51993474] w2: [-23.25872366] bias: [15.85694165] loss: 30.536235967044078\n",
      "Epoch: 4883 / 5000 batch step: 330\n",
      "w1: [26.48403113] w2: [-23.27127336] bias: [15.78619631] loss: 30.516349629015508\n",
      "Epoch: 4883 / 5000 batch step: 360\n",
      "w1: [26.49521859] w2: [-23.24158525] bias: [15.87624111] loss: 30.540105604161123\n",
      "Epoch: 4883 / 5000 batch step: 390\n",
      "w1: [26.46933165] w2: [-23.253446] bias: [15.84195928] loss: 30.52582479896688\n",
      "Epoch: 4883 / 5000 batch step: 420\n",
      "w1: [26.41974854] w2: [-23.2970269] bias: [15.74668358] loss: 30.513321041406236\n",
      "Epoch: 4883 / 5000 batch step: 450\n",
      "w1: [26.39421102] w2: [-23.31474685] bias: [15.70330842] loss: 30.519781038774582\n",
      "Epoch: 4883 / 5000 batch step: 480\n",
      "w1: [26.37734941] w2: [-23.31615909] bias: [15.67748181] loss: 30.526888942317367\n",
      "Epoch: 4884 / 5000 batch step: 0\n",
      "w1: [26.37113339] w2: [-23.31704972] bias: [15.66459484] loss: 30.53104908655913\n",
      "Epoch: 4884 / 5000 batch step: 30\n",
      "w1: [26.36454706] w2: [-23.31705285] bias: [15.65152202] loss: 30.535788167658733\n",
      "Epoch: 4884 / 5000 batch step: 60\n",
      "w1: [26.3430626] w2: [-23.32405525] bias: [15.61066437] loss: 30.55514587652303\n",
      "Epoch: 4884 / 5000 batch step: 90\n",
      "w1: [26.3364809] w2: [-23.32799182] bias: [15.59539212] loss: 30.563713671633266\n",
      "Epoch: 4884 / 5000 batch step: 120\n",
      "w1: [26.3462792] w2: [-23.2972198] bias: [15.63186595] loss: 30.54355571998597\n",
      "Epoch: 4884 / 5000 batch step: 150\n",
      "w1: [26.38082948] w2: [-23.29572543] bias: [15.67611618] loss: 30.52545319757657\n",
      "Epoch: 4884 / 5000 batch step: 180\n",
      "w1: [26.44824245] w2: [-23.27866865] bias: [15.77842158] loss: 30.5138395132022\n",
      "Epoch: 4884 / 5000 batch step: 210\n",
      "w1: [26.48468943] w2: [-23.25831035] bias: [15.83712349] loss: 30.526117092892594\n",
      "Epoch: 4884 / 5000 batch step: 240\n",
      "w1: [26.52319218] w2: [-23.25246079] bias: [15.87850461] loss: 30.54461346531752\n",
      "Epoch: 4884 / 5000 batch step: 270\n",
      "w1: [26.53951361] w2: [-23.25256332] bias: [15.8955616] loss: 30.55435291639163\n",
      "Epoch: 4884 / 5000 batch step: 300\n",
      "w1: [26.51993479] w2: [-23.25872363] bias: [15.85694162] loss: 30.53623596692406\n",
      "Epoch: 4884 / 5000 batch step: 330\n",
      "w1: [26.48403118] w2: [-23.27127333] bias: [15.78619628] loss: 30.51634962890577\n",
      "Epoch: 4884 / 5000 batch step: 360\n",
      "w1: [26.49521865] w2: [-23.24158522] bias: [15.87624108] loss: 30.540105604054418\n",
      "Epoch: 4884 / 5000 batch step: 390\n",
      "w1: [26.4693317] w2: [-23.25344597] bias: [15.84195924] loss: 30.5258247988201\n",
      "Epoch: 4884 / 5000 batch step: 420\n",
      "w1: [26.4197486] w2: [-23.29702687] bias: [15.74668354] loss: 30.513321041250027\n",
      "Epoch: 4884 / 5000 batch step: 450\n",
      "w1: [26.39421107] w2: [-23.31474682] bias: [15.70330838] loss: 30.519781038638257\n",
      "Epoch: 4884 / 5000 batch step: 480\n",
      "w1: [26.37734946] w2: [-23.31615906] bias: [15.67748178] loss: 30.526888942177802\n",
      "Epoch: 4885 / 5000 batch step: 0\n",
      "w1: [26.37113344] w2: [-23.31704969] bias: [15.66459481] loss: 30.531049086414423\n",
      "Epoch: 4885 / 5000 batch step: 30\n",
      "w1: [26.36454711] w2: [-23.31705282] bias: [15.65152198] loss: 30.535788167496165\n",
      "Epoch: 4885 / 5000 batch step: 60\n",
      "w1: [26.34306265] w2: [-23.32405522] bias: [15.61066433] loss: 30.555145876325337\n",
      "Epoch: 4885 / 5000 batch step: 90\n",
      "w1: [26.33648096] w2: [-23.32799179] bias: [15.59539208] loss: 30.563713671430975\n",
      "Epoch: 4885 / 5000 batch step: 120\n",
      "w1: [26.34627925] w2: [-23.29721977] bias: [15.63186592] loss: 30.54355571980701\n",
      "Epoch: 4885 / 5000 batch step: 150\n",
      "w1: [26.38082953] w2: [-23.2957254] bias: [15.67611615] loss: 30.52545319739773\n",
      "Epoch: 4885 / 5000 batch step: 180\n",
      "w1: [26.4482425] w2: [-23.27866862] bias: [15.77842154] loss: 30.513839513058848\n",
      "Epoch: 4885 / 5000 batch step: 210\n",
      "w1: [26.48468948] w2: [-23.25831033] bias: [15.83712346] loss: 30.52611709275\n",
      "Epoch: 4885 / 5000 batch step: 240\n",
      "w1: [26.52319224] w2: [-23.25246077] bias: [15.87850457] loss: 30.544613465162755\n",
      "Epoch: 4885 / 5000 batch step: 270\n",
      "w1: [26.53951366] w2: [-23.2525633] bias: [15.89556156] loss: 30.554352916242774\n",
      "Epoch: 4885 / 5000 batch step: 300\n",
      "w1: [26.51993484] w2: [-23.2587236] bias: [15.85694158] loss: 30.53623596680432\n",
      "Epoch: 4885 / 5000 batch step: 330\n",
      "w1: [26.48403124] w2: [-23.2712733] bias: [15.78619624] loss: 30.516349628796277\n",
      "Epoch: 4885 / 5000 batch step: 360\n",
      "w1: [26.4952187] w2: [-23.24158519] bias: [15.87624104] loss: 30.540105603947964\n",
      "Epoch: 4885 / 5000 batch step: 390\n",
      "w1: [26.46933175] w2: [-23.25344595] bias: [15.84195921] loss: 30.525824798673646\n",
      "Epoch: 4885 / 5000 batch step: 420\n",
      "w1: [26.41974865] w2: [-23.29702684] bias: [15.74668351] loss: 30.51332104109418\n",
      "Epoch: 4885 / 5000 batch step: 450\n",
      "w1: [26.39421112] w2: [-23.31474679] bias: [15.70330835] loss: 30.51978103850223\n",
      "Epoch: 4885 / 5000 batch step: 480\n",
      "w1: [26.37734952] w2: [-23.31615903] bias: [15.67748174] loss: 30.52688894203856\n",
      "Epoch: 4886 / 5000 batch step: 0\n",
      "w1: [26.37113349] w2: [-23.31704966] bias: [15.66459477] loss: 30.531049086270055\n",
      "Epoch: 4886 / 5000 batch step: 30\n",
      "w1: [26.36454716] w2: [-23.31705279] bias: [15.65152195] loss: 30.53578816733397\n",
      "Epoch: 4886 / 5000 batch step: 60\n",
      "w1: [26.3430627] w2: [-23.32405519] bias: [15.6106643] loss: 30.555145876128094\n",
      "Epoch: 4886 / 5000 batch step: 90\n",
      "w1: [26.33648101] w2: [-23.32799176] bias: [15.59539205] loss: 30.563713671229145\n",
      "Epoch: 4886 / 5000 batch step: 120\n",
      "w1: [26.3462793] w2: [-23.29721974] bias: [15.63186588] loss: 30.543555719628454\n",
      "Epoch: 4886 / 5000 batch step: 150\n",
      "w1: [26.38082958] w2: [-23.29572537] bias: [15.67611611] loss: 30.52545319721931\n",
      "Epoch: 4886 / 5000 batch step: 180\n",
      "w1: [26.44824255] w2: [-23.27866859] bias: [15.7784215] loss: 30.513839512915826\n",
      "Epoch: 4886 / 5000 batch step: 210\n",
      "w1: [26.48468953] w2: [-23.2583103] bias: [15.83712342] loss: 30.526117092607727\n",
      "Epoch: 4886 / 5000 batch step: 240\n",
      "w1: [26.52319229] w2: [-23.25246074] bias: [15.87850454] loss: 30.544613465008343\n",
      "Epoch: 4886 / 5000 batch step: 270\n",
      "w1: [26.53951371] w2: [-23.25256327] bias: [15.89556153] loss: 30.55435291609425\n",
      "Epoch: 4886 / 5000 batch step: 300\n",
      "w1: [26.51993489] w2: [-23.25872357] bias: [15.85694155] loss: 30.53623596668485\n",
      "Epoch: 4886 / 5000 batch step: 330\n",
      "w1: [26.48403129] w2: [-23.27127328] bias: [15.78619621] loss: 30.51634962868704\n",
      "Epoch: 4886 / 5000 batch step: 360\n",
      "w1: [26.49521875] w2: [-23.24158516] bias: [15.87624101] loss: 30.540105603841745\n",
      "Epoch: 4886 / 5000 batch step: 390\n",
      "w1: [26.4693318] w2: [-23.25344592] bias: [15.84195917] loss: 30.525824798527537\n",
      "Epoch: 4886 / 5000 batch step: 420\n",
      "w1: [26.4197487] w2: [-23.29702682] bias: [15.74668347] loss: 30.51332104093868\n",
      "Epoch: 4886 / 5000 batch step: 450\n",
      "w1: [26.39421117] w2: [-23.31474676] bias: [15.70330831] loss: 30.51978103836651\n",
      "Epoch: 4886 / 5000 batch step: 480\n",
      "w1: [26.37734957] w2: [-23.31615901] bias: [15.67748171] loss: 30.52688894189963\n",
      "Epoch: 4887 / 5000 batch step: 0\n",
      "w1: [26.37113354] w2: [-23.31704963] bias: [15.66459474] loss: 30.53104908612601\n",
      "Epoch: 4887 / 5000 batch step: 30\n",
      "w1: [26.36454721] w2: [-23.31705276] bias: [15.65152191] loss: 30.535788167172147\n",
      "Epoch: 4887 / 5000 batch step: 60\n",
      "w1: [26.34306275] w2: [-23.32405517] bias: [15.61066426] loss: 30.555145875931295\n",
      "Epoch: 4887 / 5000 batch step: 90\n",
      "w1: [26.33648106] w2: [-23.32799174] bias: [15.59539201] loss: 30.563713671027777\n",
      "Epoch: 4887 / 5000 batch step: 120\n",
      "w1: [26.34627935] w2: [-23.29721971] bias: [15.63186585] loss: 30.5435557194503\n",
      "Epoch: 4887 / 5000 batch step: 150\n",
      "w1: [26.38082963] w2: [-23.29572534] bias: [15.67611608] loss: 30.52545319704129\n",
      "Epoch: 4887 / 5000 batch step: 180\n",
      "w1: [26.4482426] w2: [-23.27866856] bias: [15.77842147] loss: 30.513839512773124\n",
      "Epoch: 4887 / 5000 batch step: 210\n",
      "w1: [26.48468958] w2: [-23.25831027] bias: [15.83712339] loss: 30.526117092465775\n",
      "Epoch: 4887 / 5000 batch step: 240\n",
      "w1: [26.52319234] w2: [-23.25246071] bias: [15.8785045] loss: 30.544613464854283\n",
      "Epoch: 4887 / 5000 batch step: 270\n",
      "w1: [26.53951376] w2: [-23.25256324] bias: [15.89556149] loss: 30.55435291594607\n",
      "Epoch: 4887 / 5000 batch step: 300\n",
      "w1: [26.51993494] w2: [-23.25872354] bias: [15.85694151] loss: 30.536235966565652\n",
      "Epoch: 4887 / 5000 batch step: 330\n",
      "w1: [26.48403134] w2: [-23.27127325] bias: [15.78619617] loss: 30.51634962857804\n",
      "Epoch: 4887 / 5000 batch step: 360\n",
      "w1: [26.4952188] w2: [-23.24158514] bias: [15.87624097] loss: 30.540105603735768\n",
      "Epoch: 4887 / 5000 batch step: 390\n",
      "w1: [26.46933185] w2: [-23.25344589] bias: [15.84195914] loss: 30.525824798381752\n",
      "Epoch: 4887 / 5000 batch step: 420\n",
      "w1: [26.41974875] w2: [-23.29702679] bias: [15.74668344] loss: 30.513321040783545\n",
      "Epoch: 4887 / 5000 batch step: 450\n",
      "w1: [26.39421122] w2: [-23.31474673] bias: [15.70330827] loss: 30.519781038231105\n",
      "Epoch: 4887 / 5000 batch step: 480\n",
      "w1: [26.37734962] w2: [-23.31615898] bias: [15.67748167] loss: 30.526888941761023\n",
      "Epoch: 4888 / 5000 batch step: 0\n",
      "w1: [26.37113359] w2: [-23.3170496] bias: [15.6645947] loss: 30.531049085982303\n",
      "Epoch: 4888 / 5000 batch step: 30\n",
      "w1: [26.36454726] w2: [-23.31705273] bias: [15.65152188] loss: 30.535788167010686\n",
      "Epoch: 4888 / 5000 batch step: 60\n",
      "w1: [26.3430628] w2: [-23.32405514] bias: [15.61066423] loss: 30.555145875734944\n",
      "Epoch: 4888 / 5000 batch step: 90\n",
      "w1: [26.33648111] w2: [-23.32799171] bias: [15.59539198] loss: 30.563713670826864\n",
      "Epoch: 4888 / 5000 batch step: 120\n",
      "w1: [26.3462794] w2: [-23.29721969] bias: [15.63186581] loss: 30.54355571927256\n",
      "Epoch: 4888 / 5000 batch step: 150\n",
      "w1: [26.38082968] w2: [-23.29572531] bias: [15.67611604] loss: 30.525453196863673\n",
      "Epoch: 4888 / 5000 batch step: 180\n",
      "w1: [26.44824265] w2: [-23.27866854] bias: [15.77842143] loss: 30.513839512630753\n",
      "Epoch: 4888 / 5000 batch step: 210\n",
      "w1: [26.48468963] w2: [-23.25831024] bias: [15.83712335] loss: 30.526117092324153\n",
      "Epoch: 4888 / 5000 batch step: 240\n",
      "w1: [26.52319239] w2: [-23.25246068] bias: [15.87850447] loss: 30.54461346470057\n",
      "Epoch: 4888 / 5000 batch step: 270\n",
      "w1: [26.53951382] w2: [-23.25256321] bias: [15.89556146] loss: 30.55435291579822\n",
      "Epoch: 4888 / 5000 batch step: 300\n",
      "w1: [26.519935] w2: [-23.25872351] bias: [15.85694148] loss: 30.536235966446718\n",
      "Epoch: 4888 / 5000 batch step: 330\n",
      "w1: [26.48403139] w2: [-23.27127322] bias: [15.78619614] loss: 30.516349628469296\n",
      "Epoch: 4888 / 5000 batch step: 360\n",
      "w1: [26.49521885] w2: [-23.24158511] bias: [15.87624094] loss: 30.540105603630032\n",
      "Epoch: 4888 / 5000 batch step: 390\n",
      "w1: [26.46933191] w2: [-23.25344586] bias: [15.8419591] loss: 30.525824798236304\n",
      "Epoch: 4888 / 5000 batch step: 420\n",
      "w1: [26.4197488] w2: [-23.29702676] bias: [15.7466834] loss: 30.513321040628753\n",
      "Epoch: 4888 / 5000 batch step: 450\n",
      "w1: [26.39421127] w2: [-23.3147467] bias: [15.70330824] loss: 30.519781038096003\n",
      "Epoch: 4888 / 5000 batch step: 480\n",
      "w1: [26.37734967] w2: [-23.31615895] bias: [15.67748163] loss: 30.52688894162272\n",
      "Epoch: 4889 / 5000 batch step: 0\n",
      "w1: [26.37113364] w2: [-23.31704957] bias: [15.66459467] loss: 30.531049085838912\n",
      "Epoch: 4889 / 5000 batch step: 30\n",
      "w1: [26.36454732] w2: [-23.31705271] bias: [15.65152184] loss: 30.535788166849596\n",
      "Epoch: 4889 / 5000 batch step: 60\n",
      "w1: [26.34306285] w2: [-23.32405511] bias: [15.61066419] loss: 30.555145875539043\n",
      "Epoch: 4889 / 5000 batch step: 90\n",
      "w1: [26.33648116] w2: [-23.32799168] bias: [15.59539194] loss: 30.563713670626406\n",
      "Epoch: 4889 / 5000 batch step: 120\n",
      "w1: [26.34627945] w2: [-23.29721966] bias: [15.63186577] loss: 30.543555719095224\n",
      "Epoch: 4889 / 5000 batch step: 150\n",
      "w1: [26.38082974] w2: [-23.29572528] bias: [15.67611601] loss: 30.525453196686467\n",
      "Epoch: 4889 / 5000 batch step: 180\n",
      "w1: [26.4482427] w2: [-23.27866851] bias: [15.7784214] loss: 30.5138395124887\n",
      "Epoch: 4889 / 5000 batch step: 210\n",
      "w1: [26.48468968] w2: [-23.25831021] bias: [15.83712332] loss: 30.52611709218285\n",
      "Epoch: 4889 / 5000 batch step: 240\n",
      "w1: [26.52319244] w2: [-23.25246065] bias: [15.87850443] loss: 30.544613464547208\n",
      "Epoch: 4889 / 5000 batch step: 270\n",
      "w1: [26.53951387] w2: [-23.25256318] bias: [15.89556142] loss: 30.554352915650714\n",
      "Epoch: 4889 / 5000 batch step: 300\n",
      "w1: [26.51993505] w2: [-23.25872349] bias: [15.85694144] loss: 30.536235966328064\n",
      "Epoch: 4889 / 5000 batch step: 330\n",
      "w1: [26.48403144] w2: [-23.27127319] bias: [15.7861961] loss: 30.516349628360803\n",
      "Epoch: 4889 / 5000 batch step: 360\n",
      "w1: [26.4952189] w2: [-23.24158508] bias: [15.8762409] loss: 30.540105603524538\n",
      "Epoch: 4889 / 5000 batch step: 390\n",
      "w1: [26.46933196] w2: [-23.25344583] bias: [15.84195907] loss: 30.525824798091183\n",
      "Epoch: 4889 / 5000 batch step: 420\n",
      "w1: [26.41974885] w2: [-23.29702673] bias: [15.74668337] loss: 30.51332104047432\n",
      "Epoch: 4889 / 5000 batch step: 450\n",
      "w1: [26.39421132] w2: [-23.31474668] bias: [15.7033082] loss: 30.51978103796121\n",
      "Epoch: 4889 / 5000 batch step: 480\n",
      "w1: [26.37734972] w2: [-23.31615892] bias: [15.6774816] loss: 30.52688894148474\n",
      "Epoch: 4890 / 5000 batch step: 0\n",
      "w1: [26.3711337] w2: [-23.31704955] bias: [15.66459463] loss: 30.531049085695848\n",
      "Epoch: 4890 / 5000 batch step: 30\n",
      "w1: [26.36454737] w2: [-23.31705268] bias: [15.65152181] loss: 30.535788166688867\n",
      "Epoch: 4890 / 5000 batch step: 60\n",
      "w1: [26.34306291] w2: [-23.32405508] bias: [15.61066415] loss: 30.55514587534359\n",
      "Epoch: 4890 / 5000 batch step: 90\n",
      "w1: [26.33648121] w2: [-23.32799165] bias: [15.59539191] loss: 30.563713670426402\n",
      "Epoch: 4890 / 5000 batch step: 120\n",
      "w1: [26.3462795] w2: [-23.29721963] bias: [15.63186574] loss: 30.543555718918288\n",
      "Epoch: 4890 / 5000 batch step: 150\n",
      "w1: [26.38082979] w2: [-23.29572526] bias: [15.67611597] loss: 30.525453196509652\n",
      "Epoch: 4890 / 5000 batch step: 180\n",
      "w1: [26.44824275] w2: [-23.27866848] bias: [15.77842136] loss: 30.513839512346983\n",
      "Epoch: 4890 / 5000 batch step: 210\n",
      "w1: [26.48468973] w2: [-23.25831019] bias: [15.83712328] loss: 30.526117092041865\n",
      "Epoch: 4890 / 5000 batch step: 240\n",
      "w1: [26.52319249] w2: [-23.25246062] bias: [15.87850439] loss: 30.544613464394192\n",
      "Epoch: 4890 / 5000 batch step: 270\n",
      "w1: [26.53951392] w2: [-23.25256315] bias: [15.89556139] loss: 30.554352915503536\n",
      "Epoch: 4890 / 5000 batch step: 300\n",
      "w1: [26.5199351] w2: [-23.25872346] bias: [15.85694141] loss: 30.536235966209674\n",
      "Epoch: 4890 / 5000 batch step: 330\n",
      "w1: [26.48403149] w2: [-23.27127316] bias: [15.78619607] loss: 30.51634962825255\n",
      "Epoch: 4890 / 5000 batch step: 360\n",
      "w1: [26.49521895] w2: [-23.24158505] bias: [15.87624086] loss: 30.54010560341928\n",
      "Epoch: 4890 / 5000 batch step: 390\n",
      "w1: [26.46933201] w2: [-23.25344581] bias: [15.84195903] loss: 30.52582479794639\n",
      "Epoch: 4890 / 5000 batch step: 420\n",
      "w1: [26.4197489] w2: [-23.2970267] bias: [15.74668333] loss: 30.51332104032023\n",
      "Epoch: 4890 / 5000 batch step: 450\n",
      "w1: [26.39421137] w2: [-23.31474665] bias: [15.70330817] loss: 30.519781037826732\n",
      "Epoch: 4890 / 5000 batch step: 480\n",
      "w1: [26.37734977] w2: [-23.31615889] bias: [15.67748156] loss: 30.526888941347064\n",
      "Epoch: 4891 / 5000 batch step: 0\n",
      "w1: [26.37113375] w2: [-23.31704952] bias: [15.66459459] loss: 30.531049085553114\n",
      "Epoch: 4891 / 5000 batch step: 30\n",
      "w1: [26.36454742] w2: [-23.31705265] bias: [15.65152177] loss: 30.53578816652851\n",
      "Epoch: 4891 / 5000 batch step: 60\n",
      "w1: [26.34306296] w2: [-23.32405505] bias: [15.61066412] loss: 30.55514587514858\n",
      "Epoch: 4891 / 5000 batch step: 90\n",
      "w1: [26.33648126] w2: [-23.32799162] bias: [15.59539187] loss: 30.563713670226868\n",
      "Epoch: 4891 / 5000 batch step: 120\n",
      "w1: [26.34627955] w2: [-23.2972196] bias: [15.6318657] loss: 30.543555718741747\n",
      "Epoch: 4891 / 5000 batch step: 150\n",
      "w1: [26.38082984] w2: [-23.29572523] bias: [15.67611594] loss: 30.52545319633325\n",
      "Epoch: 4891 / 5000 batch step: 180\n",
      "w1: [26.44824281] w2: [-23.27866845] bias: [15.77842133] loss: 30.51383951220557\n",
      "Epoch: 4891 / 5000 batch step: 210\n",
      "w1: [26.48468978] w2: [-23.25831016] bias: [15.83712325] loss: 30.526117091901202\n",
      "Epoch: 4891 / 5000 batch step: 240\n",
      "w1: [26.52319254] w2: [-23.2524606] bias: [15.87850436] loss: 30.54461346424153\n",
      "Epoch: 4891 / 5000 batch step: 270\n",
      "w1: [26.53951397] w2: [-23.25256313] bias: [15.89556135] loss: 30.554352915356702\n",
      "Epoch: 4891 / 5000 batch step: 300\n",
      "w1: [26.51993515] w2: [-23.25872343] bias: [15.85694137] loss: 30.536235966091557\n",
      "Epoch: 4891 / 5000 batch step: 330\n",
      "w1: [26.48403154] w2: [-23.27127314] bias: [15.78619603] loss: 30.516349628144543\n",
      "Epoch: 4891 / 5000 batch step: 360\n",
      "w1: [26.495219] w2: [-23.24158502] bias: [15.87624083] loss: 30.54010560331427\n",
      "Epoch: 4891 / 5000 batch step: 390\n",
      "w1: [26.46933206] w2: [-23.25344578] bias: [15.841959] loss: 30.525824797801935\n",
      "Epoch: 4891 / 5000 batch step: 420\n",
      "w1: [26.41974895] w2: [-23.29702668] bias: [15.7466833] loss: 30.513321040166492\n",
      "Epoch: 4891 / 5000 batch step: 450\n",
      "w1: [26.39421142] w2: [-23.31474662] bias: [15.70330813] loss: 30.51978103769255\n",
      "Epoch: 4891 / 5000 batch step: 480\n",
      "w1: [26.37734982] w2: [-23.31615887] bias: [15.67748153] loss: 30.526888941209716\n",
      "Epoch: 4892 / 5000 batch step: 0\n",
      "w1: [26.3711338] w2: [-23.31704949] bias: [15.66459456] loss: 30.5310490854107\n",
      "Epoch: 4892 / 5000 batch step: 30\n",
      "w1: [26.36454747] w2: [-23.31705262] bias: [15.65152173] loss: 30.53578816636852\n",
      "Epoch: 4892 / 5000 batch step: 60\n",
      "w1: [26.34306301] w2: [-23.32405503] bias: [15.61066408] loss: 30.555145874954015\n",
      "Epoch: 4892 / 5000 batch step: 90\n",
      "w1: [26.33648131] w2: [-23.3279916] bias: [15.59539184] loss: 30.56371367002777\n",
      "Epoch: 4892 / 5000 batch step: 120\n",
      "w1: [26.3462796] w2: [-23.29721957] bias: [15.63186567] loss: 30.543555718565617\n",
      "Epoch: 4892 / 5000 batch step: 150\n",
      "w1: [26.38082989] w2: [-23.2957252] bias: [15.6761159] loss: 30.525453196157248\n",
      "Epoch: 4892 / 5000 batch step: 180\n",
      "w1: [26.44824286] w2: [-23.27866842] bias: [15.77842129] loss: 30.51383951206449\n",
      "Epoch: 4892 / 5000 batch step: 210\n",
      "w1: [26.48468983] w2: [-23.25831013] bias: [15.83712321] loss: 30.526117091760863\n",
      "Epoch: 4892 / 5000 batch step: 240\n",
      "w1: [26.52319259] w2: [-23.25246057] bias: [15.87850432] loss: 30.54461346408921\n",
      "Epoch: 4892 / 5000 batch step: 270\n",
      "w1: [26.53951402] w2: [-23.2525631] bias: [15.89556132] loss: 30.55435291521019\n",
      "Epoch: 4892 / 5000 batch step: 300\n",
      "w1: [26.5199352] w2: [-23.2587234] bias: [15.85694134] loss: 30.5362359659737\n",
      "Epoch: 4892 / 5000 batch step: 330\n",
      "w1: [26.48403159] w2: [-23.27127311] bias: [15.786196] loss: 30.51634962803678\n",
      "Epoch: 4892 / 5000 batch step: 360\n",
      "w1: [26.49521905] w2: [-23.24158499] bias: [15.87624079] loss: 30.54010560320949\n",
      "Epoch: 4892 / 5000 batch step: 390\n",
      "w1: [26.46933211] w2: [-23.25344575] bias: [15.84195896] loss: 30.5258247976578\n",
      "Epoch: 4892 / 5000 batch step: 420\n",
      "w1: [26.419749] w2: [-23.29702665] bias: [15.74668326] loss: 30.513321040013107\n",
      "Epoch: 4892 / 5000 batch step: 450\n",
      "w1: [26.39421148] w2: [-23.31474659] bias: [15.7033081] loss: 30.519781037558673\n",
      "Epoch: 4892 / 5000 batch step: 480\n",
      "w1: [26.37734987] w2: [-23.31615884] bias: [15.67748149] loss: 30.52688894107267\n",
      "Epoch: 4893 / 5000 batch step: 0\n",
      "w1: [26.37113385] w2: [-23.31704946] bias: [15.66459452] loss: 30.531049085268613\n",
      "Epoch: 4893 / 5000 batch step: 30\n",
      "w1: [26.36454752] w2: [-23.31705259] bias: [15.6515217] loss: 30.535788166208885\n",
      "Epoch: 4893 / 5000 batch step: 60\n",
      "w1: [26.34306306] w2: [-23.324055] bias: [15.61066405] loss: 30.555145874759887\n",
      "Epoch: 4893 / 5000 batch step: 90\n",
      "w1: [26.33648136] w2: [-23.32799157] bias: [15.5953918] loss: 30.56371366982913\n",
      "Epoch: 4893 / 5000 batch step: 120\n",
      "w1: [26.34627966] w2: [-23.29721955] bias: [15.63186563] loss: 30.543555718389882\n",
      "Epoch: 4893 / 5000 batch step: 150\n",
      "w1: [26.38082994] w2: [-23.29572517] bias: [15.67611587] loss: 30.525453195981637\n",
      "Epoch: 4893 / 5000 batch step: 180\n",
      "w1: [26.44824291] w2: [-23.2786684] bias: [15.77842126] loss: 30.513839511923734\n",
      "Epoch: 4893 / 5000 batch step: 210\n",
      "w1: [26.48468988] w2: [-23.2583101] bias: [15.83712318] loss: 30.52611709162084\n",
      "Epoch: 4893 / 5000 batch step: 240\n",
      "w1: [26.52319264] w2: [-23.25246054] bias: [15.87850429] loss: 30.544613463937242\n",
      "Epoch: 4893 / 5000 batch step: 270\n",
      "w1: [26.53951407] w2: [-23.25256307] bias: [15.89556128] loss: 30.554352915064015\n",
      "Epoch: 4893 / 5000 batch step: 300\n",
      "w1: [26.51993525] w2: [-23.25872337] bias: [15.8569413] loss: 30.536235965856125\n",
      "Epoch: 4893 / 5000 batch step: 330\n",
      "w1: [26.48403164] w2: [-23.27127308] bias: [15.78619596] loss: 30.51634962792927\n",
      "Epoch: 4893 / 5000 batch step: 360\n",
      "w1: [26.4952191] w2: [-23.24158497] bias: [15.87624076] loss: 30.54010560310496\n",
      "Epoch: 4893 / 5000 batch step: 390\n",
      "w1: [26.46933216] w2: [-23.25344572] bias: [15.84195893] loss: 30.525824797514\n",
      "Epoch: 4893 / 5000 batch step: 420\n",
      "w1: [26.41974905] w2: [-23.29702662] bias: [15.74668323] loss: 30.513321039860077\n",
      "Epoch: 4893 / 5000 batch step: 450\n",
      "w1: [26.39421153] w2: [-23.31474657] bias: [15.70330806] loss: 30.5197810374251\n",
      "Epoch: 4893 / 5000 batch step: 480\n",
      "w1: [26.37734992] w2: [-23.31615881] bias: [15.67748146] loss: 30.526888940935937\n",
      "Epoch: 4894 / 5000 batch step: 0\n",
      "w1: [26.3711339] w2: [-23.31704943] bias: [15.66459449] loss: 30.531049085126842\n",
      "Epoch: 4894 / 5000 batch step: 30\n",
      "w1: [26.36454757] w2: [-23.31705257] bias: [15.65152166] loss: 30.535788166049617\n",
      "Epoch: 4894 / 5000 batch step: 60\n",
      "w1: [26.34306311] w2: [-23.32405497] bias: [15.61066401] loss: 30.5551458745662\n",
      "Epoch: 4894 / 5000 batch step: 90\n",
      "w1: [26.33648141] w2: [-23.32799154] bias: [15.59539177] loss: 30.56371366963095\n",
      "Epoch: 4894 / 5000 batch step: 120\n",
      "w1: [26.34627971] w2: [-23.29721952] bias: [15.6318656] loss: 30.543555718214552\n",
      "Epoch: 4894 / 5000 batch step: 150\n",
      "w1: [26.38082999] w2: [-23.29572514] bias: [15.67611583] loss: 30.52545319580643\n",
      "Epoch: 4894 / 5000 batch step: 180\n",
      "w1: [26.44824296] w2: [-23.27866837] bias: [15.77842122] loss: 30.51383951178329\n",
      "Epoch: 4894 / 5000 batch step: 210\n",
      "w1: [26.48468994] w2: [-23.25831007] bias: [15.83712314] loss: 30.52611709148114\n",
      "Epoch: 4894 / 5000 batch step: 240\n",
      "w1: [26.52319269] w2: [-23.25246051] bias: [15.87850425] loss: 30.544613463785616\n",
      "Epoch: 4894 / 5000 batch step: 270\n",
      "w1: [26.53951412] w2: [-23.25256304] bias: [15.89556125] loss: 30.554352914918177\n",
      "Epoch: 4894 / 5000 batch step: 300\n",
      "w1: [26.5199353] w2: [-23.25872335] bias: [15.85694127] loss: 30.53623596573881\n",
      "Epoch: 4894 / 5000 batch step: 330\n",
      "w1: [26.48403169] w2: [-23.27127305] bias: [15.78619593] loss: 30.516349627821995\n",
      "Epoch: 4894 / 5000 batch step: 360\n",
      "w1: [26.49521916] w2: [-23.24158494] bias: [15.87624073] loss: 30.540105603000658\n",
      "Epoch: 4894 / 5000 batch step: 390\n",
      "w1: [26.46933221] w2: [-23.25344569] bias: [15.84195889] loss: 30.52582479737052\n",
      "Epoch: 4894 / 5000 batch step: 420\n",
      "w1: [26.41974911] w2: [-23.29702659] bias: [15.74668319] loss: 30.51332103970738\n",
      "Epoch: 4894 / 5000 batch step: 450\n",
      "w1: [26.39421158] w2: [-23.31474654] bias: [15.70330803] loss: 30.519781037291835\n",
      "Epoch: 4894 / 5000 batch step: 480\n",
      "w1: [26.37734997] w2: [-23.31615878] bias: [15.67748142] loss: 30.526888940799513\n",
      "Epoch: 4895 / 5000 batch step: 0\n",
      "w1: [26.37113395] w2: [-23.31704941] bias: [15.66459445] loss: 30.53104908498541\n",
      "Epoch: 4895 / 5000 batch step: 30\n",
      "w1: [26.36454762] w2: [-23.31705254] bias: [15.65152163] loss: 30.53578816589071\n",
      "Epoch: 4895 / 5000 batch step: 60\n",
      "w1: [26.34306316] w2: [-23.32405494] bias: [15.61066398] loss: 30.555145874372958\n",
      "Epoch: 4895 / 5000 batch step: 90\n",
      "w1: [26.33648147] w2: [-23.32799151] bias: [15.59539173] loss: 30.563713669433206\n",
      "Epoch: 4895 / 5000 batch step: 120\n",
      "w1: [26.34627976] w2: [-23.29721949] bias: [15.63186556] loss: 30.54355571803962\n",
      "Epoch: 4895 / 5000 batch step: 150\n",
      "w1: [26.38083004] w2: [-23.29572512] bias: [15.6761158] loss: 30.525453195631624\n",
      "Epoch: 4895 / 5000 batch step: 180\n",
      "w1: [26.44824301] w2: [-23.27866834] bias: [15.77842119] loss: 30.51383951164317\n",
      "Epoch: 4895 / 5000 batch step: 210\n",
      "w1: [26.48468999] w2: [-23.25831005] bias: [15.83712311] loss: 30.526117091341753\n",
      "Epoch: 4895 / 5000 batch step: 240\n",
      "w1: [26.52319274] w2: [-23.25246049] bias: [15.87850422] loss: 30.54461346363433\n",
      "Epoch: 4895 / 5000 batch step: 270\n",
      "w1: [26.53951417] w2: [-23.25256302] bias: [15.89556121] loss: 30.55435291477267\n",
      "Epoch: 4895 / 5000 batch step: 300\n",
      "w1: [26.51993535] w2: [-23.25872332] bias: [15.85694123] loss: 30.536235965621756\n",
      "Epoch: 4895 / 5000 batch step: 330\n",
      "w1: [26.48403174] w2: [-23.27127302] bias: [15.78619589] loss: 30.516349627714977\n",
      "Epoch: 4895 / 5000 batch step: 360\n",
      "w1: [26.49521921] w2: [-23.24158491] bias: [15.87624069] loss: 30.540105602896592\n",
      "Epoch: 4895 / 5000 batch step: 390\n",
      "w1: [26.46933226] w2: [-23.25344567] bias: [15.84195886] loss: 30.52582479722737\n",
      "Epoch: 4895 / 5000 batch step: 420\n",
      "w1: [26.41974916] w2: [-23.29702657] bias: [15.74668316] loss: 30.513321039555038\n",
      "Epoch: 4895 / 5000 batch step: 450\n",
      "w1: [26.39421163] w2: [-23.31474651] bias: [15.70330799] loss: 30.51978103715887\n",
      "Epoch: 4895 / 5000 batch step: 480\n",
      "w1: [26.37735002] w2: [-23.31615875] bias: [15.67748139] loss: 30.526888940663405\n",
      "Epoch: 4896 / 5000 batch step: 0\n",
      "w1: [26.371134] w2: [-23.31704938] bias: [15.66459442] loss: 30.531049084844284\n",
      "Epoch: 4896 / 5000 batch step: 30\n",
      "w1: [26.36454767] w2: [-23.31705251] bias: [15.6515216] loss: 30.535788165732164\n",
      "Epoch: 4896 / 5000 batch step: 60\n",
      "w1: [26.34306321] w2: [-23.32405492] bias: [15.61066395] loss: 30.55514587418016\n",
      "Epoch: 4896 / 5000 batch step: 90\n",
      "w1: [26.33648152] w2: [-23.32799148] bias: [15.5953917] loss: 30.563713669235927\n",
      "Epoch: 4896 / 5000 batch step: 120\n",
      "w1: [26.34627981] w2: [-23.29721946] bias: [15.63186553] loss: 30.543555717865082\n",
      "Epoch: 4896 / 5000 batch step: 150\n",
      "w1: [26.38083009] w2: [-23.29572509] bias: [15.67611576] loss: 30.525453195457214\n",
      "Epoch: 4896 / 5000 batch step: 180\n",
      "w1: [26.44824306] w2: [-23.27866831] bias: [15.77842115] loss: 30.513839511503363\n",
      "Epoch: 4896 / 5000 batch step: 210\n",
      "w1: [26.48469004] w2: [-23.25831002] bias: [15.83712307] loss: 30.526117091202682\n",
      "Epoch: 4896 / 5000 batch step: 240\n",
      "w1: [26.52319279] w2: [-23.25246046] bias: [15.87850418] loss: 30.544613463483394\n",
      "Epoch: 4896 / 5000 batch step: 270\n",
      "w1: [26.53951422] w2: [-23.25256299] bias: [15.89556118] loss: 30.554352914627486\n",
      "Epoch: 4896 / 5000 batch step: 300\n",
      "w1: [26.5199354] w2: [-23.25872329] bias: [15.8569412] loss: 30.536235965504975\n",
      "Epoch: 4896 / 5000 batch step: 330\n",
      "w1: [26.48403179] w2: [-23.271273] bias: [15.78619586] loss: 30.51634962760819\n",
      "Epoch: 4896 / 5000 batch step: 360\n",
      "w1: [26.49521926] w2: [-23.24158488] bias: [15.87624066] loss: 30.54010560279276\n",
      "Epoch: 4896 / 5000 batch step: 390\n",
      "w1: [26.46933231] w2: [-23.25344564] bias: [15.84195882] loss: 30.525824797084542\n",
      "Epoch: 4896 / 5000 batch step: 420\n",
      "w1: [26.41974921] w2: [-23.29702654] bias: [15.74668312] loss: 30.513321039403042\n",
      "Epoch: 4896 / 5000 batch step: 450\n",
      "w1: [26.39421168] w2: [-23.31474648] bias: [15.70330796] loss: 30.519781037026213\n",
      "Epoch: 4896 / 5000 batch step: 480\n",
      "w1: [26.37735007] w2: [-23.31615873] bias: [15.67748135] loss: 30.526888940527602\n",
      "Epoch: 4897 / 5000 batch step: 0\n",
      "w1: [26.37113405] w2: [-23.31704935] bias: [15.66459438] loss: 30.53104908470349\n",
      "Epoch: 4897 / 5000 batch step: 30\n",
      "w1: [26.36454772] w2: [-23.31705248] bias: [15.65152156] loss: 30.535788165573983\n",
      "Epoch: 4897 / 5000 batch step: 60\n",
      "w1: [26.34306326] w2: [-23.32405489] bias: [15.61066391] loss: 30.55514587398779\n",
      "Epoch: 4897 / 5000 batch step: 90\n",
      "w1: [26.33648157] w2: [-23.32799146] bias: [15.59539166] loss: 30.56371366903909\n",
      "Epoch: 4897 / 5000 batch step: 120\n",
      "w1: [26.34627986] w2: [-23.29721944] bias: [15.6318655] loss: 30.543555717690946\n",
      "Epoch: 4897 / 5000 batch step: 150\n",
      "w1: [26.38083014] w2: [-23.29572506] bias: [15.67611573] loss: 30.525453195283205\n",
      "Epoch: 4897 / 5000 batch step: 180\n",
      "w1: [26.44824311] w2: [-23.27866828] bias: [15.77842112] loss: 30.513839511363884\n",
      "Epoch: 4897 / 5000 batch step: 210\n",
      "w1: [26.48469009] w2: [-23.25830999] bias: [15.83712304] loss: 30.526117091063927\n",
      "Epoch: 4897 / 5000 batch step: 240\n",
      "w1: [26.52319284] w2: [-23.25246043] bias: [15.87850415] loss: 30.544613463332798\n",
      "Epoch: 4897 / 5000 batch step: 270\n",
      "w1: [26.53951427] w2: [-23.25256296] bias: [15.89556114] loss: 30.554352914482642\n",
      "Epoch: 4897 / 5000 batch step: 300\n",
      "w1: [26.51993545] w2: [-23.25872326] bias: [15.85694116] loss: 30.536235965388464\n",
      "Epoch: 4897 / 5000 batch step: 330\n",
      "w1: [26.48403184] w2: [-23.27127297] bias: [15.78619582] loss: 30.516349627501654\n",
      "Epoch: 4897 / 5000 batch step: 360\n",
      "w1: [26.49521931] w2: [-23.24158486] bias: [15.87624062] loss: 30.540105602689177\n",
      "Epoch: 4897 / 5000 batch step: 390\n",
      "w1: [26.46933236] w2: [-23.25344561] bias: [15.84195879] loss: 30.52582479694204\n",
      "Epoch: 4897 / 5000 batch step: 420\n",
      "w1: [26.41974926] w2: [-23.29702651] bias: [15.74668309] loss: 30.513321039251398\n",
      "Epoch: 4897 / 5000 batch step: 450\n",
      "w1: [26.39421173] w2: [-23.31474646] bias: [15.70330792] loss: 30.519781036893853\n",
      "Epoch: 4897 / 5000 batch step: 480\n",
      "w1: [26.37735012] w2: [-23.3161587] bias: [15.67748132] loss: 30.526888940392112\n",
      "Epoch: 4898 / 5000 batch step: 0\n",
      "w1: [26.3711341] w2: [-23.31704932] bias: [15.66459435] loss: 30.531049084563\n",
      "Epoch: 4898 / 5000 batch step: 30\n",
      "w1: [26.36454777] w2: [-23.31705246] bias: [15.65152153] loss: 30.535788165416157\n",
      "Epoch: 4898 / 5000 batch step: 60\n",
      "w1: [26.34306331] w2: [-23.32405486] bias: [15.61066388] loss: 30.555145873795862\n",
      "Epoch: 4898 / 5000 batch step: 90\n",
      "w1: [26.33648162] w2: [-23.32799143] bias: [15.59539163] loss: 30.563713668842695\n",
      "Epoch: 4898 / 5000 batch step: 120\n",
      "w1: [26.34627991] w2: [-23.29721941] bias: [15.63186546] loss: 30.543555717517204\n",
      "Epoch: 4898 / 5000 batch step: 150\n",
      "w1: [26.38083019] w2: [-23.29572503] bias: [15.67611569] loss: 30.525453195109588\n",
      "Epoch: 4898 / 5000 batch step: 180\n",
      "w1: [26.44824316] w2: [-23.27866826] bias: [15.77842108] loss: 30.51383951122471\n",
      "Epoch: 4898 / 5000 batch step: 210\n",
      "w1: [26.48469014] w2: [-23.25830996] bias: [15.837123] loss: 30.526117090925492\n",
      "Epoch: 4898 / 5000 batch step: 240\n",
      "w1: [26.52319289] w2: [-23.2524604] bias: [15.87850411] loss: 30.54461346318255\n",
      "Epoch: 4898 / 5000 batch step: 270\n",
      "w1: [26.53951432] w2: [-23.25256293] bias: [15.89556111] loss: 30.554352914338125\n",
      "Epoch: 4898 / 5000 batch step: 300\n",
      "w1: [26.5199355] w2: [-23.25872324] bias: [15.85694113] loss: 30.53623596527221\n",
      "Epoch: 4898 / 5000 batch step: 330\n",
      "w1: [26.48403189] w2: [-23.27127294] bias: [15.78619579] loss: 30.516349627395357\n",
      "Epoch: 4898 / 5000 batch step: 360\n",
      "w1: [26.49521936] w2: [-23.24158483] bias: [15.87624059] loss: 30.540105602585818\n",
      "Epoch: 4898 / 5000 batch step: 390\n",
      "w1: [26.46933241] w2: [-23.25344558] bias: [15.84195875] loss: 30.525824796799863\n",
      "Epoch: 4898 / 5000 batch step: 420\n",
      "w1: [26.41974931] w2: [-23.29702648] bias: [15.74668305] loss: 30.513321039100095\n",
      "Epoch: 4898 / 5000 batch step: 450\n",
      "w1: [26.39421178] w2: [-23.31474643] bias: [15.70330789] loss: 30.51978103676179\n",
      "Epoch: 4898 / 5000 batch step: 480\n",
      "w1: [26.37735017] w2: [-23.31615867] bias: [15.67748128] loss: 30.52688894025692\n",
      "Epoch: 4899 / 5000 batch step: 0\n",
      "w1: [26.37113415] w2: [-23.3170493] bias: [15.66459432] loss: 30.531049084422847\n",
      "Epoch: 4899 / 5000 batch step: 30\n",
      "w1: [26.36454782] w2: [-23.31705243] bias: [15.65152149] loss: 30.535788165258694\n",
      "Epoch: 4899 / 5000 batch step: 60\n",
      "w1: [26.34306336] w2: [-23.32405483] bias: [15.61066384] loss: 30.555145873604374\n",
      "Epoch: 4899 / 5000 batch step: 90\n",
      "w1: [26.33648167] w2: [-23.3279914] bias: [15.59539159] loss: 30.563713668646756\n",
      "Epoch: 4899 / 5000 batch step: 120\n",
      "w1: [26.34627996] w2: [-23.29721938] bias: [15.63186543] loss: 30.543555717343853\n",
      "Epoch: 4899 / 5000 batch step: 150\n",
      "w1: [26.38083024] w2: [-23.29572501] bias: [15.67611566] loss: 30.525453194936365\n",
      "Epoch: 4899 / 5000 batch step: 180\n",
      "w1: [26.44824321] w2: [-23.27866823] bias: [15.77842105] loss: 30.513839511085852\n",
      "Epoch: 4899 / 5000 batch step: 210\n",
      "w1: [26.48469019] w2: [-23.25830994] bias: [15.83712297] loss: 30.52611709078737\n",
      "Epoch: 4899 / 5000 batch step: 240\n",
      "w1: [26.52319294] w2: [-23.25246038] bias: [15.87850408] loss: 30.544613463032636\n",
      "Epoch: 4899 / 5000 batch step: 270\n",
      "w1: [26.53951437] w2: [-23.25256291] bias: [15.89556107] loss: 30.554352914193935\n",
      "Epoch: 4899 / 5000 batch step: 300\n",
      "w1: [26.51993555] w2: [-23.25872321] bias: [15.85694109] loss: 30.536235965156223\n",
      "Epoch: 4899 / 5000 batch step: 330\n",
      "w1: [26.48403194] w2: [-23.27127291] bias: [15.78619575] loss: 30.516349627289298\n",
      "Epoch: 4899 / 5000 batch step: 360\n",
      "w1: [26.49521941] w2: [-23.2415848] bias: [15.87624055] loss: 30.540105602482704\n",
      "Epoch: 4899 / 5000 batch step: 390\n",
      "w1: [26.46933246] w2: [-23.25344556] bias: [15.84195872] loss: 30.525824796658014\n",
      "Epoch: 4899 / 5000 batch step: 420\n",
      "w1: [26.41974936] w2: [-23.29702646] bias: [15.74668302] loss: 30.513321038949133\n",
      "Epoch: 4899 / 5000 batch step: 450\n",
      "w1: [26.39421183] w2: [-23.3147464] bias: [15.70330785] loss: 30.519781036630032\n",
      "Epoch: 4899 / 5000 batch step: 480\n",
      "w1: [26.37735022] w2: [-23.31615864] bias: [15.67748125] loss: 30.52688894012205\n",
      "Epoch: 4900 / 5000 batch step: 0\n",
      "w1: [26.3711342] w2: [-23.31704927] bias: [15.66459428] loss: 30.531049084283005\n",
      "Epoch: 4900 / 5000 batch step: 30\n",
      "w1: [26.36454787] w2: [-23.3170524] bias: [15.65152146] loss: 30.535788165101586\n",
      "Epoch: 4900 / 5000 batch step: 60\n",
      "w1: [26.34306341] w2: [-23.32405481] bias: [15.61066381] loss: 30.555145873413313\n",
      "Epoch: 4900 / 5000 batch step: 90\n",
      "w1: [26.33648172] w2: [-23.32799137] bias: [15.59539156] loss: 30.563713668451257\n",
      "Epoch: 4900 / 5000 batch step: 120\n",
      "w1: [26.34628001] w2: [-23.29721935] bias: [15.63186539] loss: 30.5435557171709\n",
      "Epoch: 4900 / 5000 batch step: 150\n",
      "w1: [26.38083029] w2: [-23.29572498] bias: [15.67611563] loss: 30.525453194763536\n",
      "Epoch: 4900 / 5000 batch step: 180\n",
      "w1: [26.44824326] w2: [-23.2786682] bias: [15.77842102] loss: 30.513839510947328\n",
      "Epoch: 4900 / 5000 batch step: 210\n",
      "w1: [26.48469024] w2: [-23.25830991] bias: [15.83712293] loss: 30.52611709064956\n",
      "Epoch: 4900 / 5000 batch step: 240\n",
      "w1: [26.52319299] w2: [-23.25246035] bias: [15.87850405] loss: 30.54461346288307\n",
      "Epoch: 4900 / 5000 batch step: 270\n",
      "w1: [26.53951442] w2: [-23.25256288] bias: [15.89556104] loss: 30.554352914050074\n",
      "Epoch: 4900 / 5000 batch step: 300\n",
      "w1: [26.5199356] w2: [-23.25872318] bias: [15.85694106] loss: 30.5362359650405\n",
      "Epoch: 4900 / 5000 batch step: 330\n",
      "w1: [26.48403199] w2: [-23.27127289] bias: [15.78619572] loss: 30.516349627183484\n",
      "Epoch: 4900 / 5000 batch step: 360\n",
      "w1: [26.49521946] w2: [-23.24158477] bias: [15.87624052] loss: 30.540105602379818\n",
      "Epoch: 4900 / 5000 batch step: 390\n",
      "w1: [26.46933251] w2: [-23.25344553] bias: [15.84195868] loss: 30.52582479651648\n",
      "Epoch: 4900 / 5000 batch step: 420\n",
      "w1: [26.4197494] w2: [-23.29702643] bias: [15.74668298] loss: 30.513321038798512\n",
      "Epoch: 4900 / 5000 batch step: 450\n",
      "w1: [26.39421188] w2: [-23.31474637] bias: [15.70330782] loss: 30.519781036498575\n",
      "Epoch: 4900 / 5000 batch step: 480\n",
      "w1: [26.37735027] w2: [-23.31615862] bias: [15.67748122] loss: 30.526888939987472\n",
      "Epoch: 4901 / 5000 batch step: 0\n",
      "w1: [26.37113425] w2: [-23.31704924] bias: [15.66459425] loss: 30.53104908414348\n",
      "Epoch: 4901 / 5000 batch step: 30\n",
      "w1: [26.36454792] w2: [-23.31705237] bias: [15.65152142] loss: 30.535788164944837\n",
      "Epoch: 4901 / 5000 batch step: 60\n",
      "w1: [26.34306346] w2: [-23.32405478] bias: [15.61066377] loss: 30.555145873222695\n",
      "Epoch: 4901 / 5000 batch step: 90\n",
      "w1: [26.33648177] w2: [-23.32799135] bias: [15.59539153] loss: 30.563713668256206\n",
      "Epoch: 4901 / 5000 batch step: 120\n",
      "w1: [26.34628006] w2: [-23.29721933] bias: [15.63186536] loss: 30.543555716998338\n",
      "Epoch: 4901 / 5000 batch step: 150\n",
      "w1: [26.38083034] w2: [-23.29572495] bias: [15.67611559] loss: 30.5254531945911\n",
      "Epoch: 4901 / 5000 batch step: 180\n",
      "w1: [26.44824331] w2: [-23.27866817] bias: [15.77842098] loss: 30.513839510809106\n",
      "Epoch: 4901 / 5000 batch step: 210\n",
      "w1: [26.48469029] w2: [-23.25830988] bias: [15.8371229] loss: 30.526117090512063\n",
      "Epoch: 4901 / 5000 batch step: 240\n",
      "w1: [26.52319304] w2: [-23.25246032] bias: [15.87850401] loss: 30.544613462733842\n",
      "Epoch: 4901 / 5000 batch step: 270\n",
      "w1: [26.53951447] w2: [-23.25256285] bias: [15.895561] loss: 30.55435291390654\n",
      "Epoch: 4901 / 5000 batch step: 300\n",
      "w1: [26.51993565] w2: [-23.25872315] bias: [15.85694102] loss: 30.53623596492504\n",
      "Epoch: 4901 / 5000 batch step: 330\n",
      "w1: [26.48403204] w2: [-23.27127286] bias: [15.78619568] loss: 30.516349627077908\n",
      "Epoch: 4901 / 5000 batch step: 360\n",
      "w1: [26.49521951] w2: [-23.24158475] bias: [15.87624048] loss: 30.540105602277162\n",
      "Epoch: 4901 / 5000 batch step: 390\n",
      "w1: [26.46933256] w2: [-23.2534455] bias: [15.84195865] loss: 30.525824796375275\n",
      "Epoch: 4901 / 5000 batch step: 420\n",
      "w1: [26.41974945] w2: [-23.2970264] bias: [15.74668295] loss: 30.51332103864824\n",
      "Epoch: 4901 / 5000 batch step: 450\n",
      "w1: [26.39421193] w2: [-23.31474635] bias: [15.70330779] loss: 30.519781036367412\n",
      "Epoch: 4901 / 5000 batch step: 480\n",
      "w1: [26.37735032] w2: [-23.31615859] bias: [15.67748118] loss: 30.526888939853215\n",
      "Epoch: 4902 / 5000 batch step: 0\n",
      "w1: [26.3711343] w2: [-23.31704922] bias: [15.66459421] loss: 30.53104908400427\n",
      "Epoch: 4902 / 5000 batch step: 30\n",
      "w1: [26.36454797] w2: [-23.31705235] bias: [15.65152139] loss: 30.53578816478844\n",
      "Epoch: 4902 / 5000 batch step: 60\n",
      "w1: [26.34306351] w2: [-23.32405475] bias: [15.61066374] loss: 30.555145873032505\n",
      "Epoch: 4902 / 5000 batch step: 90\n",
      "w1: [26.33648182] w2: [-23.32799132] bias: [15.59539149] loss: 30.563713668061588\n",
      "Epoch: 4902 / 5000 batch step: 120\n",
      "w1: [26.34628011] w2: [-23.2972193] bias: [15.63186532] loss: 30.543555716826166\n",
      "Epoch: 4902 / 5000 batch step: 150\n",
      "w1: [26.38083039] w2: [-23.29572493] bias: [15.67611556] loss: 30.525453194419054\n",
      "Epoch: 4902 / 5000 batch step: 180\n",
      "w1: [26.44824336] w2: [-23.27866815] bias: [15.77842095] loss: 30.513839510671193\n",
      "Epoch: 4902 / 5000 batch step: 210\n",
      "w1: [26.48469033] w2: [-23.25830985] bias: [15.83712286] loss: 30.526117090374882\n",
      "Epoch: 4902 / 5000 batch step: 240\n",
      "w1: [26.52319309] w2: [-23.25246029] bias: [15.87850398] loss: 30.54461346258495\n",
      "Epoch: 4902 / 5000 batch step: 270\n",
      "w1: [26.53951452] w2: [-23.25256282] bias: [15.89556097] loss: 30.554352913763328\n",
      "Epoch: 4902 / 5000 batch step: 300\n",
      "w1: [26.5199357] w2: [-23.25872313] bias: [15.85694099] loss: 30.53623596480984\n",
      "Epoch: 4902 / 5000 batch step: 330\n",
      "w1: [26.48403209] w2: [-23.27127283] bias: [15.78619565] loss: 30.516349626972577\n",
      "Epoch: 4902 / 5000 batch step: 360\n",
      "w1: [26.49521955] w2: [-23.24158472] bias: [15.87624045] loss: 30.54010560217474\n",
      "Epoch: 4902 / 5000 batch step: 390\n",
      "w1: [26.46933261] w2: [-23.25344547] bias: [15.84195862] loss: 30.52582479623439\n",
      "Epoch: 4902 / 5000 batch step: 420\n",
      "w1: [26.4197495] w2: [-23.29702637] bias: [15.74668291] loss: 30.513321038498304\n",
      "Epoch: 4902 / 5000 batch step: 450\n",
      "w1: [26.39421197] w2: [-23.31474632] bias: [15.70330775] loss: 30.519781036236555\n",
      "Epoch: 4902 / 5000 batch step: 480\n",
      "w1: [26.37735037] w2: [-23.31615856] bias: [15.67748115] loss: 30.526888939719257\n",
      "Epoch: 4903 / 5000 batch step: 0\n",
      "w1: [26.37113435] w2: [-23.31704919] bias: [15.66459418] loss: 30.53104908386538\n",
      "Epoch: 4903 / 5000 batch step: 30\n",
      "w1: [26.36454802] w2: [-23.31705232] bias: [15.65152135] loss: 30.5357881646324\n",
      "Epoch: 4903 / 5000 batch step: 60\n",
      "w1: [26.34306356] w2: [-23.32405472] bias: [15.6106637] loss: 30.555145872842754\n",
      "Epoch: 4903 / 5000 batch step: 90\n",
      "w1: [26.33648186] w2: [-23.32799129] bias: [15.59539146] loss: 30.563713667867425\n",
      "Epoch: 4903 / 5000 batch step: 120\n",
      "w1: [26.34628016] w2: [-23.29721927] bias: [15.63186529] loss: 30.543555716654392\n",
      "Epoch: 4903 / 5000 batch step: 150\n",
      "w1: [26.38083044] w2: [-23.2957249] bias: [15.67611552] loss: 30.525453194247405\n",
      "Epoch: 4903 / 5000 batch step: 180\n",
      "w1: [26.44824341] w2: [-23.27866812] bias: [15.77842091] loss: 30.5138395105336\n",
      "Epoch: 4903 / 5000 batch step: 210\n",
      "w1: [26.48469038] w2: [-23.25830983] bias: [15.83712283] loss: 30.526117090238014\n",
      "Epoch: 4903 / 5000 batch step: 240\n",
      "w1: [26.52319314] w2: [-23.25246027] bias: [15.87850394] loss: 30.544613462436395\n",
      "Epoch: 4903 / 5000 batch step: 270\n",
      "w1: [26.53951457] w2: [-23.2525628] bias: [15.89556094] loss: 30.55435291362045\n",
      "Epoch: 4903 / 5000 batch step: 300\n",
      "w1: [26.51993575] w2: [-23.2587231] bias: [15.85694096] loss: 30.536235964694907\n",
      "Epoch: 4903 / 5000 batch step: 330\n",
      "w1: [26.48403214] w2: [-23.27127281] bias: [15.78619562] loss: 30.51634962686748\n",
      "Epoch: 4903 / 5000 batch step: 360\n",
      "w1: [26.4952196] w2: [-23.24158469] bias: [15.87624042] loss: 30.54010560207256\n",
      "Epoch: 4903 / 5000 batch step: 390\n",
      "w1: [26.46933266] w2: [-23.25344545] bias: [15.84195858] loss: 30.52582479609382\n",
      "Epoch: 4903 / 5000 batch step: 420\n",
      "w1: [26.41974955] w2: [-23.29702635] bias: [15.74668288] loss: 30.51332103834871\n",
      "Epoch: 4903 / 5000 batch step: 450\n",
      "w1: [26.39421202] w2: [-23.31474629] bias: [15.70330772] loss: 30.519781036105993\n",
      "Epoch: 4903 / 5000 batch step: 480\n",
      "w1: [26.37735042] w2: [-23.31615854] bias: [15.67748111] loss: 30.5268889395856\n",
      "Epoch: 4904 / 5000 batch step: 0\n",
      "w1: [26.3711344] w2: [-23.31704916] bias: [15.66459414] loss: 30.531049083726806\n",
      "Epoch: 4904 / 5000 batch step: 30\n",
      "w1: [26.36454807] w2: [-23.31705229] bias: [15.65152132] loss: 30.535788164476724\n",
      "Epoch: 4904 / 5000 batch step: 60\n",
      "w1: [26.34306361] w2: [-23.3240547] bias: [15.61066367] loss: 30.555145872653434\n",
      "Epoch: 4904 / 5000 batch step: 90\n",
      "w1: [26.33648191] w2: [-23.32799127] bias: [15.59539142] loss: 30.5637136676737\n",
      "Epoch: 4904 / 5000 batch step: 120\n",
      "w1: [26.3462802] w2: [-23.29721925] bias: [15.63186525] loss: 30.543555716483006\n",
      "Epoch: 4904 / 5000 batch step: 150\n",
      "w1: [26.38083049] w2: [-23.29572487] bias: [15.67611549] loss: 30.525453194076142\n",
      "Epoch: 4904 / 5000 batch step: 180\n",
      "w1: [26.44824346] w2: [-23.27866809] bias: [15.77842088] loss: 30.51383951039632\n",
      "Epoch: 4904 / 5000 batch step: 210\n",
      "w1: [26.48469043] w2: [-23.2583098] bias: [15.8371228] loss: 30.526117090101454\n",
      "Epoch: 4904 / 5000 batch step: 240\n",
      "w1: [26.52319319] w2: [-23.25246024] bias: [15.87850391] loss: 30.544613462288186\n",
      "Epoch: 4904 / 5000 batch step: 270\n",
      "w1: [26.53951462] w2: [-23.25256277] bias: [15.8955609] loss: 30.554352913477892\n",
      "Epoch: 4904 / 5000 batch step: 300\n",
      "w1: [26.5199358] w2: [-23.25872307] bias: [15.85694092] loss: 30.53623596458024\n",
      "Epoch: 4904 / 5000 batch step: 330\n",
      "w1: [26.48403219] w2: [-23.27127278] bias: [15.78619558] loss: 30.516349626762622\n",
      "Epoch: 4904 / 5000 batch step: 360\n",
      "w1: [26.49521965] w2: [-23.24158466] bias: [15.87624038] loss: 30.540105601970613\n",
      "Epoch: 4904 / 5000 batch step: 390\n",
      "w1: [26.46933271] w2: [-23.25344542] bias: [15.84195855] loss: 30.52582479595357\n",
      "Epoch: 4904 / 5000 batch step: 420\n",
      "w1: [26.4197496] w2: [-23.29702632] bias: [15.74668285] loss: 30.513321038199454\n",
      "Epoch: 4904 / 5000 batch step: 450\n",
      "w1: [26.39421207] w2: [-23.31474626] bias: [15.70330768] loss: 30.519781035975722\n",
      "Epoch: 4904 / 5000 batch step: 480\n",
      "w1: [26.37735047] w2: [-23.31615851] bias: [15.67748108] loss: 30.52688893945225\n",
      "Epoch: 4905 / 5000 batch step: 0\n",
      "w1: [26.37113445] w2: [-23.31704913] bias: [15.66459411] loss: 30.53104908358855\n",
      "Epoch: 4905 / 5000 batch step: 30\n",
      "w1: [26.36454812] w2: [-23.31705227] bias: [15.65152129] loss: 30.53578816432139\n",
      "Epoch: 4905 / 5000 batch step: 60\n",
      "w1: [26.34306366] w2: [-23.32405467] bias: [15.61066364] loss: 30.555145872464536\n",
      "Epoch: 4905 / 5000 batch step: 90\n",
      "w1: [26.33648196] w2: [-23.32799124] bias: [15.59539139] loss: 30.56371366748041\n",
      "Epoch: 4905 / 5000 batch step: 120\n",
      "w1: [26.34628025] w2: [-23.29721922] bias: [15.63186522] loss: 30.543555716312007\n",
      "Epoch: 4905 / 5000 batch step: 150\n",
      "w1: [26.38083054] w2: [-23.29572484] bias: [15.67611545] loss: 30.52545319390527\n",
      "Epoch: 4905 / 5000 batch step: 180\n",
      "w1: [26.44824351] w2: [-23.27866807] bias: [15.77842084] loss: 30.513839510259356\n",
      "Epoch: 4905 / 5000 batch step: 210\n",
      "w1: [26.48469048] w2: [-23.25830977] bias: [15.83712276] loss: 30.526117089965204\n",
      "Epoch: 4905 / 5000 batch step: 240\n",
      "w1: [26.52319324] w2: [-23.25246021] bias: [15.87850387] loss: 30.544613462140312\n",
      "Epoch: 4905 / 5000 batch step: 270\n",
      "w1: [26.53951467] w2: [-23.25256274] bias: [15.89556087] loss: 30.554352913335656\n",
      "Epoch: 4905 / 5000 batch step: 300\n",
      "w1: [26.51993585] w2: [-23.25872305] bias: [15.85694089] loss: 30.536235964465824\n",
      "Epoch: 4905 / 5000 batch step: 330\n",
      "w1: [26.48403224] w2: [-23.27127275] bias: [15.78619555] loss: 30.51634962665801\n",
      "Epoch: 4905 / 5000 batch step: 360\n",
      "w1: [26.4952197] w2: [-23.24158464] bias: [15.87624035] loss: 30.54010560186889\n",
      "Epoch: 4905 / 5000 batch step: 390\n",
      "w1: [26.46933276] w2: [-23.25344539] bias: [15.84195851] loss: 30.525824795813644\n",
      "Epoch: 4905 / 5000 batch step: 420\n",
      "w1: [26.41974965] w2: [-23.29702629] bias: [15.74668281] loss: 30.51332103805054\n",
      "Epoch: 4905 / 5000 batch step: 450\n",
      "w1: [26.39421212] w2: [-23.31474624] bias: [15.70330765] loss: 30.519781035845757\n",
      "Epoch: 4905 / 5000 batch step: 480\n",
      "w1: [26.37735052] w2: [-23.31615848] bias: [15.67748104] loss: 30.526888939319203\n",
      "Epoch: 4906 / 5000 batch step: 0\n",
      "w1: [26.37113449] w2: [-23.31704911] bias: [15.66459408] loss: 30.531049083450608\n",
      "Epoch: 4906 / 5000 batch step: 30\n",
      "w1: [26.36454817] w2: [-23.31705224] bias: [15.65152125] loss: 30.535788164166412\n",
      "Epoch: 4906 / 5000 batch step: 60\n",
      "w1: [26.34306371] w2: [-23.32405464] bias: [15.6106636] loss: 30.55514587227607\n",
      "Epoch: 4906 / 5000 batch step: 90\n",
      "w1: [26.33648201] w2: [-23.32799121] bias: [15.59539136] loss: 30.56371366728757\n",
      "Epoch: 4906 / 5000 batch step: 120\n",
      "w1: [26.3462803] w2: [-23.29721919] bias: [15.63186519] loss: 30.5435557161414\n",
      "Epoch: 4906 / 5000 batch step: 150\n",
      "w1: [26.38083059] w2: [-23.29572482] bias: [15.67611542] loss: 30.525453193734787\n",
      "Epoch: 4906 / 5000 batch step: 180\n",
      "w1: [26.44824355] w2: [-23.27866804] bias: [15.77842081] loss: 30.513839510122697\n",
      "Epoch: 4906 / 5000 batch step: 210\n",
      "w1: [26.48469053] w2: [-23.25830975] bias: [15.83712273] loss: 30.526117089829267\n",
      "Epoch: 4906 / 5000 batch step: 240\n",
      "w1: [26.52319329] w2: [-23.25246018] bias: [15.87850384] loss: 30.544613461992768\n",
      "Epoch: 4906 / 5000 batch step: 270\n",
      "w1: [26.53951472] w2: [-23.25256272] bias: [15.89556083] loss: 30.55435291319375\n",
      "Epoch: 4906 / 5000 batch step: 300\n",
      "w1: [26.5199359] w2: [-23.25872302] bias: [15.85694085] loss: 30.536235964351665\n",
      "Epoch: 4906 / 5000 batch step: 330\n",
      "w1: [26.48403229] w2: [-23.27127272] bias: [15.78619551] loss: 30.51634962655363\n",
      "Epoch: 4906 / 5000 batch step: 360\n",
      "w1: [26.49521975] w2: [-23.24158461] bias: [15.87624031] loss: 30.540105601767404\n",
      "Epoch: 4906 / 5000 batch step: 390\n",
      "w1: [26.46933281] w2: [-23.25344537] bias: [15.84195848] loss: 30.525824795674033\n",
      "Epoch: 4906 / 5000 batch step: 420\n",
      "w1: [26.4197497] w2: [-23.29702627] bias: [15.74668278] loss: 30.513321037901974\n",
      "Epoch: 4906 / 5000 batch step: 450\n",
      "w1: [26.39421217] w2: [-23.31474621] bias: [15.70330761] loss: 30.51978103571608\n",
      "Epoch: 4906 / 5000 batch step: 480\n",
      "w1: [26.37735057] w2: [-23.31615845] bias: [15.67748101] loss: 30.526888939186456\n",
      "Epoch: 4907 / 5000 batch step: 0\n",
      "w1: [26.37113454] w2: [-23.31704908] bias: [15.66459404] loss: 30.531049083312976\n",
      "Epoch: 4907 / 5000 batch step: 30\n",
      "w1: [26.36454822] w2: [-23.31705221] bias: [15.65152122] loss: 30.535788164011787\n",
      "Epoch: 4907 / 5000 batch step: 60\n",
      "w1: [26.34306375] w2: [-23.32405462] bias: [15.61066357] loss: 30.555145872088037\n",
      "Epoch: 4907 / 5000 batch step: 90\n",
      "w1: [26.33648206] w2: [-23.32799118] bias: [15.59539132] loss: 30.563713667095165\n",
      "Epoch: 4907 / 5000 batch step: 120\n",
      "w1: [26.34628035] w2: [-23.29721916] bias: [15.63186515] loss: 30.543555715971177\n",
      "Epoch: 4907 / 5000 batch step: 150\n",
      "w1: [26.38083064] w2: [-23.29572479] bias: [15.67611539] loss: 30.52545319356469\n",
      "Epoch: 4907 / 5000 batch step: 180\n",
      "w1: [26.4482436] w2: [-23.27866801] bias: [15.77842078] loss: 30.51383950998635\n",
      "Epoch: 4907 / 5000 batch step: 210\n",
      "w1: [26.48469058] w2: [-23.25830972] bias: [15.83712269] loss: 30.52611708969364\n",
      "Epoch: 4907 / 5000 batch step: 240\n",
      "w1: [26.52319334] w2: [-23.25246016] bias: [15.87850381] loss: 30.544613461845568\n",
      "Epoch: 4907 / 5000 batch step: 270\n",
      "w1: [26.53951477] w2: [-23.25256269] bias: [15.8955608] loss: 30.554352913052163\n",
      "Epoch: 4907 / 5000 batch step: 300\n",
      "w1: [26.51993595] w2: [-23.25872299] bias: [15.85694082] loss: 30.536235964237772\n",
      "Epoch: 4907 / 5000 batch step: 330\n",
      "w1: [26.48403234] w2: [-23.2712727] bias: [15.78619548] loss: 30.51634962644949\n",
      "Epoch: 4907 / 5000 batch step: 360\n",
      "w1: [26.4952198] w2: [-23.24158458] bias: [15.87624028] loss: 30.54010560166615\n",
      "Epoch: 4907 / 5000 batch step: 390\n",
      "w1: [26.46933286] w2: [-23.25344534] bias: [15.84195845] loss: 30.525824795534742\n",
      "Epoch: 4907 / 5000 batch step: 420\n",
      "w1: [26.41974975] w2: [-23.29702624] bias: [15.74668274] loss: 30.51332103775374\n",
      "Epoch: 4907 / 5000 batch step: 450\n",
      "w1: [26.39421222] w2: [-23.31474618] bias: [15.70330758] loss: 30.5197810355867\n",
      "Epoch: 4907 / 5000 batch step: 480\n",
      "w1: [26.37735062] w2: [-23.31615843] bias: [15.67748098] loss: 30.526888939054015\n",
      "Epoch: 4908 / 5000 batch step: 0\n",
      "w1: [26.37113459] w2: [-23.31704905] bias: [15.66459401] loss: 30.53104908317566\n",
      "Epoch: 4908 / 5000 batch step: 30\n",
      "w1: [26.36454826] w2: [-23.31705218] bias: [15.65152118] loss: 30.535788163857518\n",
      "Epoch: 4908 / 5000 batch step: 60\n",
      "w1: [26.3430638] w2: [-23.32405459] bias: [15.61066353] loss: 30.55514587190043\n",
      "Epoch: 4908 / 5000 batch step: 90\n",
      "w1: [26.33648211] w2: [-23.32799116] bias: [15.59539129] loss: 30.563713666903194\n",
      "Epoch: 4908 / 5000 batch step: 120\n",
      "w1: [26.3462804] w2: [-23.29721914] bias: [15.63186512] loss: 30.54355571580135\n",
      "Epoch: 4908 / 5000 batch step: 150\n",
      "w1: [26.38083068] w2: [-23.29572476] bias: [15.67611535] loss: 30.525453193394977\n",
      "Epoch: 4908 / 5000 batch step: 180\n",
      "w1: [26.44824365] w2: [-23.27866799] bias: [15.77842074] loss: 30.513839509850314\n",
      "Epoch: 4908 / 5000 batch step: 210\n",
      "w1: [26.48469063] w2: [-23.25830969] bias: [15.83712266] loss: 30.526117089558316\n",
      "Epoch: 4908 / 5000 batch step: 240\n",
      "w1: [26.52319339] w2: [-23.25246013] bias: [15.87850377] loss: 30.5446134616987\n",
      "Epoch: 4908 / 5000 batch step: 270\n",
      "w1: [26.53951481] w2: [-23.25256266] bias: [15.89556077] loss: 30.554352912910897\n",
      "Epoch: 4908 / 5000 batch step: 300\n",
      "w1: [26.51993599] w2: [-23.25872296] bias: [15.85694079] loss: 30.536235964124145\n",
      "Epoch: 4908 / 5000 batch step: 330\n",
      "w1: [26.48403239] w2: [-23.27127267] bias: [15.78619545] loss: 30.516349626345583\n",
      "Epoch: 4908 / 5000 batch step: 360\n",
      "w1: [26.49521985] w2: [-23.24158456] bias: [15.87624025] loss: 30.540105601565113\n",
      "Epoch: 4908 / 5000 batch step: 390\n",
      "w1: [26.4693329] w2: [-23.25344531] bias: [15.84195841] loss: 30.525824795395764\n",
      "Epoch: 4908 / 5000 batch step: 420\n",
      "w1: [26.4197498] w2: [-23.29702621] bias: [15.74668271] loss: 30.513321037605838\n",
      "Epoch: 4908 / 5000 batch step: 450\n",
      "w1: [26.39421227] w2: [-23.31474616] bias: [15.70330755] loss: 30.519781035457616\n",
      "Epoch: 4908 / 5000 batch step: 480\n",
      "w1: [26.37735067] w2: [-23.3161584] bias: [15.67748094] loss: 30.52688893892187\n",
      "Epoch: 4909 / 5000 batch step: 0\n",
      "w1: [26.37113464] w2: [-23.31704903] bias: [15.66459397] loss: 30.53104908303865\n",
      "Epoch: 4909 / 5000 batch step: 30\n",
      "w1: [26.36454831] w2: [-23.31705216] bias: [15.65152115] loss: 30.535788163703597\n",
      "Epoch: 4909 / 5000 batch step: 60\n",
      "w1: [26.34306385] w2: [-23.32405456] bias: [15.6106635] loss: 30.555145871713247\n",
      "Epoch: 4909 / 5000 batch step: 90\n",
      "w1: [26.33648216] w2: [-23.32799113] bias: [15.59539125] loss: 30.56371366671166\n",
      "Epoch: 4909 / 5000 batch step: 120\n",
      "w1: [26.34628045] w2: [-23.29721911] bias: [15.63186509] loss: 30.543555715631904\n",
      "Epoch: 4909 / 5000 batch step: 150\n",
      "w1: [26.38083073] w2: [-23.29572474] bias: [15.67611532] loss: 30.525453193225655\n",
      "Epoch: 4909 / 5000 batch step: 180\n",
      "w1: [26.4482437] w2: [-23.27866796] bias: [15.77842071] loss: 30.513839509714593\n",
      "Epoch: 4909 / 5000 batch step: 210\n",
      "w1: [26.48469068] w2: [-23.25830967] bias: [15.83712263] loss: 30.526117089423302\n",
      "Epoch: 4909 / 5000 batch step: 240\n",
      "w1: [26.52319344] w2: [-23.2524601] bias: [15.87850374] loss: 30.54461346155216\n",
      "Epoch: 4909 / 5000 batch step: 270\n",
      "w1: [26.53951486] w2: [-23.25256263] bias: [15.89556073] loss: 30.55435291276995\n",
      "Epoch: 4909 / 5000 batch step: 300\n",
      "w1: [26.51993604] w2: [-23.25872294] bias: [15.85694075] loss: 30.536235964010768\n",
      "Epoch: 4909 / 5000 batch step: 330\n",
      "w1: [26.48403244] w2: [-23.27127264] bias: [15.78619541] loss: 30.51634962624191\n",
      "Epoch: 4909 / 5000 batch step: 360\n",
      "w1: [26.4952199] w2: [-23.24158453] bias: [15.87624021] loss: 30.540105601464315\n",
      "Epoch: 4909 / 5000 batch step: 390\n",
      "w1: [26.46933295] w2: [-23.25344529] bias: [15.84195838] loss: 30.525824795257105\n",
      "Epoch: 4909 / 5000 batch step: 420\n",
      "w1: [26.41974985] w2: [-23.29702619] bias: [15.74668268] loss: 30.513321037458272\n",
      "Epoch: 4909 / 5000 batch step: 450\n",
      "w1: [26.39421232] w2: [-23.31474613] bias: [15.70330751] loss: 30.51978103532882\n",
      "Epoch: 4909 / 5000 batch step: 480\n",
      "w1: [26.37735071] w2: [-23.31615837] bias: [15.67748091] loss: 30.526888938790034\n",
      "Epoch: 4910 / 5000 batch step: 0\n",
      "w1: [26.37113469] w2: [-23.317049] bias: [15.66459394] loss: 30.53104908290196\n",
      "Epoch: 4910 / 5000 batch step: 30\n",
      "w1: [26.36454836] w2: [-23.31705213] bias: [15.65152112] loss: 30.535788163550027\n",
      "Epoch: 4910 / 5000 batch step: 60\n",
      "w1: [26.3430639] w2: [-23.32405453] bias: [15.61066347] loss: 30.55514587152649\n",
      "Epoch: 4910 / 5000 batch step: 90\n",
      "w1: [26.33648221] w2: [-23.3279911] bias: [15.59539122] loss: 30.56371366652056\n",
      "Epoch: 4910 / 5000 batch step: 120\n",
      "w1: [26.3462805] w2: [-23.29721908] bias: [15.63186505] loss: 30.543555715462837\n",
      "Epoch: 4910 / 5000 batch step: 150\n",
      "w1: [26.38083078] w2: [-23.29572471] bias: [15.67611529] loss: 30.52545319305672\n",
      "Epoch: 4910 / 5000 batch step: 180\n",
      "w1: [26.44824375] w2: [-23.27866793] bias: [15.77842068] loss: 30.513839509579174\n",
      "Epoch: 4910 / 5000 batch step: 210\n",
      "w1: [26.48469073] w2: [-23.25830964] bias: [15.83712259] loss: 30.526117089288594\n",
      "Epoch: 4910 / 5000 batch step: 240\n",
      "w1: [26.52319349] w2: [-23.25246008] bias: [15.87850371] loss: 30.54461346140596\n",
      "Epoch: 4910 / 5000 batch step: 270\n",
      "w1: [26.53951491] w2: [-23.25256261] bias: [15.8955607] loss: 30.554352912629327\n",
      "Epoch: 4910 / 5000 batch step: 300\n",
      "w1: [26.51993609] w2: [-23.25872291] bias: [15.85694072] loss: 30.536235963897642\n",
      "Epoch: 4910 / 5000 batch step: 330\n",
      "w1: [26.48403249] w2: [-23.27127262] bias: [15.78619538] loss: 30.516349626138478\n",
      "Epoch: 4910 / 5000 batch step: 360\n",
      "w1: [26.49521995] w2: [-23.2415845] bias: [15.87624018] loss: 30.540105601363752\n",
      "Epoch: 4910 / 5000 batch step: 390\n",
      "w1: [26.469333] w2: [-23.25344526] bias: [15.84195835] loss: 30.525824795118762\n",
      "Epoch: 4910 / 5000 batch step: 420\n",
      "w1: [26.4197499] w2: [-23.29702616] bias: [15.74668264] loss: 30.513321037311048\n",
      "Epoch: 4910 / 5000 batch step: 450\n",
      "w1: [26.39421237] w2: [-23.3147461] bias: [15.70330748] loss: 30.51978103520032\n",
      "Epoch: 4910 / 5000 batch step: 480\n",
      "w1: [26.37735076] w2: [-23.31615835] bias: [15.67748088] loss: 30.52688893865849\n",
      "Epoch: 4911 / 5000 batch step: 0\n",
      "w1: [26.37113474] w2: [-23.31704897] bias: [15.66459391] loss: 30.531049082765577\n",
      "Epoch: 4911 / 5000 batch step: 30\n",
      "w1: [26.36454841] w2: [-23.3170521] bias: [15.65152108] loss: 30.535788163396806\n",
      "Epoch: 4911 / 5000 batch step: 60\n",
      "w1: [26.34306395] w2: [-23.32405451] bias: [15.61066343] loss: 30.55514587134016\n",
      "Epoch: 4911 / 5000 batch step: 90\n",
      "w1: [26.33648226] w2: [-23.32799108] bias: [15.59539119] loss: 30.563713666329903\n",
      "Epoch: 4911 / 5000 batch step: 120\n",
      "w1: [26.34628055] w2: [-23.29721906] bias: [15.63186502] loss: 30.543555715294165\n",
      "Epoch: 4911 / 5000 batch step: 150\n",
      "w1: [26.38083083] w2: [-23.29572468] bias: [15.67611525] loss: 30.525453192888172\n",
      "Epoch: 4911 / 5000 batch step: 180\n",
      "w1: [26.4482438] w2: [-23.2786679] bias: [15.77842064] loss: 30.51383950944406\n",
      "Epoch: 4911 / 5000 batch step: 210\n",
      "w1: [26.48469078] w2: [-23.25830961] bias: [15.83712256] loss: 30.526117089154194\n",
      "Epoch: 4911 / 5000 batch step: 240\n",
      "w1: [26.52319353] w2: [-23.25246005] bias: [15.87850367] loss: 30.544613461260084\n",
      "Epoch: 4911 / 5000 batch step: 270\n",
      "w1: [26.53951496] w2: [-23.25256258] bias: [15.89556066] loss: 30.55435291248903\n",
      "Epoch: 4911 / 5000 batch step: 300\n",
      "w1: [26.51993614] w2: [-23.25872288] bias: [15.85694068] loss: 30.536235963784783\n",
      "Epoch: 4911 / 5000 batch step: 330\n",
      "w1: [26.48403253] w2: [-23.27127259] bias: [15.78619535] loss: 30.51634962603529\n",
      "Epoch: 4911 / 5000 batch step: 360\n",
      "w1: [26.49522] w2: [-23.24158448] bias: [15.87624015] loss: 30.540105601263406\n",
      "Epoch: 4911 / 5000 batch step: 390\n",
      "w1: [26.46933305] w2: [-23.25344523] bias: [15.84195831] loss: 30.525824794980732\n",
      "Epoch: 4911 / 5000 batch step: 420\n",
      "w1: [26.41974994] w2: [-23.29702613] bias: [15.74668261] loss: 30.513321037164154\n",
      "Epoch: 4911 / 5000 batch step: 450\n",
      "w1: [26.39421241] w2: [-23.31474608] bias: [15.70330744] loss: 30.519781035072114\n",
      "Epoch: 4911 / 5000 batch step: 480\n",
      "w1: [26.37735081] w2: [-23.31615832] bias: [15.67748084] loss: 30.526888938527257\n",
      "Epoch: 4912 / 5000 batch step: 0\n",
      "w1: [26.37113479] w2: [-23.31704895] bias: [15.66459387] loss: 30.531049082629508\n",
      "Epoch: 4912 / 5000 batch step: 30\n",
      "w1: [26.36454846] w2: [-23.31705208] bias: [15.65152105] loss: 30.53578816324393\n",
      "Epoch: 4912 / 5000 batch step: 60\n",
      "w1: [26.343064] w2: [-23.32405448] bias: [15.6106634] loss: 30.555145871154256\n",
      "Epoch: 4912 / 5000 batch step: 90\n",
      "w1: [26.33648231] w2: [-23.32799105] bias: [15.59539115] loss: 30.563713666139673\n",
      "Epoch: 4912 / 5000 batch step: 120\n",
      "w1: [26.3462806] w2: [-23.29721903] bias: [15.63186498] loss: 30.543555715125873\n",
      "Epoch: 4912 / 5000 batch step: 150\n",
      "w1: [26.38083088] w2: [-23.29572466] bias: [15.67611522] loss: 30.525453192719993\n",
      "Epoch: 4912 / 5000 batch step: 180\n",
      "w1: [26.44824385] w2: [-23.27866788] bias: [15.77842061] loss: 30.51383950930926\n",
      "Epoch: 4912 / 5000 batch step: 210\n",
      "w1: [26.48469082] w2: [-23.25830959] bias: [15.83712253] loss: 30.526117089020104\n",
      "Epoch: 4912 / 5000 batch step: 240\n",
      "w1: [26.52319358] w2: [-23.25246002] bias: [15.87850364] loss: 30.544613461114547\n",
      "Epoch: 4912 / 5000 batch step: 270\n",
      "w1: [26.53951501] w2: [-23.25256255] bias: [15.89556063] loss: 30.554352912349042\n",
      "Epoch: 4912 / 5000 batch step: 300\n",
      "w1: [26.51993619] w2: [-23.25872286] bias: [15.85694065] loss: 30.53623596367218\n",
      "Epoch: 4912 / 5000 batch step: 330\n",
      "w1: [26.48403258] w2: [-23.27127256] bias: [15.78619531] loss: 30.516349625932325\n",
      "Epoch: 4912 / 5000 batch step: 360\n",
      "w1: [26.49522004] w2: [-23.24158445] bias: [15.87624011] loss: 30.540105601163294\n",
      "Epoch: 4912 / 5000 batch step: 390\n",
      "w1: [26.4693331] w2: [-23.25344521] bias: [15.84195828] loss: 30.52582479484301\n",
      "Epoch: 4912 / 5000 batch step: 420\n",
      "w1: [26.41974999] w2: [-23.29702611] bias: [15.74668258] loss: 30.5133210370176\n",
      "Epoch: 4912 / 5000 batch step: 450\n",
      "w1: [26.39421246] w2: [-23.31474605] bias: [15.70330741] loss: 30.519781034944202\n",
      "Epoch: 4912 / 5000 batch step: 480\n",
      "w1: [26.37735086] w2: [-23.31615829] bias: [15.67748081] loss: 30.526888938396308\n",
      "Epoch: 4913 / 5000 batch step: 0\n",
      "w1: [26.37113484] w2: [-23.31704892] bias: [15.66459384] loss: 30.531049082493745\n",
      "Epoch: 4913 / 5000 batch step: 30\n",
      "w1: [26.36454851] w2: [-23.31705205] bias: [15.65152102] loss: 30.535788163091407\n",
      "Epoch: 4913 / 5000 batch step: 60\n",
      "w1: [26.34306405] w2: [-23.32405445] bias: [15.61066337] loss: 30.555145870968772\n",
      "Epoch: 4913 / 5000 batch step: 90\n",
      "w1: [26.33648235] w2: [-23.32799102] bias: [15.59539112] loss: 30.563713665949876\n",
      "Epoch: 4913 / 5000 batch step: 120\n",
      "w1: [26.34628064] w2: [-23.297219] bias: [15.63186495] loss: 30.54355571495796\n",
      "Epoch: 4913 / 5000 batch step: 150\n",
      "w1: [26.38083093] w2: [-23.29572463] bias: [15.67611519] loss: 30.52545319255221\n",
      "Epoch: 4913 / 5000 batch step: 180\n",
      "w1: [26.4482439] w2: [-23.27866785] bias: [15.77842058] loss: 30.513839509174765\n",
      "Epoch: 4913 / 5000 batch step: 210\n",
      "w1: [26.48469087] w2: [-23.25830956] bias: [15.83712249] loss: 30.526117088886313\n",
      "Epoch: 4913 / 5000 batch step: 240\n",
      "w1: [26.52319363] w2: [-23.25246] bias: [15.8785036] loss: 30.544613460969337\n",
      "Epoch: 4913 / 5000 batch step: 270\n",
      "w1: [26.53951506] w2: [-23.25256253] bias: [15.8955606] loss: 30.55435291220937\n",
      "Epoch: 4913 / 5000 batch step: 300\n",
      "w1: [26.51993624] w2: [-23.25872283] bias: [15.85694062] loss: 30.53623596355983\n",
      "Epoch: 4913 / 5000 batch step: 330\n",
      "w1: [26.48403263] w2: [-23.27127254] bias: [15.78619528] loss: 30.516349625829594\n",
      "Epoch: 4913 / 5000 batch step: 360\n",
      "w1: [26.49522009] w2: [-23.24158442] bias: [15.87624008] loss: 30.54010560106341\n",
      "Epoch: 4913 / 5000 batch step: 390\n",
      "w1: [26.46933315] w2: [-23.25344518] bias: [15.84195824] loss: 30.52582479470561\n",
      "Epoch: 4913 / 5000 batch step: 420\n",
      "w1: [26.41975004] w2: [-23.29702608] bias: [15.74668254] loss: 30.51332103687137\n",
      "Epoch: 4913 / 5000 batch step: 450\n",
      "w1: [26.39421251] w2: [-23.31474602] bias: [15.70330738] loss: 30.519781034816575\n",
      "Epoch: 4913 / 5000 batch step: 480\n",
      "w1: [26.37735091] w2: [-23.31615827] bias: [15.67748077] loss: 30.52688893826566\n",
      "Epoch: 4914 / 5000 batch step: 0\n",
      "w1: [26.37113488] w2: [-23.31704889] bias: [15.66459381] loss: 30.531049082358287\n",
      "Epoch: 4914 / 5000 batch step: 30\n",
      "w1: [26.36454856] w2: [-23.31705202] bias: [15.65152098] loss: 30.53578816293923\n",
      "Epoch: 4914 / 5000 batch step: 60\n",
      "w1: [26.3430641] w2: [-23.32405443] bias: [15.61066333] loss: 30.55514587078371\n",
      "Epoch: 4914 / 5000 batch step: 90\n",
      "w1: [26.3364824] w2: [-23.327991] bias: [15.59539109] loss: 30.56371366576051\n",
      "Epoch: 4914 / 5000 batch step: 120\n",
      "w1: [26.34628069] w2: [-23.29721898] bias: [15.63186492] loss: 30.54355571479044\n",
      "Epoch: 4914 / 5000 batch step: 150\n",
      "w1: [26.38083098] w2: [-23.2957246] bias: [15.67611515] loss: 30.5254531923848\n",
      "Epoch: 4914 / 5000 batch step: 180\n",
      "w1: [26.44824394] w2: [-23.27866783] bias: [15.77842054] loss: 30.513839509040572\n",
      "Epoch: 4914 / 5000 batch step: 210\n",
      "w1: [26.48469092] w2: [-23.25830953] bias: [15.83712246] loss: 30.526117088752827\n",
      "Epoch: 4914 / 5000 batch step: 240\n",
      "w1: [26.52319368] w2: [-23.25245997] bias: [15.87850357] loss: 30.54461346082446\n",
      "Epoch: 4914 / 5000 batch step: 270\n",
      "w1: [26.5395151] w2: [-23.2525625] bias: [15.89556056] loss: 30.554352912070023\n",
      "Epoch: 4914 / 5000 batch step: 300\n",
      "w1: [26.51993629] w2: [-23.2587228] bias: [15.85694058] loss: 30.536235963447737\n",
      "Epoch: 4914 / 5000 batch step: 330\n",
      "w1: [26.48403268] w2: [-23.27127251] bias: [15.78619525] loss: 30.516349625727102\n",
      "Epoch: 4914 / 5000 batch step: 360\n",
      "w1: [26.49522014] w2: [-23.2415844] bias: [15.87624005] loss: 30.540105600963756\n",
      "Epoch: 4914 / 5000 batch step: 390\n",
      "w1: [26.46933319] w2: [-23.25344515] bias: [15.84195821] loss: 30.525824794568518\n",
      "Epoch: 4914 / 5000 batch step: 420\n",
      "w1: [26.41975009] w2: [-23.29702605] bias: [15.74668251] loss: 30.513321036725475\n",
      "Epoch: 4914 / 5000 batch step: 450\n",
      "w1: [26.39421256] w2: [-23.314746] bias: [15.70330734] loss: 30.51978103468924\n",
      "Epoch: 4914 / 5000 batch step: 480\n",
      "w1: [26.37735096] w2: [-23.31615824] bias: [15.67748074] loss: 30.52688893813531\n",
      "Epoch: 4915 / 5000 batch step: 0\n",
      "w1: [26.37113493] w2: [-23.31704887] bias: [15.66459377] loss: 30.531049082223145\n",
      "Epoch: 4915 / 5000 batch step: 30\n",
      "w1: [26.3645486] w2: [-23.317052] bias: [15.65152095] loss: 30.535788162787394\n",
      "Epoch: 4915 / 5000 batch step: 60\n",
      "w1: [26.34306414] w2: [-23.3240544] bias: [15.6106633] loss: 30.55514587059907\n",
      "Epoch: 4915 / 5000 batch step: 90\n",
      "w1: [26.33648245] w2: [-23.32799097] bias: [15.59539105] loss: 30.563713665571584\n",
      "Epoch: 4915 / 5000 batch step: 120\n",
      "w1: [26.34628074] w2: [-23.29721895] bias: [15.63186488] loss: 30.543555714623288\n",
      "Epoch: 4915 / 5000 batch step: 150\n",
      "w1: [26.38083102] w2: [-23.29572458] bias: [15.67611512] loss: 30.525453192217775\n",
      "Epoch: 4915 / 5000 batch step: 180\n",
      "w1: [26.44824399] w2: [-23.2786678] bias: [15.77842051] loss: 30.51383950890669\n",
      "Epoch: 4915 / 5000 batch step: 210\n",
      "w1: [26.48469097] w2: [-23.25830951] bias: [15.83712243] loss: 30.526117088619646\n",
      "Epoch: 4915 / 5000 batch step: 240\n",
      "w1: [26.52319373] w2: [-23.25245994] bias: [15.87850354] loss: 30.54461346067992\n",
      "Epoch: 4915 / 5000 batch step: 270\n",
      "w1: [26.53951515] w2: [-23.25256247] bias: [15.89556053] loss: 30.554352911930994\n",
      "Epoch: 4915 / 5000 batch step: 300\n",
      "w1: [26.51993633] w2: [-23.25872278] bias: [15.85694055] loss: 30.536235963335905\n",
      "Epoch: 4915 / 5000 batch step: 330\n",
      "w1: [26.48403273] w2: [-23.27127248] bias: [15.78619521] loss: 30.516349625624837\n",
      "Epoch: 4915 / 5000 batch step: 360\n",
      "w1: [26.49522019] w2: [-23.24158437] bias: [15.87624001] loss: 30.54010560086433\n",
      "Epoch: 4915 / 5000 batch step: 390\n",
      "w1: [26.46933324] w2: [-23.25344513] bias: [15.84195818] loss: 30.525824794431745\n",
      "Epoch: 4915 / 5000 batch step: 420\n",
      "w1: [26.41975014] w2: [-23.29702603] bias: [15.74668248] loss: 30.51332103657992\n",
      "Epoch: 4915 / 5000 batch step: 450\n",
      "w1: [26.39421261] w2: [-23.31474597] bias: [15.70330731] loss: 30.519781034562193\n",
      "Epoch: 4915 / 5000 batch step: 480\n",
      "w1: [26.377351] w2: [-23.31615822] bias: [15.67748071] loss: 30.526888938005257\n",
      "Epoch: 4916 / 5000 batch step: 0\n",
      "w1: [26.37113498] w2: [-23.31704884] bias: [15.66459374] loss: 30.531049082088305\n",
      "Epoch: 4916 / 5000 batch step: 30\n",
      "w1: [26.36454865] w2: [-23.31705197] bias: [15.65152092] loss: 30.53578816263591\n",
      "Epoch: 4916 / 5000 batch step: 60\n",
      "w1: [26.34306419] w2: [-23.32405438] bias: [15.61066327] loss: 30.555145870414847\n",
      "Epoch: 4916 / 5000 batch step: 90\n",
      "w1: [26.3364825] w2: [-23.32799094] bias: [15.59539102] loss: 30.563713665383073\n",
      "Epoch: 4916 / 5000 batch step: 120\n",
      "w1: [26.34628079] w2: [-23.29721892] bias: [15.63186485] loss: 30.543555714456524\n",
      "Epoch: 4916 / 5000 batch step: 150\n",
      "w1: [26.38083107] w2: [-23.29572455] bias: [15.67611509] loss: 30.525453192051135\n",
      "Epoch: 4916 / 5000 batch step: 180\n",
      "w1: [26.44824404] w2: [-23.27866777] bias: [15.77842048] loss: 30.51383950877311\n",
      "Epoch: 4916 / 5000 batch step: 210\n",
      "w1: [26.48469102] w2: [-23.25830948] bias: [15.83712239] loss: 30.526117088486767\n",
      "Epoch: 4916 / 5000 batch step: 240\n",
      "w1: [26.52319377] w2: [-23.25245992] bias: [15.8785035] loss: 30.544613460535697\n",
      "Epoch: 4916 / 5000 batch step: 270\n",
      "w1: [26.5395152] w2: [-23.25256245] bias: [15.8955605] loss: 30.55435291179228\n",
      "Epoch: 4916 / 5000 batch step: 300\n",
      "w1: [26.51993638] w2: [-23.25872275] bias: [15.85694052] loss: 30.536235963224314\n",
      "Epoch: 4916 / 5000 batch step: 330\n",
      "w1: [26.48403278] w2: [-23.27127246] bias: [15.78619518] loss: 30.51634962552281\n",
      "Epoch: 4916 / 5000 batch step: 360\n",
      "w1: [26.49522024] w2: [-23.24158434] bias: [15.87623998] loss: 30.540105600765123\n",
      "Epoch: 4916 / 5000 batch step: 390\n",
      "w1: [26.46933329] w2: [-23.2534451] bias: [15.84195815] loss: 30.525824794295282\n",
      "Epoch: 4916 / 5000 batch step: 420\n",
      "w1: [26.41975018] w2: [-23.297026] bias: [15.74668244] loss: 30.513321036434686\n",
      "Epoch: 4916 / 5000 batch step: 450\n",
      "w1: [26.39421265] w2: [-23.31474594] bias: [15.70330728] loss: 30.51978103443544\n",
      "Epoch: 4916 / 5000 batch step: 480\n",
      "w1: [26.37735105] w2: [-23.31615819] bias: [15.67748067] loss: 30.526888937875498\n",
      "Epoch: 4917 / 5000 batch step: 0\n",
      "w1: [26.37113503] w2: [-23.31704881] bias: [15.66459371] loss: 30.53104908195377\n",
      "Epoch: 4917 / 5000 batch step: 30\n",
      "w1: [26.3645487] w2: [-23.31705195] bias: [15.65152088] loss: 30.535788162484764\n",
      "Epoch: 4917 / 5000 batch step: 60\n",
      "w1: [26.34306424] w2: [-23.32405435] bias: [15.61066323] loss: 30.55514587023104\n",
      "Epoch: 4917 / 5000 batch step: 90\n",
      "w1: [26.33648255] w2: [-23.32799092] bias: [15.59539099] loss: 30.56371366519499\n",
      "Epoch: 4917 / 5000 batch step: 120\n",
      "w1: [26.34628084] w2: [-23.2972189] bias: [15.63186482] loss: 30.54355571429013\n",
      "Epoch: 4917 / 5000 batch step: 150\n",
      "w1: [26.38083112] w2: [-23.29572452] bias: [15.67611505] loss: 30.525453191884857\n",
      "Epoch: 4917 / 5000 batch step: 180\n",
      "w1: [26.44824409] w2: [-23.27866775] bias: [15.77842044] loss: 30.513839508639837\n",
      "Epoch: 4917 / 5000 batch step: 210\n",
      "w1: [26.48469106] w2: [-23.25830945] bias: [15.83712236] loss: 30.52611708835419\n",
      "Epoch: 4917 / 5000 batch step: 240\n",
      "w1: [26.52319382] w2: [-23.25245989] bias: [15.87850347] loss: 30.54461346039181\n",
      "Epoch: 4917 / 5000 batch step: 270\n",
      "w1: [26.53951525] w2: [-23.25256242] bias: [15.89556046] loss: 30.554352911653883\n",
      "Epoch: 4917 / 5000 batch step: 300\n",
      "w1: [26.51993643] w2: [-23.25872273] bias: [15.85694048] loss: 30.53623596311299\n",
      "Epoch: 4917 / 5000 batch step: 330\n",
      "w1: [26.48403282] w2: [-23.27127243] bias: [15.78619515] loss: 30.516349625421018\n",
      "Epoch: 4917 / 5000 batch step: 360\n",
      "w1: [26.49522028] w2: [-23.24158432] bias: [15.87623995] loss: 30.540105600666145\n",
      "Epoch: 4917 / 5000 batch step: 390\n",
      "w1: [26.46933334] w2: [-23.25344507] bias: [15.84195811] loss: 30.525824794159124\n",
      "Epoch: 4917 / 5000 batch step: 420\n",
      "w1: [26.41975023] w2: [-23.29702597] bias: [15.74668241] loss: 30.51332103628979\n",
      "Epoch: 4917 / 5000 batch step: 450\n",
      "w1: [26.3942127] w2: [-23.31474592] bias: [15.70330724] loss: 30.51978103430897\n",
      "Epoch: 4917 / 5000 batch step: 480\n",
      "w1: [26.3773511] w2: [-23.31615816] bias: [15.67748064] loss: 30.526888937746037\n",
      "Epoch: 4918 / 5000 batch step: 0\n",
      "w1: [26.37113508] w2: [-23.31704879] bias: [15.66459367] loss: 30.531049081819543\n",
      "Epoch: 4918 / 5000 batch step: 30\n",
      "w1: [26.36454875] w2: [-23.31705192] bias: [15.65152085] loss: 30.535788162333965\n",
      "Epoch: 4918 / 5000 batch step: 60\n",
      "w1: [26.34306429] w2: [-23.32405432] bias: [15.6106632] loss: 30.555145870047657\n",
      "Epoch: 4918 / 5000 batch step: 90\n",
      "w1: [26.33648259] w2: [-23.32799089] bias: [15.59539095] loss: 30.563713665007345\n",
      "Epoch: 4918 / 5000 batch step: 120\n",
      "w1: [26.34628088] w2: [-23.29721887] bias: [15.63186479] loss: 30.54355571412412\n",
      "Epoch: 4918 / 5000 batch step: 150\n",
      "w1: [26.38083117] w2: [-23.2957245] bias: [15.67611502] loss: 30.52545319171897\n",
      "Epoch: 4918 / 5000 batch step: 180\n",
      "w1: [26.44824414] w2: [-23.27866772] bias: [15.77842041] loss: 30.513839508506862\n",
      "Epoch: 4918 / 5000 batch step: 210\n",
      "w1: [26.48469111] w2: [-23.25830943] bias: [15.83712233] loss: 30.52611708822192\n",
      "Epoch: 4918 / 5000 batch step: 240\n",
      "w1: [26.52319387] w2: [-23.25245987] bias: [15.87850344] loss: 30.544613460248243\n",
      "Epoch: 4918 / 5000 batch step: 270\n",
      "w1: [26.5395153] w2: [-23.2525624] bias: [15.89556043] loss: 30.554352911515796\n",
      "Epoch: 4918 / 5000 batch step: 300\n",
      "w1: [26.51993648] w2: [-23.2587227] bias: [15.85694045] loss: 30.536235963001918\n",
      "Epoch: 4918 / 5000 batch step: 330\n",
      "w1: [26.48403287] w2: [-23.2712724] bias: [15.78619511] loss: 30.51634962531945\n",
      "Epoch: 4918 / 5000 batch step: 360\n",
      "w1: [26.49522033] w2: [-23.24158429] bias: [15.87623991] loss: 30.540105600567387\n",
      "Epoch: 4918 / 5000 batch step: 390\n",
      "w1: [26.46933339] w2: [-23.25344505] bias: [15.84195808] loss: 30.525824794023272\n",
      "Epoch: 4918 / 5000 batch step: 420\n",
      "w1: [26.41975028] w2: [-23.29702595] bias: [15.74668238] loss: 30.513321036145218\n",
      "Epoch: 4918 / 5000 batch step: 450\n",
      "w1: [26.39421275] w2: [-23.31474589] bias: [15.70330721] loss: 30.51978103418279\n",
      "Epoch: 4918 / 5000 batch step: 480\n",
      "w1: [26.37735115] w2: [-23.31615814] bias: [15.67748061] loss: 30.526888937616878\n",
      "Epoch: 4919 / 5000 batch step: 0\n",
      "w1: [26.37113512] w2: [-23.31704876] bias: [15.66459364] loss: 30.53104908168562\n",
      "Epoch: 4919 / 5000 batch step: 30\n",
      "w1: [26.3645488] w2: [-23.31705189] bias: [15.65152082] loss: 30.53578816218351\n",
      "Epoch: 4919 / 5000 batch step: 60\n",
      "w1: [26.34306433] w2: [-23.3240543] bias: [15.61066317] loss: 30.55514586986469\n",
      "Epoch: 4919 / 5000 batch step: 90\n",
      "w1: [26.33648264] w2: [-23.32799087] bias: [15.59539092] loss: 30.563713664820128\n",
      "Epoch: 4919 / 5000 batch step: 120\n",
      "w1: [26.34628093] w2: [-23.29721885] bias: [15.63186475] loss: 30.543555713958487\n",
      "Epoch: 4919 / 5000 batch step: 150\n",
      "w1: [26.38083122] w2: [-23.29572447] bias: [15.67611499] loss: 30.525453191553463\n",
      "Epoch: 4919 / 5000 batch step: 180\n",
      "w1: [26.44824418] w2: [-23.27866769] bias: [15.77842038] loss: 30.51383950837419\n",
      "Epoch: 4919 / 5000 batch step: 210\n",
      "w1: [26.48469116] w2: [-23.2583094] bias: [15.83712229] loss: 30.52611708808994\n",
      "Epoch: 4919 / 5000 batch step: 240\n",
      "w1: [26.52319392] w2: [-23.25245984] bias: [15.87850341] loss: 30.54461346010501\n",
      "Epoch: 4919 / 5000 batch step: 270\n",
      "w1: [26.53951534] w2: [-23.25256237] bias: [15.8955604] loss: 30.55435291137802\n",
      "Epoch: 4919 / 5000 batch step: 300\n",
      "w1: [26.51993652] w2: [-23.25872267] bias: [15.85694042] loss: 30.536235962891087\n",
      "Epoch: 4919 / 5000 batch step: 330\n",
      "w1: [26.48403292] w2: [-23.27127238] bias: [15.78619508] loss: 30.516349625218115\n",
      "Epoch: 4919 / 5000 batch step: 360\n",
      "w1: [26.49522038] w2: [-23.24158426] bias: [15.87623988] loss: 30.540105600468856\n",
      "Epoch: 4919 / 5000 batch step: 390\n",
      "w1: [26.46933343] w2: [-23.25344502] bias: [15.84195805] loss: 30.525824793887733\n",
      "Epoch: 4919 / 5000 batch step: 420\n",
      "w1: [26.41975033] w2: [-23.29702592] bias: [15.74668234] loss: 30.513321036000978\n",
      "Epoch: 4919 / 5000 batch step: 450\n",
      "w1: [26.3942128] w2: [-23.31474587] bias: [15.70330718] loss: 30.5197810340569\n",
      "Epoch: 4919 / 5000 batch step: 480\n",
      "w1: [26.3773512] w2: [-23.31615811] bias: [15.67748058] loss: 30.526888937488003\n",
      "Epoch: 4920 / 5000 batch step: 0\n",
      "w1: [26.37113517] w2: [-23.31704874] bias: [15.66459361] loss: 30.53104908155201\n",
      "Epoch: 4920 / 5000 batch step: 30\n",
      "w1: [26.36454884] w2: [-23.31705187] bias: [15.65152078] loss: 30.535788162033395\n",
      "Epoch: 4920 / 5000 batch step: 60\n",
      "w1: [26.34306438] w2: [-23.32405427] bias: [15.61066314] loss: 30.555145869682136\n",
      "Epoch: 4920 / 5000 batch step: 90\n",
      "w1: [26.33648269] w2: [-23.32799084] bias: [15.59539089] loss: 30.56371366463333\n",
      "Epoch: 4920 / 5000 batch step: 120\n",
      "w1: [26.34628098] w2: [-23.29721882] bias: [15.63186472] loss: 30.54355571379324\n",
      "Epoch: 4920 / 5000 batch step: 150\n",
      "w1: [26.38083126] w2: [-23.29572444] bias: [15.67611495] loss: 30.525453191388323\n",
      "Epoch: 4920 / 5000 batch step: 180\n",
      "w1: [26.44824423] w2: [-23.27866767] bias: [15.77842034] loss: 30.513839508241823\n",
      "Epoch: 4920 / 5000 batch step: 210\n",
      "w1: [26.48469121] w2: [-23.25830937] bias: [15.83712226] loss: 30.526117087958266\n",
      "Epoch: 4920 / 5000 batch step: 240\n",
      "w1: [26.52319397] w2: [-23.25245981] bias: [15.87850337] loss: 30.5446134599621\n",
      "Epoch: 4920 / 5000 batch step: 270\n",
      "w1: [26.53951539] w2: [-23.25256234] bias: [15.89556036] loss: 30.554352911240567\n",
      "Epoch: 4920 / 5000 batch step: 300\n",
      "w1: [26.51993657] w2: [-23.25872265] bias: [15.85694039] loss: 30.53623596278052\n",
      "Epoch: 4920 / 5000 batch step: 330\n",
      "w1: [26.48403297] w2: [-23.27127235] bias: [15.78619505] loss: 30.516349625117012\n",
      "Epoch: 4920 / 5000 batch step: 360\n",
      "w1: [26.49522043] w2: [-23.24158424] bias: [15.87623985] loss: 30.540105600370556\n",
      "Epoch: 4920 / 5000 batch step: 390\n",
      "w1: [26.46933348] w2: [-23.25344499] bias: [15.84195801] loss: 30.5258247937525\n",
      "Epoch: 4920 / 5000 batch step: 420\n",
      "w1: [26.41975038] w2: [-23.29702589] bias: [15.74668231] loss: 30.513321035857064\n",
      "Epoch: 4920 / 5000 batch step: 450\n",
      "w1: [26.39421285] w2: [-23.31474584] bias: [15.70330715] loss: 30.51978103393129\n",
      "Epoch: 4920 / 5000 batch step: 480\n",
      "w1: [26.37735124] w2: [-23.31615808] bias: [15.67748054] loss: 30.526888937359427\n",
      "Epoch: 4921 / 5000 batch step: 0\n",
      "w1: [26.37113522] w2: [-23.31704871] bias: [15.66459357] loss: 30.531049081418697\n",
      "Epoch: 4921 / 5000 batch step: 30\n",
      "w1: [26.36454889] w2: [-23.31705184] bias: [15.65152075] loss: 30.53578816188362\n",
      "Epoch: 4921 / 5000 batch step: 60\n",
      "w1: [26.34306443] w2: [-23.32405424] bias: [15.6106631] loss: 30.5551458695\n",
      "Epoch: 4921 / 5000 batch step: 90\n",
      "w1: [26.33648274] w2: [-23.32799081] bias: [15.59539086] loss: 30.56371366444696\n",
      "Epoch: 4921 / 5000 batch step: 120\n",
      "w1: [26.34628103] w2: [-23.29721879] bias: [15.63186469] loss: 30.543555713628354\n",
      "Epoch: 4921 / 5000 batch step: 150\n",
      "w1: [26.38083131] w2: [-23.29572442] bias: [15.67611492] loss: 30.525453191223566\n",
      "Epoch: 4921 / 5000 batch step: 180\n",
      "w1: [26.44824428] w2: [-23.27866764] bias: [15.77842031] loss: 30.513839508109754\n",
      "Epoch: 4921 / 5000 batch step: 210\n",
      "w1: [26.48469126] w2: [-23.25830935] bias: [15.83712223] loss: 30.526117087826893\n",
      "Epoch: 4921 / 5000 batch step: 240\n",
      "w1: [26.52319401] w2: [-23.25245979] bias: [15.87850334] loss: 30.54461345981952\n",
      "Epoch: 4921 / 5000 batch step: 270\n",
      "w1: [26.53951544] w2: [-23.25256232] bias: [15.89556033] loss: 30.55435291110342\n",
      "Epoch: 4921 / 5000 batch step: 300\n",
      "w1: [26.51993662] w2: [-23.25872262] bias: [15.85694035] loss: 30.5362359626702\n",
      "Epoch: 4921 / 5000 batch step: 330\n",
      "w1: [26.48403301] w2: [-23.27127233] bias: [15.78619502] loss: 30.516349625016137\n",
      "Epoch: 4921 / 5000 batch step: 360\n",
      "w1: [26.49522047] w2: [-23.24158421] bias: [15.87623981] loss: 30.540105600272476\n",
      "Epoch: 4921 / 5000 batch step: 390\n",
      "w1: [26.46933353] w2: [-23.25344497] bias: [15.84195798] loss: 30.52582479361758\n",
      "Epoch: 4921 / 5000 batch step: 420\n",
      "w1: [26.41975042] w2: [-23.29702587] bias: [15.74668228] loss: 30.51332103571348\n",
      "Epoch: 4921 / 5000 batch step: 450\n",
      "w1: [26.39421289] w2: [-23.31474581] bias: [15.70330711] loss: 30.519781033805966\n",
      "Epoch: 4921 / 5000 batch step: 480\n",
      "w1: [26.37735129] w2: [-23.31615806] bias: [15.67748051] loss: 30.526888937231135\n",
      "Epoch: 4922 / 5000 batch step: 0\n",
      "w1: [26.37113527] w2: [-23.31704868] bias: [15.66459354] loss: 30.531049081285683\n",
      "Epoch: 4922 / 5000 batch step: 30\n",
      "w1: [26.36454894] w2: [-23.31705181] bias: [15.65152072] loss: 30.53578816173419\n",
      "Epoch: 4922 / 5000 batch step: 60\n",
      "w1: [26.34306448] w2: [-23.32405422] bias: [15.61066307] loss: 30.55514586931828\n",
      "Epoch: 4922 / 5000 batch step: 90\n",
      "w1: [26.33648278] w2: [-23.32799079] bias: [15.59539082] loss: 30.56371366426101\n",
      "Epoch: 4922 / 5000 batch step: 120\n",
      "w1: [26.34628107] w2: [-23.29721877] bias: [15.63186465] loss: 30.543555713463846\n",
      "Epoch: 4922 / 5000 batch step: 150\n",
      "w1: [26.38083136] w2: [-23.29572439] bias: [15.67611489] loss: 30.525453191059178\n",
      "Epoch: 4922 / 5000 batch step: 180\n",
      "w1: [26.44824433] w2: [-23.27866762] bias: [15.77842028] loss: 30.51383950797798\n",
      "Epoch: 4922 / 5000 batch step: 210\n",
      "w1: [26.4846913] w2: [-23.25830932] bias: [15.83712219] loss: 30.52611708769582\n",
      "Epoch: 4922 / 5000 batch step: 240\n",
      "w1: [26.52319406] w2: [-23.25245976] bias: [15.87850331] loss: 30.544613459677247\n",
      "Epoch: 4922 / 5000 batch step: 270\n",
      "w1: [26.53951549] w2: [-23.25256229] bias: [15.8955603] loss: 30.55435291096659\n",
      "Epoch: 4922 / 5000 batch step: 300\n",
      "w1: [26.51993667] w2: [-23.25872259] bias: [15.85694032] loss: 30.536235962560134\n",
      "Epoch: 4922 / 5000 batch step: 330\n",
      "w1: [26.48403306] w2: [-23.2712723] bias: [15.78619498] loss: 30.516349624915488\n",
      "Epoch: 4922 / 5000 batch step: 360\n",
      "w1: [26.49522052] w2: [-23.24158419] bias: [15.87623978] loss: 30.540105600174616\n",
      "Epoch: 4922 / 5000 batch step: 390\n",
      "w1: [26.46933358] w2: [-23.25344494] bias: [15.84195795] loss: 30.525824793482965\n",
      "Epoch: 4922 / 5000 batch step: 420\n",
      "w1: [26.41975047] w2: [-23.29702584] bias: [15.74668224] loss: 30.513321035570215\n",
      "Epoch: 4922 / 5000 batch step: 450\n",
      "w1: [26.39421294] w2: [-23.31474579] bias: [15.70330708] loss: 30.519781033680932\n",
      "Epoch: 4922 / 5000 batch step: 480\n",
      "w1: [26.37735134] w2: [-23.31615803] bias: [15.67748048] loss: 30.526888937103134\n",
      "Epoch: 4923 / 5000 batch step: 0\n",
      "w1: [26.37113531] w2: [-23.31704866] bias: [15.66459351] loss: 30.531049081152972\n",
      "Epoch: 4923 / 5000 batch step: 30\n",
      "w1: [26.36454898] w2: [-23.31705179] bias: [15.65152069] loss: 30.5357881615851\n",
      "Epoch: 4923 / 5000 batch step: 60\n",
      "w1: [26.34306452] w2: [-23.32405419] bias: [15.61066304] loss: 30.55514586913697\n",
      "Epoch: 4923 / 5000 batch step: 90\n",
      "w1: [26.33648283] w2: [-23.32799076] bias: [15.59539079] loss: 30.563713664075486\n",
      "Epoch: 4923 / 5000 batch step: 120\n",
      "w1: [26.34628112] w2: [-23.29721874] bias: [15.63186462] loss: 30.543555713299718\n",
      "Epoch: 4923 / 5000 batch step: 150\n",
      "w1: [26.38083141] w2: [-23.29572437] bias: [15.67611486] loss: 30.52545319089517\n",
      "Epoch: 4923 / 5000 batch step: 180\n",
      "w1: [26.44824437] w2: [-23.27866759] bias: [15.77842025] loss: 30.513839507846516\n",
      "Epoch: 4923 / 5000 batch step: 210\n",
      "w1: [26.48469135] w2: [-23.2583093] bias: [15.83712216] loss: 30.52611708756504\n",
      "Epoch: 4923 / 5000 batch step: 240\n",
      "w1: [26.52319411] w2: [-23.25245973] bias: [15.87850327] loss: 30.544613459535313\n",
      "Epoch: 4923 / 5000 batch step: 270\n",
      "w1: [26.53951553] w2: [-23.25256227] bias: [15.89556027] loss: 30.554352910830065\n",
      "Epoch: 4923 / 5000 batch step: 300\n",
      "w1: [26.51993671] w2: [-23.25872257] bias: [15.85694029] loss: 30.53623596245031\n",
      "Epoch: 4923 / 5000 batch step: 330\n",
      "w1: [26.48403311] w2: [-23.27127227] bias: [15.78619495] loss: 30.516349624815074\n",
      "Epoch: 4923 / 5000 batch step: 360\n",
      "w1: [26.49522057] w2: [-23.24158416] bias: [15.87623975] loss: 30.54010560007698\n",
      "Epoch: 4923 / 5000 batch step: 390\n",
      "w1: [26.46933362] w2: [-23.25344492] bias: [15.84195791] loss: 30.52582479334865\n",
      "Epoch: 4923 / 5000 batch step: 420\n",
      "w1: [26.41975052] w2: [-23.29702582] bias: [15.74668221] loss: 30.513321035427285\n",
      "Epoch: 4923 / 5000 batch step: 450\n",
      "w1: [26.39421299] w2: [-23.31474576] bias: [15.70330705] loss: 30.519781033556182\n",
      "Epoch: 4923 / 5000 batch step: 480\n",
      "w1: [26.37735138] w2: [-23.31615801] bias: [15.67748044] loss: 30.526888936975432\n",
      "Epoch: 4924 / 5000 batch step: 0\n",
      "w1: [26.37113536] w2: [-23.31704863] bias: [15.66459348] loss: 30.531049081020573\n",
      "Epoch: 4924 / 5000 batch step: 30\n",
      "w1: [26.36454903] w2: [-23.31705176] bias: [15.65152065] loss: 30.535788161436344\n",
      "Epoch: 4924 / 5000 batch step: 60\n",
      "w1: [26.34306457] w2: [-23.32405417] bias: [15.610663] loss: 30.55514586895607\n",
      "Epoch: 4924 / 5000 batch step: 90\n",
      "w1: [26.33648288] w2: [-23.32799073] bias: [15.59539076] loss: 30.563713663890386\n",
      "Epoch: 4924 / 5000 batch step: 120\n",
      "w1: [26.34628117] w2: [-23.29721872] bias: [15.63186459] loss: 30.543555713135962\n",
      "Epoch: 4924 / 5000 batch step: 150\n",
      "w1: [26.38083145] w2: [-23.29572434] bias: [15.67611482] loss: 30.52545319073153\n",
      "Epoch: 4924 / 5000 batch step: 180\n",
      "w1: [26.44824442] w2: [-23.27866756] bias: [15.77842021] loss: 30.513839507715346\n",
      "Epoch: 4924 / 5000 batch step: 210\n",
      "w1: [26.4846914] w2: [-23.25830927] bias: [15.83712213] loss: 30.526117087434557\n",
      "Epoch: 4924 / 5000 batch step: 240\n",
      "w1: [26.52319415] w2: [-23.25245971] bias: [15.87850324] loss: 30.544613459393695\n",
      "Epoch: 4924 / 5000 batch step: 270\n",
      "w1: [26.53951558] w2: [-23.25256224] bias: [15.89556023] loss: 30.55435291069385\n",
      "Epoch: 4924 / 5000 batch step: 300\n",
      "w1: [26.51993676] w2: [-23.25872254] bias: [15.85694026] loss: 30.53623596234074\n",
      "Epoch: 4924 / 5000 batch step: 330\n",
      "w1: [26.48403316] w2: [-23.27127225] bias: [15.78619492] loss: 30.516349624714888\n",
      "Epoch: 4924 / 5000 batch step: 360\n",
      "w1: [26.49522062] w2: [-23.24158413] bias: [15.87623972] loss: 30.54010559997956\n",
      "Epoch: 4924 / 5000 batch step: 390\n",
      "w1: [26.46933367] w2: [-23.25344489] bias: [15.84195788] loss: 30.525824793214642\n",
      "Epoch: 4924 / 5000 batch step: 420\n",
      "w1: [26.41975056] w2: [-23.29702579] bias: [15.74668218] loss: 30.513321035284683\n",
      "Epoch: 4924 / 5000 batch step: 450\n",
      "w1: [26.39421303] w2: [-23.31474574] bias: [15.70330701] loss: 30.519781033431713\n",
      "Epoch: 4924 / 5000 batch step: 480\n",
      "w1: [26.37735143] w2: [-23.31615798] bias: [15.67748041] loss: 30.52688893684802\n",
      "Epoch: 4925 / 5000 batch step: 0\n",
      "w1: [26.37113541] w2: [-23.31704861] bias: [15.66459344] loss: 30.53104908088847\n",
      "Epoch: 4925 / 5000 batch step: 30\n",
      "w1: [26.36454908] w2: [-23.31705174] bias: [15.65152062] loss: 30.53578816128793\n",
      "Epoch: 4925 / 5000 batch step: 60\n",
      "w1: [26.34306462] w2: [-23.32405414] bias: [15.61066297] loss: 30.55514586877559\n",
      "Epoch: 4925 / 5000 batch step: 90\n",
      "w1: [26.33648293] w2: [-23.32799071] bias: [15.59539072] loss: 30.563713663705702\n",
      "Epoch: 4925 / 5000 batch step: 120\n",
      "w1: [26.34628122] w2: [-23.29721869] bias: [15.63186456] loss: 30.543555712972577\n",
      "Epoch: 4925 / 5000 batch step: 150\n",
      "w1: [26.3808315] w2: [-23.29572431] bias: [15.67611479] loss: 30.525453190568268\n",
      "Epoch: 4925 / 5000 batch step: 180\n",
      "w1: [26.44824447] w2: [-23.27866754] bias: [15.77842018] loss: 30.51383950758448\n",
      "Epoch: 4925 / 5000 batch step: 210\n",
      "w1: [26.48469144] w2: [-23.25830924] bias: [15.8371221] loss: 30.526117087304375\n",
      "Epoch: 4925 / 5000 batch step: 240\n",
      "w1: [26.5231942] w2: [-23.25245968] bias: [15.87850321] loss: 30.5446134592524\n",
      "Epoch: 4925 / 5000 batch step: 270\n",
      "w1: [26.53951563] w2: [-23.25256221] bias: [15.8955602] loss: 30.55435291055795\n",
      "Epoch: 4925 / 5000 batch step: 300\n",
      "w1: [26.51993681] w2: [-23.25872252] bias: [15.85694022] loss: 30.536235962231416\n",
      "Epoch: 4925 / 5000 batch step: 330\n",
      "w1: [26.4840332] w2: [-23.27127222] bias: [15.78619489] loss: 30.51634962461493\n",
      "Epoch: 4925 / 5000 batch step: 360\n",
      "w1: [26.49522066] w2: [-23.24158411] bias: [15.87623968] loss: 30.54010559988237\n",
      "Epoch: 4925 / 5000 batch step: 390\n",
      "w1: [26.46933372] w2: [-23.25344486] bias: [15.84195785] loss: 30.525824793080947\n",
      "Epoch: 4925 / 5000 batch step: 420\n",
      "w1: [26.41975061] w2: [-23.29702577] bias: [15.74668215] loss: 30.513321035142393\n",
      "Epoch: 4925 / 5000 batch step: 450\n",
      "w1: [26.39421308] w2: [-23.31474571] bias: [15.70330698] loss: 30.519781033307527\n",
      "Epoch: 4925 / 5000 batch step: 480\n",
      "w1: [26.37735148] w2: [-23.31615795] bias: [15.67748038] loss: 30.526888936720898\n",
      "Epoch: 4926 / 5000 batch step: 0\n",
      "w1: [26.37113545] w2: [-23.31704858] bias: [15.66459341] loss: 30.531049080756663\n",
      "Epoch: 4926 / 5000 batch step: 30\n",
      "w1: [26.36454913] w2: [-23.31705171] bias: [15.65152059] loss: 30.535788161139855\n",
      "Epoch: 4926 / 5000 batch step: 60\n",
      "w1: [26.34306467] w2: [-23.32405411] bias: [15.61066294] loss: 30.555145868595517\n",
      "Epoch: 4926 / 5000 batch step: 90\n",
      "w1: [26.33648297] w2: [-23.32799068] bias: [15.59539069] loss: 30.563713663521444\n",
      "Epoch: 4926 / 5000 batch step: 120\n",
      "w1: [26.34628126] w2: [-23.29721866] bias: [15.63186452] loss: 30.54355571280957\n",
      "Epoch: 4926 / 5000 batch step: 150\n",
      "w1: [26.38083155] w2: [-23.29572429] bias: [15.67611476] loss: 30.525453190405372\n",
      "Epoch: 4926 / 5000 batch step: 180\n",
      "w1: [26.44824451] w2: [-23.27866751] bias: [15.77842015] loss: 30.513839507453905\n",
      "Epoch: 4926 / 5000 batch step: 210\n",
      "w1: [26.48469149] w2: [-23.25830922] bias: [15.83712206] loss: 30.526117087174487\n",
      "Epoch: 4926 / 5000 batch step: 240\n",
      "w1: [26.52319425] w2: [-23.25245966] bias: [15.87850318] loss: 30.54461345911142\n",
      "Epoch: 4926 / 5000 batch step: 270\n",
      "w1: [26.53951567] w2: [-23.25256219] bias: [15.89556017] loss: 30.554352910422356\n",
      "Epoch: 4926 / 5000 batch step: 300\n",
      "w1: [26.51993686] w2: [-23.25872249] bias: [15.85694019] loss: 30.536235962122348\n",
      "Epoch: 4926 / 5000 batch step: 330\n",
      "w1: [26.48403325] w2: [-23.2712722] bias: [15.78619485] loss: 30.516349624515197\n",
      "Epoch: 4926 / 5000 batch step: 360\n",
      "w1: [26.49522071] w2: [-23.24158408] bias: [15.87623965] loss: 30.540105599785402\n",
      "Epoch: 4926 / 5000 batch step: 390\n",
      "w1: [26.46933376] w2: [-23.25344484] bias: [15.84195782] loss: 30.525824792947553\n",
      "Epoch: 4926 / 5000 batch step: 420\n",
      "w1: [26.41975066] w2: [-23.29702574] bias: [15.74668211] loss: 30.513321035000434\n",
      "Epoch: 4926 / 5000 batch step: 450\n",
      "w1: [26.39421313] w2: [-23.31474568] bias: [15.70330695] loss: 30.519781033183627\n",
      "Epoch: 4926 / 5000 batch step: 480\n",
      "w1: [26.37735153] w2: [-23.31615793] bias: [15.67748035] loss: 30.52688893659406\n",
      "Epoch: 4927 / 5000 batch step: 0\n",
      "w1: [26.3711355] w2: [-23.31704855] bias: [15.66459338] loss: 30.531049080625156\n",
      "Epoch: 4927 / 5000 batch step: 30\n",
      "w1: [26.36454917] w2: [-23.31705169] bias: [15.65152056] loss: 30.535788160992116\n",
      "Epoch: 4927 / 5000 batch step: 60\n",
      "w1: [26.34306471] w2: [-23.32405409] bias: [15.61066291] loss: 30.555145868415845\n",
      "Epoch: 4927 / 5000 batch step: 90\n",
      "w1: [26.33648302] w2: [-23.32799066] bias: [15.59539066] loss: 30.5637136633376\n",
      "Epoch: 4927 / 5000 batch step: 120\n",
      "w1: [26.34628131] w2: [-23.29721864] bias: [15.63186449] loss: 30.54355571264692\n",
      "Epoch: 4927 / 5000 batch step: 150\n",
      "w1: [26.38083159] w2: [-23.29572426] bias: [15.67611473] loss: 30.52545319024285\n",
      "Epoch: 4927 / 5000 batch step: 180\n",
      "w1: [26.44824456] w2: [-23.27866749] bias: [15.77842012] loss: 30.513839507323627\n",
      "Epoch: 4927 / 5000 batch step: 210\n",
      "w1: [26.48469154] w2: [-23.25830919] bias: [15.83712203] loss: 30.52611708704489\n",
      "Epoch: 4927 / 5000 batch step: 240\n",
      "w1: [26.5231943] w2: [-23.25245963] bias: [15.87850314] loss: 30.544613458970773\n",
      "Epoch: 4927 / 5000 batch step: 270\n",
      "w1: [26.53951572] w2: [-23.25256216] bias: [15.89556014] loss: 30.554352910287072\n",
      "Epoch: 4927 / 5000 batch step: 300\n",
      "w1: [26.5199369] w2: [-23.25872247] bias: [15.85694016] loss: 30.536235962013524\n",
      "Epoch: 4927 / 5000 batch step: 330\n",
      "w1: [26.4840333] w2: [-23.27127217] bias: [15.78619482] loss: 30.51634962441569\n",
      "Epoch: 4927 / 5000 batch step: 360\n",
      "w1: [26.49522076] w2: [-23.24158406] bias: [15.87623962] loss: 30.54010559968865\n",
      "Epoch: 4927 / 5000 batch step: 390\n",
      "w1: [26.46933381] w2: [-23.25344481] bias: [15.84195779] loss: 30.525824792814458\n",
      "Epoch: 4927 / 5000 batch step: 420\n",
      "w1: [26.4197507] w2: [-23.29702571] bias: [15.74668208] loss: 30.513321034858798\n",
      "Epoch: 4927 / 5000 batch step: 450\n",
      "w1: [26.39421317] w2: [-23.31474566] bias: [15.70330692] loss: 30.51978103306001\n",
      "Epoch: 4927 / 5000 batch step: 480\n",
      "w1: [26.37735157] w2: [-23.3161579] bias: [15.67748031] loss: 30.526888936467515\n",
      "Epoch: 4928 / 5000 batch step: 0\n",
      "w1: [26.37113555] w2: [-23.31704853] bias: [15.66459335] loss: 30.531049080493958\n",
      "Epoch: 4928 / 5000 batch step: 30\n",
      "w1: [26.36454922] w2: [-23.31705166] bias: [15.65152052] loss: 30.535788160844707\n",
      "Epoch: 4928 / 5000 batch step: 60\n",
      "w1: [26.34306476] w2: [-23.32405406] bias: [15.61066287] loss: 30.55514586823659\n",
      "Epoch: 4928 / 5000 batch step: 90\n",
      "w1: [26.33648307] w2: [-23.32799063] bias: [15.59539063] loss: 30.56371366315417\n",
      "Epoch: 4928 / 5000 batch step: 120\n",
      "w1: [26.34628136] w2: [-23.29721861] bias: [15.63186446] loss: 30.54355571248465\n",
      "Epoch: 4928 / 5000 batch step: 150\n",
      "w1: [26.38083164] w2: [-23.29572424] bias: [15.67611469] loss: 30.52545319008069\n",
      "Epoch: 4928 / 5000 batch step: 180\n",
      "w1: [26.44824461] w2: [-23.27866746] bias: [15.77842008] loss: 30.513839507193648\n",
      "Epoch: 4928 / 5000 batch step: 210\n",
      "w1: [26.48469158] w2: [-23.25830917] bias: [15.837122] loss: 30.526117086915605\n",
      "Epoch: 4928 / 5000 batch step: 240\n",
      "w1: [26.52319434] w2: [-23.25245961] bias: [15.87850311] loss: 30.544613458830444\n",
      "Epoch: 4928 / 5000 batch step: 270\n",
      "w1: [26.53951577] w2: [-23.25256214] bias: [15.8955601] loss: 30.554352910152094\n",
      "Epoch: 4928 / 5000 batch step: 300\n",
      "w1: [26.51993695] w2: [-23.25872244] bias: [15.85694013] loss: 30.53623596190495\n",
      "Epoch: 4928 / 5000 batch step: 330\n",
      "w1: [26.48403334] w2: [-23.27127214] bias: [15.78619479] loss: 30.51634962431641\n",
      "Epoch: 4928 / 5000 batch step: 360\n",
      "w1: [26.4952208] w2: [-23.24158403] bias: [15.87623959] loss: 30.54010559959212\n",
      "Epoch: 4928 / 5000 batch step: 390\n",
      "w1: [26.46933386] w2: [-23.25344479] bias: [15.84195775] loss: 30.52582479268167\n",
      "Epoch: 4928 / 5000 batch step: 420\n",
      "w1: [26.41975075] w2: [-23.29702569] bias: [15.74668205] loss: 30.513321034717485\n",
      "Epoch: 4928 / 5000 batch step: 450\n",
      "w1: [26.39421322] w2: [-23.31474563] bias: [15.70330688] loss: 30.519781032936663\n",
      "Epoch: 4928 / 5000 batch step: 480\n",
      "w1: [26.37735162] w2: [-23.31615788] bias: [15.67748028] loss: 30.526888936341255\n",
      "Epoch: 4929 / 5000 batch step: 0\n",
      "w1: [26.37113559] w2: [-23.3170485] bias: [15.66459331] loss: 30.531049080363047\n",
      "Epoch: 4929 / 5000 batch step: 30\n",
      "w1: [26.36454927] w2: [-23.31705163] bias: [15.65152049] loss: 30.53578816069764\n",
      "Epoch: 4929 / 5000 batch step: 60\n",
      "w1: [26.34306481] w2: [-23.32405404] bias: [15.61066284] loss: 30.555145868057743\n",
      "Epoch: 4929 / 5000 batch step: 90\n",
      "w1: [26.33648311] w2: [-23.32799061] bias: [15.5953906] loss: 30.563713662971164\n",
      "Epoch: 4929 / 5000 batch step: 120\n",
      "w1: [26.3462814] w2: [-23.29721859] bias: [15.63186443] loss: 30.543555712322746\n",
      "Epoch: 4929 / 5000 batch step: 150\n",
      "w1: [26.38083169] w2: [-23.29572421] bias: [15.67611466] loss: 30.525453189918903\n",
      "Epoch: 4929 / 5000 batch step: 180\n",
      "w1: [26.44824465] w2: [-23.27866743] bias: [15.77842005] loss: 30.51383950706396\n",
      "Epoch: 4929 / 5000 batch step: 210\n",
      "w1: [26.48469163] w2: [-23.25830914] bias: [15.83712197] loss: 30.526117086786595\n",
      "Epoch: 4929 / 5000 batch step: 240\n",
      "w1: [26.52319439] w2: [-23.25245958] bias: [15.87850308] loss: 30.54461345869043\n",
      "Epoch: 4929 / 5000 batch step: 270\n",
      "w1: [26.53951581] w2: [-23.25256211] bias: [15.89556007] loss: 30.554352910017425\n",
      "Epoch: 4929 / 5000 batch step: 300\n",
      "w1: [26.519937] w2: [-23.25872241] bias: [15.85694009] loss: 30.536235961796624\n",
      "Epoch: 4929 / 5000 batch step: 330\n",
      "w1: [26.48403339] w2: [-23.27127212] bias: [15.78619476] loss: 30.51634962421736\n",
      "Epoch: 4929 / 5000 batch step: 360\n",
      "w1: [26.49522085] w2: [-23.24158401] bias: [15.87623956] loss: 30.540105599495817\n",
      "Epoch: 4929 / 5000 batch step: 390\n",
      "w1: [26.4693339] w2: [-23.25344476] bias: [15.84195772] loss: 30.52582479254918\n",
      "Epoch: 4929 / 5000 batch step: 420\n",
      "w1: [26.4197508] w2: [-23.29702566] bias: [15.74668202] loss: 30.513321034576485\n",
      "Epoch: 4929 / 5000 batch step: 450\n",
      "w1: [26.39421327] w2: [-23.31474561] bias: [15.70330685] loss: 30.519781032813604\n",
      "Epoch: 4929 / 5000 batch step: 480\n",
      "w1: [26.37735166] w2: [-23.31615785] bias: [15.67748025] loss: 30.526888936215283\n",
      "Epoch: 4930 / 5000 batch step: 0\n",
      "w1: [26.37113564] w2: [-23.31704848] bias: [15.66459328] loss: 30.531049080232435\n",
      "Epoch: 4930 / 5000 batch step: 30\n",
      "w1: [26.36454931] w2: [-23.31705161] bias: [15.65152046] loss: 30.5357881605509\n",
      "Epoch: 4930 / 5000 batch step: 60\n",
      "w1: [26.34306485] w2: [-23.32405401] bias: [15.61066281] loss: 30.555145867879293\n",
      "Epoch: 4930 / 5000 batch step: 90\n",
      "w1: [26.33648316] w2: [-23.32799058] bias: [15.59539056] loss: 30.56371366278858\n",
      "Epoch: 4930 / 5000 batch step: 120\n",
      "w1: [26.34628145] w2: [-23.29721856] bias: [15.63186439] loss: 30.54355571216121\n",
      "Epoch: 4930 / 5000 batch step: 150\n",
      "w1: [26.38083173] w2: [-23.29572419] bias: [15.67611463] loss: 30.52545318975749\n",
      "Epoch: 4930 / 5000 batch step: 180\n",
      "w1: [26.4482447] w2: [-23.27866741] bias: [15.77842002] loss: 30.513839506934573\n",
      "Epoch: 4930 / 5000 batch step: 210\n",
      "w1: [26.48469168] w2: [-23.25830912] bias: [15.83712193] loss: 30.526117086657884\n",
      "Epoch: 4930 / 5000 batch step: 240\n",
      "w1: [26.52319443] w2: [-23.25245955] bias: [15.87850305] loss: 30.54461345855074\n",
      "Epoch: 4930 / 5000 batch step: 270\n",
      "w1: [26.53951586] w2: [-23.25256208] bias: [15.89556004] loss: 30.554352909883065\n",
      "Epoch: 4930 / 5000 batch step: 300\n",
      "w1: [26.51993704] w2: [-23.25872239] bias: [15.85694006] loss: 30.536235961688543\n",
      "Epoch: 4930 / 5000 batch step: 330\n",
      "w1: [26.48403344] w2: [-23.27127209] bias: [15.78619472] loss: 30.516349624118526\n",
      "Epoch: 4930 / 5000 batch step: 360\n",
      "w1: [26.4952209] w2: [-23.24158398] bias: [15.87623952] loss: 30.54010559939972\n",
      "Epoch: 4930 / 5000 batch step: 390\n",
      "w1: [26.46933395] w2: [-23.25344474] bias: [15.84195769] loss: 30.525824792416994\n",
      "Epoch: 4930 / 5000 batch step: 420\n",
      "w1: [26.41975084] w2: [-23.29702564] bias: [15.74668198] loss: 30.513321034435815\n",
      "Epoch: 4930 / 5000 batch step: 450\n",
      "w1: [26.39421331] w2: [-23.31474558] bias: [15.70330682] loss: 30.51978103269083\n",
      "Epoch: 4930 / 5000 batch step: 480\n",
      "w1: [26.37735171] w2: [-23.31615783] bias: [15.67748022] loss: 30.526888936089595\n",
      "Epoch: 4931 / 5000 batch step: 0\n",
      "w1: [26.37113569] w2: [-23.31704845] bias: [15.66459325] loss: 30.53104908010213\n",
      "Epoch: 4931 / 5000 batch step: 30\n",
      "w1: [26.36454936] w2: [-23.31705158] bias: [15.65152043] loss: 30.5357881604045\n",
      "Epoch: 4931 / 5000 batch step: 60\n",
      "w1: [26.3430649] w2: [-23.32405399] bias: [15.61066278] loss: 30.555145867701263\n",
      "Epoch: 4931 / 5000 batch step: 90\n",
      "w1: [26.33648321] w2: [-23.32799056] bias: [15.59539053] loss: 30.563713662606403\n",
      "Epoch: 4931 / 5000 batch step: 120\n",
      "w1: [26.3462815] w2: [-23.29721854] bias: [15.63186436] loss: 30.543555712000046\n",
      "Epoch: 4931 / 5000 batch step: 150\n",
      "w1: [26.38083178] w2: [-23.29572416] bias: [15.6761146] loss: 30.52545318959644\n",
      "Epoch: 4931 / 5000 batch step: 180\n",
      "w1: [26.44824475] w2: [-23.27866738] bias: [15.77841999] loss: 30.513839506805482\n",
      "Epoch: 4931 / 5000 batch step: 210\n",
      "w1: [26.48469172] w2: [-23.25830909] bias: [15.8371219] loss: 30.526117086529467\n",
      "Epoch: 4931 / 5000 batch step: 240\n",
      "w1: [26.52319448] w2: [-23.25245953] bias: [15.87850301] loss: 30.54461345841136\n",
      "Epoch: 4931 / 5000 batch step: 270\n",
      "w1: [26.53951591] w2: [-23.25256206] bias: [15.89556001] loss: 30.554352909749003\n",
      "Epoch: 4931 / 5000 batch step: 300\n",
      "w1: [26.51993709] w2: [-23.25872236] bias: [15.85694003] loss: 30.536235961580704\n",
      "Epoch: 4931 / 5000 batch step: 330\n",
      "w1: [26.48403348] w2: [-23.27127207] bias: [15.78619469] loss: 30.516349624019924\n",
      "Epoch: 4931 / 5000 batch step: 360\n",
      "w1: [26.49522094] w2: [-23.24158395] bias: [15.87623949] loss: 30.540105599303846\n",
      "Epoch: 4931 / 5000 batch step: 390\n",
      "w1: [26.469334] w2: [-23.25344471] bias: [15.84195766] loss: 30.52582479228511\n",
      "Epoch: 4931 / 5000 batch step: 420\n",
      "w1: [26.41975089] w2: [-23.29702561] bias: [15.74668195] loss: 30.51332103429546\n",
      "Epoch: 4931 / 5000 batch step: 450\n",
      "w1: [26.39421336] w2: [-23.31474556] bias: [15.70330679] loss: 30.51978103256833\n",
      "Epoch: 4931 / 5000 batch step: 480\n",
      "w1: [26.37735176] w2: [-23.3161578] bias: [15.67748019] loss: 30.526888935964198\n",
      "Epoch: 4932 / 5000 batch step: 0\n",
      "w1: [26.37113573] w2: [-23.31704843] bias: [15.66459322] loss: 30.53104907997211\n",
      "Epoch: 4932 / 5000 batch step: 30\n",
      "w1: [26.36454941] w2: [-23.31705156] bias: [15.65152039] loss: 30.535788160258438\n",
      "Epoch: 4932 / 5000 batch step: 60\n",
      "w1: [26.34306495] w2: [-23.32405396] bias: [15.61066275] loss: 30.555145867523635\n",
      "Epoch: 4932 / 5000 batch step: 90\n",
      "w1: [26.33648325] w2: [-23.32799053] bias: [15.5953905] loss: 30.563713662424636\n",
      "Epoch: 4932 / 5000 batch step: 120\n",
      "w1: [26.34628154] w2: [-23.29721851] bias: [15.63186433] loss: 30.543555711839247\n",
      "Epoch: 4932 / 5000 batch step: 150\n",
      "w1: [26.38083183] w2: [-23.29572414] bias: [15.67611456] loss: 30.525453189435755\n",
      "Epoch: 4932 / 5000 batch step: 180\n",
      "w1: [26.44824479] w2: [-23.27866736] bias: [15.77841995] loss: 30.513839506676675\n",
      "Epoch: 4932 / 5000 batch step: 210\n",
      "w1: [26.48469177] w2: [-23.25830906] bias: [15.83712187] loss: 30.52611708640134\n",
      "Epoch: 4932 / 5000 batch step: 240\n",
      "w1: [26.52319453] w2: [-23.2524595] bias: [15.87850298] loss: 30.5446134582723\n",
      "Epoch: 4932 / 5000 batch step: 270\n",
      "w1: [26.53951595] w2: [-23.25256203] bias: [15.89555998] loss: 30.554352909615243\n",
      "Epoch: 4932 / 5000 batch step: 300\n",
      "w1: [26.51993713] w2: [-23.25872234] bias: [15.85694] loss: 30.53623596147311\n",
      "Epoch: 4932 / 5000 batch step: 330\n",
      "w1: [26.48403353] w2: [-23.27127204] bias: [15.78619466] loss: 30.516349623921545\n",
      "Epoch: 4932 / 5000 batch step: 360\n",
      "w1: [26.49522099] w2: [-23.24158393] bias: [15.87623946] loss: 30.54010559920819\n",
      "Epoch: 4932 / 5000 batch step: 390\n",
      "w1: [26.46933404] w2: [-23.25344469] bias: [15.84195762] loss: 30.525824792153525\n",
      "Epoch: 4932 / 5000 batch step: 420\n",
      "w1: [26.41975094] w2: [-23.29702559] bias: [15.74668192] loss: 30.513321034155425\n",
      "Epoch: 4932 / 5000 batch step: 450\n",
      "w1: [26.39421341] w2: [-23.31474553] bias: [15.70330676] loss: 30.51978103244611\n",
      "Epoch: 4932 / 5000 batch step: 480\n",
      "w1: [26.3773518] w2: [-23.31615778] bias: [15.67748015] loss: 30.526888935839086\n",
      "Epoch: 4933 / 5000 batch step: 0\n",
      "w1: [26.37113578] w2: [-23.3170484] bias: [15.66459318] loss: 30.531049079842393\n",
      "Epoch: 4933 / 5000 batch step: 30\n",
      "w1: [26.36454945] w2: [-23.31705153] bias: [15.65152036] loss: 30.5357881601127\n",
      "Epoch: 4933 / 5000 batch step: 60\n",
      "w1: [26.34306499] w2: [-23.32405394] bias: [15.61066271] loss: 30.5551458673464\n",
      "Epoch: 4933 / 5000 batch step: 90\n",
      "w1: [26.3364833] w2: [-23.3279905] bias: [15.59539047] loss: 30.56371366224329\n",
      "Epoch: 4933 / 5000 batch step: 120\n",
      "w1: [26.34628159] w2: [-23.29721848] bias: [15.6318643] loss: 30.54355571167881\n",
      "Epoch: 4933 / 5000 batch step: 150\n",
      "w1: [26.38083187] w2: [-23.29572411] bias: [15.67611453] loss: 30.52545318927543\n",
      "Epoch: 4933 / 5000 batch step: 180\n",
      "w1: [26.44824484] w2: [-23.27866733] bias: [15.77841992] loss: 30.513839506548166\n",
      "Epoch: 4933 / 5000 batch step: 210\n",
      "w1: [26.48469182] w2: [-23.25830904] bias: [15.83712184] loss: 30.52611708627351\n",
      "Epoch: 4933 / 5000 batch step: 240\n",
      "w1: [26.52319457] w2: [-23.25245948] bias: [15.87850295] loss: 30.54461345813355\n",
      "Epoch: 4933 / 5000 batch step: 270\n",
      "w1: [26.539516] w2: [-23.25256201] bias: [15.89555994] loss: 30.554352909481803\n",
      "Epoch: 4933 / 5000 batch step: 300\n",
      "w1: [26.51993718] w2: [-23.25872231] bias: [15.85693996] loss: 30.53623596136576\n",
      "Epoch: 4933 / 5000 batch step: 330\n",
      "w1: [26.48403358] w2: [-23.27127202] bias: [15.78619463] loss: 30.516349623823395\n",
      "Epoch: 4933 / 5000 batch step: 360\n",
      "w1: [26.49522104] w2: [-23.2415839] bias: [15.87623943] loss: 30.540105599112753\n",
      "Epoch: 4933 / 5000 batch step: 390\n",
      "w1: [26.46933409] w2: [-23.25344466] bias: [15.84195759] loss: 30.525824792022238\n",
      "Epoch: 4933 / 5000 batch step: 420\n",
      "w1: [26.41975098] w2: [-23.29702556] bias: [15.74668189] loss: 30.51332103401571\n",
      "Epoch: 4933 / 5000 batch step: 450\n",
      "w1: [26.39421345] w2: [-23.31474551] bias: [15.70330672] loss: 30.51978103232417\n",
      "Epoch: 4933 / 5000 batch step: 480\n",
      "w1: [26.37735185] w2: [-23.31615775] bias: [15.67748012] loss: 30.526888935714247\n",
      "Epoch: 4934 / 5000 batch step: 0\n",
      "w1: [26.37113583] w2: [-23.31704838] bias: [15.66459315] loss: 30.531049079712968\n",
      "Epoch: 4934 / 5000 batch step: 30\n",
      "w1: [26.3645495] w2: [-23.31705151] bias: [15.65152033] loss: 30.535788159967293\n",
      "Epoch: 4934 / 5000 batch step: 60\n",
      "w1: [26.34306504] w2: [-23.32405391] bias: [15.61066268] loss: 30.55514586716958\n",
      "Epoch: 4934 / 5000 batch step: 90\n",
      "w1: [26.33648334] w2: [-23.32799048] bias: [15.59539044] loss: 30.56371366206235\n",
      "Epoch: 4934 / 5000 batch step: 120\n",
      "w1: [26.34628164] w2: [-23.29721846] bias: [15.63186427] loss: 30.543555711518735\n",
      "Epoch: 4934 / 5000 batch step: 150\n",
      "w1: [26.38083192] w2: [-23.29572408] bias: [15.6761145] loss: 30.525453189115474\n",
      "Epoch: 4934 / 5000 batch step: 180\n",
      "w1: [26.44824489] w2: [-23.27866731] bias: [15.77841989] loss: 30.51383950641995\n",
      "Epoch: 4934 / 5000 batch step: 210\n",
      "w1: [26.48469186] w2: [-23.25830901] bias: [15.83712181] loss: 30.526117086145963\n",
      "Epoch: 4934 / 5000 batch step: 240\n",
      "w1: [26.52319462] w2: [-23.25245945] bias: [15.87850292] loss: 30.544613457995126\n",
      "Epoch: 4934 / 5000 batch step: 270\n",
      "w1: [26.53951605] w2: [-23.25256198] bias: [15.89555991] loss: 30.554352909348655\n",
      "Epoch: 4934 / 5000 batch step: 300\n",
      "w1: [26.51993723] w2: [-23.25872229] bias: [15.85693993] loss: 30.53623596125866\n",
      "Epoch: 4934 / 5000 batch step: 330\n",
      "w1: [26.48403362] w2: [-23.27127199] bias: [15.7861946] loss: 30.516349623725464\n",
      "Epoch: 4934 / 5000 batch step: 360\n",
      "w1: [26.49522108] w2: [-23.24158388] bias: [15.8762394] loss: 30.540105599017533\n",
      "Epoch: 4934 / 5000 batch step: 390\n",
      "w1: [26.46933414] w2: [-23.25344463] bias: [15.84195756] loss: 30.525824791891253\n",
      "Epoch: 4934 / 5000 batch step: 420\n",
      "w1: [26.41975103] w2: [-23.29702554] bias: [15.74668186] loss: 30.51332103387631\n",
      "Epoch: 4934 / 5000 batch step: 450\n",
      "w1: [26.3942135] w2: [-23.31474548] bias: [15.70330669] loss: 30.5197810322025\n",
      "Epoch: 4934 / 5000 batch step: 480\n",
      "w1: [26.3773519] w2: [-23.31615772] bias: [15.67748009] loss: 30.526888935589703\n",
      "Epoch: 4935 / 5000 batch step: 0\n",
      "w1: [26.37113587] w2: [-23.31704835] bias: [15.66459312] loss: 30.53104907958384\n",
      "Epoch: 4935 / 5000 batch step: 30\n",
      "w1: [26.36454954] w2: [-23.31705148] bias: [15.6515203] loss: 30.53578815982222\n",
      "Epoch: 4935 / 5000 batch step: 60\n",
      "w1: [26.34306508] w2: [-23.32405388] bias: [15.61066265] loss: 30.555145866993147\n",
      "Epoch: 4935 / 5000 batch step: 90\n",
      "w1: [26.33648339] w2: [-23.32799045] bias: [15.5953904] loss: 30.56371366188183\n",
      "Epoch: 4935 / 5000 batch step: 120\n",
      "w1: [26.34628168] w2: [-23.29721843] bias: [15.63186423] loss: 30.543555711359026\n",
      "Epoch: 4935 / 5000 batch step: 150\n",
      "w1: [26.38083196] w2: [-23.29572406] bias: [15.67611447] loss: 30.525453188955886\n",
      "Epoch: 4935 / 5000 batch step: 180\n",
      "w1: [26.44824493] w2: [-23.27866728] bias: [15.77841986] loss: 30.513839506292026\n",
      "Epoch: 4935 / 5000 batch step: 210\n",
      "w1: [26.48469191] w2: [-23.25830899] bias: [15.83712177] loss: 30.52611708601871\n",
      "Epoch: 4935 / 5000 batch step: 240\n",
      "w1: [26.52319467] w2: [-23.25245943] bias: [15.87850289] loss: 30.54461345785701\n",
      "Epoch: 4935 / 5000 batch step: 270\n",
      "w1: [26.53951609] w2: [-23.25256196] bias: [15.89555988] loss: 30.554352909215815\n",
      "Epoch: 4935 / 5000 batch step: 300\n",
      "w1: [26.51993727] w2: [-23.25872226] bias: [15.8569399] loss: 30.536235961151803\n",
      "Epoch: 4935 / 5000 batch step: 330\n",
      "w1: [26.48403367] w2: [-23.27127197] bias: [15.78619456] loss: 30.516349623627747\n",
      "Epoch: 4935 / 5000 batch step: 360\n",
      "w1: [26.49522113] w2: [-23.24158385] bias: [15.87623936] loss: 30.540105598922533\n",
      "Epoch: 4935 / 5000 batch step: 390\n",
      "w1: [26.46933418] w2: [-23.25344461] bias: [15.84195753] loss: 30.52582479176056\n",
      "Epoch: 4935 / 5000 batch step: 420\n",
      "w1: [26.41975107] w2: [-23.29702551] bias: [15.74668182] loss: 30.513321033737228\n",
      "Epoch: 4935 / 5000 batch step: 450\n",
      "w1: [26.39421354] w2: [-23.31474546] bias: [15.70330666] loss: 30.519781032081106\n",
      "Epoch: 4935 / 5000 batch step: 480\n",
      "w1: [26.37735194] w2: [-23.3161577] bias: [15.67748006] loss: 30.52688893546544\n",
      "Epoch: 4936 / 5000 batch step: 0\n",
      "w1: [26.37113592] w2: [-23.31704832] bias: [15.66459309] loss: 30.531049079455002\n",
      "Epoch: 4936 / 5000 batch step: 30\n",
      "w1: [26.36454959] w2: [-23.31705146] bias: [15.65152027] loss: 30.535788159677473\n",
      "Epoch: 4936 / 5000 batch step: 60\n",
      "w1: [26.34306513] w2: [-23.32405386] bias: [15.61066262] loss: 30.55514586681713\n",
      "Epoch: 4936 / 5000 batch step: 90\n",
      "w1: [26.33648344] w2: [-23.32799043] bias: [15.59539037] loss: 30.563713661701716\n",
      "Epoch: 4936 / 5000 batch step: 120\n",
      "w1: [26.34628173] w2: [-23.29721841] bias: [15.6318642] loss: 30.543555711199676\n",
      "Epoch: 4936 / 5000 batch step: 150\n",
      "w1: [26.38083201] w2: [-23.29572403] bias: [15.67611444] loss: 30.525453188796654\n",
      "Epoch: 4936 / 5000 batch step: 180\n",
      "w1: [26.44824498] w2: [-23.27866726] bias: [15.77841983] loss: 30.51383950616439\n",
      "Epoch: 4936 / 5000 batch step: 210\n",
      "w1: [26.48469195] w2: [-23.25830896] bias: [15.83712174] loss: 30.526117085891748\n",
      "Epoch: 4936 / 5000 batch step: 240\n",
      "w1: [26.52319471] w2: [-23.2524594] bias: [15.87850285] loss: 30.544613457719215\n",
      "Epoch: 4936 / 5000 batch step: 270\n",
      "w1: [26.53951614] w2: [-23.25256193] bias: [15.89555985] loss: 30.554352909083274\n",
      "Epoch: 4936 / 5000 batch step: 300\n",
      "w1: [26.51993732] w2: [-23.25872224] bias: [15.85693987] loss: 30.536235961045186\n",
      "Epoch: 4936 / 5000 batch step: 330\n",
      "w1: [26.48403371] w2: [-23.27127194] bias: [15.78619453] loss: 30.516349623530267\n",
      "Epoch: 4936 / 5000 batch step: 360\n",
      "w1: [26.49522117] w2: [-23.24158383] bias: [15.87623933] loss: 30.540105598827736\n",
      "Epoch: 4936 / 5000 batch step: 390\n",
      "w1: [26.46933423] w2: [-23.25344458] bias: [15.8419575] loss: 30.52582479163017\n",
      "Epoch: 4936 / 5000 batch step: 420\n",
      "w1: [26.41975112] w2: [-23.29702549] bias: [15.74668179] loss: 30.513321033598462\n",
      "Epoch: 4936 / 5000 batch step: 450\n",
      "w1: [26.39421359] w2: [-23.31474543] bias: [15.70330663] loss: 30.519781031959994\n",
      "Epoch: 4936 / 5000 batch step: 480\n",
      "w1: [26.37735199] w2: [-23.31615767] bias: [15.67748003] loss: 30.52688893534146\n",
      "Epoch: 4937 / 5000 batch step: 0\n",
      "w1: [26.37113596] w2: [-23.3170483] bias: [15.66459306] loss: 30.531049079326458\n",
      "Epoch: 4937 / 5000 batch step: 30\n",
      "w1: [26.36454964] w2: [-23.31705143] bias: [15.65152023] loss: 30.535788159533062\n",
      "Epoch: 4937 / 5000 batch step: 60\n",
      "w1: [26.34306518] w2: [-23.32405383] bias: [15.61066259] loss: 30.55514586664151\n",
      "Epoch: 4937 / 5000 batch step: 90\n",
      "w1: [26.33648348] w2: [-23.3279904] bias: [15.59539034] loss: 30.563713661522012\n",
      "Epoch: 4937 / 5000 batch step: 120\n",
      "w1: [26.34628177] w2: [-23.29721838] bias: [15.63186417] loss: 30.543555711040707\n",
      "Epoch: 4937 / 5000 batch step: 150\n",
      "w1: [26.38083206] w2: [-23.29572401] bias: [15.67611441] loss: 30.52545318863779\n",
      "Epoch: 4937 / 5000 batch step: 180\n",
      "w1: [26.44824502] w2: [-23.27866723] bias: [15.7784198] loss: 30.51383950603705\n",
      "Epoch: 4937 / 5000 batch step: 210\n",
      "w1: [26.484692] w2: [-23.25830894] bias: [15.83712171] loss: 30.526117085765073\n",
      "Epoch: 4937 / 5000 batch step: 240\n",
      "w1: [26.52319476] w2: [-23.25245938] bias: [15.87850282] loss: 30.544613457581733\n",
      "Epoch: 4937 / 5000 batch step: 270\n",
      "w1: [26.53951618] w2: [-23.25256191] bias: [15.89555982] loss: 30.55435290895103\n",
      "Epoch: 4937 / 5000 batch step: 300\n",
      "w1: [26.51993736] w2: [-23.25872221] bias: [15.85693984] loss: 30.536235960938818\n",
      "Epoch: 4937 / 5000 batch step: 330\n",
      "w1: [26.48403376] w2: [-23.27127192] bias: [15.7861945] loss: 30.516349623432998\n",
      "Epoch: 4937 / 5000 batch step: 360\n",
      "w1: [26.49522122] w2: [-23.2415838] bias: [15.8762393] loss: 30.540105598733167\n",
      "Epoch: 4937 / 5000 batch step: 390\n",
      "w1: [26.46933427] w2: [-23.25344456] bias: [15.84195747] loss: 30.525824791500074\n",
      "Epoch: 4937 / 5000 batch step: 420\n",
      "w1: [26.41975117] w2: [-23.29702546] bias: [15.74668176] loss: 30.513321033460016\n",
      "Epoch: 4937 / 5000 batch step: 450\n",
      "w1: [26.39421364] w2: [-23.31474541] bias: [15.7033066] loss: 30.51978103183916\n",
      "Epoch: 4937 / 5000 batch step: 480\n",
      "w1: [26.37735203] w2: [-23.31615765] bias: [15.67747999] loss: 30.526888935217766\n",
      "Epoch: 4938 / 5000 batch step: 0\n",
      "w1: [26.37113601] w2: [-23.31704827] bias: [15.66459303] loss: 30.5310490791982\n",
      "Epoch: 4938 / 5000 batch step: 30\n",
      "w1: [26.36454968] w2: [-23.31705141] bias: [15.6515202] loss: 30.535788159388975\n",
      "Epoch: 4938 / 5000 batch step: 60\n",
      "w1: [26.34306522] w2: [-23.32405381] bias: [15.61066256] loss: 30.555145866466287\n",
      "Epoch: 4938 / 5000 batch step: 90\n",
      "w1: [26.33648353] w2: [-23.32799038] bias: [15.59539031] loss: 30.563713661342714\n",
      "Epoch: 4938 / 5000 batch step: 120\n",
      "w1: [26.34628182] w2: [-23.29721836] bias: [15.63186414] loss: 30.54355571088208\n",
      "Epoch: 4938 / 5000 batch step: 150\n",
      "w1: [26.3808321] w2: [-23.29572398] bias: [15.67611437] loss: 30.525453188479286\n",
      "Epoch: 4938 / 5000 batch step: 180\n",
      "w1: [26.44824507] w2: [-23.27866721] bias: [15.77841976] loss: 30.513839505909992\n",
      "Epoch: 4938 / 5000 batch step: 210\n",
      "w1: [26.48469205] w2: [-23.25830891] bias: [15.83712168] loss: 30.52611708563869\n",
      "Epoch: 4938 / 5000 batch step: 240\n",
      "w1: [26.5231948] w2: [-23.25245935] bias: [15.87850279] loss: 30.54461345744456\n",
      "Epoch: 4938 / 5000 batch step: 270\n",
      "w1: [26.53951623] w2: [-23.25256188] bias: [15.89555978] loss: 30.554352908819098\n",
      "Epoch: 4938 / 5000 batch step: 300\n",
      "w1: [26.51993741] w2: [-23.25872219] bias: [15.85693981] loss: 30.536235960832677\n",
      "Epoch: 4938 / 5000 batch step: 330\n",
      "w1: [26.4840338] w2: [-23.27127189] bias: [15.78619447] loss: 30.516349623335955\n",
      "Epoch: 4938 / 5000 batch step: 360\n",
      "w1: [26.49522126] w2: [-23.24158378] bias: [15.87623927] loss: 30.540105598638807\n",
      "Epoch: 4938 / 5000 batch step: 390\n",
      "w1: [26.46933432] w2: [-23.25344453] bias: [15.84195743] loss: 30.525824791370276\n",
      "Epoch: 4938 / 5000 batch step: 420\n",
      "w1: [26.41975121] w2: [-23.29702544] bias: [15.74668173] loss: 30.513321033321876\n",
      "Epoch: 4938 / 5000 batch step: 450\n",
      "w1: [26.39421368] w2: [-23.31474538] bias: [15.70330656] loss: 30.519781031718594\n",
      "Epoch: 4938 / 5000 batch step: 480\n",
      "w1: [26.37735208] w2: [-23.31615762] bias: [15.67747996] loss: 30.526888935094348\n",
      "Epoch: 4939 / 5000 batch step: 0\n",
      "w1: [26.37113605] w2: [-23.31704825] bias: [15.66459299] loss: 30.531049079070243\n",
      "Epoch: 4939 / 5000 batch step: 30\n",
      "w1: [26.36454973] w2: [-23.31705138] bias: [15.65152017] loss: 30.535788159245215\n",
      "Epoch: 4939 / 5000 batch step: 60\n",
      "w1: [26.34306527] w2: [-23.32405378] bias: [15.61066252] loss: 30.555145866291465\n",
      "Epoch: 4939 / 5000 batch step: 90\n",
      "w1: [26.33648357] w2: [-23.32799035] bias: [15.59539028] loss: 30.563713661163828\n",
      "Epoch: 4939 / 5000 batch step: 120\n",
      "w1: [26.34628186] w2: [-23.29721833] bias: [15.63186411] loss: 30.543555710723822\n",
      "Epoch: 4939 / 5000 batch step: 150\n",
      "w1: [26.38083215] w2: [-23.29572396] bias: [15.67611434] loss: 30.52545318832114\n",
      "Epoch: 4939 / 5000 batch step: 180\n",
      "w1: [26.44824512] w2: [-23.27866718] bias: [15.77841973] loss: 30.513839505783228\n",
      "Epoch: 4939 / 5000 batch step: 210\n",
      "w1: [26.48469209] w2: [-23.25830889] bias: [15.83712165] loss: 30.526117085512585\n",
      "Epoch: 4939 / 5000 batch step: 240\n",
      "w1: [26.52319485] w2: [-23.25245933] bias: [15.87850276] loss: 30.544613457307694\n",
      "Epoch: 4939 / 5000 batch step: 270\n",
      "w1: [26.53951627] w2: [-23.25256186] bias: [15.89555975] loss: 30.554352908687456\n",
      "Epoch: 4939 / 5000 batch step: 300\n",
      "w1: [26.51993746] w2: [-23.25872216] bias: [15.85693977] loss: 30.536235960726792\n",
      "Epoch: 4939 / 5000 batch step: 330\n",
      "w1: [26.48403385] w2: [-23.27127187] bias: [15.78619444] loss: 30.51634962323913\n",
      "Epoch: 4939 / 5000 batch step: 360\n",
      "w1: [26.49522131] w2: [-23.24158375] bias: [15.87623924] loss: 30.540105598544663\n",
      "Epoch: 4939 / 5000 batch step: 390\n",
      "w1: [26.46933436] w2: [-23.25344451] bias: [15.8419574] loss: 30.525824791240762\n",
      "Epoch: 4939 / 5000 batch step: 420\n",
      "w1: [26.41975126] w2: [-23.29702541] bias: [15.7466817] loss: 30.513321033184063\n",
      "Epoch: 4939 / 5000 batch step: 450\n",
      "w1: [26.39421373] w2: [-23.31474536] bias: [15.70330653] loss: 30.519781031598303\n",
      "Epoch: 4939 / 5000 batch step: 480\n",
      "w1: [26.37735212] w2: [-23.3161576] bias: [15.67747993] loss: 30.526888934971204\n",
      "Epoch: 4940 / 5000 batch step: 0\n",
      "w1: [26.3711361] w2: [-23.31704822] bias: [15.66459296] loss: 30.531049078942576\n",
      "Epoch: 4940 / 5000 batch step: 30\n",
      "w1: [26.36454977] w2: [-23.31705136] bias: [15.65152014] loss: 30.53578815910178\n",
      "Epoch: 4940 / 5000 batch step: 60\n",
      "w1: [26.34306531] w2: [-23.32405376] bias: [15.61066249] loss: 30.555145866117037\n",
      "Epoch: 4940 / 5000 batch step: 90\n",
      "w1: [26.33648362] w2: [-23.32799033] bias: [15.59539025] loss: 30.563713660985346\n",
      "Epoch: 4940 / 5000 batch step: 120\n",
      "w1: [26.34628191] w2: [-23.29721831] bias: [15.63186408] loss: 30.54355571056592\n",
      "Epoch: 4940 / 5000 batch step: 150\n",
      "w1: [26.38083219] w2: [-23.29572393] bias: [15.67611431] loss: 30.525453188163358\n",
      "Epoch: 4940 / 5000 batch step: 180\n",
      "w1: [26.44824516] w2: [-23.27866716] bias: [15.7784197] loss: 30.513839505656758\n",
      "Epoch: 4940 / 5000 batch step: 210\n",
      "w1: [26.48469214] w2: [-23.25830886] bias: [15.83712162] loss: 30.526117085386772\n",
      "Epoch: 4940 / 5000 batch step: 240\n",
      "w1: [26.52319489] w2: [-23.2524593] bias: [15.87850273] loss: 30.54461345717115\n",
      "Epoch: 4940 / 5000 batch step: 270\n",
      "w1: [26.53951632] w2: [-23.25256183] bias: [15.89555972] loss: 30.554352908556123\n",
      "Epoch: 4940 / 5000 batch step: 300\n",
      "w1: [26.5199375] w2: [-23.25872214] bias: [15.85693974] loss: 30.536235960621145\n",
      "Epoch: 4940 / 5000 batch step: 330\n",
      "w1: [26.4840339] w2: [-23.27127184] bias: [15.78619441] loss: 30.516349623142528\n",
      "Epoch: 4940 / 5000 batch step: 360\n",
      "w1: [26.49522136] w2: [-23.24158373] bias: [15.87623921] loss: 30.540105598450744\n",
      "Epoch: 4940 / 5000 batch step: 390\n",
      "w1: [26.46933441] w2: [-23.25344448] bias: [15.84195737] loss: 30.525824791111557\n",
      "Epoch: 4940 / 5000 batch step: 420\n",
      "w1: [26.4197513] w2: [-23.29702539] bias: [15.74668167] loss: 30.51332103304655\n",
      "Epoch: 4940 / 5000 batch step: 450\n",
      "w1: [26.39421377] w2: [-23.31474533] bias: [15.7033065] loss: 30.51978103147829\n",
      "Epoch: 4940 / 5000 batch step: 480\n",
      "w1: [26.37735217] w2: [-23.31615757] bias: [15.6774799] loss: 30.526888934848355\n",
      "Epoch: 4941 / 5000 batch step: 0\n",
      "w1: [26.37113615] w2: [-23.3170482] bias: [15.66459293] loss: 30.531049078815197\n",
      "Epoch: 4941 / 5000 batch step: 30\n",
      "w1: [26.36454982] w2: [-23.31705133] bias: [15.65152011] loss: 30.535788158958674\n",
      "Epoch: 4941 / 5000 batch step: 60\n",
      "w1: [26.34306536] w2: [-23.32405373] bias: [15.61066246] loss: 30.555145865943008\n",
      "Epoch: 4941 / 5000 batch step: 90\n",
      "w1: [26.33648366] w2: [-23.3279903] bias: [15.59539021] loss: 30.563713660807267\n",
      "Epoch: 4941 / 5000 batch step: 120\n",
      "w1: [26.34628196] w2: [-23.29721828] bias: [15.63186405] loss: 30.54355571040838\n",
      "Epoch: 4941 / 5000 batch step: 150\n",
      "w1: [26.38083224] w2: [-23.29572391] bias: [15.67611428] loss: 30.52545318800593\n",
      "Epoch: 4941 / 5000 batch step: 180\n",
      "w1: [26.44824521] w2: [-23.27866713] bias: [15.77841967] loss: 30.513839505530566\n",
      "Epoch: 4941 / 5000 batch step: 210\n",
      "w1: [26.48469218] w2: [-23.25830884] bias: [15.83712159] loss: 30.526117085261244\n",
      "Epoch: 4941 / 5000 batch step: 240\n",
      "w1: [26.52319494] w2: [-23.25245928] bias: [15.8785027] loss: 30.544613457034902\n",
      "Epoch: 4941 / 5000 batch step: 270\n",
      "w1: [26.53951636] w2: [-23.25256181] bias: [15.89555969] loss: 30.554352908425074\n",
      "Epoch: 4941 / 5000 batch step: 300\n",
      "w1: [26.51993755] w2: [-23.25872211] bias: [15.85693971] loss: 30.53623596051573\n",
      "Epoch: 4941 / 5000 batch step: 330\n",
      "w1: [26.48403394] w2: [-23.27127182] bias: [15.78619438] loss: 30.516349623046146\n",
      "Epoch: 4941 / 5000 batch step: 360\n",
      "w1: [26.4952214] w2: [-23.2415837] bias: [15.87623918] loss: 30.54010559835702\n",
      "Epoch: 4941 / 5000 batch step: 390\n",
      "w1: [26.46933445] w2: [-23.25344446] bias: [15.84195734] loss: 30.525824790982643\n",
      "Epoch: 4941 / 5000 batch step: 420\n",
      "w1: [26.41975135] w2: [-23.29702536] bias: [15.74668164] loss: 30.513321032909356\n",
      "Epoch: 4941 / 5000 batch step: 450\n",
      "w1: [26.39421382] w2: [-23.31474531] bias: [15.70330647] loss: 30.519781031358548\n",
      "Epoch: 4941 / 5000 batch step: 480\n",
      "w1: [26.37735221] w2: [-23.31615755] bias: [15.67747987] loss: 30.52688893472578\n",
      "Epoch: 4942 / 5000 batch step: 0\n",
      "w1: [26.37113619] w2: [-23.31704817] bias: [15.6645929] loss: 30.53104907868811\n",
      "Epoch: 4942 / 5000 batch step: 30\n",
      "w1: [26.36454986] w2: [-23.31705131] bias: [15.65152008] loss: 30.535788158815894\n",
      "Epoch: 4942 / 5000 batch step: 60\n",
      "w1: [26.3430654] w2: [-23.32405371] bias: [15.61066243] loss: 30.55514586576938\n",
      "Epoch: 4942 / 5000 batch step: 90\n",
      "w1: [26.33648371] w2: [-23.32799028] bias: [15.59539018] loss: 30.563713660629595\n",
      "Epoch: 4942 / 5000 batch step: 120\n",
      "w1: [26.346282] w2: [-23.29721826] bias: [15.63186401] loss: 30.5435557102512\n",
      "Epoch: 4942 / 5000 batch step: 150\n",
      "w1: [26.38083228] w2: [-23.29572388] bias: [15.67611425] loss: 30.525453187848857\n",
      "Epoch: 4942 / 5000 batch step: 180\n",
      "w1: [26.44824525] w2: [-23.27866711] bias: [15.77841964] loss: 30.513839505404658\n",
      "Epoch: 4942 / 5000 batch step: 210\n",
      "w1: [26.48469223] w2: [-23.25830881] bias: [15.83712155] loss: 30.526117085136008\n",
      "Epoch: 4942 / 5000 batch step: 240\n",
      "w1: [26.52319498] w2: [-23.25245925] bias: [15.87850267] loss: 30.544613456898983\n",
      "Epoch: 4942 / 5000 batch step: 270\n",
      "w1: [26.53951641] w2: [-23.25256178] bias: [15.89555966] loss: 30.554352908294334\n",
      "Epoch: 4942 / 5000 batch step: 300\n",
      "w1: [26.51993759] w2: [-23.25872209] bias: [15.85693968] loss: 30.53623596041056\n",
      "Epoch: 4942 / 5000 batch step: 330\n",
      "w1: [26.48403399] w2: [-23.27127179] bias: [15.78619434] loss: 30.516349622949978\n",
      "Epoch: 4942 / 5000 batch step: 360\n",
      "w1: [26.49522145] w2: [-23.24158368] bias: [15.87623914] loss: 30.540105598263523\n",
      "Epoch: 4942 / 5000 batch step: 390\n",
      "w1: [26.4693345] w2: [-23.25344443] bias: [15.84195731] loss: 30.525824790854013\n",
      "Epoch: 4942 / 5000 batch step: 420\n",
      "w1: [26.41975139] w2: [-23.29702534] bias: [15.7466816] loss: 30.513321032772478\n",
      "Epoch: 4942 / 5000 batch step: 450\n",
      "w1: [26.39421386] w2: [-23.31474528] bias: [15.70330644] loss: 30.519781031239077\n",
      "Epoch: 4942 / 5000 batch step: 480\n",
      "w1: [26.37735226] w2: [-23.31615752] bias: [15.67747984] loss: 30.52688893460348\n",
      "Epoch: 4943 / 5000 batch step: 0\n",
      "w1: [26.37113624] w2: [-23.31704815] bias: [15.66459287] loss: 30.531049078561313\n",
      "Epoch: 4943 / 5000 batch step: 30\n",
      "w1: [26.36454991] w2: [-23.31705128] bias: [15.65152005] loss: 30.53578815867344\n",
      "Epoch: 4943 / 5000 batch step: 60\n",
      "w1: [26.34306545] w2: [-23.32405368] bias: [15.6106624] loss: 30.555145865596135\n",
      "Epoch: 4943 / 5000 batch step: 90\n",
      "w1: [26.33648376] w2: [-23.32799025] bias: [15.59539015] loss: 30.563713660452333\n",
      "Epoch: 4943 / 5000 batch step: 120\n",
      "w1: [26.34628205] w2: [-23.29721823] bias: [15.63186398] loss: 30.543555710094374\n",
      "Epoch: 4943 / 5000 batch step: 150\n",
      "w1: [26.38083233] w2: [-23.29572386] bias: [15.67611422] loss: 30.525453187692154\n",
      "Epoch: 4943 / 5000 batch step: 180\n",
      "w1: [26.4482453] w2: [-23.27866708] bias: [15.77841961] loss: 30.513839505279048\n",
      "Epoch: 4943 / 5000 batch step: 210\n",
      "w1: [26.48469227] w2: [-23.25830879] bias: [15.83712152] loss: 30.526117085011048\n",
      "Epoch: 4943 / 5000 batch step: 240\n",
      "w1: [26.52319503] w2: [-23.25245923] bias: [15.87850263] loss: 30.544613456763358\n",
      "Epoch: 4943 / 5000 batch step: 270\n",
      "w1: [26.53951646] w2: [-23.25256176] bias: [15.89555963] loss: 30.55435290816389\n",
      "Epoch: 4943 / 5000 batch step: 300\n",
      "w1: [26.51993764] w2: [-23.25872206] bias: [15.85693965] loss: 30.53623596030563\n",
      "Epoch: 4943 / 5000 batch step: 330\n",
      "w1: [26.48403403] w2: [-23.27127177] bias: [15.78619431] loss: 30.516349622854033\n",
      "Epoch: 4943 / 5000 batch step: 360\n",
      "w1: [26.49522149] w2: [-23.24158365] bias: [15.87623911] loss: 30.540105598170232\n",
      "Epoch: 4943 / 5000 batch step: 390\n",
      "w1: [26.46933454] w2: [-23.25344441] bias: [15.84195728] loss: 30.525824790725686\n",
      "Epoch: 4943 / 5000 batch step: 420\n",
      "w1: [26.41975144] w2: [-23.29702531] bias: [15.74668157] loss: 30.513321032635904\n",
      "Epoch: 4943 / 5000 batch step: 450\n",
      "w1: [26.39421391] w2: [-23.31474526] bias: [15.70330641] loss: 30.51978103111988\n",
      "Epoch: 4943 / 5000 batch step: 480\n",
      "w1: [26.3773523] w2: [-23.3161575] bias: [15.67747981] loss: 30.52688893448146\n",
      "Epoch: 4944 / 5000 batch step: 0\n",
      "w1: [26.37113628] w2: [-23.31704813] bias: [15.66459284] loss: 30.531049078434798\n",
      "Epoch: 4944 / 5000 batch step: 30\n",
      "w1: [26.36454995] w2: [-23.31705126] bias: [15.65152002] loss: 30.535788158531314\n",
      "Epoch: 4944 / 5000 batch step: 60\n",
      "w1: [26.34306549] w2: [-23.32405366] bias: [15.61066237] loss: 30.555145865423295\n",
      "Epoch: 4944 / 5000 batch step: 90\n",
      "w1: [26.3364838] w2: [-23.32799023] bias: [15.59539012] loss: 30.563713660275468\n",
      "Epoch: 4944 / 5000 batch step: 120\n",
      "w1: [26.34628209] w2: [-23.29721821] bias: [15.63186395] loss: 30.543555709937905\n",
      "Epoch: 4944 / 5000 batch step: 150\n",
      "w1: [26.38083237] w2: [-23.29572383] bias: [15.67611419] loss: 30.525453187535796\n",
      "Epoch: 4944 / 5000 batch step: 180\n",
      "w1: [26.44824534] w2: [-23.27866706] bias: [15.77841958] loss: 30.51383950515371\n",
      "Epoch: 4944 / 5000 batch step: 210\n",
      "w1: [26.48469232] w2: [-23.25830876] bias: [15.83712149] loss: 30.526117084886376\n",
      "Epoch: 4944 / 5000 batch step: 240\n",
      "w1: [26.52319507] w2: [-23.2524592] bias: [15.8785026] loss: 30.544613456628046\n",
      "Epoch: 4944 / 5000 batch step: 270\n",
      "w1: [26.5395165] w2: [-23.25256173] bias: [15.8955596] loss: 30.554352908033742\n",
      "Epoch: 4944 / 5000 batch step: 300\n",
      "w1: [26.51993768] w2: [-23.25872204] bias: [15.85693962] loss: 30.536235960200944\n",
      "Epoch: 4944 / 5000 batch step: 330\n",
      "w1: [26.48403408] w2: [-23.27127174] bias: [15.78619428] loss: 30.51634962275831\n",
      "Epoch: 4944 / 5000 batch step: 360\n",
      "w1: [26.49522154] w2: [-23.24158363] bias: [15.87623908] loss: 30.540105598077155\n",
      "Epoch: 4944 / 5000 batch step: 390\n",
      "w1: [26.46933459] w2: [-23.25344438] bias: [15.84195725] loss: 30.525824790597643\n",
      "Epoch: 4944 / 5000 batch step: 420\n",
      "w1: [26.41975148] w2: [-23.29702529] bias: [15.74668154] loss: 30.513321032499643\n",
      "Epoch: 4944 / 5000 batch step: 450\n",
      "w1: [26.39421395] w2: [-23.31474523] bias: [15.70330638] loss: 30.519781031000953\n",
      "Epoch: 4944 / 5000 batch step: 480\n",
      "w1: [26.37735235] w2: [-23.31615748] bias: [15.67747977] loss: 30.526888934359715\n",
      "Epoch: 4945 / 5000 batch step: 0\n",
      "w1: [26.37113633] w2: [-23.3170481] bias: [15.66459281] loss: 30.531049078308573\n",
      "Epoch: 4945 / 5000 batch step: 30\n",
      "w1: [26.36455] w2: [-23.31705123] bias: [15.65151998] loss: 30.5357881583895\n",
      "Epoch: 4945 / 5000 batch step: 60\n",
      "w1: [26.34306554] w2: [-23.32405364] bias: [15.61066234] loss: 30.55514586525084\n",
      "Epoch: 4945 / 5000 batch step: 90\n",
      "w1: [26.33648385] w2: [-23.3279902] bias: [15.59539009] loss: 30.56371366009901\n",
      "Epoch: 4945 / 5000 batch step: 120\n",
      "w1: [26.34628214] w2: [-23.29721818] bias: [15.63186392] loss: 30.543555709781796\n",
      "Epoch: 4945 / 5000 batch step: 150\n",
      "w1: [26.38083242] w2: [-23.29572381] bias: [15.67611416] loss: 30.5254531873798\n",
      "Epoch: 4945 / 5000 batch step: 180\n",
      "w1: [26.44824539] w2: [-23.27866703] bias: [15.77841955] loss: 30.51383950502867\n",
      "Epoch: 4945 / 5000 batch step: 210\n",
      "w1: [26.48469236] w2: [-23.25830874] bias: [15.83712146] loss: 30.526117084761985\n",
      "Epoch: 4945 / 5000 batch step: 240\n",
      "w1: [26.52319512] w2: [-23.25245918] bias: [15.87850257] loss: 30.544613456493042\n",
      "Epoch: 4945 / 5000 batch step: 270\n",
      "w1: [26.53951655] w2: [-23.25256171] bias: [15.89555957] loss: 30.554352907903887\n",
      "Epoch: 4945 / 5000 batch step: 300\n",
      "w1: [26.51993773] w2: [-23.25872201] bias: [15.85693959] loss: 30.536235960096487\n",
      "Epoch: 4945 / 5000 batch step: 330\n",
      "w1: [26.48403412] w2: [-23.27127172] bias: [15.78619425] loss: 30.516349622662798\n",
      "Epoch: 4945 / 5000 batch step: 360\n",
      "w1: [26.49522158] w2: [-23.2415836] bias: [15.87623905] loss: 30.54010559798429\n",
      "Epoch: 4945 / 5000 batch step: 390\n",
      "w1: [26.46933463] w2: [-23.25344436] bias: [15.84195722] loss: 30.525824790469898\n",
      "Epoch: 4945 / 5000 batch step: 420\n",
      "w1: [26.41975153] w2: [-23.29702526] bias: [15.74668151] loss: 30.51332103236369\n",
      "Epoch: 4945 / 5000 batch step: 450\n",
      "w1: [26.394214] w2: [-23.31474521] bias: [15.70330634] loss: 30.519781030882292\n",
      "Epoch: 4945 / 5000 batch step: 480\n",
      "w1: [26.37735239] w2: [-23.31615745] bias: [15.67747974] loss: 30.526888934238247\n",
      "Epoch: 4946 / 5000 batch step: 0\n",
      "w1: [26.37113637] w2: [-23.31704808] bias: [15.66459277] loss: 30.531049078182637\n",
      "Epoch: 4946 / 5000 batch step: 30\n",
      "w1: [26.36455004] w2: [-23.31705121] bias: [15.65151995] loss: 30.535788158248014\n",
      "Epoch: 4946 / 5000 batch step: 60\n",
      "w1: [26.34306558] w2: [-23.32405361] bias: [15.61066231] loss: 30.555145865078785\n",
      "Epoch: 4946 / 5000 batch step: 90\n",
      "w1: [26.33648389] w2: [-23.32799018] bias: [15.59539006] loss: 30.563713659922946\n",
      "Epoch: 4946 / 5000 batch step: 120\n",
      "w1: [26.34628218] w2: [-23.29721816] bias: [15.63186389] loss: 30.54355570962604\n",
      "Epoch: 4946 / 5000 batch step: 150\n",
      "w1: [26.38083246] w2: [-23.29572378] bias: [15.67611412] loss: 30.525453187224155\n",
      "Epoch: 4946 / 5000 batch step: 180\n",
      "w1: [26.44824543] w2: [-23.27866701] bias: [15.77841951] loss: 30.51383950490391\n",
      "Epoch: 4946 / 5000 batch step: 210\n",
      "w1: [26.48469241] w2: [-23.25830871] bias: [15.83712143] loss: 30.526117084637885\n",
      "Epoch: 4946 / 5000 batch step: 240\n",
      "w1: [26.52319516] w2: [-23.25245915] bias: [15.87850254] loss: 30.544613456358345\n",
      "Epoch: 4946 / 5000 batch step: 270\n",
      "w1: [26.53951659] w2: [-23.25256168] bias: [15.89555953] loss: 30.554352907774337\n",
      "Epoch: 4946 / 5000 batch step: 300\n",
      "w1: [26.51993777] w2: [-23.25872199] bias: [15.85693956] loss: 30.536235959992272\n",
      "Epoch: 4946 / 5000 batch step: 330\n",
      "w1: [26.48403417] w2: [-23.27127169] bias: [15.78619422] loss: 30.516349622567503\n",
      "Epoch: 4946 / 5000 batch step: 360\n",
      "w1: [26.49522163] w2: [-23.24158358] bias: [15.87623902] loss: 30.540105597891635\n",
      "Epoch: 4946 / 5000 batch step: 390\n",
      "w1: [26.46933468] w2: [-23.25344434] bias: [15.84195718] loss: 30.525824790342437\n",
      "Epoch: 4946 / 5000 batch step: 420\n",
      "w1: [26.41975157] w2: [-23.29702524] bias: [15.74668148] loss: 30.513321032228053\n",
      "Epoch: 4946 / 5000 batch step: 450\n",
      "w1: [26.39421404] w2: [-23.31474518] bias: [15.70330631] loss: 30.51978103076391\n",
      "Epoch: 4946 / 5000 batch step: 480\n",
      "w1: [26.37735244] w2: [-23.31615743] bias: [15.67747971] loss: 30.52688893411706\n",
      "Epoch: 4947 / 5000 batch step: 0\n",
      "w1: [26.37113642] w2: [-23.31704805] bias: [15.66459274] loss: 30.531049078056988\n",
      "Epoch: 4947 / 5000 batch step: 30\n",
      "w1: [26.36455009] w2: [-23.31705118] bias: [15.65151992] loss: 30.535788158106847\n",
      "Epoch: 4947 / 5000 batch step: 60\n",
      "w1: [26.34306563] w2: [-23.32405359] bias: [15.61066228] loss: 30.55514586490711\n",
      "Epoch: 4947 / 5000 batch step: 90\n",
      "w1: [26.33648394] w2: [-23.32799015] bias: [15.59539003] loss: 30.563713659747286\n",
      "Epoch: 4947 / 5000 batch step: 120\n",
      "w1: [26.34628223] w2: [-23.29721814] bias: [15.63186386] loss: 30.54355570947063\n",
      "Epoch: 4947 / 5000 batch step: 150\n",
      "w1: [26.38083251] w2: [-23.29572376] bias: [15.67611409] loss: 30.525453187068866\n",
      "Epoch: 4947 / 5000 batch step: 180\n",
      "w1: [26.44824548] w2: [-23.27866698] bias: [15.77841948] loss: 30.51383950477943\n",
      "Epoch: 4947 / 5000 batch step: 210\n",
      "w1: [26.48469245] w2: [-23.25830869] bias: [15.8371214] loss: 30.526117084514063\n",
      "Epoch: 4947 / 5000 batch step: 240\n",
      "w1: [26.52319521] w2: [-23.25245913] bias: [15.87850251] loss: 30.54461345622396\n",
      "Epoch: 4947 / 5000 batch step: 270\n",
      "w1: [26.53951663] w2: [-23.25256166] bias: [15.8955595] loss: 30.554352907645075\n",
      "Epoch: 4947 / 5000 batch step: 300\n",
      "w1: [26.51993782] w2: [-23.25872196] bias: [15.85693953] loss: 30.53623595988829\n",
      "Epoch: 4947 / 5000 batch step: 330\n",
      "w1: [26.48403421] w2: [-23.27127167] bias: [15.78619419] loss: 30.51634962247243\n",
      "Epoch: 4947 / 5000 batch step: 360\n",
      "w1: [26.49522167] w2: [-23.24158355] bias: [15.87623899] loss: 30.540105597799194\n",
      "Epoch: 4947 / 5000 batch step: 390\n",
      "w1: [26.46933472] w2: [-23.25344431] bias: [15.84195715] loss: 30.52582479021527\n",
      "Epoch: 4947 / 5000 batch step: 420\n",
      "w1: [26.41975162] w2: [-23.29702521] bias: [15.74668145] loss: 30.51332103209272\n",
      "Epoch: 4947 / 5000 batch step: 450\n",
      "w1: [26.39421409] w2: [-23.31474516] bias: [15.70330628] loss: 30.519781030645788\n",
      "Epoch: 4947 / 5000 batch step: 480\n",
      "w1: [26.37735248] w2: [-23.3161574] bias: [15.67747968] loss: 30.526888933996148\n",
      "Epoch: 4948 / 5000 batch step: 0\n",
      "w1: [26.37113646] w2: [-23.31704803] bias: [15.66459271] loss: 30.531049077931623\n",
      "Epoch: 4948 / 5000 batch step: 30\n",
      "w1: [26.36455013] w2: [-23.31705116] bias: [15.65151989] loss: 30.535788157966007\n",
      "Epoch: 4948 / 5000 batch step: 60\n",
      "w1: [26.34306567] w2: [-23.32405356] bias: [15.61066224] loss: 30.555145864735827\n",
      "Epoch: 4948 / 5000 batch step: 90\n",
      "w1: [26.33648398] w2: [-23.32799013] bias: [15.59539] loss: 30.563713659572027\n",
      "Epoch: 4948 / 5000 batch step: 120\n",
      "w1: [26.34628227] w2: [-23.29721811] bias: [15.63186383] loss: 30.543555709315587\n",
      "Epoch: 4948 / 5000 batch step: 150\n",
      "w1: [26.38083255] w2: [-23.29572374] bias: [15.67611406] loss: 30.525453186913925\n",
      "Epoch: 4948 / 5000 batch step: 180\n",
      "w1: [26.44824552] w2: [-23.27866696] bias: [15.77841945] loss: 30.513839504655238\n",
      "Epoch: 4948 / 5000 batch step: 210\n",
      "w1: [26.4846925] w2: [-23.25830867] bias: [15.83712137] loss: 30.526117084390517\n",
      "Epoch: 4948 / 5000 batch step: 240\n",
      "w1: [26.52319525] w2: [-23.2524591] bias: [15.87850248] loss: 30.54461345608987\n",
      "Epoch: 4948 / 5000 batch step: 270\n",
      "w1: [26.53951668] w2: [-23.25256163] bias: [15.89555947] loss: 30.554352907516105\n",
      "Epoch: 4948 / 5000 batch step: 300\n",
      "w1: [26.51993786] w2: [-23.25872194] bias: [15.85693949] loss: 30.536235959784555\n",
      "Epoch: 4948 / 5000 batch step: 330\n",
      "w1: [26.48403426] w2: [-23.27127164] bias: [15.78619416] loss: 30.51634962237757\n",
      "Epoch: 4948 / 5000 batch step: 360\n",
      "w1: [26.49522172] w2: [-23.24158353] bias: [15.87623896] loss: 30.54010559770696\n",
      "Epoch: 4948 / 5000 batch step: 390\n",
      "w1: [26.46933477] w2: [-23.25344429] bias: [15.84195712] loss: 30.525824790088393\n",
      "Epoch: 4948 / 5000 batch step: 420\n",
      "w1: [26.41975166] w2: [-23.29702519] bias: [15.74668142] loss: 30.513321031957688\n",
      "Epoch: 4948 / 5000 batch step: 450\n",
      "w1: [26.39421413] w2: [-23.31474513] bias: [15.70330625] loss: 30.51978103052794\n",
      "Epoch: 4948 / 5000 batch step: 480\n",
      "w1: [26.37735253] w2: [-23.31615738] bias: [15.67747965] loss: 30.526888933875505\n",
      "Epoch: 4949 / 5000 batch step: 0\n",
      "w1: [26.3711365] w2: [-23.317048] bias: [15.66459268] loss: 30.531049077806543\n",
      "Epoch: 4949 / 5000 batch step: 30\n",
      "w1: [26.36455018] w2: [-23.31705113] bias: [15.65151986] loss: 30.535788157825483\n",
      "Epoch: 4949 / 5000 batch step: 60\n",
      "w1: [26.34306572] w2: [-23.32405354] bias: [15.61066221] loss: 30.555145864564945\n",
      "Epoch: 4949 / 5000 batch step: 90\n",
      "w1: [26.33648402] w2: [-23.32799011] bias: [15.59538997] loss: 30.56371365939716\n",
      "Epoch: 4949 / 5000 batch step: 120\n",
      "w1: [26.34628231] w2: [-23.29721809] bias: [15.6318638] loss: 30.54355570916088\n",
      "Epoch: 4949 / 5000 batch step: 150\n",
      "w1: [26.3808326] w2: [-23.29572371] bias: [15.67611403] loss: 30.52545318675934\n",
      "Epoch: 4949 / 5000 batch step: 180\n",
      "w1: [26.44824557] w2: [-23.27866693] bias: [15.77841942] loss: 30.51383950453133\n",
      "Epoch: 4949 / 5000 batch step: 210\n",
      "w1: [26.48469254] w2: [-23.25830864] bias: [15.83712134] loss: 30.526117084267256\n",
      "Epoch: 4949 / 5000 batch step: 240\n",
      "w1: [26.5231953] w2: [-23.25245908] bias: [15.87850245] loss: 30.544613455956092\n",
      "Epoch: 4949 / 5000 batch step: 270\n",
      "w1: [26.53951672] w2: [-23.25256161] bias: [15.89555944] loss: 30.55435290738743\n",
      "Epoch: 4949 / 5000 batch step: 300\n",
      "w1: [26.51993791] w2: [-23.25872191] bias: [15.85693946] loss: 30.536235959681047\n",
      "Epoch: 4949 / 5000 batch step: 330\n",
      "w1: [26.4840343] w2: [-23.27127162] bias: [15.78619413] loss: 30.516349622282924\n",
      "Epoch: 4949 / 5000 batch step: 360\n",
      "w1: [26.49522176] w2: [-23.2415835] bias: [15.87623893] loss: 30.54010559761494\n",
      "Epoch: 4949 / 5000 batch step: 390\n",
      "w1: [26.46933481] w2: [-23.25344426] bias: [15.84195709] loss: 30.525824789961806\n",
      "Epoch: 4949 / 5000 batch step: 420\n",
      "w1: [26.41975171] w2: [-23.29702516] bias: [15.74668139] loss: 30.513321031822976\n",
      "Epoch: 4949 / 5000 batch step: 450\n",
      "w1: [26.39421418] w2: [-23.31474511] bias: [15.70330622] loss: 30.51978103041036\n",
      "Epoch: 4949 / 5000 batch step: 480\n",
      "w1: [26.37735257] w2: [-23.31615735] bias: [15.67747962] loss: 30.526888933755142\n",
      "Epoch: 4950 / 5000 batch step: 0\n",
      "w1: [26.37113655] w2: [-23.31704798] bias: [15.66459265] loss: 30.53104907768175\n",
      "Epoch: 4950 / 5000 batch step: 30\n",
      "w1: [26.36455022] w2: [-23.31705111] bias: [15.65151983] loss: 30.535788157685282\n",
      "Epoch: 4950 / 5000 batch step: 60\n",
      "w1: [26.34306576] w2: [-23.32405351] bias: [15.61066218] loss: 30.555145864394447\n",
      "Epoch: 4950 / 5000 batch step: 90\n",
      "w1: [26.33648407] w2: [-23.32799008] bias: [15.59538994] loss: 30.563713659222703\n",
      "Epoch: 4950 / 5000 batch step: 120\n",
      "w1: [26.34628236] w2: [-23.29721806] bias: [15.63186377] loss: 30.54355570900654\n",
      "Epoch: 4950 / 5000 batch step: 150\n",
      "w1: [26.38083264] w2: [-23.29572369] bias: [15.676114] loss: 30.52545318660511\n",
      "Epoch: 4950 / 5000 batch step: 180\n",
      "w1: [26.44824561] w2: [-23.27866691] bias: [15.77841939] loss: 30.5138395044077\n",
      "Epoch: 4950 / 5000 batch step: 210\n",
      "w1: [26.48469259] w2: [-23.25830862] bias: [15.83712131] loss: 30.52611708414428\n",
      "Epoch: 4950 / 5000 batch step: 240\n",
      "w1: [26.52319534] w2: [-23.25245906] bias: [15.87850242] loss: 30.54461345582261\n",
      "Epoch: 4950 / 5000 batch step: 270\n",
      "w1: [26.53951677] w2: [-23.25256159] bias: [15.89555941] loss: 30.554352907259037\n",
      "Epoch: 4950 / 5000 batch step: 300\n",
      "w1: [26.51993795] w2: [-23.25872189] bias: [15.85693943] loss: 30.53623595957777\n",
      "Epoch: 4950 / 5000 batch step: 330\n",
      "w1: [26.48403434] w2: [-23.27127159] bias: [15.7861941] loss: 30.5163496221885\n",
      "Epoch: 4950 / 5000 batch step: 360\n",
      "w1: [26.4952218] w2: [-23.24158348] bias: [15.8762389] loss: 30.540105597523127\n",
      "Epoch: 4950 / 5000 batch step: 390\n",
      "w1: [26.46933486] w2: [-23.25344424] bias: [15.84195706] loss: 30.5258247898355\n",
      "Epoch: 4950 / 5000 batch step: 420\n",
      "w1: [26.41975175] w2: [-23.29702514] bias: [15.74668136] loss: 30.513321031688566\n",
      "Epoch: 4950 / 5000 batch step: 450\n",
      "w1: [26.39421422] w2: [-23.31474508] bias: [15.70330619] loss: 30.519781030293046\n",
      "Epoch: 4950 / 5000 batch step: 480\n",
      "w1: [26.37735262] w2: [-23.31615733] bias: [15.67747959] loss: 30.526888933635053\n",
      "Epoch: 4951 / 5000 batch step: 0\n",
      "w1: [26.37113659] w2: [-23.31704795] bias: [15.66459262] loss: 30.531049077557242\n",
      "Epoch: 4951 / 5000 batch step: 30\n",
      "w1: [26.36455027] w2: [-23.31705108] bias: [15.6515198] loss: 30.535788157545397\n",
      "Epoch: 4951 / 5000 batch step: 60\n",
      "w1: [26.34306581] w2: [-23.32405349] bias: [15.61066215] loss: 30.555145864224336\n",
      "Epoch: 4951 / 5000 batch step: 90\n",
      "w1: [26.33648411] w2: [-23.32799006] bias: [15.59538991] loss: 30.563713659048634\n",
      "Epoch: 4951 / 5000 batch step: 120\n",
      "w1: [26.3462824] w2: [-23.29721804] bias: [15.63186374] loss: 30.543555708852544\n",
      "Epoch: 4951 / 5000 batch step: 150\n",
      "w1: [26.38083269] w2: [-23.29572366] bias: [15.67611397] loss: 30.525453186451227\n",
      "Epoch: 4951 / 5000 batch step: 180\n",
      "w1: [26.44824565] w2: [-23.27866688] bias: [15.77841936] loss: 30.51383950428435\n",
      "Epoch: 4951 / 5000 batch step: 210\n",
      "w1: [26.48469263] w2: [-23.25830859] bias: [15.83712128] loss: 30.52611708402158\n",
      "Epoch: 4951 / 5000 batch step: 240\n",
      "w1: [26.52319539] w2: [-23.25245903] bias: [15.87850239] loss: 30.54461345568944\n",
      "Epoch: 4951 / 5000 batch step: 270\n",
      "w1: [26.53951681] w2: [-23.25256156] bias: [15.89555938] loss: 30.554352907130955\n",
      "Epoch: 4951 / 5000 batch step: 300\n",
      "w1: [26.51993799] w2: [-23.25872186] bias: [15.8569394] loss: 30.536235959474734\n",
      "Epoch: 4951 / 5000 batch step: 330\n",
      "w1: [26.48403439] w2: [-23.27127157] bias: [15.78619407] loss: 30.516349622094282\n",
      "Epoch: 4951 / 5000 batch step: 360\n",
      "w1: [26.49522185] w2: [-23.24158346] bias: [15.87623887] loss: 30.540105597431516\n",
      "Epoch: 4951 / 5000 batch step: 390\n",
      "w1: [26.4693349] w2: [-23.25344421] bias: [15.84195703] loss: 30.525824789709485\n",
      "Epoch: 4951 / 5000 batch step: 420\n",
      "w1: [26.41975179] w2: [-23.29702511] bias: [15.74668133] loss: 30.513321031554458\n",
      "Epoch: 4951 / 5000 batch step: 450\n",
      "w1: [26.39421426] w2: [-23.31474506] bias: [15.70330616] loss: 30.519781030176\n",
      "Epoch: 4951 / 5000 batch step: 480\n",
      "w1: [26.37735266] w2: [-23.3161573] bias: [15.67747956] loss: 30.52688893351523\n",
      "Epoch: 4952 / 5000 batch step: 0\n",
      "w1: [26.37113664] w2: [-23.31704793] bias: [15.66459259] loss: 30.53104907743301\n",
      "Epoch: 4952 / 5000 batch step: 30\n",
      "w1: [26.36455031] w2: [-23.31705106] bias: [15.65151977] loss: 30.53578815740583\n",
      "Epoch: 4952 / 5000 batch step: 60\n",
      "w1: [26.34306585] w2: [-23.32405346] bias: [15.61066212] loss: 30.55514586405461\n",
      "Epoch: 4952 / 5000 batch step: 90\n",
      "w1: [26.33648416] w2: [-23.32799003] bias: [15.59538987] loss: 30.563713658874967\n",
      "Epoch: 4952 / 5000 batch step: 120\n",
      "w1: [26.34628245] w2: [-23.29721801] bias: [15.63186371] loss: 30.543555708698904\n",
      "Epoch: 4952 / 5000 batch step: 150\n",
      "w1: [26.38083273] w2: [-23.29572364] bias: [15.67611394] loss: 30.525453186297696\n",
      "Epoch: 4952 / 5000 batch step: 180\n",
      "w1: [26.4482457] w2: [-23.27866686] bias: [15.77841933] loss: 30.51383950416128\n",
      "Epoch: 4952 / 5000 batch step: 210\n",
      "w1: [26.48469267] w2: [-23.25830857] bias: [15.83712124] loss: 30.526117083899155\n",
      "Epoch: 4952 / 5000 batch step: 240\n",
      "w1: [26.52319543] w2: [-23.25245901] bias: [15.87850236] loss: 30.54461345555657\n",
      "Epoch: 4952 / 5000 batch step: 270\n",
      "w1: [26.53951686] w2: [-23.25256154] bias: [15.89555935] loss: 30.554352907003153\n",
      "Epoch: 4952 / 5000 batch step: 300\n",
      "w1: [26.51993804] w2: [-23.25872184] bias: [15.85693937] loss: 30.53623595937193\n",
      "Epoch: 4952 / 5000 batch step: 330\n",
      "w1: [26.48403443] w2: [-23.27127154] bias: [15.78619404] loss: 30.516349622000284\n",
      "Epoch: 4952 / 5000 batch step: 360\n",
      "w1: [26.49522189] w2: [-23.24158343] bias: [15.87623884] loss: 30.54010559734012\n",
      "Epoch: 4952 / 5000 batch step: 390\n",
      "w1: [26.46933495] w2: [-23.25344419] bias: [15.841957] loss: 30.525824789583755\n",
      "Epoch: 4952 / 5000 batch step: 420\n",
      "w1: [26.41975184] w2: [-23.29702509] bias: [15.74668129] loss: 30.513321031420656\n",
      "Epoch: 4952 / 5000 batch step: 450\n",
      "w1: [26.39421431] w2: [-23.31474504] bias: [15.70330613] loss: 30.519781030059214\n",
      "Epoch: 4952 / 5000 batch step: 480\n",
      "w1: [26.37735271] w2: [-23.31615728] bias: [15.67747953] loss: 30.526888933395686\n",
      "Epoch: 4953 / 5000 batch step: 0\n",
      "w1: [26.37113668] w2: [-23.3170479] bias: [15.66459256] loss: 30.53104907730906\n",
      "Epoch: 4953 / 5000 batch step: 30\n",
      "w1: [26.36455035] w2: [-23.31705104] bias: [15.65151974] loss: 30.53578815726658\n",
      "Epoch: 4953 / 5000 batch step: 60\n",
      "w1: [26.3430659] w2: [-23.32405344] bias: [15.61066209] loss: 30.555145863885276\n",
      "Epoch: 4953 / 5000 batch step: 90\n",
      "w1: [26.3364842] w2: [-23.32799001] bias: [15.59538984] loss: 30.56371365870169\n",
      "Epoch: 4953 / 5000 batch step: 120\n",
      "w1: [26.34628249] w2: [-23.29721799] bias: [15.63186367] loss: 30.54355570854561\n",
      "Epoch: 4953 / 5000 batch step: 150\n",
      "w1: [26.38083278] w2: [-23.29572361] bias: [15.67611391] loss: 30.525453186144514\n",
      "Epoch: 4953 / 5000 batch step: 180\n",
      "w1: [26.44824574] w2: [-23.27866684] bias: [15.7784193] loss: 30.513839504038486\n",
      "Epoch: 4953 / 5000 batch step: 210\n",
      "w1: [26.48469272] w2: [-23.25830854] bias: [15.83712121] loss: 30.526117083777013\n",
      "Epoch: 4953 / 5000 batch step: 240\n",
      "w1: [26.52319547] w2: [-23.25245898] bias: [15.87850233] loss: 30.544613455424003\n",
      "Epoch: 4953 / 5000 batch step: 270\n",
      "w1: [26.5395169] w2: [-23.25256151] bias: [15.89555932] loss: 30.554352906875643\n",
      "Epoch: 4953 / 5000 batch step: 300\n",
      "w1: [26.51993808] w2: [-23.25872182] bias: [15.85693934] loss: 30.536235959269366\n",
      "Epoch: 4953 / 5000 batch step: 330\n",
      "w1: [26.48403448] w2: [-23.27127152] bias: [15.78619401] loss: 30.5163496219065\n",
      "Epoch: 4953 / 5000 batch step: 360\n",
      "w1: [26.49522194] w2: [-23.24158341] bias: [15.87623881] loss: 30.540105597248928\n",
      "Epoch: 4953 / 5000 batch step: 390\n",
      "w1: [26.46933499] w2: [-23.25344416] bias: [15.84195697] loss: 30.525824789458316\n",
      "Epoch: 4953 / 5000 batch step: 420\n",
      "w1: [26.41975188] w2: [-23.29702507] bias: [15.74668126] loss: 30.513321031287163\n",
      "Epoch: 4953 / 5000 batch step: 450\n",
      "w1: [26.39421435] w2: [-23.31474501] bias: [15.7033061] loss: 30.5197810299427\n",
      "Epoch: 4953 / 5000 batch step: 480\n",
      "w1: [26.37735275] w2: [-23.31615726] bias: [15.6774795] loss: 30.526888933276418\n",
      "Epoch: 4954 / 5000 batch step: 0\n",
      "w1: [26.37113673] w2: [-23.31704788] bias: [15.66459253] loss: 30.531049077185397\n",
      "Epoch: 4954 / 5000 batch step: 30\n",
      "w1: [26.3645504] w2: [-23.31705101] bias: [15.65151971] loss: 30.535788157127648\n",
      "Epoch: 4954 / 5000 batch step: 60\n",
      "w1: [26.34306594] w2: [-23.32405342] bias: [15.61066206] loss: 30.555145863716316\n",
      "Epoch: 4954 / 5000 batch step: 90\n",
      "w1: [26.33648425] w2: [-23.32798998] bias: [15.59538981] loss: 30.56371365852881\n",
      "Epoch: 4954 / 5000 batch step: 120\n",
      "w1: [26.34628254] w2: [-23.29721796] bias: [15.63186364] loss: 30.54355570839266\n",
      "Epoch: 4954 / 5000 batch step: 150\n",
      "w1: [26.38083282] w2: [-23.29572359] bias: [15.67611388] loss: 30.525453185991672\n",
      "Epoch: 4954 / 5000 batch step: 180\n",
      "w1: [26.44824579] w2: [-23.27866681] bias: [15.77841927] loss: 30.513839503915985\n",
      "Epoch: 4954 / 5000 batch step: 210\n",
      "w1: [26.48469276] w2: [-23.25830852] bias: [15.83712118] loss: 30.52611708365514\n",
      "Epoch: 4954 / 5000 batch step: 240\n",
      "w1: [26.52319552] w2: [-23.25245896] bias: [15.8785023] loss: 30.54461345529174\n",
      "Epoch: 4954 / 5000 batch step: 270\n",
      "w1: [26.53951694] w2: [-23.25256149] bias: [15.89555929] loss: 30.554352906748424\n",
      "Epoch: 4954 / 5000 batch step: 300\n",
      "w1: [26.51993813] w2: [-23.25872179] bias: [15.85693931] loss: 30.53623595916703\n",
      "Epoch: 4954 / 5000 batch step: 330\n",
      "w1: [26.48403452] w2: [-23.2712715] bias: [15.78619398] loss: 30.516349621812925\n",
      "Epoch: 4954 / 5000 batch step: 360\n",
      "w1: [26.49522198] w2: [-23.24158338] bias: [15.87623877] loss: 30.54010559715795\n",
      "Epoch: 4954 / 5000 batch step: 390\n",
      "w1: [26.46933503] w2: [-23.25344414] bias: [15.84195694] loss: 30.525824789333157\n",
      "Epoch: 4954 / 5000 batch step: 420\n",
      "w1: [26.41975193] w2: [-23.29702504] bias: [15.74668123] loss: 30.513321031153964\n",
      "Epoch: 4954 / 5000 batch step: 450\n",
      "w1: [26.3942144] w2: [-23.31474499] bias: [15.70330607] loss: 30.51978102982645\n",
      "Epoch: 4954 / 5000 batch step: 480\n",
      "w1: [26.37735279] w2: [-23.31615723] bias: [15.67747947] loss: 30.526888933157412\n",
      "Epoch: 4955 / 5000 batch step: 0\n",
      "w1: [26.37113677] w2: [-23.31704786] bias: [15.6645925] loss: 30.531049077062022\n",
      "Epoch: 4955 / 5000 batch step: 30\n",
      "w1: [26.36455044] w2: [-23.31705099] bias: [15.65151968] loss: 30.535788156989028\n",
      "Epoch: 4955 / 5000 batch step: 60\n",
      "w1: [26.34306598] w2: [-23.32405339] bias: [15.61066203] loss: 30.555145863547743\n",
      "Epoch: 4955 / 5000 batch step: 90\n",
      "w1: [26.33648429] w2: [-23.32798996] bias: [15.59538978] loss: 30.563713658356317\n",
      "Epoch: 4955 / 5000 batch step: 120\n",
      "w1: [26.34628258] w2: [-23.29721794] bias: [15.63186361] loss: 30.543555708240067\n",
      "Epoch: 4955 / 5000 batch step: 150\n",
      "w1: [26.38083286] w2: [-23.29572357] bias: [15.67611385] loss: 30.525453185839186\n",
      "Epoch: 4955 / 5000 batch step: 180\n",
      "w1: [26.44824583] w2: [-23.27866679] bias: [15.77841924] loss: 30.513839503793747\n",
      "Epoch: 4955 / 5000 batch step: 210\n",
      "w1: [26.48469281] w2: [-23.25830849] bias: [15.83712115] loss: 30.526117083533556\n",
      "Epoch: 4955 / 5000 batch step: 240\n",
      "w1: [26.52319556] w2: [-23.25245893] bias: [15.87850226] loss: 30.544613455159766\n",
      "Epoch: 4955 / 5000 batch step: 270\n",
      "w1: [26.53951699] w2: [-23.25256146] bias: [15.89555926] loss: 30.554352906621496\n",
      "Epoch: 4955 / 5000 batch step: 300\n",
      "w1: [26.51993817] w2: [-23.25872177] bias: [15.85693928] loss: 30.53623595906493\n",
      "Epoch: 4955 / 5000 batch step: 330\n",
      "w1: [26.48403457] w2: [-23.27127147] bias: [15.78619394] loss: 30.516349621719566\n",
      "Epoch: 4955 / 5000 batch step: 360\n",
      "w1: [26.49522203] w2: [-23.24158336] bias: [15.87623874] loss: 30.540105597067175\n",
      "Epoch: 4955 / 5000 batch step: 390\n",
      "w1: [26.46933508] w2: [-23.25344412] bias: [15.84195691] loss: 30.52582478920828\n",
      "Epoch: 4955 / 5000 batch step: 420\n",
      "w1: [26.41975197] w2: [-23.29702502] bias: [15.7466812] loss: 30.51332103102108\n",
      "Epoch: 4955 / 5000 batch step: 450\n",
      "w1: [26.39421444] w2: [-23.31474496] bias: [15.70330604] loss: 30.519781029710465\n",
      "Epoch: 4955 / 5000 batch step: 480\n",
      "w1: [26.37735284] w2: [-23.31615721] bias: [15.67747944] loss: 30.526888933038684\n",
      "Epoch: 4956 / 5000 batch step: 0\n",
      "w1: [26.37113681] w2: [-23.31704783] bias: [15.66459247] loss: 30.531049076938917\n",
      "Epoch: 4956 / 5000 batch step: 30\n",
      "w1: [26.36455049] w2: [-23.31705096] bias: [15.65151965] loss: 30.53578815685073\n",
      "Epoch: 4956 / 5000 batch step: 60\n",
      "w1: [26.34306603] w2: [-23.32405337] bias: [15.610662] loss: 30.555145863379558\n",
      "Epoch: 4956 / 5000 batch step: 90\n",
      "w1: [26.33648433] w2: [-23.32798994] bias: [15.59538975] loss: 30.563713658184216\n",
      "Epoch: 4956 / 5000 batch step: 120\n",
      "w1: [26.34628262] w2: [-23.29721792] bias: [15.63186358] loss: 30.543555708087816\n",
      "Epoch: 4956 / 5000 batch step: 150\n",
      "w1: [26.38083291] w2: [-23.29572354] bias: [15.67611382] loss: 30.525453185687045\n",
      "Epoch: 4956 / 5000 batch step: 180\n",
      "w1: [26.44824587] w2: [-23.27866676] bias: [15.77841921] loss: 30.5138395036718\n",
      "Epoch: 4956 / 5000 batch step: 210\n",
      "w1: [26.48469285] w2: [-23.25830847] bias: [15.83712112] loss: 30.526117083412238\n",
      "Epoch: 4956 / 5000 batch step: 240\n",
      "w1: [26.52319561] w2: [-23.25245891] bias: [15.87850223] loss: 30.544613455028106\n",
      "Epoch: 4956 / 5000 batch step: 270\n",
      "w1: [26.53951703] w2: [-23.25256144] bias: [15.89555923] loss: 30.554352906494856\n",
      "Epoch: 4956 / 5000 batch step: 300\n",
      "w1: [26.51993821] w2: [-23.25872174] bias: [15.85693925] loss: 30.536235958963054\n",
      "Epoch: 4956 / 5000 batch step: 330\n",
      "w1: [26.48403461] w2: [-23.27127145] bias: [15.78619391] loss: 30.516349621626418\n",
      "Epoch: 4956 / 5000 batch step: 360\n",
      "w1: [26.49522207] w2: [-23.24158333] bias: [15.87623871] loss: 30.540105596976606\n",
      "Epoch: 4956 / 5000 batch step: 390\n",
      "w1: [26.46933512] w2: [-23.25344409] bias: [15.84195688] loss: 30.525824789083696\n",
      "Epoch: 4956 / 5000 batch step: 420\n",
      "w1: [26.41975201] w2: [-23.29702499] bias: [15.74668117] loss: 30.513321030888488\n",
      "Epoch: 4956 / 5000 batch step: 450\n",
      "w1: [26.39421448] w2: [-23.31474494] bias: [15.70330601] loss: 30.519781029594743\n",
      "Epoch: 4956 / 5000 batch step: 480\n",
      "w1: [26.37735288] w2: [-23.31615718] bias: [15.67747941] loss: 30.52688893292022\n",
      "Epoch: 4957 / 5000 batch step: 0\n",
      "w1: [26.37113686] w2: [-23.31704781] bias: [15.66459244] loss: 30.531049076816092\n",
      "Epoch: 4957 / 5000 batch step: 30\n",
      "w1: [26.36455053] w2: [-23.31705094] bias: [15.65151962] loss: 30.535788156712744\n",
      "Epoch: 4957 / 5000 batch step: 60\n",
      "w1: [26.34306607] w2: [-23.32405334] bias: [15.61066197] loss: 30.555145863211752\n",
      "Epoch: 4957 / 5000 batch step: 90\n",
      "w1: [26.33648438] w2: [-23.32798991] bias: [15.59538972] loss: 30.563713658012514\n",
      "Epoch: 4957 / 5000 batch step: 120\n",
      "w1: [26.34628267] w2: [-23.29721789] bias: [15.63186355] loss: 30.54355570793591\n",
      "Epoch: 4957 / 5000 batch step: 150\n",
      "w1: [26.38083295] w2: [-23.29572352] bias: [15.67611379] loss: 30.525453185535255\n",
      "Epoch: 4957 / 5000 batch step: 180\n",
      "w1: [26.44824592] w2: [-23.27866674] bias: [15.77841918] loss: 30.513839503550123\n",
      "Epoch: 4957 / 5000 batch step: 210\n",
      "w1: [26.48469289] w2: [-23.25830845] bias: [15.83712109] loss: 30.526117083291204\n",
      "Epoch: 4957 / 5000 batch step: 240\n",
      "w1: [26.52319565] w2: [-23.25245889] bias: [15.8785022] loss: 30.544613454896737\n",
      "Epoch: 4957 / 5000 batch step: 270\n",
      "w1: [26.53951708] w2: [-23.25256142] bias: [15.8955592] loss: 30.554352906368504\n",
      "Epoch: 4957 / 5000 batch step: 300\n",
      "w1: [26.51993826] w2: [-23.25872172] bias: [15.85693922] loss: 30.53623595886142\n",
      "Epoch: 4957 / 5000 batch step: 330\n",
      "w1: [26.48403465] w2: [-23.27127142] bias: [15.78619388] loss: 30.516349621533482\n",
      "Epoch: 4957 / 5000 batch step: 360\n",
      "w1: [26.49522211] w2: [-23.24158331] bias: [15.87623868] loss: 30.540105596886246\n",
      "Epoch: 4957 / 5000 batch step: 390\n",
      "w1: [26.46933517] w2: [-23.25344407] bias: [15.84195685] loss: 30.525824788959387\n",
      "Epoch: 4957 / 5000 batch step: 420\n",
      "w1: [26.41975206] w2: [-23.29702497] bias: [15.74668114] loss: 30.513321030756206\n",
      "Epoch: 4957 / 5000 batch step: 450\n",
      "w1: [26.39421453] w2: [-23.31474492] bias: [15.70330598] loss: 30.519781029479283\n",
      "Epoch: 4957 / 5000 batch step: 480\n",
      "w1: [26.37735292] w2: [-23.31615716] bias: [15.67747937] loss: 30.526888932802024\n",
      "Epoch: 4958 / 5000 batch step: 0\n",
      "w1: [26.3711369] w2: [-23.31704778] bias: [15.66459241] loss: 30.531049076693552\n",
      "Epoch: 4958 / 5000 batch step: 30\n",
      "w1: [26.36455057] w2: [-23.31705092] bias: [15.65151959] loss: 30.535788156575073\n",
      "Epoch: 4958 / 5000 batch step: 60\n",
      "w1: [26.34306611] w2: [-23.32405332] bias: [15.61066194] loss: 30.55514586304433\n",
      "Epoch: 4958 / 5000 batch step: 90\n",
      "w1: [26.33648442] w2: [-23.32798989] bias: [15.59538969] loss: 30.5637136578412\n",
      "Epoch: 4958 / 5000 batch step: 120\n",
      "w1: [26.34628271] w2: [-23.29721787] bias: [15.63186352] loss: 30.543555707784353\n",
      "Epoch: 4958 / 5000 batch step: 150\n",
      "w1: [26.380833] w2: [-23.29572349] bias: [15.67611376] loss: 30.525453185383803\n",
      "Epoch: 4958 / 5000 batch step: 180\n",
      "w1: [26.44824596] w2: [-23.27866672] bias: [15.77841915] loss: 30.513839503428724\n",
      "Epoch: 4958 / 5000 batch step: 210\n",
      "w1: [26.48469294] w2: [-23.25830842] bias: [15.83712106] loss: 30.526117083170444\n",
      "Epoch: 4958 / 5000 batch step: 240\n",
      "w1: [26.52319569] w2: [-23.25245886] bias: [15.87850217] loss: 30.54461345476567\n",
      "Epoch: 4958 / 5000 batch step: 270\n",
      "w1: [26.53951712] w2: [-23.25256139] bias: [15.89555917] loss: 30.55435290624244\n",
      "Epoch: 4958 / 5000 batch step: 300\n",
      "w1: [26.5199383] w2: [-23.25872169] bias: [15.85693919] loss: 30.536235958760013\n",
      "Epoch: 4958 / 5000 batch step: 330\n",
      "w1: [26.4840347] w2: [-23.2712714] bias: [15.78619385] loss: 30.51634962144076\n",
      "Epoch: 4958 / 5000 batch step: 360\n",
      "w1: [26.49522216] w2: [-23.24158329] bias: [15.87623865] loss: 30.540105596796092\n",
      "Epoch: 4958 / 5000 batch step: 390\n",
      "w1: [26.46933521] w2: [-23.25344404] bias: [15.84195682] loss: 30.525824788835365\n",
      "Epoch: 4958 / 5000 batch step: 420\n",
      "w1: [26.4197521] w2: [-23.29702495] bias: [15.74668111] loss: 30.513321030624216\n",
      "Epoch: 4958 / 5000 batch step: 450\n",
      "w1: [26.39421457] w2: [-23.31474489] bias: [15.70330595] loss: 30.51978102936409\n",
      "Epoch: 4958 / 5000 batch step: 480\n",
      "w1: [26.37735297] w2: [-23.31615714] bias: [15.67747934] loss: 30.526888932684102\n",
      "Epoch: 4959 / 5000 batch step: 0\n",
      "w1: [26.37113694] w2: [-23.31704776] bias: [15.66459238] loss: 30.53104907657129\n",
      "Epoch: 4959 / 5000 batch step: 30\n",
      "w1: [26.36455062] w2: [-23.31705089] bias: [15.65151956] loss: 30.53578815643771\n",
      "Epoch: 4959 / 5000 batch step: 60\n",
      "w1: [26.34306616] w2: [-23.32405329] bias: [15.61066191] loss: 30.555145862877293\n",
      "Epoch: 4959 / 5000 batch step: 90\n",
      "w1: [26.33648446] w2: [-23.32798986] bias: [15.59538966] loss: 30.563713657670277\n",
      "Epoch: 4959 / 5000 batch step: 120\n",
      "w1: [26.34628275] w2: [-23.29721784] bias: [15.63186349] loss: 30.543555707633132\n",
      "Epoch: 4959 / 5000 batch step: 150\n",
      "w1: [26.38083304] w2: [-23.29572347] bias: [15.67611373] loss: 30.5254531852327\n",
      "Epoch: 4959 / 5000 batch step: 180\n",
      "w1: [26.44824601] w2: [-23.27866669] bias: [15.77841912] loss: 30.5138395033076\n",
      "Epoch: 4959 / 5000 batch step: 210\n",
      "w1: [26.48469298] w2: [-23.2583084] bias: [15.83712103] loss: 30.52611708304996\n",
      "Epoch: 4959 / 5000 batch step: 240\n",
      "w1: [26.52319574] w2: [-23.25245884] bias: [15.87850214] loss: 30.544613454634902\n",
      "Epoch: 4959 / 5000 batch step: 270\n",
      "w1: [26.53951716] w2: [-23.25256137] bias: [15.89555914] loss: 30.55435290611666\n",
      "Epoch: 4959 / 5000 batch step: 300\n",
      "w1: [26.51993834] w2: [-23.25872167] bias: [15.85693916] loss: 30.536235958658832\n",
      "Epoch: 4959 / 5000 batch step: 330\n",
      "w1: [26.48403474] w2: [-23.27127138] bias: [15.78619382] loss: 30.516349621348244\n",
      "Epoch: 4959 / 5000 batch step: 360\n",
      "w1: [26.4952222] w2: [-23.24158326] bias: [15.87623862] loss: 30.540105596706134\n",
      "Epoch: 4959 / 5000 batch step: 390\n",
      "w1: [26.46933525] w2: [-23.25344402] bias: [15.84195679] loss: 30.525824788711628\n",
      "Epoch: 4959 / 5000 batch step: 420\n",
      "w1: [26.41975214] w2: [-23.29702492] bias: [15.74668108] loss: 30.51332103049253\n",
      "Epoch: 4959 / 5000 batch step: 450\n",
      "w1: [26.39421461] w2: [-23.31474487] bias: [15.70330592] loss: 30.519781029249152\n",
      "Epoch: 4959 / 5000 batch step: 480\n",
      "w1: [26.37735301] w2: [-23.31615711] bias: [15.67747931] loss: 30.526888932566447\n",
      "Epoch: 4960 / 5000 batch step: 0\n",
      "w1: [26.37113699] w2: [-23.31704774] bias: [15.66459235] loss: 30.531049076449296\n",
      "Epoch: 4960 / 5000 batch step: 30\n",
      "w1: [26.36455066] w2: [-23.31705087] bias: [15.65151953] loss: 30.53578815630067\n",
      "Epoch: 4960 / 5000 batch step: 60\n",
      "w1: [26.3430662] w2: [-23.32405327] bias: [15.61066188] loss: 30.555145862710628\n",
      "Epoch: 4960 / 5000 batch step: 90\n",
      "w1: [26.33648451] w2: [-23.32798984] bias: [15.59538963] loss: 30.563713657499733\n",
      "Epoch: 4960 / 5000 batch step: 120\n",
      "w1: [26.3462828] w2: [-23.29721782] bias: [15.63186346] loss: 30.543555707482263\n",
      "Epoch: 4960 / 5000 batch step: 150\n",
      "w1: [26.38083308] w2: [-23.29572345] bias: [15.6761137] loss: 30.52545318508194\n",
      "Epoch: 4960 / 5000 batch step: 180\n",
      "w1: [26.44824605] w2: [-23.27866667] bias: [15.77841909] loss: 30.513839503186755\n",
      "Epoch: 4960 / 5000 batch step: 210\n",
      "w1: [26.48469302] w2: [-23.25830837] bias: [15.837121] loss: 30.526117082929744\n",
      "Epoch: 4960 / 5000 batch step: 240\n",
      "w1: [26.52319578] w2: [-23.25245881] bias: [15.87850211] loss: 30.544613454504432\n",
      "Epoch: 4960 / 5000 batch step: 270\n",
      "w1: [26.53951721] w2: [-23.25256134] bias: [15.89555911] loss: 30.554352905991166\n",
      "Epoch: 4960 / 5000 batch step: 300\n",
      "w1: [26.51993839] w2: [-23.25872165] bias: [15.85693913] loss: 30.53623595855789\n",
      "Epoch: 4960 / 5000 batch step: 330\n",
      "w1: [26.48403478] w2: [-23.27127135] bias: [15.78619379] loss: 30.51634962125594\n",
      "Epoch: 4960 / 5000 batch step: 360\n",
      "w1: [26.49522224] w2: [-23.24158324] bias: [15.87623859] loss: 30.54010559661639\n",
      "Epoch: 4960 / 5000 batch step: 390\n",
      "w1: [26.4693353] w2: [-23.253444] bias: [15.84195676] loss: 30.525824788588167\n",
      "Epoch: 4960 / 5000 batch step: 420\n",
      "w1: [26.41975219] w2: [-23.2970249] bias: [15.74668105] loss: 30.513321030361137\n",
      "Epoch: 4960 / 5000 batch step: 450\n",
      "w1: [26.39421466] w2: [-23.31474484] bias: [15.70330589] loss: 30.51978102913448\n",
      "Epoch: 4960 / 5000 batch step: 480\n",
      "w1: [26.37735306] w2: [-23.31615709] bias: [15.67747928] loss: 30.526888932449058\n",
      "Epoch: 4961 / 5000 batch step: 0\n",
      "w1: [26.37113703] w2: [-23.31704771] bias: [15.66459232] loss: 30.53104907632759\n",
      "Epoch: 4961 / 5000 batch step: 30\n",
      "w1: [26.3645507] w2: [-23.31705084] bias: [15.6515195] loss: 30.535788156163928\n",
      "Epoch: 4961 / 5000 batch step: 60\n",
      "w1: [26.34306625] w2: [-23.32405325] bias: [15.61066185] loss: 30.55514586254435\n",
      "Epoch: 4961 / 5000 batch step: 90\n",
      "w1: [26.33648455] w2: [-23.32798982] bias: [15.5953896] loss: 30.56371365732959\n",
      "Epoch: 4961 / 5000 batch step: 120\n",
      "w1: [26.34628284] w2: [-23.2972178] bias: [15.63186343] loss: 30.543555707331734\n",
      "Epoch: 4961 / 5000 batch step: 150\n",
      "w1: [26.38083313] w2: [-23.29572342] bias: [15.67611367] loss: 30.525453184931514\n",
      "Epoch: 4961 / 5000 batch step: 180\n",
      "w1: [26.44824609] w2: [-23.27866664] bias: [15.77841906] loss: 30.51383950306618\n",
      "Epoch: 4961 / 5000 batch step: 210\n",
      "w1: [26.48469307] w2: [-23.25830835] bias: [15.83712097] loss: 30.526117082809808\n",
      "Epoch: 4961 / 5000 batch step: 240\n",
      "w1: [26.52319582] w2: [-23.25245879] bias: [15.87850208] loss: 30.544613454374257\n",
      "Epoch: 4961 / 5000 batch step: 270\n",
      "w1: [26.53951725] w2: [-23.25256132] bias: [15.89555908] loss: 30.554352905865958\n",
      "Epoch: 4961 / 5000 batch step: 300\n",
      "w1: [26.51993843] w2: [-23.25872162] bias: [15.8569391] loss: 30.536235958457176\n",
      "Epoch: 4961 / 5000 batch step: 330\n",
      "w1: [26.48403483] w2: [-23.27127133] bias: [15.78619376] loss: 30.516349621163847\n",
      "Epoch: 4961 / 5000 batch step: 360\n",
      "w1: [26.49522229] w2: [-23.24158321] bias: [15.87623856] loss: 30.540105596526843\n",
      "Epoch: 4961 / 5000 batch step: 390\n",
      "w1: [26.46933534] w2: [-23.25344397] bias: [15.84195673] loss: 30.525824788464988\n",
      "Epoch: 4961 / 5000 batch step: 420\n",
      "w1: [26.41975223] w2: [-23.29702487] bias: [15.74668102] loss: 30.51332103023006\n",
      "Epoch: 4961 / 5000 batch step: 450\n",
      "w1: [26.3942147] w2: [-23.31474482] bias: [15.70330586] loss: 30.519781029020066\n",
      "Epoch: 4961 / 5000 batch step: 480\n",
      "w1: [26.3773531] w2: [-23.31615706] bias: [15.67747925] loss: 30.526888932331936\n",
      "Epoch: 4962 / 5000 batch step: 0\n",
      "w1: [26.37113707] w2: [-23.31704769] bias: [15.66459229] loss: 30.53104907620616\n",
      "Epoch: 4962 / 5000 batch step: 30\n",
      "w1: [26.36455075] w2: [-23.31705082] bias: [15.65151947] loss: 30.535788156027504\n",
      "Epoch: 4962 / 5000 batch step: 60\n",
      "w1: [26.34306629] w2: [-23.32405322] bias: [15.61066182] loss: 30.55514586237844\n",
      "Epoch: 4962 / 5000 batch step: 90\n",
      "w1: [26.3364846] w2: [-23.32798979] bias: [15.59538957] loss: 30.563713657159827\n",
      "Epoch: 4962 / 5000 batch step: 120\n",
      "w1: [26.34628288] w2: [-23.29721777] bias: [15.6318634] loss: 30.543555707181547\n",
      "Epoch: 4962 / 5000 batch step: 150\n",
      "w1: [26.38083317] w2: [-23.2957234] bias: [15.67611364] loss: 30.52545318478144\n",
      "Epoch: 4962 / 5000 batch step: 180\n",
      "w1: [26.44824614] w2: [-23.27866662] bias: [15.77841903] loss: 30.513839502945885\n",
      "Epoch: 4962 / 5000 batch step: 210\n",
      "w1: [26.48469311] w2: [-23.25830833] bias: [15.83712094] loss: 30.526117082690142\n",
      "Epoch: 4962 / 5000 batch step: 240\n",
      "w1: [26.52319587] w2: [-23.25245877] bias: [15.87850205] loss: 30.54461345424438\n",
      "Epoch: 4962 / 5000 batch step: 270\n",
      "w1: [26.53951729] w2: [-23.2525613] bias: [15.89555905] loss: 30.55435290574103\n",
      "Epoch: 4962 / 5000 batch step: 300\n",
      "w1: [26.51993847] w2: [-23.2587216] bias: [15.85693907] loss: 30.536235958356684\n",
      "Epoch: 4962 / 5000 batch step: 330\n",
      "w1: [26.48403487] w2: [-23.2712713] bias: [15.78619373] loss: 30.516349621071967\n",
      "Epoch: 4962 / 5000 batch step: 360\n",
      "w1: [26.49522233] w2: [-23.24158319] bias: [15.87623853] loss: 30.540105596437506\n",
      "Epoch: 4962 / 5000 batch step: 390\n",
      "w1: [26.46933538] w2: [-23.25344395] bias: [15.8419567] loss: 30.52582478834209\n",
      "Epoch: 4962 / 5000 batch step: 420\n",
      "w1: [26.41975227] w2: [-23.29702485] bias: [15.74668099] loss: 30.513321030099267\n",
      "Epoch: 4962 / 5000 batch step: 450\n",
      "w1: [26.39421474] w2: [-23.3147448] bias: [15.70330583] loss: 30.519781028905918\n",
      "Epoch: 4962 / 5000 batch step: 480\n",
      "w1: [26.37735314] w2: [-23.31615704] bias: [15.67747922] loss: 30.526888932215083\n",
      "Epoch: 4963 / 5000 batch step: 0\n",
      "w1: [26.37113712] w2: [-23.31704767] bias: [15.66459226] loss: 30.53104907608501\n",
      "Epoch: 4963 / 5000 batch step: 30\n",
      "w1: [26.36455079] w2: [-23.3170508] bias: [15.65151944] loss: 30.53578815589139\n",
      "Epoch: 4963 / 5000 batch step: 60\n",
      "w1: [26.34306633] w2: [-23.3240532] bias: [15.61066179] loss: 30.55514586221291\n",
      "Epoch: 4963 / 5000 batch step: 90\n",
      "w1: [26.33648464] w2: [-23.32798977] bias: [15.59538954] loss: 30.563713656990448\n",
      "Epoch: 4963 / 5000 batch step: 120\n",
      "w1: [26.34628293] w2: [-23.29721775] bias: [15.63186337] loss: 30.543555707031707\n",
      "Epoch: 4963 / 5000 batch step: 150\n",
      "w1: [26.38083321] w2: [-23.29572337] bias: [15.67611361] loss: 30.5254531846317\n",
      "Epoch: 4963 / 5000 batch step: 180\n",
      "w1: [26.44824618] w2: [-23.2786666] bias: [15.778419] loss: 30.513839502825864\n",
      "Epoch: 4963 / 5000 batch step: 210\n",
      "w1: [26.48469315] w2: [-23.2583083] bias: [15.83712091] loss: 30.526117082570746\n",
      "Epoch: 4963 / 5000 batch step: 240\n",
      "w1: [26.52319591] w2: [-23.25245874] bias: [15.87850202] loss: 30.544613454114792\n",
      "Epoch: 4963 / 5000 batch step: 270\n",
      "w1: [26.53951734] w2: [-23.25256127] bias: [15.89555902] loss: 30.554352905616398\n",
      "Epoch: 4963 / 5000 batch step: 300\n",
      "w1: [26.51993852] w2: [-23.25872158] bias: [15.85693904] loss: 30.536235958256427\n",
      "Epoch: 4963 / 5000 batch step: 330\n",
      "w1: [26.48403491] w2: [-23.27127128] bias: [15.7861937] loss: 30.51634962098029\n",
      "Epoch: 4963 / 5000 batch step: 360\n",
      "w1: [26.49522237] w2: [-23.24158317] bias: [15.8762385] loss: 30.540105596348372\n",
      "Epoch: 4963 / 5000 batch step: 390\n",
      "w1: [26.46933543] w2: [-23.25344392] bias: [15.84195667] loss: 30.525824788219467\n",
      "Epoch: 4963 / 5000 batch step: 420\n",
      "w1: [26.41975232] w2: [-23.29702483] bias: [15.74668096] loss: 30.513321029968775\n",
      "Epoch: 4963 / 5000 batch step: 450\n",
      "w1: [26.39421479] w2: [-23.31474477] bias: [15.7033058] loss: 30.51978102879202\n",
      "Epoch: 4963 / 5000 batch step: 480\n",
      "w1: [26.37735318] w2: [-23.31615702] bias: [15.67747919] loss: 30.526888932098494\n",
      "Epoch: 4964 / 5000 batch step: 0\n",
      "w1: [26.37113716] w2: [-23.31704764] bias: [15.66459223] loss: 30.531049075964123\n",
      "Epoch: 4964 / 5000 batch step: 30\n",
      "w1: [26.36455083] w2: [-23.31705077] bias: [15.65151941] loss: 30.535788155755583\n",
      "Epoch: 4964 / 5000 batch step: 60\n",
      "w1: [26.34306637] w2: [-23.32405318] bias: [15.61066176] loss: 30.55514586204776\n",
      "Epoch: 4964 / 5000 batch step: 90\n",
      "w1: [26.33648468] w2: [-23.32798974] bias: [15.59538951] loss: 30.563713656821456\n",
      "Epoch: 4964 / 5000 batch step: 120\n",
      "w1: [26.34628297] w2: [-23.29721773] bias: [15.63186334] loss: 30.5435557068822\n",
      "Epoch: 4964 / 5000 batch step: 150\n",
      "w1: [26.38083326] w2: [-23.29572335] bias: [15.67611358] loss: 30.525453184482313\n",
      "Epoch: 4964 / 5000 batch step: 180\n",
      "w1: [26.44824622] w2: [-23.27866657] bias: [15.77841897] loss: 30.51383950270611\n",
      "Epoch: 4964 / 5000 batch step: 210\n",
      "w1: [26.4846932] w2: [-23.25830828] bias: [15.83712088] loss: 30.526117082451623\n",
      "Epoch: 4964 / 5000 batch step: 240\n",
      "w1: [26.52319595] w2: [-23.25245872] bias: [15.87850199] loss: 30.54461345398551\n",
      "Epoch: 4964 / 5000 batch step: 270\n",
      "w1: [26.53951738] w2: [-23.25256125] bias: [15.89555899] loss: 30.554352905492046\n",
      "Epoch: 4964 / 5000 batch step: 300\n",
      "w1: [26.51993856] w2: [-23.25872155] bias: [15.85693901] loss: 30.536235958156396\n",
      "Epoch: 4964 / 5000 batch step: 330\n",
      "w1: [26.48403496] w2: [-23.27127126] bias: [15.78619368] loss: 30.51634962088882\n",
      "Epoch: 4964 / 5000 batch step: 360\n",
      "w1: [26.49522242] w2: [-23.24158314] bias: [15.87623847] loss: 30.540105596259437\n",
      "Epoch: 4964 / 5000 batch step: 390\n",
      "w1: [26.46933547] w2: [-23.2534439] bias: [15.84195664] loss: 30.525824788097136\n",
      "Epoch: 4964 / 5000 batch step: 420\n",
      "w1: [26.41975236] w2: [-23.2970248] bias: [15.74668093] loss: 30.51332102983858\n",
      "Epoch: 4964 / 5000 batch step: 450\n",
      "w1: [26.39421483] w2: [-23.31474475] bias: [15.70330577] loss: 30.519781028678388\n",
      "Epoch: 4964 / 5000 batch step: 480\n",
      "w1: [26.37735323] w2: [-23.31615699] bias: [15.67747916] loss: 30.526888931982175\n",
      "Epoch: 4965 / 5000 batch step: 0\n",
      "w1: [26.3711372] w2: [-23.31704762] bias: [15.6645922] loss: 30.531049075843523\n",
      "Epoch: 4965 / 5000 batch step: 30\n",
      "w1: [26.36455088] w2: [-23.31705075] bias: [15.65151938] loss: 30.535788155620086\n",
      "Epoch: 4965 / 5000 batch step: 60\n",
      "w1: [26.34306642] w2: [-23.32405315] bias: [15.61066173] loss: 30.55514586188298\n",
      "Epoch: 4965 / 5000 batch step: 90\n",
      "w1: [26.33648472] w2: [-23.32798972] bias: [15.59538948] loss: 30.563713656652848\n",
      "Epoch: 4965 / 5000 batch step: 120\n",
      "w1: [26.34628301] w2: [-23.2972177] bias: [15.63186331] loss: 30.543555706733038\n",
      "Epoch: 4965 / 5000 batch step: 150\n",
      "w1: [26.3808333] w2: [-23.29572333] bias: [15.67611355] loss: 30.525453184333255\n",
      "Epoch: 4965 / 5000 batch step: 180\n",
      "w1: [26.44824627] w2: [-23.27866655] bias: [15.77841894] loss: 30.51383950258663\n",
      "Epoch: 4965 / 5000 batch step: 210\n",
      "w1: [26.48469324] w2: [-23.25830826] bias: [15.83712085] loss: 30.52611708233277\n",
      "Epoch: 4965 / 5000 batch step: 240\n",
      "w1: [26.523196] w2: [-23.2524587] bias: [15.87850196] loss: 30.54461345385651\n",
      "Epoch: 4965 / 5000 batch step: 270\n",
      "w1: [26.53951742] w2: [-23.25256123] bias: [15.89555896] loss: 30.554352905367967\n",
      "Epoch: 4965 / 5000 batch step: 300\n",
      "w1: [26.5199386] w2: [-23.25872153] bias: [15.85693898] loss: 30.53623595805659\n",
      "Epoch: 4965 / 5000 batch step: 330\n",
      "w1: [26.484035] w2: [-23.27127123] bias: [15.78619365] loss: 30.516349620797566\n",
      "Epoch: 4965 / 5000 batch step: 360\n",
      "w1: [26.49522246] w2: [-23.24158312] bias: [15.87623845] loss: 30.540105596170704\n",
      "Epoch: 4965 / 5000 batch step: 390\n",
      "w1: [26.46933551] w2: [-23.25344388] bias: [15.84195661] loss: 30.52582478797507\n",
      "Epoch: 4965 / 5000 batch step: 420\n",
      "w1: [26.4197524] w2: [-23.29702478] bias: [15.7466809] loss: 30.513321029708678\n",
      "Epoch: 4965 / 5000 batch step: 450\n",
      "w1: [26.39421487] w2: [-23.31474473] bias: [15.70330574] loss: 30.519781028565014\n",
      "Epoch: 4965 / 5000 batch step: 480\n",
      "w1: [26.37735327] w2: [-23.31615697] bias: [15.67747913] loss: 30.526888931866118\n",
      "Epoch: 4966 / 5000 batch step: 0\n",
      "w1: [26.37113725] w2: [-23.31704759] bias: [15.66459217] loss: 30.531049075723185\n",
      "Epoch: 4966 / 5000 batch step: 30\n",
      "w1: [26.36455092] w2: [-23.31705073] bias: [15.65151935] loss: 30.535788155484894\n",
      "Epoch: 4966 / 5000 batch step: 60\n",
      "w1: [26.34306646] w2: [-23.32405313] bias: [15.6106617] loss: 30.555145861718575\n",
      "Epoch: 4966 / 5000 batch step: 90\n",
      "w1: [26.33648477] w2: [-23.3279897] bias: [15.59538945] loss: 30.563713656484623\n",
      "Epoch: 4966 / 5000 batch step: 120\n",
      "w1: [26.34628306] w2: [-23.29721768] bias: [15.63186328] loss: 30.54355570658421\n",
      "Epoch: 4966 / 5000 batch step: 150\n",
      "w1: [26.38083334] w2: [-23.2957233] bias: [15.67611352] loss: 30.52545318418454\n",
      "Epoch: 4966 / 5000 batch step: 180\n",
      "w1: [26.44824631] w2: [-23.27866653] bias: [15.77841891] loss: 30.51383950246742\n",
      "Epoch: 4966 / 5000 batch step: 210\n",
      "w1: [26.48469328] w2: [-23.25830823] bias: [15.83712082] loss: 30.526117082214192\n",
      "Epoch: 4966 / 5000 batch step: 240\n",
      "w1: [26.52319604] w2: [-23.25245867] bias: [15.87850193] loss: 30.54461345372781\n",
      "Epoch: 4966 / 5000 batch step: 270\n",
      "w1: [26.53951746] w2: [-23.2525612] bias: [15.89555893] loss: 30.554352905244176\n",
      "Epoch: 4966 / 5000 batch step: 300\n",
      "w1: [26.51993865] w2: [-23.2587215] bias: [15.85693895] loss: 30.53623595795701\n",
      "Epoch: 4966 / 5000 batch step: 330\n",
      "w1: [26.48403504] w2: [-23.27127121] bias: [15.78619362] loss: 30.51634962070652\n",
      "Epoch: 4966 / 5000 batch step: 360\n",
      "w1: [26.4952225] w2: [-23.2415831] bias: [15.87623842] loss: 30.54010559608217\n",
      "Epoch: 4966 / 5000 batch step: 390\n",
      "w1: [26.46933555] w2: [-23.25344385] bias: [15.84195658] loss: 30.525824787853292\n",
      "Epoch: 4966 / 5000 batch step: 420\n",
      "w1: [26.41975245] w2: [-23.29702476] bias: [15.74668087] loss: 30.513321029579075\n",
      "Epoch: 4966 / 5000 batch step: 450\n",
      "w1: [26.39421491] w2: [-23.3147447] bias: [15.70330571] loss: 30.5197810284519\n",
      "Epoch: 4966 / 5000 batch step: 480\n",
      "w1: [26.37735331] w2: [-23.31615695] bias: [15.67747911] loss: 30.52688893175032\n",
      "Epoch: 4967 / 5000 batch step: 0\n",
      "w1: [26.37113729] w2: [-23.31704757] bias: [15.66459214] loss: 30.53104907560313\n",
      "Epoch: 4967 / 5000 batch step: 30\n",
      "w1: [26.36455096] w2: [-23.3170507] bias: [15.65151932] loss: 30.535788155350016\n",
      "Epoch: 4967 / 5000 batch step: 60\n",
      "w1: [26.3430665] w2: [-23.32405311] bias: [15.61066167] loss: 30.555145861554553\n",
      "Epoch: 4967 / 5000 batch step: 90\n",
      "w1: [26.33648481] w2: [-23.32798967] bias: [15.59538942] loss: 30.563713656316786\n",
      "Epoch: 4967 / 5000 batch step: 120\n",
      "w1: [26.3462831] w2: [-23.29721765] bias: [15.63186325] loss: 30.543555706435725\n",
      "Epoch: 4967 / 5000 batch step: 150\n",
      "w1: [26.38083338] w2: [-23.29572328] bias: [15.67611349] loss: 30.525453184036163\n",
      "Epoch: 4967 / 5000 batch step: 180\n",
      "w1: [26.44824635] w2: [-23.2786665] bias: [15.77841888] loss: 30.51383950234849\n",
      "Epoch: 4967 / 5000 batch step: 210\n",
      "w1: [26.48469333] w2: [-23.25830821] bias: [15.83712079] loss: 30.526117082095883\n",
      "Epoch: 4967 / 5000 batch step: 240\n",
      "w1: [26.52319608] w2: [-23.25245865] bias: [15.8785019] loss: 30.5446134535994\n",
      "Epoch: 4967 / 5000 batch step: 270\n",
      "w1: [26.53951751] w2: [-23.25256118] bias: [15.8955589] loss: 30.554352905120673\n",
      "Epoch: 4967 / 5000 batch step: 300\n",
      "w1: [26.51993869] w2: [-23.25872148] bias: [15.85693892] loss: 30.536235957857663\n",
      "Epoch: 4967 / 5000 batch step: 330\n",
      "w1: [26.48403508] w2: [-23.27127119] bias: [15.78619359] loss: 30.51634962061567\n",
      "Epoch: 4967 / 5000 batch step: 360\n",
      "w1: [26.49522254] w2: [-23.24158307] bias: [15.87623839] loss: 30.540105595993843\n",
      "Epoch: 4967 / 5000 batch step: 390\n",
      "w1: [26.4693356] w2: [-23.25344383] bias: [15.84195655] loss: 30.525824787731782\n",
      "Epoch: 4967 / 5000 batch step: 420\n",
      "w1: [26.41975249] w2: [-23.29702473] bias: [15.74668084] loss: 30.513321029449763\n",
      "Epoch: 4967 / 5000 batch step: 450\n",
      "w1: [26.39421496] w2: [-23.31474468] bias: [15.70330568] loss: 30.51978102833904\n",
      "Epoch: 4967 / 5000 batch step: 480\n",
      "w1: [26.37735336] w2: [-23.31615692] bias: [15.67747908] loss: 30.526888931634783\n",
      "Epoch: 4968 / 5000 batch step: 0\n",
      "w1: [26.37113733] w2: [-23.31704755] bias: [15.66459211] loss: 30.53104907548335\n",
      "Epoch: 4968 / 5000 batch step: 30\n",
      "w1: [26.364551] w2: [-23.31705068] bias: [15.65151929] loss: 30.535788155215442\n",
      "Epoch: 4968 / 5000 batch step: 60\n",
      "w1: [26.34306655] w2: [-23.32405308] bias: [15.61066164] loss: 30.5551458613909\n",
      "Epoch: 4968 / 5000 batch step: 90\n",
      "w1: [26.33648485] w2: [-23.32798965] bias: [15.59538939] loss: 30.563713656149325\n",
      "Epoch: 4968 / 5000 batch step: 120\n",
      "w1: [26.34628314] w2: [-23.29721763] bias: [15.63186323] loss: 30.54355570628758\n",
      "Epoch: 4968 / 5000 batch step: 150\n",
      "w1: [26.38083343] w2: [-23.29572326] bias: [15.67611346] loss: 30.52545318388812\n",
      "Epoch: 4968 / 5000 batch step: 180\n",
      "w1: [26.44824639] w2: [-23.27866648] bias: [15.77841885] loss: 30.513839502229818\n",
      "Epoch: 4968 / 5000 batch step: 210\n",
      "w1: [26.48469337] w2: [-23.25830819] bias: [15.83712076] loss: 30.52611708197784\n",
      "Epoch: 4968 / 5000 batch step: 240\n",
      "w1: [26.52319612] w2: [-23.25245862] bias: [15.87850188] loss: 30.544613453471282\n",
      "Epoch: 4968 / 5000 batch step: 270\n",
      "w1: [26.53951755] w2: [-23.25256115] bias: [15.89555887] loss: 30.55435290499744\n",
      "Epoch: 4968 / 5000 batch step: 300\n",
      "w1: [26.51993873] w2: [-23.25872146] bias: [15.85693889] loss: 30.536235957758535\n",
      "Epoch: 4968 / 5000 batch step: 330\n",
      "w1: [26.48403513] w2: [-23.27127116] bias: [15.78619356] loss: 30.51634962052503\n",
      "Epoch: 4968 / 5000 batch step: 360\n",
      "w1: [26.49522259] w2: [-23.24158305] bias: [15.87623836] loss: 30.540105595905718\n",
      "Epoch: 4968 / 5000 batch step: 390\n",
      "w1: [26.46933564] w2: [-23.25344381] bias: [15.84195652] loss: 30.525824787610546\n",
      "Epoch: 4968 / 5000 batch step: 420\n",
      "w1: [26.41975253] w2: [-23.29702471] bias: [15.74668081] loss: 30.513321029320753\n",
      "Epoch: 4968 / 5000 batch step: 450\n",
      "w1: [26.394215] w2: [-23.31474466] bias: [15.70330565] loss: 30.519781028226436\n",
      "Epoch: 4968 / 5000 batch step: 480\n",
      "w1: [26.3773534] w2: [-23.3161569] bias: [15.67747905] loss: 30.52688893151952\n",
      "Epoch: 4969 / 5000 batch step: 0\n",
      "w1: [26.37113737] w2: [-23.31704752] bias: [15.66459208] loss: 30.531049075363835\n",
      "Epoch: 4969 / 5000 batch step: 30\n",
      "w1: [26.36455105] w2: [-23.31705066] bias: [15.65151926] loss: 30.535788155081175\n",
      "Epoch: 4969 / 5000 batch step: 60\n",
      "w1: [26.34306659] w2: [-23.32405306] bias: [15.61066161] loss: 30.55514586122762\n",
      "Epoch: 4969 / 5000 batch step: 90\n",
      "w1: [26.3364849] w2: [-23.32798963] bias: [15.59538937] loss: 30.563713655982255\n",
      "Epoch: 4969 / 5000 batch step: 120\n",
      "w1: [26.34628319] w2: [-23.29721761] bias: [15.6318632] loss: 30.543555706139767\n",
      "Epoch: 4969 / 5000 batch step: 150\n",
      "w1: [26.38083347] w2: [-23.29572323] bias: [15.67611343] loss: 30.52545318374042\n",
      "Epoch: 4969 / 5000 batch step: 180\n",
      "w1: [26.44824644] w2: [-23.27866645] bias: [15.77841882] loss: 30.51383950211142\n",
      "Epoch: 4969 / 5000 batch step: 210\n",
      "w1: [26.48469341] w2: [-23.25830816] bias: [15.83712073] loss: 30.526117081860065\n",
      "Epoch: 4969 / 5000 batch step: 240\n",
      "w1: [26.52319617] w2: [-23.2524586] bias: [15.87850185] loss: 30.544613453343455\n",
      "Epoch: 4969 / 5000 batch step: 270\n",
      "w1: [26.53951759] w2: [-23.25256113] bias: [15.89555884] loss: 30.554352904874495\n",
      "Epoch: 4969 / 5000 batch step: 300\n",
      "w1: [26.51993877] w2: [-23.25872143] bias: [15.85693886] loss: 30.53623595765964\n",
      "Epoch: 4969 / 5000 batch step: 330\n",
      "w1: [26.48403517] w2: [-23.27127114] bias: [15.78619353] loss: 30.516349620434607\n",
      "Epoch: 4969 / 5000 batch step: 360\n",
      "w1: [26.49522263] w2: [-23.24158303] bias: [15.87623833] loss: 30.540105595817792\n",
      "Epoch: 4969 / 5000 batch step: 390\n",
      "w1: [26.46933568] w2: [-23.25344378] bias: [15.84195649] loss: 30.525824787489594\n",
      "Epoch: 4969 / 5000 batch step: 420\n",
      "w1: [26.41975257] w2: [-23.29702469] bias: [15.74668078] loss: 30.513321029192028\n",
      "Epoch: 4969 / 5000 batch step: 450\n",
      "w1: [26.39421504] w2: [-23.31474463] bias: [15.70330562] loss: 30.519781028114085\n",
      "Epoch: 4969 / 5000 batch step: 480\n",
      "w1: [26.37735344] w2: [-23.31615688] bias: [15.67747902] loss: 30.526888931404514\n",
      "Epoch: 4970 / 5000 batch step: 0\n",
      "w1: [26.37113742] w2: [-23.3170475] bias: [15.66459205] loss: 30.5310490752446\n",
      "Epoch: 4970 / 5000 batch step: 30\n",
      "w1: [26.36455109] w2: [-23.31705063] bias: [15.65151923] loss: 30.535788154947216\n",
      "Epoch: 4970 / 5000 batch step: 60\n",
      "w1: [26.34306663] w2: [-23.32405303] bias: [15.61066158] loss: 30.55514586106471\n",
      "Epoch: 4970 / 5000 batch step: 90\n",
      "w1: [26.33648494] w2: [-23.3279896] bias: [15.59538934] loss: 30.563713655815555\n",
      "Epoch: 4970 / 5000 batch step: 120\n",
      "w1: [26.34628323] w2: [-23.29721758] bias: [15.63186317] loss: 30.543555705992297\n",
      "Epoch: 4970 / 5000 batch step: 150\n",
      "w1: [26.38083351] w2: [-23.29572321] bias: [15.6761134] loss: 30.525453183593047\n",
      "Epoch: 4970 / 5000 batch step: 180\n",
      "w1: [26.44824648] w2: [-23.27866643] bias: [15.77841879] loss: 30.5138395019933\n",
      "Epoch: 4970 / 5000 batch step: 210\n",
      "w1: [26.48469345] w2: [-23.25830814] bias: [15.83712071] loss: 30.52611708174256\n",
      "Epoch: 4970 / 5000 batch step: 240\n",
      "w1: [26.52319621] w2: [-23.25245858] bias: [15.87850182] loss: 30.544613453215923\n",
      "Epoch: 4970 / 5000 batch step: 270\n",
      "w1: [26.53951763] w2: [-23.25256111] bias: [15.89555881] loss: 30.554352904751823\n",
      "Epoch: 4970 / 5000 batch step: 300\n",
      "w1: [26.51993882] w2: [-23.25872141] bias: [15.85693883] loss: 30.53623595756097\n",
      "Epoch: 4970 / 5000 batch step: 330\n",
      "w1: [26.48403521] w2: [-23.27127112] bias: [15.7861935] loss: 30.516349620344375\n",
      "Epoch: 4970 / 5000 batch step: 360\n",
      "w1: [26.49522267] w2: [-23.241583] bias: [15.8762383] loss: 30.54010559573006\n",
      "Epoch: 4970 / 5000 batch step: 390\n",
      "w1: [26.46933572] w2: [-23.25344376] bias: [15.84195646] loss: 30.52582478736891\n",
      "Epoch: 4970 / 5000 batch step: 420\n",
      "w1: [26.41975262] w2: [-23.29702466] bias: [15.74668075] loss: 30.513321029063604\n",
      "Epoch: 4970 / 5000 batch step: 450\n",
      "w1: [26.39421508] w2: [-23.31474461] bias: [15.70330559] loss: 30.519781028001994\n",
      "Epoch: 4970 / 5000 batch step: 480\n",
      "w1: [26.37735348] w2: [-23.31615685] bias: [15.67747899] loss: 30.526888931289772\n",
      "Epoch: 4971 / 5000 batch step: 0\n",
      "w1: [26.37113746] w2: [-23.31704748] bias: [15.66459202] loss: 30.531049075125626\n",
      "Epoch: 4971 / 5000 batch step: 30\n",
      "w1: [26.36455113] w2: [-23.31705061] bias: [15.6515192] loss: 30.535788154813552\n",
      "Epoch: 4971 / 5000 batch step: 60\n",
      "w1: [26.34306667] w2: [-23.32405301] bias: [15.61066155] loss: 30.555145860902172\n",
      "Epoch: 4971 / 5000 batch step: 90\n",
      "w1: [26.33648498] w2: [-23.32798958] bias: [15.59538931] loss: 30.563713655649234\n",
      "Epoch: 4971 / 5000 batch step: 120\n",
      "w1: [26.34628327] w2: [-23.29721756] bias: [15.63186314] loss: 30.543555705845158\n",
      "Epoch: 4971 / 5000 batch step: 150\n",
      "w1: [26.38083355] w2: [-23.29572319] bias: [15.67611337] loss: 30.525453183446015\n",
      "Epoch: 4971 / 5000 batch step: 180\n",
      "w1: [26.44824652] w2: [-23.27866641] bias: [15.77841876] loss: 30.513839501875438\n",
      "Epoch: 4971 / 5000 batch step: 210\n",
      "w1: [26.4846935] w2: [-23.25830812] bias: [15.83712068] loss: 30.526117081625323\n",
      "Epoch: 4971 / 5000 batch step: 240\n",
      "w1: [26.52319625] w2: [-23.25245855] bias: [15.87850179] loss: 30.54461345308868\n",
      "Epoch: 4971 / 5000 batch step: 270\n",
      "w1: [26.53951768] w2: [-23.25256108] bias: [15.89555878] loss: 30.554352904629432\n",
      "Epoch: 4971 / 5000 batch step: 300\n",
      "w1: [26.51993886] w2: [-23.25872139] bias: [15.8569388] loss: 30.536235957462512\n",
      "Epoch: 4971 / 5000 batch step: 330\n",
      "w1: [26.48403525] w2: [-23.27127109] bias: [15.78619347] loss: 30.516349620254356\n",
      "Epoch: 4971 / 5000 batch step: 360\n",
      "w1: [26.49522271] w2: [-23.24158298] bias: [15.87623827] loss: 30.540105595642537\n",
      "Epoch: 4971 / 5000 batch step: 390\n",
      "w1: [26.46933577] w2: [-23.25344374] bias: [15.84195643] loss: 30.52582478724851\n",
      "Epoch: 4971 / 5000 batch step: 420\n",
      "w1: [26.41975266] w2: [-23.29702464] bias: [15.74668073] loss: 30.51332102893546\n",
      "Epoch: 4971 / 5000 batch step: 450\n",
      "w1: [26.39421513] w2: [-23.31474459] bias: [15.70330556] loss: 30.519781027890154\n",
      "Epoch: 4971 / 5000 batch step: 480\n",
      "w1: [26.37735353] w2: [-23.31615683] bias: [15.67747896] loss: 30.526888931175282\n",
      "Epoch: 4972 / 5000 batch step: 0\n",
      "w1: [26.3711375] w2: [-23.31704745] bias: [15.66459199] loss: 30.53104907500693\n",
      "Epoch: 4972 / 5000 batch step: 30\n",
      "w1: [26.36455117] w2: [-23.31705059] bias: [15.65151917] loss: 30.5357881546802\n",
      "Epoch: 4972 / 5000 batch step: 60\n",
      "w1: [26.34306672] w2: [-23.32405299] bias: [15.61066152] loss: 30.555145860739998\n",
      "Epoch: 4972 / 5000 batch step: 90\n",
      "w1: [26.33648502] w2: [-23.32798956] bias: [15.59538928] loss: 30.56371365548329\n",
      "Epoch: 4972 / 5000 batch step: 120\n",
      "w1: [26.34628331] w2: [-23.29721754] bias: [15.63186311] loss: 30.543555705698353\n",
      "Epoch: 4972 / 5000 batch step: 150\n",
      "w1: [26.3808336] w2: [-23.29572316] bias: [15.67611334] loss: 30.52545318329932\n",
      "Epoch: 4972 / 5000 batch step: 180\n",
      "w1: [26.44824656] w2: [-23.27866639] bias: [15.77841873] loss: 30.51383950175785\n",
      "Epoch: 4972 / 5000 batch step: 210\n",
      "w1: [26.48469354] w2: [-23.25830809] bias: [15.83712065] loss: 30.526117081508346\n",
      "Epoch: 4972 / 5000 batch step: 240\n",
      "w1: [26.52319629] w2: [-23.25245853] bias: [15.87850176] loss: 30.544613452961727\n",
      "Epoch: 4972 / 5000 batch step: 270\n",
      "w1: [26.53951772] w2: [-23.25256106] bias: [15.89555875] loss: 30.554352904507326\n",
      "Epoch: 4972 / 5000 batch step: 300\n",
      "w1: [26.5199389] w2: [-23.25872136] bias: [15.85693877] loss: 30.53623595736429\n",
      "Epoch: 4972 / 5000 batch step: 330\n",
      "w1: [26.4840353] w2: [-23.27127107] bias: [15.78619344] loss: 30.516349620164547\n",
      "Epoch: 4972 / 5000 batch step: 360\n",
      "w1: [26.49522276] w2: [-23.24158296] bias: [15.87623824] loss: 30.54010559555521\n",
      "Epoch: 4972 / 5000 batch step: 390\n",
      "w1: [26.46933581] w2: [-23.25344371] bias: [15.8419564] loss: 30.525824787128375\n",
      "Epoch: 4972 / 5000 batch step: 420\n",
      "w1: [26.4197527] w2: [-23.29702462] bias: [15.7466807] loss: 30.513321028807617\n",
      "Epoch: 4972 / 5000 batch step: 450\n",
      "w1: [26.39421517] w2: [-23.31474456] bias: [15.70330553] loss: 30.519781027778574\n",
      "Epoch: 4972 / 5000 batch step: 480\n",
      "w1: [26.37735357] w2: [-23.31615681] bias: [15.67747893] loss: 30.52688893106106\n",
      "Epoch: 4973 / 5000 batch step: 0\n",
      "w1: [26.37113754] w2: [-23.31704743] bias: [15.66459196] loss: 30.5310490748885\n",
      "Epoch: 4973 / 5000 batch step: 30\n",
      "w1: [26.36455122] w2: [-23.31705056] bias: [15.65151914] loss: 30.53578815454715\n",
      "Epoch: 4973 / 5000 batch step: 60\n",
      "w1: [26.34306676] w2: [-23.32405297] bias: [15.6106615] loss: 30.555145860578193\n",
      "Epoch: 4973 / 5000 batch step: 90\n",
      "w1: [26.33648506] w2: [-23.32798953] bias: [15.59538925] loss: 30.563713655317727\n",
      "Epoch: 4973 / 5000 batch step: 120\n",
      "w1: [26.34628335] w2: [-23.29721751] bias: [15.63186308] loss: 30.543555705551874\n",
      "Epoch: 4973 / 5000 batch step: 150\n",
      "w1: [26.38083364] w2: [-23.29572314] bias: [15.67611331] loss: 30.52545318315295\n",
      "Epoch: 4973 / 5000 batch step: 180\n",
      "w1: [26.44824661] w2: [-23.27866636] bias: [15.7784187] loss: 30.513839501640525\n",
      "Epoch: 4973 / 5000 batch step: 210\n",
      "w1: [26.48469358] w2: [-23.25830807] bias: [15.83712062] loss: 30.52611708139164\n",
      "Epoch: 4973 / 5000 batch step: 240\n",
      "w1: [26.52319634] w2: [-23.25245851] bias: [15.87850173] loss: 30.54461345283506\n",
      "Epoch: 4973 / 5000 batch step: 270\n",
      "w1: [26.53951776] w2: [-23.25256104] bias: [15.89555872] loss: 30.554352904385496\n",
      "Epoch: 4973 / 5000 batch step: 300\n",
      "w1: [26.51993894] w2: [-23.25872134] bias: [15.85693875] loss: 30.536235957266292\n",
      "Epoch: 4973 / 5000 batch step: 330\n",
      "w1: [26.48403534] w2: [-23.27127105] bias: [15.78619341] loss: 30.516349620074934\n",
      "Epoch: 4973 / 5000 batch step: 360\n",
      "w1: [26.4952228] w2: [-23.24158293] bias: [15.87623821] loss: 30.540105595468077\n",
      "Epoch: 4973 / 5000 batch step: 390\n",
      "w1: [26.46933585] w2: [-23.25344369] bias: [15.84195637] loss: 30.525824787008514\n",
      "Epoch: 4973 / 5000 batch step: 420\n",
      "w1: [26.41975274] w2: [-23.29702459] bias: [15.74668067] loss: 30.513321028680064\n",
      "Epoch: 4973 / 5000 batch step: 450\n",
      "w1: [26.39421521] w2: [-23.31474454] bias: [15.7033055] loss: 30.519781027667243\n",
      "Epoch: 4973 / 5000 batch step: 480\n",
      "w1: [26.37735361] w2: [-23.31615678] bias: [15.6774789] loss: 30.526888930947095\n",
      "Epoch: 4974 / 5000 batch step: 0\n",
      "w1: [26.37113759] w2: [-23.31704741] bias: [15.66459193] loss: 30.53104907477034\n",
      "Epoch: 4974 / 5000 batch step: 30\n",
      "w1: [26.36455126] w2: [-23.31705054] bias: [15.65151911] loss: 30.535788154414405\n",
      "Epoch: 4974 / 5000 batch step: 60\n",
      "w1: [26.3430668] w2: [-23.32405294] bias: [15.61066147] loss: 30.555145860416758\n",
      "Epoch: 4974 / 5000 batch step: 90\n",
      "w1: [26.33648511] w2: [-23.32798951] bias: [15.59538922] loss: 30.563713655152544\n",
      "Epoch: 4974 / 5000 batch step: 120\n",
      "w1: [26.3462834] w2: [-23.29721749] bias: [15.63186305] loss: 30.543555705405737\n",
      "Epoch: 4974 / 5000 batch step: 150\n",
      "w1: [26.38083368] w2: [-23.29572312] bias: [15.67611329] loss: 30.52545318300692\n",
      "Epoch: 4974 / 5000 batch step: 180\n",
      "w1: [26.44824665] w2: [-23.27866634] bias: [15.77841867] loss: 30.51383950152347\n",
      "Epoch: 4974 / 5000 batch step: 210\n",
      "w1: [26.48469362] w2: [-23.25830805] bias: [15.83712059] loss: 30.526117081275196\n",
      "Epoch: 4974 / 5000 batch step: 240\n",
      "w1: [26.52319638] w2: [-23.25245848] bias: [15.8785017] loss: 30.544613452708678\n",
      "Epoch: 4974 / 5000 batch step: 270\n",
      "w1: [26.5395178] w2: [-23.25256101] bias: [15.89555869] loss: 30.55435290426394\n",
      "Epoch: 4974 / 5000 batch step: 300\n",
      "w1: [26.51993899] w2: [-23.25872132] bias: [15.85693872] loss: 30.536235957168508\n",
      "Epoch: 4974 / 5000 batch step: 330\n",
      "w1: [26.48403538] w2: [-23.27127102] bias: [15.78619338] loss: 30.516349619985526\n",
      "Epoch: 4974 / 5000 batch step: 360\n",
      "w1: [26.49522284] w2: [-23.24158291] bias: [15.87623818] loss: 30.540105595381146\n",
      "Epoch: 4974 / 5000 batch step: 390\n",
      "w1: [26.46933589] w2: [-23.25344367] bias: [15.84195634] loss: 30.525824786888933\n",
      "Epoch: 4974 / 5000 batch step: 420\n",
      "w1: [26.41975278] w2: [-23.29702457] bias: [15.74668064] loss: 30.513321028552802\n",
      "Epoch: 4974 / 5000 batch step: 450\n",
      "w1: [26.39421525] w2: [-23.31474452] bias: [15.70330547] loss: 30.51978102755617\n",
      "Epoch: 4974 / 5000 batch step: 480\n",
      "w1: [26.37735365] w2: [-23.31615676] bias: [15.67747887] loss: 30.526888930833387\n",
      "Epoch: 4975 / 5000 batch step: 0\n",
      "w1: [26.37113763] w2: [-23.31704738] bias: [15.6645919] loss: 30.53104907465245\n",
      "Epoch: 4975 / 5000 batch step: 30\n",
      "w1: [26.3645513] w2: [-23.31705052] bias: [15.65151908] loss: 30.535788154281956\n",
      "Epoch: 4975 / 5000 batch step: 60\n",
      "w1: [26.34306684] w2: [-23.32405292] bias: [15.61066144] loss: 30.555145860255696\n",
      "Epoch: 4975 / 5000 batch step: 90\n",
      "w1: [26.33648515] w2: [-23.32798949] bias: [15.59538919] loss: 30.56371365498773\n",
      "Epoch: 4975 / 5000 batch step: 120\n",
      "w1: [26.34628344] w2: [-23.29721747] bias: [15.63186302] loss: 30.543555705259934\n",
      "Epoch: 4975 / 5000 batch step: 150\n",
      "w1: [26.38083372] w2: [-23.29572309] bias: [15.67611326] loss: 30.525453182861224\n",
      "Epoch: 4975 / 5000 batch step: 180\n",
      "w1: [26.44824669] w2: [-23.27866632] bias: [15.77841865] loss: 30.513839501406686\n",
      "Epoch: 4975 / 5000 batch step: 210\n",
      "w1: [26.48469366] w2: [-23.25830802] bias: [15.83712056] loss: 30.526117081159022\n",
      "Epoch: 4975 / 5000 batch step: 240\n",
      "w1: [26.52319642] w2: [-23.25245846] bias: [15.87850167] loss: 30.54461345258259\n",
      "Epoch: 4975 / 5000 batch step: 270\n",
      "w1: [26.53951785] w2: [-23.25256099] bias: [15.89555866] loss: 30.554352904142657\n",
      "Epoch: 4975 / 5000 batch step: 300\n",
      "w1: [26.51993903] w2: [-23.25872129] bias: [15.85693869] loss: 30.536235957070954\n",
      "Epoch: 4975 / 5000 batch step: 330\n",
      "w1: [26.48403542] w2: [-23.271271] bias: [15.78619335] loss: 30.51634961989632\n",
      "Epoch: 4975 / 5000 batch step: 360\n",
      "w1: [26.49522288] w2: [-23.24158289] bias: [15.87623815] loss: 30.54010559529441\n",
      "Epoch: 4975 / 5000 batch step: 390\n",
      "w1: [26.46933594] w2: [-23.25344364] bias: [15.84195632] loss: 30.52582478676962\n",
      "Epoch: 4975 / 5000 batch step: 420\n",
      "w1: [26.41975283] w2: [-23.29702455] bias: [15.74668061] loss: 30.51332102842582\n",
      "Epoch: 4975 / 5000 batch step: 450\n",
      "w1: [26.3942153] w2: [-23.31474449] bias: [15.70330544] loss: 30.519781027445347\n",
      "Epoch: 4975 / 5000 batch step: 480\n",
      "w1: [26.37735369] w2: [-23.31615674] bias: [15.67747884] loss: 30.52688893071994\n",
      "Epoch: 4976 / 5000 batch step: 0\n",
      "w1: [26.37113767] w2: [-23.31704736] bias: [15.66459187] loss: 30.531049074534828\n",
      "Epoch: 4976 / 5000 batch step: 30\n",
      "w1: [26.36455134] w2: [-23.31705049] bias: [15.65151905] loss: 30.53578815414981\n",
      "Epoch: 4976 / 5000 batch step: 60\n",
      "w1: [26.34306688] w2: [-23.3240529] bias: [15.61066141] loss: 30.555145860094992\n",
      "Epoch: 4976 / 5000 batch step: 90\n",
      "w1: [26.33648519] w2: [-23.32798946] bias: [15.59538916] loss: 30.563713654823292\n",
      "Epoch: 4976 / 5000 batch step: 120\n",
      "w1: [26.34628348] w2: [-23.29721745] bias: [15.63186299] loss: 30.543555705114457\n",
      "Epoch: 4976 / 5000 batch step: 150\n",
      "w1: [26.38083376] w2: [-23.29572307] bias: [15.67611323] loss: 30.525453182715854\n",
      "Epoch: 4976 / 5000 batch step: 180\n",
      "w1: [26.44824673] w2: [-23.27866629] bias: [15.77841862] loss: 30.513839501290157\n",
      "Epoch: 4976 / 5000 batch step: 210\n",
      "w1: [26.48469371] w2: [-23.258308] bias: [15.83712053] loss: 30.526117081043108\n",
      "Epoch: 4976 / 5000 batch step: 240\n",
      "w1: [26.52319646] w2: [-23.25245844] bias: [15.87850164] loss: 30.54461345245678\n",
      "Epoch: 4976 / 5000 batch step: 270\n",
      "w1: [26.53951789] w2: [-23.25256097] bias: [15.89555863] loss: 30.554352904021655\n",
      "Epoch: 4976 / 5000 batch step: 300\n",
      "w1: [26.51993907] w2: [-23.25872127] bias: [15.85693866] loss: 30.536235956973613\n",
      "Epoch: 4976 / 5000 batch step: 330\n",
      "w1: [26.48403547] w2: [-23.27127098] bias: [15.78619332] loss: 30.516349619807322\n",
      "Epoch: 4976 / 5000 batch step: 360\n",
      "w1: [26.49522292] w2: [-23.24158286] bias: [15.87623812] loss: 30.540105595207876\n",
      "Epoch: 4976 / 5000 batch step: 390\n",
      "w1: [26.46933598] w2: [-23.25344362] bias: [15.84195629] loss: 30.52582478665057\n",
      "Epoch: 4976 / 5000 batch step: 420\n",
      "w1: [26.41975287] w2: [-23.29702452] bias: [15.74668058] loss: 30.513321028299142\n",
      "Epoch: 4976 / 5000 batch step: 450\n",
      "w1: [26.39421534] w2: [-23.31474447] bias: [15.70330541] loss: 30.519781027334773\n",
      "Epoch: 4976 / 5000 batch step: 480\n",
      "w1: [26.37735374] w2: [-23.31615671] bias: [15.67747881] loss: 30.526888930606756\n",
      "Epoch: 4977 / 5000 batch step: 0\n",
      "w1: [26.37113771] w2: [-23.31704734] bias: [15.66459184] loss: 30.531049074417474\n",
      "Epoch: 4977 / 5000 batch step: 30\n",
      "w1: [26.36455138] w2: [-23.31705047] bias: [15.65151902] loss: 30.535788154017965\n",
      "Epoch: 4977 / 5000 batch step: 60\n",
      "w1: [26.34306693] w2: [-23.32405287] bias: [15.61066138] loss: 30.55514585993466\n",
      "Epoch: 4977 / 5000 batch step: 90\n",
      "w1: [26.33648523] w2: [-23.32798944] bias: [15.59538913] loss: 30.563713654659228\n",
      "Epoch: 4977 / 5000 batch step: 120\n",
      "w1: [26.34628352] w2: [-23.29721742] bias: [15.63186296] loss: 30.543555704969314\n",
      "Epoch: 4977 / 5000 batch step: 150\n",
      "w1: [26.38083381] w2: [-23.29572305] bias: [15.6761132] loss: 30.525453182570814\n",
      "Epoch: 4977 / 5000 batch step: 180\n",
      "w1: [26.44824677] w2: [-23.27866627] bias: [15.77841859] loss: 30.513839501173898\n",
      "Epoch: 4977 / 5000 batch step: 210\n",
      "w1: [26.48469375] w2: [-23.25830798] bias: [15.8371205] loss: 30.52611708092746\n",
      "Epoch: 4977 / 5000 batch step: 240\n",
      "w1: [26.5231965] w2: [-23.25245842] bias: [15.87850161] loss: 30.544613452331262\n",
      "Epoch: 4977 / 5000 batch step: 270\n",
      "w1: [26.53951793] w2: [-23.25256095] bias: [15.89555861] loss: 30.554352903900927\n",
      "Epoch: 4977 / 5000 batch step: 300\n",
      "w1: [26.51993911] w2: [-23.25872125] bias: [15.85693863] loss: 30.536235956876503\n",
      "Epoch: 4977 / 5000 batch step: 330\n",
      "w1: [26.48403551] w2: [-23.27127095] bias: [15.7861933] loss: 30.516349619718525\n",
      "Epoch: 4977 / 5000 batch step: 360\n",
      "w1: [26.49522297] w2: [-23.24158284] bias: [15.8762381] loss: 30.540105595121535\n",
      "Epoch: 4977 / 5000 batch step: 390\n",
      "w1: [26.46933602] w2: [-23.2534436] bias: [15.84195626] loss: 30.525824786531803\n",
      "Epoch: 4977 / 5000 batch step: 420\n",
      "w1: [26.41975291] w2: [-23.2970245] bias: [15.74668055] loss: 30.513321028172744\n",
      "Epoch: 4977 / 5000 batch step: 450\n",
      "w1: [26.39421538] w2: [-23.31474445] bias: [15.70330538] loss: 30.519781027224457\n",
      "Epoch: 4977 / 5000 batch step: 480\n",
      "w1: [26.37735378] w2: [-23.31615669] bias: [15.67747878] loss: 30.526888930493822\n",
      "Epoch: 4978 / 5000 batch step: 0\n",
      "w1: [26.37113775] w2: [-23.31704732] bias: [15.66459182] loss: 30.531049074300388\n",
      "Epoch: 4978 / 5000 batch step: 30\n",
      "w1: [26.36455143] w2: [-23.31705045] bias: [15.651519] loss: 30.53578815388642\n",
      "Epoch: 4978 / 5000 batch step: 60\n",
      "w1: [26.34306697] w2: [-23.32405285] bias: [15.61066135] loss: 30.55514585977469\n",
      "Epoch: 4978 / 5000 batch step: 90\n",
      "w1: [26.33648527] w2: [-23.32798942] bias: [15.5953891] loss: 30.563713654495544\n",
      "Epoch: 4978 / 5000 batch step: 120\n",
      "w1: [26.34628356] w2: [-23.2972174] bias: [15.63186293] loss: 30.543555704824506\n",
      "Epoch: 4978 / 5000 batch step: 150\n",
      "w1: [26.38083385] w2: [-23.29572302] bias: [15.67611317] loss: 30.525453182426105\n",
      "Epoch: 4978 / 5000 batch step: 180\n",
      "w1: [26.44824681] w2: [-23.27866625] bias: [15.77841856] loss: 30.5138395010579\n",
      "Epoch: 4978 / 5000 batch step: 210\n",
      "w1: [26.48469379] w2: [-23.25830795] bias: [15.83712047] loss: 30.52611708081207\n",
      "Epoch: 4978 / 5000 batch step: 240\n",
      "w1: [26.52319654] w2: [-23.25245839] bias: [15.87850158] loss: 30.54461345220603\n",
      "Epoch: 4978 / 5000 batch step: 270\n",
      "w1: [26.53951797] w2: [-23.25256092] bias: [15.89555858] loss: 30.554352903780472\n",
      "Epoch: 4978 / 5000 batch step: 300\n",
      "w1: [26.51993915] w2: [-23.25872123] bias: [15.8569386] loss: 30.53623595677961\n",
      "Epoch: 4978 / 5000 batch step: 330\n",
      "w1: [26.48403555] w2: [-23.27127093] bias: [15.78619327] loss: 30.516349619629928\n",
      "Epoch: 4978 / 5000 batch step: 360\n",
      "w1: [26.49522301] w2: [-23.24158282] bias: [15.87623807] loss: 30.540105595035396\n",
      "Epoch: 4978 / 5000 batch step: 390\n",
      "w1: [26.46933606] w2: [-23.25344358] bias: [15.84195623] loss: 30.5258247864133\n",
      "Epoch: 4978 / 5000 batch step: 420\n",
      "w1: [26.41975295] w2: [-23.29702448] bias: [15.74668052] loss: 30.513321028046633\n",
      "Epoch: 4978 / 5000 batch step: 450\n",
      "w1: [26.39421542] w2: [-23.31474442] bias: [15.70330535] loss: 30.519781027114387\n",
      "Epoch: 4978 / 5000 batch step: 480\n",
      "w1: [26.37735382] w2: [-23.31615667] bias: [15.67747875] loss: 30.526888930381148\n",
      "Epoch: 4979 / 5000 batch step: 0\n",
      "w1: [26.37113779] w2: [-23.31704729] bias: [15.66459179] loss: 30.531049074183567\n",
      "Epoch: 4979 / 5000 batch step: 30\n",
      "w1: [26.36455147] w2: [-23.31705042] bias: [15.65151897] loss: 30.535788153755174\n",
      "Epoch: 4979 / 5000 batch step: 60\n",
      "w1: [26.34306701] w2: [-23.32405283] bias: [15.61066132] loss: 30.555145859615084\n",
      "Epoch: 4979 / 5000 batch step: 90\n",
      "w1: [26.33648532] w2: [-23.3279894] bias: [15.59538908] loss: 30.563713654332222\n",
      "Epoch: 4979 / 5000 batch step: 120\n",
      "w1: [26.34628361] w2: [-23.29721738] bias: [15.63186291] loss: 30.543555704680017\n",
      "Epoch: 4979 / 5000 batch step: 150\n",
      "w1: [26.38083389] w2: [-23.295723] bias: [15.67611314] loss: 30.525453182281726\n",
      "Epoch: 4979 / 5000 batch step: 180\n",
      "w1: [26.44824686] w2: [-23.27866622] bias: [15.77841853] loss: 30.513839500942176\n",
      "Epoch: 4979 / 5000 batch step: 210\n",
      "w1: [26.48469383] w2: [-23.25830793] bias: [15.83712044] loss: 30.526117080696952\n",
      "Epoch: 4979 / 5000 batch step: 240\n",
      "w1: [26.52319659] w2: [-23.25245837] bias: [15.87850155] loss: 30.544613452081077\n",
      "Epoch: 4979 / 5000 batch step: 270\n",
      "w1: [26.53951801] w2: [-23.2525609] bias: [15.89555855] loss: 30.55435290366029\n",
      "Epoch: 4979 / 5000 batch step: 300\n",
      "w1: [26.51993919] w2: [-23.2587212] bias: [15.85693857] loss: 30.53623595668293\n",
      "Epoch: 4979 / 5000 batch step: 330\n",
      "w1: [26.48403559] w2: [-23.27127091] bias: [15.78619324] loss: 30.516349619541533\n",
      "Epoch: 4979 / 5000 batch step: 360\n",
      "w1: [26.49522305] w2: [-23.24158279] bias: [15.87623804] loss: 30.54010559494944\n",
      "Epoch: 4979 / 5000 batch step: 390\n",
      "w1: [26.4693361] w2: [-23.25344355] bias: [15.8419562] loss: 30.52582478629507\n",
      "Epoch: 4979 / 5000 batch step: 420\n",
      "w1: [26.41975299] w2: [-23.29702446] bias: [15.74668049] loss: 30.513321027920806\n",
      "Epoch: 4979 / 5000 batch step: 450\n",
      "w1: [26.39421546] w2: [-23.3147444] bias: [15.70330533] loss: 30.519781027004573\n",
      "Epoch: 4979 / 5000 batch step: 480\n",
      "w1: [26.37735386] w2: [-23.31615665] bias: [15.67747873] loss: 30.52688893026873\n",
      "Epoch: 4980 / 5000 batch step: 0\n",
      "w1: [26.37113784] w2: [-23.31704727] bias: [15.66459176] loss: 30.53104907406701\n",
      "Epoch: 4980 / 5000 batch step: 30\n",
      "w1: [26.36455151] w2: [-23.3170504] bias: [15.65151894] loss: 30.535788153624225\n",
      "Epoch: 4980 / 5000 batch step: 60\n",
      "w1: [26.34306705] w2: [-23.3240528] bias: [15.61066129] loss: 30.555145859455838\n",
      "Epoch: 4980 / 5000 batch step: 90\n",
      "w1: [26.33648536] w2: [-23.32798937] bias: [15.59538905] loss: 30.563713654169277\n",
      "Epoch: 4980 / 5000 batch step: 120\n",
      "w1: [26.34628365] w2: [-23.29721735] bias: [15.63186288] loss: 30.543555704535862\n",
      "Epoch: 4980 / 5000 batch step: 150\n",
      "w1: [26.38083393] w2: [-23.29572298] bias: [15.67611311] loss: 30.525453182137678\n",
      "Epoch: 4980 / 5000 batch step: 180\n",
      "w1: [26.4482469] w2: [-23.2786662] bias: [15.7784185] loss: 30.51383950082671\n",
      "Epoch: 4980 / 5000 batch step: 210\n",
      "w1: [26.48469387] w2: [-23.25830791] bias: [15.83712042] loss: 30.526117080582093\n",
      "Epoch: 4980 / 5000 batch step: 240\n",
      "w1: [26.52319663] w2: [-23.25245835] bias: [15.87850153] loss: 30.54461345195642\n",
      "Epoch: 4980 / 5000 batch step: 270\n",
      "w1: [26.53951805] w2: [-23.25256088] bias: [15.89555852] loss: 30.554352903540384\n",
      "Epoch: 4980 / 5000 batch step: 300\n",
      "w1: [26.51993924] w2: [-23.25872118] bias: [15.85693854] loss: 30.536235956586477\n",
      "Epoch: 4980 / 5000 batch step: 330\n",
      "w1: [26.48403563] w2: [-23.27127088] bias: [15.78619321] loss: 30.516349619453337\n",
      "Epoch: 4980 / 5000 batch step: 360\n",
      "w1: [26.49522309] w2: [-23.24158277] bias: [15.87623801] loss: 30.540105594863693\n",
      "Epoch: 4980 / 5000 batch step: 390\n",
      "w1: [26.46933614] w2: [-23.25344353] bias: [15.84195617] loss: 30.5258247861771\n",
      "Epoch: 4980 / 5000 batch step: 420\n",
      "w1: [26.41975303] w2: [-23.29702443] bias: [15.74668046] loss: 30.513321027795264\n",
      "Epoch: 4980 / 5000 batch step: 450\n",
      "w1: [26.3942155] w2: [-23.31474438] bias: [15.7033053] loss: 30.519781026895\n",
      "Epoch: 4980 / 5000 batch step: 480\n",
      "w1: [26.3773539] w2: [-23.31615662] bias: [15.6774787] loss: 30.52688893015657\n",
      "Epoch: 4981 / 5000 batch step: 0\n",
      "w1: [26.37113788] w2: [-23.31704725] bias: [15.66459173] loss: 30.531049073950715\n",
      "Epoch: 4981 / 5000 batch step: 30\n",
      "w1: [26.36455155] w2: [-23.31705038] bias: [15.65151891] loss: 30.535788153493574\n",
      "Epoch: 4981 / 5000 batch step: 60\n",
      "w1: [26.34306709] w2: [-23.32405278] bias: [15.61066126] loss: 30.555145859296957\n",
      "Epoch: 4981 / 5000 batch step: 90\n",
      "w1: [26.3364854] w2: [-23.32798935] bias: [15.59538902] loss: 30.5637136540067\n",
      "Epoch: 4981 / 5000 batch step: 120\n",
      "w1: [26.34628369] w2: [-23.29721733] bias: [15.63186285] loss: 30.54355570439203\n",
      "Epoch: 4981 / 5000 batch step: 150\n",
      "w1: [26.38083397] w2: [-23.29572296] bias: [15.67611308] loss: 30.525453181993953\n",
      "Epoch: 4981 / 5000 batch step: 180\n",
      "w1: [26.44824694] w2: [-23.27866618] bias: [15.77841847] loss: 30.5138395007115\n",
      "Epoch: 4981 / 5000 batch step: 210\n",
      "w1: [26.48469391] w2: [-23.25830789] bias: [15.83712039] loss: 30.526117080467497\n",
      "Epoch: 4981 / 5000 batch step: 240\n",
      "w1: [26.52319667] w2: [-23.25245832] bias: [15.8785015] loss: 30.54461345183204\n",
      "Epoch: 4981 / 5000 batch step: 270\n",
      "w1: [26.53951809] w2: [-23.25256085] bias: [15.89555849] loss: 30.554352903420753\n",
      "Epoch: 4981 / 5000 batch step: 300\n",
      "w1: [26.51993928] w2: [-23.25872116] bias: [15.85693851] loss: 30.536235956490252\n",
      "Epoch: 4981 / 5000 batch step: 330\n",
      "w1: [26.48403567] w2: [-23.27127086] bias: [15.78619318] loss: 30.516349619365343\n",
      "Epoch: 4981 / 5000 batch step: 360\n",
      "w1: [26.49522313] w2: [-23.24158275] bias: [15.87623798] loss: 30.540105594778137\n",
      "Epoch: 4981 / 5000 batch step: 390\n",
      "w1: [26.46933618] w2: [-23.25344351] bias: [15.84195614] loss: 30.525824786059406\n",
      "Epoch: 4981 / 5000 batch step: 420\n",
      "w1: [26.41975308] w2: [-23.29702441] bias: [15.74668044] loss: 30.513321027670013\n",
      "Epoch: 4981 / 5000 batch step: 450\n",
      "w1: [26.39421554] w2: [-23.31474436] bias: [15.70330527] loss: 30.519781026785683\n",
      "Epoch: 4981 / 5000 batch step: 480\n",
      "w1: [26.37735394] w2: [-23.3161566] bias: [15.67747867] loss: 30.526888930044663\n",
      "Epoch: 4982 / 5000 batch step: 0\n",
      "w1: [26.37113792] w2: [-23.31704722] bias: [15.6645917] loss: 30.531049073834694\n",
      "Epoch: 4982 / 5000 batch step: 30\n",
      "w1: [26.36455159] w2: [-23.31705036] bias: [15.65151888] loss: 30.535788153363224\n",
      "Epoch: 4982 / 5000 batch step: 60\n",
      "w1: [26.34306713] w2: [-23.32405276] bias: [15.61066124] loss: 30.555145859138438\n",
      "Epoch: 4982 / 5000 batch step: 90\n",
      "w1: [26.33648544] w2: [-23.32798933] bias: [15.59538899] loss: 30.5637136538445\n",
      "Epoch: 4982 / 5000 batch step: 120\n",
      "w1: [26.34628373] w2: [-23.29721731] bias: [15.63186282] loss: 30.543555704248533\n",
      "Epoch: 4982 / 5000 batch step: 150\n",
      "w1: [26.38083401] w2: [-23.29572293] bias: [15.67611306] loss: 30.52545318185056\n",
      "Epoch: 4982 / 5000 batch step: 180\n",
      "w1: [26.44824698] w2: [-23.27866616] bias: [15.77841844] loss: 30.513839500596557\n",
      "Epoch: 4982 / 5000 batch step: 210\n",
      "w1: [26.48469395] w2: [-23.25830786] bias: [15.83712036] loss: 30.52611708035315\n",
      "Epoch: 4982 / 5000 batch step: 240\n",
      "w1: [26.52319671] w2: [-23.2524583] bias: [15.87850147] loss: 30.544613451707942\n",
      "Epoch: 4982 / 5000 batch step: 270\n",
      "w1: [26.53951814] w2: [-23.25256083] bias: [15.89555846] loss: 30.554352903301393\n",
      "Epoch: 4982 / 5000 batch step: 300\n",
      "w1: [26.51993932] w2: [-23.25872113] bias: [15.85693849] loss: 30.536235956394233\n",
      "Epoch: 4982 / 5000 batch step: 330\n",
      "w1: [26.48403571] w2: [-23.27127084] bias: [15.78619315] loss: 30.516349619277552\n",
      "Epoch: 4982 / 5000 batch step: 360\n",
      "w1: [26.49522317] w2: [-23.24158273] bias: [15.87623795] loss: 30.540105594692772\n",
      "Epoch: 4982 / 5000 batch step: 390\n",
      "w1: [26.46933623] w2: [-23.25344348] bias: [15.84195611] loss: 30.52582478594198\n",
      "Epoch: 4982 / 5000 batch step: 420\n",
      "w1: [26.41975312] w2: [-23.29702439] bias: [15.74668041] loss: 30.51332102754505\n",
      "Epoch: 4982 / 5000 batch step: 450\n",
      "w1: [26.39421559] w2: [-23.31474433] bias: [15.70330524] loss: 30.519781026676608\n",
      "Epoch: 4982 / 5000 batch step: 480\n",
      "w1: [26.37735398] w2: [-23.31615658] bias: [15.67747864] loss: 30.526888929933005\n",
      "Epoch: 4983 / 5000 batch step: 0\n",
      "w1: [26.37113796] w2: [-23.3170472] bias: [15.66459167] loss: 30.531049073718933\n",
      "Epoch: 4983 / 5000 batch step: 30\n",
      "w1: [26.36455163] w2: [-23.31705033] bias: [15.65151885] loss: 30.535788153233167\n",
      "Epoch: 4983 / 5000 batch step: 60\n",
      "w1: [26.34306718] w2: [-23.32405274] bias: [15.61066121] loss: 30.555145858980282\n",
      "Epoch: 4983 / 5000 batch step: 90\n",
      "w1: [26.33648548] w2: [-23.3279893] bias: [15.59538896] loss: 30.563713653682658\n",
      "Epoch: 4983 / 5000 batch step: 120\n",
      "w1: [26.34628377] w2: [-23.29721729] bias: [15.63186279] loss: 30.54355570410536\n",
      "Epoch: 4983 / 5000 batch step: 150\n",
      "w1: [26.38083406] w2: [-23.29572291] bias: [15.67611303] loss: 30.525453181707483\n",
      "Epoch: 4983 / 5000 batch step: 180\n",
      "w1: [26.44824702] w2: [-23.27866613] bias: [15.77841842] loss: 30.513839500481875\n",
      "Epoch: 4983 / 5000 batch step: 210\n",
      "w1: [26.484694] w2: [-23.25830784] bias: [15.83712033] loss: 30.52611708023907\n",
      "Epoch: 4983 / 5000 batch step: 240\n",
      "w1: [26.52319675] w2: [-23.25245828] bias: [15.87850144] loss: 30.54461345158413\n",
      "Epoch: 4983 / 5000 batch step: 270\n",
      "w1: [26.53951818] w2: [-23.25256081] bias: [15.89555843] loss: 30.5543529031823\n",
      "Epoch: 4983 / 5000 batch step: 300\n",
      "w1: [26.51993936] w2: [-23.25872111] bias: [15.85693846] loss: 30.536235956298434\n",
      "Epoch: 4983 / 5000 batch step: 330\n",
      "w1: [26.48403576] w2: [-23.27127082] bias: [15.78619312] loss: 30.516349619189956\n",
      "Epoch: 4983 / 5000 batch step: 360\n",
      "w1: [26.49522321] w2: [-23.2415827] bias: [15.87623792] loss: 30.540105594607603\n",
      "Epoch: 4983 / 5000 batch step: 390\n",
      "w1: [26.46933627] w2: [-23.25344346] bias: [15.84195609] loss: 30.525824785824824\n",
      "Epoch: 4983 / 5000 batch step: 420\n",
      "w1: [26.41975316] w2: [-23.29702436] bias: [15.74668038] loss: 30.513321027420368\n",
      "Epoch: 4983 / 5000 batch step: 450\n",
      "w1: [26.39421563] w2: [-23.31474431] bias: [15.70330521] loss: 30.519781026567788\n",
      "Epoch: 4983 / 5000 batch step: 480\n",
      "w1: [26.37735403] w2: [-23.31615655] bias: [15.67747861] loss: 30.52688892982161\n",
      "Epoch: 4984 / 5000 batch step: 0\n",
      "w1: [26.371138] w2: [-23.31704718] bias: [15.66459164] loss: 30.53104907360343\n",
      "Epoch: 4984 / 5000 batch step: 30\n",
      "w1: [26.36455167] w2: [-23.31705031] bias: [15.65151882] loss: 30.535788153103407\n",
      "Epoch: 4984 / 5000 batch step: 60\n",
      "w1: [26.34306722] w2: [-23.32405271] bias: [15.61066118] loss: 30.55514585882248\n",
      "Epoch: 4984 / 5000 batch step: 90\n",
      "w1: [26.33648552] w2: [-23.32798928] bias: [15.59538893] loss: 30.56371365352119\n",
      "Epoch: 4984 / 5000 batch step: 120\n",
      "w1: [26.34628381] w2: [-23.29721726] bias: [15.63186276] loss: 30.543555703962515\n",
      "Epoch: 4984 / 5000 batch step: 150\n",
      "w1: [26.3808341] w2: [-23.29572289] bias: [15.676113] loss: 30.525453181564746\n",
      "Epoch: 4984 / 5000 batch step: 180\n",
      "w1: [26.44824706] w2: [-23.27866611] bias: [15.77841839] loss: 30.513839500367457\n",
      "Epoch: 4984 / 5000 batch step: 210\n",
      "w1: [26.48469404] w2: [-23.25830782] bias: [15.8371203] loss: 30.526117080125246\n",
      "Epoch: 4984 / 5000 batch step: 240\n",
      "w1: [26.52319679] w2: [-23.25245826] bias: [15.87850141] loss: 30.544613451460588\n",
      "Epoch: 4984 / 5000 batch step: 270\n",
      "w1: [26.53951822] w2: [-23.25256079] bias: [15.8955584] loss: 30.554352903063478\n",
      "Epoch: 4984 / 5000 batch step: 300\n",
      "w1: [26.5199394] w2: [-23.25872109] bias: [15.85693843] loss: 30.53623595620286\n",
      "Epoch: 4984 / 5000 batch step: 330\n",
      "w1: [26.4840358] w2: [-23.27127079] bias: [15.7861931] loss: 30.516349619102566\n",
      "Epoch: 4984 / 5000 batch step: 360\n",
      "w1: [26.49522326] w2: [-23.24158268] bias: [15.8762379] loss: 30.540105594522625\n",
      "Epoch: 4984 / 5000 batch step: 390\n",
      "w1: [26.46933631] w2: [-23.25344344] bias: [15.84195606] loss: 30.525824785707925\n",
      "Epoch: 4984 / 5000 batch step: 420\n",
      "w1: [26.4197532] w2: [-23.29702434] bias: [15.74668035] loss: 30.51332102729597\n",
      "Epoch: 4984 / 5000 batch step: 450\n",
      "w1: [26.39421567] w2: [-23.31474429] bias: [15.70330518] loss: 30.519781026459214\n",
      "Epoch: 4984 / 5000 batch step: 480\n",
      "w1: [26.37735407] w2: [-23.31615653] bias: [15.67747858] loss: 30.526888929710463\n",
      "Epoch: 4985 / 5000 batch step: 0\n",
      "w1: [26.37113804] w2: [-23.31704716] bias: [15.66459162] loss: 30.531049073488195\n",
      "Epoch: 4985 / 5000 batch step: 30\n",
      "w1: [26.36455172] w2: [-23.31705029] bias: [15.6515188] loss: 30.535788152973943\n",
      "Epoch: 4985 / 5000 batch step: 60\n",
      "w1: [26.34306726] w2: [-23.32405269] bias: [15.61066115] loss: 30.555145858665036\n",
      "Epoch: 4985 / 5000 batch step: 90\n",
      "w1: [26.33648556] w2: [-23.32798926] bias: [15.5953889] loss: 30.563713653360086\n",
      "Epoch: 4985 / 5000 batch step: 120\n",
      "w1: [26.34628385] w2: [-23.29721724] bias: [15.63186273] loss: 30.543555703819987\n",
      "Epoch: 4985 / 5000 batch step: 150\n",
      "w1: [26.38083414] w2: [-23.29572287] bias: [15.67611297] loss: 30.52545318142232\n",
      "Epoch: 4985 / 5000 batch step: 180\n",
      "w1: [26.4482471] w2: [-23.27866609] bias: [15.77841836] loss: 30.513839500253294\n",
      "Epoch: 4985 / 5000 batch step: 210\n",
      "w1: [26.48469408] w2: [-23.25830779] bias: [15.83712027] loss: 30.52611708001169\n",
      "Epoch: 4985 / 5000 batch step: 240\n",
      "w1: [26.52319683] w2: [-23.25245823] bias: [15.87850138] loss: 30.544613451337334\n",
      "Epoch: 4985 / 5000 batch step: 270\n",
      "w1: [26.53951826] w2: [-23.25256076] bias: [15.89555838] loss: 30.554352902944927\n",
      "Epoch: 4985 / 5000 batch step: 300\n",
      "w1: [26.51993944] w2: [-23.25872107] bias: [15.8569384] loss: 30.536235956107497\n",
      "Epoch: 4985 / 5000 batch step: 330\n",
      "w1: [26.48403584] w2: [-23.27127077] bias: [15.78619307] loss: 30.516349619015365\n",
      "Epoch: 4985 / 5000 batch step: 360\n",
      "w1: [26.4952233] w2: [-23.24158266] bias: [15.87623787] loss: 30.540105594437847\n",
      "Epoch: 4985 / 5000 batch step: 390\n",
      "w1: [26.46933635] w2: [-23.25344342] bias: [15.84195603] loss: 30.525824785591293\n",
      "Epoch: 4985 / 5000 batch step: 420\n",
      "w1: [26.41975324] w2: [-23.29702432] bias: [15.74668032] loss: 30.51332102717185\n",
      "Epoch: 4985 / 5000 batch step: 450\n",
      "w1: [26.39421571] w2: [-23.31474427] bias: [15.70330515] loss: 30.519781026350884\n",
      "Epoch: 4985 / 5000 batch step: 480\n",
      "w1: [26.37735411] w2: [-23.31615651] bias: [15.67747855] loss: 30.526888929599572\n",
      "Epoch: 4986 / 5000 batch step: 0\n",
      "w1: [26.37113808] w2: [-23.31704713] bias: [15.66459159] loss: 30.531049073373214\n",
      "Epoch: 4986 / 5000 batch step: 30\n",
      "w1: [26.36455176] w2: [-23.31705027] bias: [15.65151877] loss: 30.535788152844773\n",
      "Epoch: 4986 / 5000 batch step: 60\n",
      "w1: [26.3430673] w2: [-23.32405267] bias: [15.61066112] loss: 30.555145858507952\n",
      "Epoch: 4986 / 5000 batch step: 90\n",
      "w1: [26.3364856] w2: [-23.32798924] bias: [15.59538888] loss: 30.56371365319935\n",
      "Epoch: 4986 / 5000 batch step: 120\n",
      "w1: [26.34628389] w2: [-23.29721722] bias: [15.63186271] loss: 30.543555703677786\n",
      "Epoch: 4986 / 5000 batch step: 150\n",
      "w1: [26.38083418] w2: [-23.29572284] bias: [15.67611294] loss: 30.52545318128022\n",
      "Epoch: 4986 / 5000 batch step: 180\n",
      "w1: [26.44824715] w2: [-23.27866606] bias: [15.77841833] loss: 30.513839500139394\n",
      "Epoch: 4986 / 5000 batch step: 210\n",
      "w1: [26.48469412] w2: [-23.25830777] bias: [15.83712024] loss: 30.52611707989839\n",
      "Epoch: 4986 / 5000 batch step: 240\n",
      "w1: [26.52319687] w2: [-23.25245821] bias: [15.87850135] loss: 30.544613451214367\n",
      "Epoch: 4986 / 5000 batch step: 270\n",
      "w1: [26.5395183] w2: [-23.25256074] bias: [15.89555835] loss: 30.55435290282665\n",
      "Epoch: 4986 / 5000 batch step: 300\n",
      "w1: [26.51993948] w2: [-23.25872104] bias: [15.85693837] loss: 30.53623595601235\n",
      "Epoch: 4986 / 5000 batch step: 330\n",
      "w1: [26.48403588] w2: [-23.27127075] bias: [15.78619304] loss: 30.516349618928373\n",
      "Epoch: 4986 / 5000 batch step: 360\n",
      "w1: [26.49522334] w2: [-23.24158264] bias: [15.87623784] loss: 30.54010559435326\n",
      "Epoch: 4986 / 5000 batch step: 390\n",
      "w1: [26.46933639] w2: [-23.25344339] bias: [15.841956] loss: 30.52582478547494\n",
      "Epoch: 4986 / 5000 batch step: 420\n",
      "w1: [26.41975328] w2: [-23.2970243] bias: [15.74668029] loss: 30.51332102704802\n",
      "Epoch: 4986 / 5000 batch step: 450\n",
      "w1: [26.39421575] w2: [-23.31474424] bias: [15.70330513] loss: 30.519781026242804\n",
      "Epoch: 4986 / 5000 batch step: 480\n",
      "w1: [26.37735415] w2: [-23.31615649] bias: [15.67747853] loss: 30.526888929488933\n",
      "Epoch: 4987 / 5000 batch step: 0\n",
      "w1: [26.37113812] w2: [-23.31704711] bias: [15.66459156] loss: 30.531049073258508\n",
      "Epoch: 4987 / 5000 batch step: 30\n",
      "w1: [26.3645518] w2: [-23.31705024] bias: [15.65151874] loss: 30.5357881527159\n",
      "Epoch: 4987 / 5000 batch step: 60\n",
      "w1: [26.34306734] w2: [-23.32405265] bias: [15.61066109] loss: 30.555145858351228\n",
      "Epoch: 4987 / 5000 batch step: 90\n",
      "w1: [26.33648565] w2: [-23.32798921] bias: [15.59538885] loss: 30.563713653038985\n",
      "Epoch: 4987 / 5000 batch step: 120\n",
      "w1: [26.34628394] w2: [-23.2972172] bias: [15.63186268] loss: 30.54355570353591\n",
      "Epoch: 4987 / 5000 batch step: 150\n",
      "w1: [26.38083422] w2: [-23.29572282] bias: [15.67611291] loss: 30.525453181138452\n",
      "Epoch: 4987 / 5000 batch step: 180\n",
      "w1: [26.44824719] w2: [-23.27866604] bias: [15.7784183] loss: 30.513839500025753\n",
      "Epoch: 4987 / 5000 batch step: 210\n",
      "w1: [26.48469416] w2: [-23.25830775] bias: [15.83712022] loss: 30.526117079785344\n",
      "Epoch: 4987 / 5000 batch step: 240\n",
      "w1: [26.52319692] w2: [-23.25245819] bias: [15.87850133] loss: 30.54461345109167\n",
      "Epoch: 4987 / 5000 batch step: 270\n",
      "w1: [26.53951834] w2: [-23.25256072] bias: [15.89555832] loss: 30.55435290270864\n",
      "Epoch: 4987 / 5000 batch step: 300\n",
      "w1: [26.51993952] w2: [-23.25872102] bias: [15.85693834] loss: 30.536235955917423\n",
      "Epoch: 4987 / 5000 batch step: 330\n",
      "w1: [26.48403592] w2: [-23.27127073] bias: [15.78619301] loss: 30.516349618841566\n",
      "Epoch: 4987 / 5000 batch step: 360\n",
      "w1: [26.49522338] w2: [-23.24158261] bias: [15.87623781] loss: 30.540105594268862\n",
      "Epoch: 4987 / 5000 batch step: 390\n",
      "w1: [26.46933643] w2: [-23.25344337] bias: [15.84195597] loss: 30.525824785358832\n",
      "Epoch: 4987 / 5000 batch step: 420\n",
      "w1: [26.41975332] w2: [-23.29702427] bias: [15.74668027] loss: 30.513321026924466\n",
      "Epoch: 4987 / 5000 batch step: 450\n",
      "w1: [26.39421579] w2: [-23.31474422] bias: [15.7033051] loss: 30.519781026134964\n",
      "Epoch: 4987 / 5000 batch step: 480\n",
      "w1: [26.37735419] w2: [-23.31615646] bias: [15.6774785] loss: 30.52688892937854\n",
      "Epoch: 4988 / 5000 batch step: 0\n",
      "w1: [26.37113817] w2: [-23.31704709] bias: [15.66459153] loss: 30.531049073144057\n",
      "Epoch: 4988 / 5000 batch step: 30\n",
      "w1: [26.36455184] w2: [-23.31705022] bias: [15.65151871] loss: 30.535788152587315\n",
      "Epoch: 4988 / 5000 batch step: 60\n",
      "w1: [26.34306738] w2: [-23.32405262] bias: [15.61066107] loss: 30.555145858194862\n",
      "Epoch: 4988 / 5000 batch step: 90\n",
      "w1: [26.33648569] w2: [-23.32798919] bias: [15.59538882] loss: 30.56371365287898\n",
      "Epoch: 4988 / 5000 batch step: 120\n",
      "w1: [26.34628398] w2: [-23.29721717] bias: [15.63186265] loss: 30.543555703394354\n",
      "Epoch: 4988 / 5000 batch step: 150\n",
      "w1: [26.38083426] w2: [-23.2957228] bias: [15.67611289] loss: 30.525453180997005\n",
      "Epoch: 4988 / 5000 batch step: 180\n",
      "w1: [26.44824723] w2: [-23.27866602] bias: [15.77841827] loss: 30.51383949991237\n",
      "Epoch: 4988 / 5000 batch step: 210\n",
      "w1: [26.4846942] w2: [-23.25830773] bias: [15.83712019] loss: 30.526117079672556\n",
      "Epoch: 4988 / 5000 batch step: 240\n",
      "w1: [26.52319696] w2: [-23.25245817] bias: [15.8785013] loss: 30.54461345096926\n",
      "Epoch: 4988 / 5000 batch step: 270\n",
      "w1: [26.53951838] w2: [-23.2525607] bias: [15.89555829] loss: 30.554352902590892\n",
      "Epoch: 4988 / 5000 batch step: 300\n",
      "w1: [26.51993956] w2: [-23.258721] bias: [15.85693832] loss: 30.53623595582271\n",
      "Epoch: 4988 / 5000 batch step: 330\n",
      "w1: [26.48403596] w2: [-23.2712707] bias: [15.78619298] loss: 30.516349618754965\n",
      "Epoch: 4988 / 5000 batch step: 360\n",
      "w1: [26.49522342] w2: [-23.24158259] bias: [15.87623778] loss: 30.540105594184656\n",
      "Epoch: 4988 / 5000 batch step: 390\n",
      "w1: [26.46933647] w2: [-23.25344335] bias: [15.84195594] loss: 30.525824785242996\n",
      "Epoch: 4988 / 5000 batch step: 420\n",
      "w1: [26.41975336] w2: [-23.29702425] bias: [15.74668024] loss: 30.51332102680119\n",
      "Epoch: 4988 / 5000 batch step: 450\n",
      "w1: [26.39421583] w2: [-23.3147442] bias: [15.70330507] loss: 30.519781026027374\n",
      "Epoch: 4988 / 5000 batch step: 480\n",
      "w1: [26.37735423] w2: [-23.31615644] bias: [15.67747847] loss: 30.526888929268406\n",
      "Epoch: 4989 / 5000 batch step: 0\n",
      "w1: [26.37113821] w2: [-23.31704707] bias: [15.6645915] loss: 30.531049073029862\n",
      "Epoch: 4989 / 5000 batch step: 30\n",
      "w1: [26.36455188] w2: [-23.3170502] bias: [15.65151868] loss: 30.535788152459023\n",
      "Epoch: 4989 / 5000 batch step: 60\n",
      "w1: [26.34306742] w2: [-23.3240526] bias: [15.61066104] loss: 30.555145858038845\n",
      "Epoch: 4989 / 5000 batch step: 90\n",
      "w1: [26.33648573] w2: [-23.32798917] bias: [15.59538879] loss: 30.56371365271934\n",
      "Epoch: 4989 / 5000 batch step: 120\n",
      "w1: [26.34628402] w2: [-23.29721715] bias: [15.63186262] loss: 30.543555703253123\n",
      "Epoch: 4989 / 5000 batch step: 150\n",
      "w1: [26.3808343] w2: [-23.29572278] bias: [15.67611286] loss: 30.525453180855873\n",
      "Epoch: 4989 / 5000 batch step: 180\n",
      "w1: [26.44824727] w2: [-23.278666] bias: [15.77841825] loss: 30.51383949979924\n",
      "Epoch: 4989 / 5000 batch step: 210\n",
      "w1: [26.48469424] w2: [-23.25830771] bias: [15.83712016] loss: 30.526117079560017\n",
      "Epoch: 4989 / 5000 batch step: 240\n",
      "w1: [26.523197] w2: [-23.25245814] bias: [15.87850127] loss: 30.544613450847123\n",
      "Epoch: 4989 / 5000 batch step: 270\n",
      "w1: [26.53951842] w2: [-23.25256067] bias: [15.89555826] loss: 30.554352902473415\n",
      "Epoch: 4989 / 5000 batch step: 300\n",
      "w1: [26.5199396] w2: [-23.25872098] bias: [15.85693829] loss: 30.536235955728213\n",
      "Epoch: 4989 / 5000 batch step: 330\n",
      "w1: [26.484036] w2: [-23.27127068] bias: [15.78619295] loss: 30.516349618668567\n",
      "Epoch: 4989 / 5000 batch step: 360\n",
      "w1: [26.49522346] w2: [-23.24158257] bias: [15.87623775] loss: 30.540105594100645\n",
      "Epoch: 4989 / 5000 batch step: 390\n",
      "w1: [26.46933651] w2: [-23.25344333] bias: [15.84195592] loss: 30.525824785127423\n",
      "Epoch: 4989 / 5000 batch step: 420\n",
      "w1: [26.4197534] w2: [-23.29702423] bias: [15.74668021] loss: 30.5133210266782\n",
      "Epoch: 4989 / 5000 batch step: 450\n",
      "w1: [26.39421587] w2: [-23.31474418] bias: [15.70330504] loss: 30.51978102592003\n",
      "Epoch: 4989 / 5000 batch step: 480\n",
      "w1: [26.37735427] w2: [-23.31615642] bias: [15.67747844] loss: 30.52688892915852\n",
      "Epoch: 4990 / 5000 batch step: 0\n",
      "w1: [26.37113825] w2: [-23.31704704] bias: [15.66459147] loss: 30.531049072915934\n",
      "Epoch: 4990 / 5000 batch step: 30\n",
      "w1: [26.36455192] w2: [-23.31705018] bias: [15.65151865] loss: 30.53578815233103\n",
      "Epoch: 4990 / 5000 batch step: 60\n",
      "w1: [26.34306746] w2: [-23.32405258] bias: [15.61066101] loss: 30.555145857883193\n",
      "Epoch: 4990 / 5000 batch step: 90\n",
      "w1: [26.33648577] w2: [-23.32798915] bias: [15.59538876] loss: 30.56371365256006\n",
      "Epoch: 4990 / 5000 batch step: 120\n",
      "w1: [26.34628406] w2: [-23.29721713] bias: [15.63186259] loss: 30.54355570311222\n",
      "Epoch: 4990 / 5000 batch step: 150\n",
      "w1: [26.38083434] w2: [-23.29572275] bias: [15.67611283] loss: 30.52545318071506\n",
      "Epoch: 4990 / 5000 batch step: 180\n",
      "w1: [26.44824731] w2: [-23.27866598] bias: [15.77841822] loss: 30.51383949968637\n",
      "Epoch: 4990 / 5000 batch step: 210\n",
      "w1: [26.48469428] w2: [-23.25830768] bias: [15.83712013] loss: 30.526117079447747\n",
      "Epoch: 4990 / 5000 batch step: 240\n",
      "w1: [26.52319704] w2: [-23.25245812] bias: [15.87850124] loss: 30.54461345072526\n",
      "Epoch: 4990 / 5000 batch step: 270\n",
      "w1: [26.53951846] w2: [-23.25256065] bias: [15.89555824] loss: 30.55435290235621\n",
      "Epoch: 4990 / 5000 batch step: 300\n",
      "w1: [26.51993965] w2: [-23.25872095] bias: [15.85693826] loss: 30.53623595563393\n",
      "Epoch: 4990 / 5000 batch step: 330\n",
      "w1: [26.48403604] w2: [-23.27127066] bias: [15.78619293] loss: 30.516349618582353\n",
      "Epoch: 4990 / 5000 batch step: 360\n",
      "w1: [26.4952235] w2: [-23.24158255] bias: [15.87623773] loss: 30.54010559401682\n",
      "Epoch: 4990 / 5000 batch step: 390\n",
      "w1: [26.46933655] w2: [-23.2534433] bias: [15.84195589] loss: 30.525824785012123\n",
      "Epoch: 4990 / 5000 batch step: 420\n",
      "w1: [26.41975344] w2: [-23.29702421] bias: [15.74668018] loss: 30.513321026555484\n",
      "Epoch: 4990 / 5000 batch step: 450\n",
      "w1: [26.39421591] w2: [-23.31474415] bias: [15.70330501] loss: 30.51978102581293\n",
      "Epoch: 4990 / 5000 batch step: 480\n",
      "w1: [26.37735431] w2: [-23.3161564] bias: [15.67747841] loss: 30.526888929048884\n",
      "Epoch: 4991 / 5000 batch step: 0\n",
      "w1: [26.37113829] w2: [-23.31704702] bias: [15.66459145] loss: 30.531049072802258\n",
      "Epoch: 4991 / 5000 batch step: 30\n",
      "w1: [26.36455196] w2: [-23.31705015] bias: [15.65151863] loss: 30.535788152203313\n",
      "Epoch: 4991 / 5000 batch step: 60\n",
      "w1: [26.3430675] w2: [-23.32405256] bias: [15.61066098] loss: 30.555145857727883\n",
      "Epoch: 4991 / 5000 batch step: 90\n",
      "w1: [26.33648581] w2: [-23.32798912] bias: [15.59538874] loss: 30.563713652401145\n",
      "Epoch: 4991 / 5000 batch step: 120\n",
      "w1: [26.3462841] w2: [-23.29721711] bias: [15.63186257] loss: 30.543555702971624\n",
      "Epoch: 4991 / 5000 batch step: 150\n",
      "w1: [26.38083438] w2: [-23.29572273] bias: [15.6761128] loss: 30.525453180574573\n",
      "Epoch: 4991 / 5000 batch step: 180\n",
      "w1: [26.44824735] w2: [-23.27866595] bias: [15.77841819] loss: 30.513839499573763\n",
      "Epoch: 4991 / 5000 batch step: 210\n",
      "w1: [26.48469432] w2: [-23.25830766] bias: [15.8371201] loss: 30.526117079335727\n",
      "Epoch: 4991 / 5000 batch step: 240\n",
      "w1: [26.52319708] w2: [-23.2524581] bias: [15.87850121] loss: 30.544613450603684\n",
      "Epoch: 4991 / 5000 batch step: 270\n",
      "w1: [26.5395185] w2: [-23.25256063] bias: [15.89555821] loss: 30.55435290223927\n",
      "Epoch: 4991 / 5000 batch step: 300\n",
      "w1: [26.51993969] w2: [-23.25872093] bias: [15.85693823] loss: 30.536235955539865\n",
      "Epoch: 4991 / 5000 batch step: 330\n",
      "w1: [26.48403608] w2: [-23.27127064] bias: [15.7861929] loss: 30.516349618496342\n",
      "Epoch: 4991 / 5000 batch step: 360\n",
      "w1: [26.49522354] w2: [-23.24158252] bias: [15.8762377] loss: 30.540105593933188\n",
      "Epoch: 4991 / 5000 batch step: 390\n",
      "w1: [26.46933659] w2: [-23.25344328] bias: [15.84195586] loss: 30.525824784897072\n",
      "Epoch: 4991 / 5000 batch step: 420\n",
      "w1: [26.41975348] w2: [-23.29702419] bias: [15.74668015] loss: 30.51332102643305\n",
      "Epoch: 4991 / 5000 batch step: 450\n",
      "w1: [26.39421595] w2: [-23.31474413] bias: [15.70330498] loss: 30.519781025706063\n",
      "Epoch: 4991 / 5000 batch step: 480\n",
      "w1: [26.37735435] w2: [-23.31615638] bias: [15.67747838] loss: 30.526888928939492\n",
      "Epoch: 4992 / 5000 batch step: 0\n",
      "w1: [26.37113833] w2: [-23.317047] bias: [15.66459142] loss: 30.53104907268884\n",
      "Epoch: 4992 / 5000 batch step: 30\n",
      "w1: [26.364552] w2: [-23.31705013] bias: [15.6515186] loss: 30.5357881520759\n",
      "Epoch: 4992 / 5000 batch step: 60\n",
      "w1: [26.34306754] w2: [-23.32405253] bias: [15.61066095] loss: 30.555145857572928\n",
      "Epoch: 4992 / 5000 batch step: 90\n",
      "w1: [26.33648585] w2: [-23.3279891] bias: [15.59538871] loss: 30.563713652242587\n",
      "Epoch: 4992 / 5000 batch step: 120\n",
      "w1: [26.34628414] w2: [-23.29721708] bias: [15.63186254] loss: 30.543555702831352\n",
      "Epoch: 4992 / 5000 batch step: 150\n",
      "w1: [26.38083442] w2: [-23.29572271] bias: [15.67611277] loss: 30.525453180434408\n",
      "Epoch: 4992 / 5000 batch step: 180\n",
      "w1: [26.44824739] w2: [-23.27866593] bias: [15.77841816] loss: 30.5138394994614\n",
      "Epoch: 4992 / 5000 batch step: 210\n",
      "w1: [26.48469436] w2: [-23.25830764] bias: [15.83712008] loss: 30.526117079223962\n",
      "Epoch: 4992 / 5000 batch step: 240\n",
      "w1: [26.52319712] w2: [-23.25245808] bias: [15.87850119] loss: 30.544613450482387\n",
      "Epoch: 4992 / 5000 batch step: 270\n",
      "w1: [26.53951854] w2: [-23.25256061] bias: [15.89555818] loss: 30.554352902122602\n",
      "Epoch: 4992 / 5000 batch step: 300\n",
      "w1: [26.51993973] w2: [-23.25872091] bias: [15.8569382] loss: 30.536235955446006\n",
      "Epoch: 4992 / 5000 batch step: 330\n",
      "w1: [26.48403612] w2: [-23.27127061] bias: [15.78619287] loss: 30.516349618410526\n",
      "Epoch: 4992 / 5000 batch step: 360\n",
      "w1: [26.49522358] w2: [-23.2415825] bias: [15.87623767] loss: 30.540105593849752\n",
      "Epoch: 4992 / 5000 batch step: 390\n",
      "w1: [26.46933663] w2: [-23.25344326] bias: [15.84195583] loss: 30.525824784782287\n",
      "Epoch: 4992 / 5000 batch step: 420\n",
      "w1: [26.41975352] w2: [-23.29702416] bias: [15.74668012] loss: 30.513321026310898\n",
      "Epoch: 4992 / 5000 batch step: 450\n",
      "w1: [26.39421599] w2: [-23.31474411] bias: [15.70330496] loss: 30.519781025599453\n",
      "Epoch: 4992 / 5000 batch step: 480\n",
      "w1: [26.37735439] w2: [-23.31615635] bias: [15.67747836] loss: 30.526888928830353\n",
      "Epoch: 4993 / 5000 batch step: 0\n",
      "w1: [26.37113837] w2: [-23.31704698] bias: [15.66459139] loss: 30.531049072575684\n",
      "Epoch: 4993 / 5000 batch step: 30\n",
      "w1: [26.36455204] w2: [-23.31705011] bias: [15.65151857] loss: 30.535788151948772\n",
      "Epoch: 4993 / 5000 batch step: 60\n",
      "w1: [26.34306758] w2: [-23.32405251] bias: [15.61066093] loss: 30.555145857418324\n",
      "Epoch: 4993 / 5000 batch step: 90\n",
      "w1: [26.33648589] w2: [-23.32798908] bias: [15.59538868] loss: 30.56371365208439\n",
      "Epoch: 4993 / 5000 batch step: 120\n",
      "w1: [26.34628418] w2: [-23.29721706] bias: [15.63186251] loss: 30.543555702691396\n",
      "Epoch: 4993 / 5000 batch step: 150\n",
      "w1: [26.38083446] w2: [-23.29572269] bias: [15.67611275] loss: 30.52545318029455\n",
      "Epoch: 4993 / 5000 batch step: 180\n",
      "w1: [26.44824743] w2: [-23.27866591] bias: [15.77841813] loss: 30.5138394993493\n",
      "Epoch: 4993 / 5000 batch step: 210\n",
      "w1: [26.4846944] w2: [-23.25830762] bias: [15.83712005] loss: 30.52611707911245\n",
      "Epoch: 4993 / 5000 batch step: 240\n",
      "w1: [26.52319716] w2: [-23.25245806] bias: [15.87850116] loss: 30.544613450361357\n",
      "Epoch: 4993 / 5000 batch step: 270\n",
      "w1: [26.53951858] w2: [-23.25256059] bias: [15.89555815] loss: 30.554352902006194\n",
      "Epoch: 4993 / 5000 batch step: 300\n",
      "w1: [26.51993977] w2: [-23.25872089] bias: [15.85693818] loss: 30.536235955352378\n",
      "Epoch: 4993 / 5000 batch step: 330\n",
      "w1: [26.48403616] w2: [-23.27127059] bias: [15.78619284] loss: 30.516349618324902\n",
      "Epoch: 4993 / 5000 batch step: 360\n",
      "w1: [26.49522362] w2: [-23.24158248] bias: [15.87623764] loss: 30.5401055937665\n",
      "Epoch: 4993 / 5000 batch step: 390\n",
      "w1: [26.46933667] w2: [-23.25344324] bias: [15.84195581] loss: 30.525824784667765\n",
      "Epoch: 4993 / 5000 batch step: 420\n",
      "w1: [26.41975356] w2: [-23.29702414] bias: [15.7466801] loss: 30.513321026189026\n",
      "Epoch: 4993 / 5000 batch step: 450\n",
      "w1: [26.39421603] w2: [-23.31474409] bias: [15.70330493] loss: 30.519781025493078\n",
      "Epoch: 4993 / 5000 batch step: 480\n",
      "w1: [26.37735443] w2: [-23.31615633] bias: [15.67747833] loss: 30.52688892872146\n",
      "Epoch: 4994 / 5000 batch step: 0\n",
      "w1: [26.37113841] w2: [-23.31704696] bias: [15.66459136] loss: 30.531049072462785\n",
      "Epoch: 4994 / 5000 batch step: 30\n",
      "w1: [26.36455208] w2: [-23.31705009] bias: [15.65151854] loss: 30.53578815182193\n",
      "Epoch: 4994 / 5000 batch step: 60\n",
      "w1: [26.34306762] w2: [-23.32405249] bias: [15.6106609] loss: 30.55514585726408\n",
      "Epoch: 4994 / 5000 batch step: 90\n",
      "w1: [26.33648593] w2: [-23.32798906] bias: [15.59538865] loss: 30.563713651926555\n",
      "Epoch: 4994 / 5000 batch step: 120\n",
      "w1: [26.34628422] w2: [-23.29721704] bias: [15.63186248] loss: 30.543555702551775\n",
      "Epoch: 4994 / 5000 batch step: 150\n",
      "w1: [26.3808345] w2: [-23.29572266] bias: [15.67611272] loss: 30.525453180155026\n",
      "Epoch: 4994 / 5000 batch step: 180\n",
      "w1: [26.44824747] w2: [-23.27866589] bias: [15.77841811] loss: 30.513839499237463\n",
      "Epoch: 4994 / 5000 batch step: 210\n",
      "w1: [26.48469444] w2: [-23.25830759] bias: [15.83712002] loss: 30.526117079001192\n",
      "Epoch: 4994 / 5000 batch step: 240\n",
      "w1: [26.5231972] w2: [-23.25245803] bias: [15.87850113] loss: 30.544613450240597\n",
      "Epoch: 4994 / 5000 batch step: 270\n",
      "w1: [26.53951862] w2: [-23.25256056] bias: [15.89555812] loss: 30.55435290189004\n",
      "Epoch: 4994 / 5000 batch step: 300\n",
      "w1: [26.51993981] w2: [-23.25872087] bias: [15.85693815] loss: 30.536235955258945\n",
      "Epoch: 4994 / 5000 batch step: 330\n",
      "w1: [26.4840362] w2: [-23.27127057] bias: [15.78619281] loss: 30.516349618239474\n",
      "Epoch: 4994 / 5000 batch step: 360\n",
      "w1: [26.49522366] w2: [-23.24158246] bias: [15.87623762] loss: 30.540105593683435\n",
      "Epoch: 4994 / 5000 batch step: 390\n",
      "w1: [26.46933671] w2: [-23.25344322] bias: [15.84195578] loss: 30.5258247845535\n",
      "Epoch: 4994 / 5000 batch step: 420\n",
      "w1: [26.4197536] w2: [-23.29702412] bias: [15.74668007] loss: 30.51332102606742\n",
      "Epoch: 4994 / 5000 batch step: 450\n",
      "w1: [26.39421607] w2: [-23.31474407] bias: [15.7033049] loss: 30.51978102538695\n",
      "Epoch: 4994 / 5000 batch step: 480\n",
      "w1: [26.37735447] w2: [-23.31615631] bias: [15.6774783] loss: 30.52688892861282\n",
      "Epoch: 4995 / 5000 batch step: 0\n",
      "w1: [26.37113845] w2: [-23.31704693] bias: [15.66459133] loss: 30.531049072350143\n",
      "Epoch: 4995 / 5000 batch step: 30\n",
      "w1: [26.36455212] w2: [-23.31705007] bias: [15.65151851] loss: 30.535788151695378\n",
      "Epoch: 4995 / 5000 batch step: 60\n",
      "w1: [26.34306766] w2: [-23.32405247] bias: [15.61066087] loss: 30.55514585711018\n",
      "Epoch: 4995 / 5000 batch step: 90\n",
      "w1: [26.33648597] w2: [-23.32798904] bias: [15.59538862] loss: 30.56371365176909\n",
      "Epoch: 4995 / 5000 batch step: 120\n",
      "w1: [26.34628426] w2: [-23.29721702] bias: [15.63186245] loss: 30.543555702412455\n",
      "Epoch: 4995 / 5000 batch step: 150\n",
      "w1: [26.38083454] w2: [-23.29572264] bias: [15.67611269] loss: 30.52545318001581\n",
      "Epoch: 4995 / 5000 batch step: 180\n",
      "w1: [26.44824751] w2: [-23.27866586] bias: [15.77841808] loss: 30.513839499125865\n",
      "Epoch: 4995 / 5000 batch step: 210\n",
      "w1: [26.48469448] w2: [-23.25830757] bias: [15.83711999] loss: 30.526117078890188\n",
      "Epoch: 4995 / 5000 batch step: 240\n",
      "w1: [26.52319724] w2: [-23.25245801] bias: [15.8785011] loss: 30.54461345012012\n",
      "Epoch: 4995 / 5000 batch step: 270\n",
      "w1: [26.53951866] w2: [-23.25256054] bias: [15.8955581] loss: 30.55435290177416\n",
      "Epoch: 4995 / 5000 batch step: 300\n",
      "w1: [26.51993985] w2: [-23.25872084] bias: [15.85693812] loss: 30.536235955165733\n",
      "Epoch: 4995 / 5000 batch step: 330\n",
      "w1: [26.48403624] w2: [-23.27127055] bias: [15.78619279] loss: 30.516349618154244\n",
      "Epoch: 4995 / 5000 batch step: 360\n",
      "w1: [26.4952237] w2: [-23.24158244] bias: [15.87623759] loss: 30.540105593600565\n",
      "Epoch: 4995 / 5000 batch step: 390\n",
      "w1: [26.46933675] w2: [-23.25344319] bias: [15.84195575] loss: 30.525824784439504\n",
      "Epoch: 4995 / 5000 batch step: 420\n",
      "w1: [26.41975364] w2: [-23.2970241] bias: [15.74668004] loss: 30.5133210259461\n",
      "Epoch: 4995 / 5000 batch step: 450\n",
      "w1: [26.39421611] w2: [-23.31474404] bias: [15.70330487] loss: 30.519781025281063\n",
      "Epoch: 4995 / 5000 batch step: 480\n",
      "w1: [26.37735451] w2: [-23.31615629] bias: [15.67747827] loss: 30.526888928504416\n",
      "Epoch: 4996 / 5000 batch step: 0\n",
      "w1: [26.37113849] w2: [-23.31704691] bias: [15.66459131] loss: 30.531049072237753\n",
      "Epoch: 4996 / 5000 batch step: 30\n",
      "w1: [26.36455216] w2: [-23.31705004] bias: [15.65151849] loss: 30.53578815156912\n",
      "Epoch: 4996 / 5000 batch step: 60\n",
      "w1: [26.3430677] w2: [-23.32405245] bias: [15.61066084] loss: 30.55514585695663\n",
      "Epoch: 4996 / 5000 batch step: 90\n",
      "w1: [26.33648601] w2: [-23.32798901] bias: [15.5953886] loss: 30.563713651611963\n",
      "Epoch: 4996 / 5000 batch step: 120\n",
      "w1: [26.3462843] w2: [-23.297217] bias: [15.63186243] loss: 30.543555702273455\n",
      "Epoch: 4996 / 5000 batch step: 150\n",
      "w1: [26.38083458] w2: [-23.29572262] bias: [15.67611266] loss: 30.525453179876912\n",
      "Epoch: 4996 / 5000 batch step: 180\n",
      "w1: [26.44824755] w2: [-23.27866584] bias: [15.77841805] loss: 30.513839499014527\n",
      "Epoch: 4996 / 5000 batch step: 210\n",
      "w1: [26.48469452] w2: [-23.25830755] bias: [15.83711996] loss: 30.526117078779436\n",
      "Epoch: 4996 / 5000 batch step: 240\n",
      "w1: [26.52319728] w2: [-23.25245799] bias: [15.87850107] loss: 30.54461344999992\n",
      "Epoch: 4996 / 5000 batch step: 270\n",
      "w1: [26.5395187] w2: [-23.25256052] bias: [15.89555807] loss: 30.55435290165854\n",
      "Epoch: 4996 / 5000 batch step: 300\n",
      "w1: [26.51993989] w2: [-23.25872082] bias: [15.85693809] loss: 30.536235955072733\n",
      "Epoch: 4996 / 5000 batch step: 330\n",
      "w1: [26.48403628] w2: [-23.27127053] bias: [15.78619276] loss: 30.516349618069203\n",
      "Epoch: 4996 / 5000 batch step: 360\n",
      "w1: [26.49522374] w2: [-23.24158241] bias: [15.87623756] loss: 30.540105593517875\n",
      "Epoch: 4996 / 5000 batch step: 390\n",
      "w1: [26.46933679] w2: [-23.25344317] bias: [15.84195572] loss: 30.525824784325756\n",
      "Epoch: 4996 / 5000 batch step: 420\n",
      "w1: [26.41975368] w2: [-23.29702408] bias: [15.74668001] loss: 30.51332102582505\n",
      "Epoch: 4996 / 5000 batch step: 450\n",
      "w1: [26.39421615] w2: [-23.31474402] bias: [15.70330485] loss: 30.51978102517541\n",
      "Epoch: 4996 / 5000 batch step: 480\n",
      "w1: [26.37735455] w2: [-23.31615627] bias: [15.67747825] loss: 30.52688892839627\n",
      "Epoch: 4997 / 5000 batch step: 0\n",
      "w1: [26.37113853] w2: [-23.31704689] bias: [15.66459128] loss: 30.53104907212563\n",
      "Epoch: 4997 / 5000 batch step: 30\n",
      "w1: [26.3645522] w2: [-23.31705002] bias: [15.65151846] loss: 30.535788151443146\n",
      "Epoch: 4997 / 5000 batch step: 60\n",
      "w1: [26.34306774] w2: [-23.32405242] bias: [15.61066082] loss: 30.55514585680343\n",
      "Epoch: 4997 / 5000 batch step: 90\n",
      "w1: [26.33648605] w2: [-23.32798899] bias: [15.59538857] loss: 30.563713651455203\n",
      "Epoch: 4997 / 5000 batch step: 120\n",
      "w1: [26.34628434] w2: [-23.29721697] bias: [15.6318624] loss: 30.54355570213477\n",
      "Epoch: 4997 / 5000 batch step: 150\n",
      "w1: [26.38083462] w2: [-23.2957226] bias: [15.67611264] loss: 30.525453179738335\n",
      "Epoch: 4997 / 5000 batch step: 180\n",
      "w1: [26.44824759] w2: [-23.27866582] bias: [15.77841802] loss: 30.513839498903447\n",
      "Epoch: 4997 / 5000 batch step: 210\n",
      "w1: [26.48469456] w2: [-23.25830753] bias: [15.83711994] loss: 30.526117078668932\n",
      "Epoch: 4997 / 5000 batch step: 240\n",
      "w1: [26.52319732] w2: [-23.25245797] bias: [15.87850105] loss: 30.544613449879986\n",
      "Epoch: 4997 / 5000 batch step: 270\n",
      "w1: [26.53951874] w2: [-23.2525605] bias: [15.89555804] loss: 30.554352901543187\n",
      "Epoch: 4997 / 5000 batch step: 300\n",
      "w1: [26.51993993] w2: [-23.2587208] bias: [15.85693807] loss: 30.536235954979936\n",
      "Epoch: 4997 / 5000 batch step: 330\n",
      "w1: [26.48403632] w2: [-23.2712705] bias: [15.78619273] loss: 30.516349617984357\n",
      "Epoch: 4997 / 5000 batch step: 360\n",
      "w1: [26.49522378] w2: [-23.24158239] bias: [15.87623753] loss: 30.540105593435378\n",
      "Epoch: 4997 / 5000 batch step: 390\n",
      "w1: [26.46933683] w2: [-23.25344315] bias: [15.84195569] loss: 30.525824784212272\n",
      "Epoch: 4997 / 5000 batch step: 420\n",
      "w1: [26.41975372] w2: [-23.29702405] bias: [15.74667999] loss: 30.51332102570428\n",
      "Epoch: 4997 / 5000 batch step: 450\n",
      "w1: [26.39421619] w2: [-23.314744] bias: [15.70330482] loss: 30.51978102507\n",
      "Epoch: 4997 / 5000 batch step: 480\n",
      "w1: [26.37735459] w2: [-23.31615624] bias: [15.67747822] loss: 30.52688892828836\n",
      "Epoch: 4998 / 5000 batch step: 0\n",
      "w1: [26.37113857] w2: [-23.31704687] bias: [15.66459125] loss: 30.53104907201375\n",
      "Epoch: 4998 / 5000 batch step: 30\n",
      "w1: [26.36455224] w2: [-23.31705] bias: [15.65151843] loss: 30.53578815131745\n",
      "Epoch: 4998 / 5000 batch step: 60\n",
      "w1: [26.34306778] w2: [-23.3240524] bias: [15.61066079] loss: 30.555145856650586\n",
      "Epoch: 4998 / 5000 batch step: 90\n",
      "w1: [26.33648609] w2: [-23.32798897] bias: [15.59538854] loss: 30.5637136512988\n",
      "Epoch: 4998 / 5000 batch step: 120\n",
      "w1: [26.34628438] w2: [-23.29721695] bias: [15.63186237] loss: 30.543555701996407\n",
      "Epoch: 4998 / 5000 batch step: 150\n",
      "w1: [26.38083466] w2: [-23.29572258] bias: [15.67611261] loss: 30.525453179600063\n",
      "Epoch: 4998 / 5000 batch step: 180\n",
      "w1: [26.44824763] w2: [-23.2786658] bias: [15.778418] loss: 30.513839498792613\n",
      "Epoch: 4998 / 5000 batch step: 210\n",
      "w1: [26.4846946] w2: [-23.25830751] bias: [15.83711991] loss: 30.52611707855868\n",
      "Epoch: 4998 / 5000 batch step: 240\n",
      "w1: [26.52319736] w2: [-23.25245795] bias: [15.87850102] loss: 30.54461344976033\n",
      "Epoch: 4998 / 5000 batch step: 270\n",
      "w1: [26.53951878] w2: [-23.25256048] bias: [15.89555801] loss: 30.5543529014281\n",
      "Epoch: 4998 / 5000 batch step: 300\n",
      "w1: [26.51993997] w2: [-23.25872078] bias: [15.85693804] loss: 30.536235954887363\n",
      "Epoch: 4998 / 5000 batch step: 330\n",
      "w1: [26.48403636] w2: [-23.27127048] bias: [15.7861927] loss: 30.516349617899703\n",
      "Epoch: 4998 / 5000 batch step: 360\n",
      "w1: [26.49522382] w2: [-23.24158237] bias: [15.8762375] loss: 30.540105593353076\n",
      "Epoch: 4998 / 5000 batch step: 390\n",
      "w1: [26.46933687] w2: [-23.25344313] bias: [15.84195567] loss: 30.525824784099047\n",
      "Epoch: 4998 / 5000 batch step: 420\n",
      "w1: [26.41975376] w2: [-23.29702403] bias: [15.74667996] loss: 30.51332102558378\n",
      "Epoch: 4998 / 5000 batch step: 450\n",
      "w1: [26.39421623] w2: [-23.31474398] bias: [15.70330479] loss: 30.51978102496483\n",
      "Epoch: 4998 / 5000 batch step: 480\n",
      "w1: [26.37735463] w2: [-23.31615622] bias: [15.67747819] loss: 30.526888928180707\n",
      "Epoch: 4999 / 5000 batch step: 0\n",
      "w1: [26.37113861] w2: [-23.31704685] bias: [15.66459122] loss: 30.531049071902128\n",
      "Epoch: 4999 / 5000 batch step: 30\n",
      "w1: [26.36455228] w2: [-23.31704998] bias: [15.6515184] loss: 30.535788151192047\n",
      "Epoch: 4999 / 5000 batch step: 60\n",
      "w1: [26.34306782] w2: [-23.32405238] bias: [15.61066076] loss: 30.555145856498086\n",
      "Epoch: 4999 / 5000 batch step: 90\n",
      "w1: [26.33648613] w2: [-23.32798895] bias: [15.59538851] loss: 30.563713651142756\n",
      "Epoch: 4999 / 5000 batch step: 120\n",
      "w1: [26.34628442] w2: [-23.29721693] bias: [15.63186234] loss: 30.543555701858352\n",
      "Epoch: 4999 / 5000 batch step: 150\n",
      "w1: [26.3808347] w2: [-23.29572255] bias: [15.67611258] loss: 30.525453179462108\n",
      "Epoch: 4999 / 5000 batch step: 180\n",
      "w1: [26.44824767] w2: [-23.27866578] bias: [15.77841797] loss: 30.51383949868203\n",
      "Epoch: 4999 / 5000 batch step: 210\n",
      "w1: [26.48469464] w2: [-23.25830748] bias: [15.83711988] loss: 30.526117078448685\n",
      "Epoch: 4999 / 5000 batch step: 240\n",
      "w1: [26.5231974] w2: [-23.25245792] bias: [15.87850099] loss: 30.54461344964094\n",
      "Epoch: 4999 / 5000 batch step: 270\n",
      "w1: [26.53951882] w2: [-23.25256045] bias: [15.89555799] loss: 30.554352901313266\n",
      "Epoch: 4999 / 5000 batch step: 300\n",
      "w1: [26.51994001] w2: [-23.25872076] bias: [15.85693801] loss: 30.53623595479499\n",
      "Epoch: 4999 / 5000 batch step: 330\n",
      "w1: [26.4840364] w2: [-23.27127046] bias: [15.78619268] loss: 30.516349617815248\n",
      "Epoch: 4999 / 5000 batch step: 360\n",
      "w1: [26.49522386] w2: [-23.24158235] bias: [15.87623748] loss: 30.540105593270958\n",
      "Epoch: 4999 / 5000 batch step: 390\n",
      "w1: [26.46933691] w2: [-23.25344311] bias: [15.84195564] loss: 30.52582478398607\n",
      "Epoch: 4999 / 5000 batch step: 420\n",
      "w1: [26.4197538] w2: [-23.29702401] bias: [15.74667993] loss: 30.513321025463558\n",
      "Epoch: 4999 / 5000 batch step: 450\n",
      "w1: [26.39421627] w2: [-23.31474396] bias: [15.70330476] loss: 30.519781024859903\n",
      "Epoch: 4999 / 5000 batch step: 480\n",
      "w1: [26.37735467] w2: [-23.3161562] bias: [15.67747816] loss: 30.52688892807329\n",
      "Epoch: 5000 / 5000 batch step: 0\n",
      "w1: [26.37113865] w2: [-23.31704682] bias: [15.6645912] loss: 30.531049071790758\n",
      "Epoch: 5000 / 5000 batch step: 30\n",
      "w1: [26.36455232] w2: [-23.31704996] bias: [15.65151838] loss: 30.535788151066928\n",
      "Epoch: 5000 / 5000 batch step: 60\n",
      "w1: [26.34306786] w2: [-23.32405236] bias: [15.61066073] loss: 30.555145856345927\n",
      "Epoch: 5000 / 5000 batch step: 90\n",
      "w1: [26.33648617] w2: [-23.32798893] bias: [15.59538849] loss: 30.563713650987058\n",
      "Epoch: 5000 / 5000 batch step: 120\n",
      "w1: [26.34628446] w2: [-23.29721691] bias: [15.63186232] loss: 30.54355570172061\n",
      "Epoch: 5000 / 5000 batch step: 150\n",
      "w1: [26.38083474] w2: [-23.29572253] bias: [15.67611255] loss: 30.52545317932446\n",
      "Epoch: 5000 / 5000 batch step: 180\n",
      "w1: [26.44824771] w2: [-23.27866575] bias: [15.77841794] loss: 30.51383949857171\n",
      "Epoch: 5000 / 5000 batch step: 210\n",
      "w1: [26.48469468] w2: [-23.25830746] bias: [15.83711985] loss: 30.52611707833894\n",
      "Epoch: 5000 / 5000 batch step: 240\n",
      "w1: [26.52319744] w2: [-23.2524579] bias: [15.87850096] loss: 30.544613449521822\n",
      "Epoch: 5000 / 5000 batch step: 270\n",
      "w1: [26.53951886] w2: [-23.25256043] bias: [15.89555796] loss: 30.554352901198698\n",
      "Epoch: 5000 / 5000 batch step: 300\n",
      "w1: [26.51994005] w2: [-23.25872073] bias: [15.85693798] loss: 30.53623595470283\n",
      "Epoch: 5000 / 5000 batch step: 330\n",
      "w1: [26.48403644] w2: [-23.27127044] bias: [15.78619265] loss: 30.516349617730977\n",
      "Epoch: 5000 / 5000 batch step: 360\n",
      "w1: [26.4952239] w2: [-23.24158233] bias: [15.87623745] loss: 30.540105593189022\n",
      "Epoch: 5000 / 5000 batch step: 390\n",
      "w1: [26.46933695] w2: [-23.25344308] bias: [15.84195561] loss: 30.525824783873365\n",
      "Epoch: 5000 / 5000 batch step: 420\n",
      "w1: [26.41975384] w2: [-23.29702399] bias: [15.7466799] loss: 30.513321025343608\n",
      "Epoch: 5000 / 5000 batch step: 450\n",
      "w1: [26.39421631] w2: [-23.31474393] bias: [15.70330473] loss: 30.519781024755215\n",
      "Epoch: 5000 / 5000 batch step: 480\n",
      "w1: [26.37735471] w2: [-23.31615618] bias: [15.67747814] loss: 30.526888927966123\n",
      "##### 최종 w1, w2, bias #######\n",
      "[26.37735471] [-23.31615618] [15.67747814]\n"
     ]
    }
   ],
   "source": [
    "w1, w2, bias = batch_gradient_descent(scaled_features, bostonDF['PRICE'].values, iter_epochs=5000, batch_size=30, verbose=True)\n",
    "print('##### 최종 w1, w2, bias #######')\n",
    "print(w1, w2, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "LDjRvxN51REb",
    "outputId": "ad8e8a6c-66e2-4b87-cb70-29e5e6907005"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bf727929-0b99-4137-bd9c-6b97c7816b14\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
       "      <th>PREDICTED_PRICE_BATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.937588</td>\n",
       "      <td>28.819549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>25.486589</td>\n",
       "      <td>25.364749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>32.529370</td>\n",
       "      <td>32.513763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.324713</td>\n",
       "      <td>32.269932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>31.500316</td>\n",
       "      <td>31.485311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>28.081091</td>\n",
       "      <td>27.938726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>21.356486</td>\n",
       "      <td>21.180895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>17.775532</td>\n",
       "      <td>17.666026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>8.140533</td>\n",
       "      <td>7.996101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.286595</td>\n",
       "      <td>18.135869</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bf727929-0b99-4137-bd9c-6b97c7816b14')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bf727929-0b99-4137-bd9c-6b97c7816b14 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bf727929-0b99-4137-bd9c-6b97c7816b14');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE_BATCH_RANDOM  \\\n",
       "0     15.3  396.90   4.98   24.0                     28.937588   \n",
       "1     17.8  396.90   9.14   21.6                     25.486589   \n",
       "2     17.8  392.83   4.03   34.7                     32.529370   \n",
       "3     18.7  394.63   2.94   33.4                     32.324713   \n",
       "4     18.7  396.90   5.33   36.2                     31.500316   \n",
       "5     18.7  394.12   5.21   28.7                     28.081091   \n",
       "6     15.2  395.60  12.43   22.9                     21.356486   \n",
       "7     15.2  396.90  19.15   27.1                     17.775532   \n",
       "8     15.2  386.63  29.93   16.5                      8.140533   \n",
       "9     15.2  386.71  17.10   18.9                     18.286595   \n",
       "\n",
       "   PREDICTED_PRICE_BATCH  \n",
       "0              28.819549  \n",
       "1              25.364749  \n",
       "2              32.513763  \n",
       "3              32.269932  \n",
       "4              31.485311  \n",
       "5              27.938726  \n",
       "6              21.180895  \n",
       "7              17.666026  \n",
       "8               7.996101  \n",
       "9              18.135869  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = scaled_features[:, 0]*w1 + scaled_features[:, 1]*w2 + bias\n",
    "bostonDF['PREDICTED_PRICE_BATCH'] = predicted\n",
    "bostonDF.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yd1bWN-S1REb"
   },
   "source": [
    "### Mini BATCH GD를 Keras로 수행\n",
    "* Keras는 기본적으로 Mini Batch GD를 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L5JZCpyT_tg7",
    "outputId": "4dc0c41c-0d5a-4ca2-c23c-3980324a983a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (2.8.2+zzzcolab20220527125636)\n",
      "Requirement already satisfied: gast>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.5.3)\n",
      "Requirement already satisfied: absl-py>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.26.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.2)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (4.2.0)\n",
      "Requirement already satisfied: libclang>=9.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (14.0.1)\n",
      "Requirement already satisfied: tensorflow-estimator<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.15.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.46.3)\n",
      "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.21.6)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.1.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from tensorflow) (57.4.0)\n",
      "Requirement already satisfied: flatbuffers>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (1.1.0)\n",
      "Requirement already satisfied: tensorboard<2.9,>=2.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (2.8.0)\n",
      "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow) (3.17.3)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow) (1.5.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (3.3.7)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.35.0)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (2.23.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.0.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.9,>=2.8->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.2.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (4.11.4)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.9,>=2.8->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.9,>=2.8->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2.10)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (1.24.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (2022.5.18.1)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.9,>=2.8->tensorflow) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.9,>=2.8->tensorflow) (3.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XwGrjTA81REc",
    "outputId": "77f4751d-84a5-46a4-cba5-5a2640939469"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "17/17 [==============================] - 1s 5ms/step - loss: 541.8936 - mse: 541.8936\n",
      "Epoch 2/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 529.0566 - mse: 529.0566\n",
      "Epoch 3/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 516.3418 - mse: 516.3418\n",
      "Epoch 4/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 503.9677 - mse: 503.9677\n",
      "Epoch 5/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 492.0231 - mse: 492.0231\n",
      "Epoch 6/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 480.0396 - mse: 480.0396\n",
      "Epoch 7/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 468.5280 - mse: 468.5280\n",
      "Epoch 8/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 457.3204 - mse: 457.3204\n",
      "Epoch 9/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 446.1890 - mse: 446.1890\n",
      "Epoch 10/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 435.4426 - mse: 435.4426\n",
      "Epoch 11/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 424.8618 - mse: 424.8618\n",
      "Epoch 12/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 414.6590 - mse: 414.6590\n",
      "Epoch 13/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 404.6525 - mse: 404.6525\n",
      "Epoch 14/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 394.7774 - mse: 394.7774\n",
      "Epoch 15/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 385.2831 - mse: 385.2831\n",
      "Epoch 16/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 375.9724 - mse: 375.9724\n",
      "Epoch 17/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 366.8982 - mse: 366.8982\n",
      "Epoch 18/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 358.0033 - mse: 358.0033\n",
      "Epoch 19/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 349.4041 - mse: 349.4041\n",
      "Epoch 20/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 340.9788 - mse: 340.9788\n",
      "Epoch 21/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 332.7986 - mse: 332.7986\n",
      "Epoch 22/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 324.7588 - mse: 324.7588\n",
      "Epoch 23/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 317.0654 - mse: 317.0654\n",
      "Epoch 24/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 309.4646 - mse: 309.4646\n",
      "Epoch 25/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 302.0775 - mse: 302.0775\n",
      "Epoch 26/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 294.8950 - mse: 294.8950\n",
      "Epoch 27/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 287.8897 - mse: 287.8897\n",
      "Epoch 28/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 281.1474 - mse: 281.1474\n",
      "Epoch 29/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 274.5285 - mse: 274.5285\n",
      "Epoch 30/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 268.1255 - mse: 268.1255\n",
      "Epoch 31/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 261.7509 - mse: 261.7509\n",
      "Epoch 32/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 255.8087 - mse: 255.8087\n",
      "Epoch 33/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 249.8442 - mse: 249.8442\n",
      "Epoch 34/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 244.1934 - mse: 244.1934\n",
      "Epoch 35/1000\n",
      "17/17 [==============================] - 0s 9ms/step - loss: 238.5724 - mse: 238.5724\n",
      "Epoch 36/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 233.2188 - mse: 233.2188\n",
      "Epoch 37/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 227.9218 - mse: 227.9217\n",
      "Epoch 38/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 222.8523 - mse: 222.8523\n",
      "Epoch 39/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 217.9623 - mse: 217.9623\n",
      "Epoch 40/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 213.1505 - mse: 213.1505\n",
      "Epoch 41/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 208.4698 - mse: 208.4698\n",
      "Epoch 42/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 204.0437 - mse: 204.0437\n",
      "Epoch 43/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 199.6652 - mse: 199.6652\n",
      "Epoch 44/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 195.3673 - mse: 195.3673\n",
      "Epoch 45/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 191.3507 - mse: 191.3507\n",
      "Epoch 46/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 187.3382 - mse: 187.3382\n",
      "Epoch 47/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 183.6003 - mse: 183.6003\n",
      "Epoch 48/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 179.7466 - mse: 179.7466\n",
      "Epoch 49/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 176.2073 - mse: 176.2073\n",
      "Epoch 50/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 172.7691 - mse: 172.7691\n",
      "Epoch 51/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 169.3658 - mse: 169.3658\n",
      "Epoch 52/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 166.1453 - mse: 166.1453\n",
      "Epoch 53/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 162.9492 - mse: 162.9492\n",
      "Epoch 54/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 159.9540 - mse: 159.9540\n",
      "Epoch 55/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 156.9917 - mse: 156.9917\n",
      "Epoch 56/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 154.1893 - mse: 154.1893\n",
      "Epoch 57/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 151.4499 - mse: 151.4499\n",
      "Epoch 58/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 148.8016 - mse: 148.8016\n",
      "Epoch 59/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 146.2331 - mse: 146.2331\n",
      "Epoch 60/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 143.7599 - mse: 143.7599\n",
      "Epoch 61/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 141.4009 - mse: 141.4009\n",
      "Epoch 62/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 139.1054 - mse: 139.1054\n",
      "Epoch 63/1000\n",
      "17/17 [==============================] - 0s 8ms/step - loss: 136.8617 - mse: 136.8617\n",
      "Epoch 64/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 134.7445 - mse: 134.7445\n",
      "Epoch 65/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 132.6977 - mse: 132.6977\n",
      "Epoch 66/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 130.7045 - mse: 130.7045\n",
      "Epoch 67/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 128.7536 - mse: 128.7536\n",
      "Epoch 68/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 126.9350 - mse: 126.9350\n",
      "Epoch 69/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 125.1464 - mse: 125.1464\n",
      "Epoch 70/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 123.4076 - mse: 123.4076\n",
      "Epoch 71/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 121.7868 - mse: 121.7868\n",
      "Epoch 72/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 120.1614 - mse: 120.1614\n",
      "Epoch 73/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 118.6393 - mse: 118.6393\n",
      "Epoch 74/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 117.0996 - mse: 117.0996\n",
      "Epoch 75/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 115.7198 - mse: 115.7198\n",
      "Epoch 76/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 114.2745 - mse: 114.2745\n",
      "Epoch 77/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 112.9468 - mse: 112.9468\n",
      "Epoch 78/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 111.6738 - mse: 111.6738\n",
      "Epoch 79/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 110.4418 - mse: 110.4418\n",
      "Epoch 80/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 109.2324 - mse: 109.2324\n",
      "Epoch 81/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 108.0309 - mse: 108.0309\n",
      "Epoch 82/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 106.9569 - mse: 106.9569\n",
      "Epoch 83/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 105.8229 - mse: 105.8229\n",
      "Epoch 84/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 104.8181 - mse: 104.8181\n",
      "Epoch 85/1000\n",
      "17/17 [==============================] - 0s 7ms/step - loss: 103.7637 - mse: 103.7637\n",
      "Epoch 86/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 102.8075 - mse: 102.8075\n",
      "Epoch 87/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 101.8648 - mse: 101.8648\n",
      "Epoch 88/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 100.9190 - mse: 100.9190\n",
      "Epoch 89/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 100.0403 - mse: 100.0403\n",
      "Epoch 90/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 99.1956 - mse: 99.1956\n",
      "Epoch 91/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 98.3270 - mse: 98.3270\n",
      "Epoch 92/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 97.5085 - mse: 97.5085\n",
      "Epoch 93/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 96.7500 - mse: 96.7500\n",
      "Epoch 94/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 95.9887 - mse: 95.9887\n",
      "Epoch 95/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 95.2025 - mse: 95.2025\n",
      "Epoch 96/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 94.5018 - mse: 94.5018\n",
      "Epoch 97/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 93.7774 - mse: 93.7774\n",
      "Epoch 98/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 93.1286 - mse: 93.1286\n",
      "Epoch 99/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 92.4217 - mse: 92.4217\n",
      "Epoch 100/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 91.7922 - mse: 91.7922\n",
      "Epoch 101/1000\n",
      "17/17 [==============================] - 0s 5ms/step - loss: 91.1410 - mse: 91.1410\n",
      "Epoch 102/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 90.5206 - mse: 90.5206\n",
      "Epoch 103/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 89.9154 - mse: 89.9154\n",
      "Epoch 104/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 89.3062 - mse: 89.3062\n",
      "Epoch 105/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 88.7402 - mse: 88.7402\n",
      "Epoch 106/1000\n",
      "17/17 [==============================] - 0s 6ms/step - loss: 88.1492 - mse: 88.1492\n",
      "Epoch 107/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 87.5877 - mse: 87.5877\n",
      "Epoch 108/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 87.0685 - mse: 87.0685\n",
      "Epoch 109/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 86.4859 - mse: 86.4859\n",
      "Epoch 110/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 85.9716 - mse: 85.9716\n",
      "Epoch 111/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 85.4378 - mse: 85.4378\n",
      "Epoch 112/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 84.9178 - mse: 84.9178\n",
      "Epoch 113/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 84.4169 - mse: 84.4169\n",
      "Epoch 114/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 83.9226 - mse: 83.9226\n",
      "Epoch 115/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 83.4186 - mse: 83.4186\n",
      "Epoch 116/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 82.9436 - mse: 82.9436\n",
      "Epoch 117/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 82.4559 - mse: 82.4559\n",
      "Epoch 118/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 81.9752 - mse: 81.9752\n",
      "Epoch 119/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 81.5179 - mse: 81.5179\n",
      "Epoch 120/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 81.0540 - mse: 81.0540\n",
      "Epoch 121/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 80.5885 - mse: 80.5885\n",
      "Epoch 122/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 80.1370 - mse: 80.1370\n",
      "Epoch 123/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 79.6910 - mse: 79.6910\n",
      "Epoch 124/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 79.2405 - mse: 79.2405\n",
      "Epoch 125/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 78.8023 - mse: 78.8023\n",
      "Epoch 126/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 78.3724 - mse: 78.3724\n",
      "Epoch 127/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 77.9364 - mse: 77.9364\n",
      "Epoch 128/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 77.5055 - mse: 77.5055\n",
      "Epoch 129/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 77.0837 - mse: 77.0837\n",
      "Epoch 130/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 76.6720 - mse: 76.6720\n",
      "Epoch 131/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 76.2378 - mse: 76.2378\n",
      "Epoch 132/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75.8317 - mse: 75.8317\n",
      "Epoch 133/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75.4078 - mse: 75.4078\n",
      "Epoch 134/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 75.0086 - mse: 75.0086\n",
      "Epoch 135/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 74.6076 - mse: 74.6076\n",
      "Epoch 136/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 74.1885 - mse: 74.1885\n",
      "Epoch 137/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73.8008 - mse: 73.8008\n",
      "Epoch 138/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73.3904 - mse: 73.3904\n",
      "Epoch 139/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 73.0110 - mse: 73.0110\n",
      "Epoch 140/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72.6011 - mse: 72.6011\n",
      "Epoch 141/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 72.2217 - mse: 72.2217\n",
      "Epoch 142/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71.8289 - mse: 71.8289\n",
      "Epoch 143/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71.4309 - mse: 71.4309\n",
      "Epoch 144/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 71.0431 - mse: 71.0431\n",
      "Epoch 145/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70.6701 - mse: 70.6701\n",
      "Epoch 146/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 70.2922 - mse: 70.2922\n",
      "Epoch 147/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 69.9165 - mse: 69.9165\n",
      "Epoch 148/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 69.5315 - mse: 69.5315\n",
      "Epoch 149/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 69.1569 - mse: 69.1569\n",
      "Epoch 150/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68.7871 - mse: 68.7871\n",
      "Epoch 151/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68.4200 - mse: 68.4200\n",
      "Epoch 152/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 68.0448 - mse: 68.0448\n",
      "Epoch 153/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67.6904 - mse: 67.6904\n",
      "Epoch 154/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 67.3201 - mse: 67.3201\n",
      "Epoch 155/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66.9662 - mse: 66.9662\n",
      "Epoch 156/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66.6130 - mse: 66.6130\n",
      "Epoch 157/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 66.2397 - mse: 66.2397\n",
      "Epoch 158/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65.8920 - mse: 65.8920\n",
      "Epoch 159/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65.5338 - mse: 65.5338\n",
      "Epoch 160/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 65.1921 - mse: 65.1921\n",
      "Epoch 161/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64.8349 - mse: 64.8349\n",
      "Epoch 162/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64.4884 - mse: 64.4884\n",
      "Epoch 163/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 64.1474 - mse: 64.1474\n",
      "Epoch 164/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63.8043 - mse: 63.8043\n",
      "Epoch 165/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63.4660 - mse: 63.4660\n",
      "Epoch 166/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 63.1289 - mse: 63.1289\n",
      "Epoch 167/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62.7927 - mse: 62.7927\n",
      "Epoch 168/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62.4596 - mse: 62.4596\n",
      "Epoch 169/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 62.1237 - mse: 62.1237\n",
      "Epoch 170/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61.7956 - mse: 61.7956\n",
      "Epoch 171/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61.4668 - mse: 61.4668\n",
      "Epoch 172/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 61.1502 - mse: 61.1502\n",
      "Epoch 173/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60.8203 - mse: 60.8203\n",
      "Epoch 174/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60.5071 - mse: 60.5071\n",
      "Epoch 175/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 60.1793 - mse: 60.1793\n",
      "Epoch 176/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59.8617 - mse: 59.8617\n",
      "Epoch 177/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59.5452 - mse: 59.5452\n",
      "Epoch 178/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 59.2381 - mse: 59.2381\n",
      "Epoch 179/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58.9242 - mse: 58.9242\n",
      "Epoch 180/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58.6107 - mse: 58.6107\n",
      "Epoch 181/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58.3059 - mse: 58.3059\n",
      "Epoch 182/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 58.0042 - mse: 58.0042\n",
      "Epoch 183/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57.6997 - mse: 57.6997\n",
      "Epoch 184/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57.3971 - mse: 57.3971\n",
      "Epoch 185/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 57.0969 - mse: 57.0969\n",
      "Epoch 186/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56.8109 - mse: 56.8109\n",
      "Epoch 187/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56.5028 - mse: 56.5028\n",
      "Epoch 188/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 56.2204 - mse: 56.2204\n",
      "Epoch 189/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.9157 - mse: 55.9157\n",
      "Epoch 190/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.6417 - mse: 55.6417\n",
      "Epoch 191/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.3501 - mse: 55.3501\n",
      "Epoch 192/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 55.0686 - mse: 55.0686\n",
      "Epoch 193/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54.7930 - mse: 54.7930\n",
      "Epoch 194/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54.5015 - mse: 54.5015\n",
      "Epoch 195/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 54.2230 - mse: 54.2230\n",
      "Epoch 196/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53.9481 - mse: 53.9481\n",
      "Epoch 197/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53.6723 - mse: 53.6723\n",
      "Epoch 198/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53.4026 - mse: 53.4026\n",
      "Epoch 199/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 53.1322 - mse: 53.1322\n",
      "Epoch 200/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52.8608 - mse: 52.8608\n",
      "Epoch 201/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52.5957 - mse: 52.5957\n",
      "Epoch 202/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52.3321 - mse: 52.3321\n",
      "Epoch 203/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 52.0774 - mse: 52.0774\n",
      "Epoch 204/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51.8079 - mse: 51.8079\n",
      "Epoch 205/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51.5541 - mse: 51.5541\n",
      "Epoch 206/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 51.2892 - mse: 51.2892\n",
      "Epoch 207/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 51.0440 - mse: 51.0440\n",
      "Epoch 208/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50.7925 - mse: 50.7925\n",
      "Epoch 209/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50.5323 - mse: 50.5323\n",
      "Epoch 210/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50.2860 - mse: 50.2860\n",
      "Epoch 211/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 50.0553 - mse: 50.0553\n",
      "Epoch 212/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49.7973 - mse: 49.7973\n",
      "Epoch 213/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49.5571 - mse: 49.5571\n",
      "Epoch 214/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49.3186 - mse: 49.3186\n",
      "Epoch 215/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 49.0883 - mse: 49.0883\n",
      "Epoch 216/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48.8401 - mse: 48.8401\n",
      "Epoch 217/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48.6078 - mse: 48.6078\n",
      "Epoch 218/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 48.3777 - mse: 48.3777\n",
      "Epoch 219/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 48.1448 - mse: 48.1448\n",
      "Epoch 220/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.9208 - mse: 47.9208\n",
      "Epoch 221/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.6954 - mse: 47.6954\n",
      "Epoch 222/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.4684 - mse: 47.4684\n",
      "Epoch 223/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.2430 - mse: 47.2430\n",
      "Epoch 224/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 47.0160 - mse: 47.0160\n",
      "Epoch 225/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.8070 - mse: 46.8070\n",
      "Epoch 226/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.5906 - mse: 46.5906\n",
      "Epoch 227/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.3700 - mse: 46.3700\n",
      "Epoch 228/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 46.1584 - mse: 46.1584\n",
      "Epoch 229/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45.9455 - mse: 45.9455\n",
      "Epoch 230/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45.7399 - mse: 45.7399\n",
      "Epoch 231/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45.5343 - mse: 45.5343\n",
      "Epoch 232/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45.3270 - mse: 45.3270\n",
      "Epoch 233/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 45.1338 - mse: 45.1338\n",
      "Epoch 234/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44.9154 - mse: 44.9154\n",
      "Epoch 235/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44.7238 - mse: 44.7238\n",
      "Epoch 236/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44.5187 - mse: 44.5187\n",
      "Epoch 237/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44.3346 - mse: 44.3346\n",
      "Epoch 238/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 44.1298 - mse: 44.1298\n",
      "Epoch 239/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.9416 - mse: 43.9416\n",
      "Epoch 240/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.7516 - mse: 43.7516\n",
      "Epoch 241/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.5625 - mse: 43.5625\n",
      "Epoch 242/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.3762 - mse: 43.3762\n",
      "Epoch 243/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.1921 - mse: 43.1921\n",
      "Epoch 244/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 43.0046 - mse: 43.0046\n",
      "Epoch 245/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.8263 - mse: 42.8263\n",
      "Epoch 246/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.6513 - mse: 42.6513\n",
      "Epoch 247/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.4734 - mse: 42.4734\n",
      "Epoch 248/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.3049 - mse: 42.3049\n",
      "Epoch 249/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 42.1237 - mse: 42.1237\n",
      "Epoch 250/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.9485 - mse: 41.9485\n",
      "Epoch 251/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.7843 - mse: 41.7843\n",
      "Epoch 252/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.6130 - mse: 41.6130\n",
      "Epoch 253/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.4465 - mse: 41.4465\n",
      "Epoch 254/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.2774 - mse: 41.2774\n",
      "Epoch 255/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 41.1244 - mse: 41.1244\n",
      "Epoch 256/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.9535 - mse: 40.9535\n",
      "Epoch 257/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.7944 - mse: 40.7944\n",
      "Epoch 258/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.6396 - mse: 40.6396\n",
      "Epoch 259/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.4786 - mse: 40.4786\n",
      "Epoch 260/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.3284 - mse: 40.3284\n",
      "Epoch 261/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.1801 - mse: 40.1801\n",
      "Epoch 262/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 40.0302 - mse: 40.0302\n",
      "Epoch 263/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.8724 - mse: 39.8724\n",
      "Epoch 264/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.7210 - mse: 39.7210\n",
      "Epoch 265/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 39.5777 - mse: 39.5777\n",
      "Epoch 266/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.4380 - mse: 39.4380\n",
      "Epoch 267/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.2913 - mse: 39.2913\n",
      "Epoch 268/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.1492 - mse: 39.1492\n",
      "Epoch 269/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 39.0148 - mse: 39.0148\n",
      "Epoch 270/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.8722 - mse: 38.8722\n",
      "Epoch 271/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.7381 - mse: 38.7381\n",
      "Epoch 272/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.5953 - mse: 38.5953\n",
      "Epoch 273/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.4658 - mse: 38.4658\n",
      "Epoch 274/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.3370 - mse: 38.3370\n",
      "Epoch 275/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.2074 - mse: 38.2074\n",
      "Epoch 276/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 38.0742 - mse: 38.0742\n",
      "Epoch 277/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.9499 - mse: 37.9499\n",
      "Epoch 278/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.8290 - mse: 37.8290\n",
      "Epoch 279/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.6979 - mse: 37.6979\n",
      "Epoch 280/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.5756 - mse: 37.5756\n",
      "Epoch 281/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.4510 - mse: 37.4510\n",
      "Epoch 282/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.3382 - mse: 37.3382\n",
      "Epoch 283/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.2264 - mse: 37.2264\n",
      "Epoch 284/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 37.1069 - mse: 37.1069\n",
      "Epoch 285/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.9880 - mse: 36.9880\n",
      "Epoch 286/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.8705 - mse: 36.8705\n",
      "Epoch 287/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.7675 - mse: 36.7675\n",
      "Epoch 288/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.6531 - mse: 36.6531\n",
      "Epoch 289/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.5404 - mse: 36.5404\n",
      "Epoch 290/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.4331 - mse: 36.4331\n",
      "Epoch 291/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.3263 - mse: 36.3263\n",
      "Epoch 292/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.2249 - mse: 36.2249\n",
      "Epoch 293/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.1194 - mse: 36.1194\n",
      "Epoch 294/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 36.0155 - mse: 36.0155\n",
      "Epoch 295/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.9186 - mse: 35.9186\n",
      "Epoch 296/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.8217 - mse: 35.8217\n",
      "Epoch 297/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.7172 - mse: 35.7172\n",
      "Epoch 298/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.6205 - mse: 35.6205\n",
      "Epoch 299/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.5340 - mse: 35.5340\n",
      "Epoch 300/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.4336 - mse: 35.4336\n",
      "Epoch 301/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.3513 - mse: 35.3513\n",
      "Epoch 302/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.2458 - mse: 35.2458\n",
      "Epoch 303/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.1623 - mse: 35.1623\n",
      "Epoch 304/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 35.0695 - mse: 35.0695\n",
      "Epoch 305/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.9835 - mse: 34.9835\n",
      "Epoch 306/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.9034 - mse: 34.9034\n",
      "Epoch 307/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.8129 - mse: 34.8129\n",
      "Epoch 308/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.7349 - mse: 34.7349\n",
      "Epoch 309/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.6420 - mse: 34.6420\n",
      "Epoch 310/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.5625 - mse: 34.5625\n",
      "Epoch 311/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.4837 - mse: 34.4837\n",
      "Epoch 312/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.4052 - mse: 34.4052\n",
      "Epoch 313/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.3328 - mse: 34.3328\n",
      "Epoch 314/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.2479 - mse: 34.2479\n",
      "Epoch 315/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.1791 - mse: 34.1791\n",
      "Epoch 316/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.1048 - mse: 34.1048\n",
      "Epoch 317/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 34.0292 - mse: 34.0292\n",
      "Epoch 318/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.9607 - mse: 33.9607\n",
      "Epoch 319/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.8854 - mse: 33.8854\n",
      "Epoch 320/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.8164 - mse: 33.8164\n",
      "Epoch 321/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.7493 - mse: 33.7493\n",
      "Epoch 322/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.6814 - mse: 33.6814\n",
      "Epoch 323/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.6140 - mse: 33.6140\n",
      "Epoch 324/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.5530 - mse: 33.5530\n",
      "Epoch 325/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.4910 - mse: 33.4910\n",
      "Epoch 326/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.4196 - mse: 33.4196\n",
      "Epoch 327/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.3638 - mse: 33.3638\n",
      "Epoch 328/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.3000 - mse: 33.3000\n",
      "Epoch 329/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.2475 - mse: 33.2475\n",
      "Epoch 330/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.1806 - mse: 33.1806\n",
      "Epoch 331/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.1260 - mse: 33.1260\n",
      "Epoch 332/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.0709 - mse: 33.0709\n",
      "Epoch 333/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 33.0268 - mse: 33.0268\n",
      "Epoch 334/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 32.9548 - mse: 32.9548\n",
      "Epoch 335/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.9092 - mse: 32.9092\n",
      "Epoch 336/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.8635 - mse: 32.8635\n",
      "Epoch 337/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.8101 - mse: 32.8101\n",
      "Epoch 338/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.7487 - mse: 32.7487\n",
      "Epoch 339/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.6995 - mse: 32.6995\n",
      "Epoch 340/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.6510 - mse: 32.6510\n",
      "Epoch 341/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.6017 - mse: 32.6017\n",
      "Epoch 342/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.5625 - mse: 32.5625\n",
      "Epoch 343/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.5042 - mse: 32.5042\n",
      "Epoch 344/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.4927 - mse: 32.4927\n",
      "Epoch 345/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.4124 - mse: 32.4124\n",
      "Epoch 346/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.3755 - mse: 32.3755\n",
      "Epoch 347/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.3320 - mse: 32.3320\n",
      "Epoch 348/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.2914 - mse: 32.2914\n",
      "Epoch 349/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.2456 - mse: 32.2456\n",
      "Epoch 350/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.2060 - mse: 32.2060\n",
      "Epoch 351/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.1745 - mse: 32.1745\n",
      "Epoch 352/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.1297 - mse: 32.1297\n",
      "Epoch 353/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.1000 - mse: 32.1000\n",
      "Epoch 354/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.0510 - mse: 32.0510\n",
      "Epoch 355/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 32.0118 - mse: 32.0118\n",
      "Epoch 356/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.9810 - mse: 31.9810\n",
      "Epoch 357/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.9489 - mse: 31.9489\n",
      "Epoch 358/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.9083 - mse: 31.9083\n",
      "Epoch 359/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.8732 - mse: 31.8732\n",
      "Epoch 360/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.8432 - mse: 31.8432\n",
      "Epoch 361/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.8224 - mse: 31.8224\n",
      "Epoch 362/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.7731 - mse: 31.7731\n",
      "Epoch 363/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.7458 - mse: 31.7458\n",
      "Epoch 364/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.7148 - mse: 31.7148\n",
      "Epoch 365/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.6849 - mse: 31.6849\n",
      "Epoch 366/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.6633 - mse: 31.6633\n",
      "Epoch 367/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.6346 - mse: 31.6346\n",
      "Epoch 368/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.5987 - mse: 31.5987\n",
      "Epoch 369/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.5774 - mse: 31.5774\n",
      "Epoch 370/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.5456 - mse: 31.5456\n",
      "Epoch 371/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.5200 - mse: 31.5200\n",
      "Epoch 372/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.4992 - mse: 31.4992\n",
      "Epoch 373/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.4669 - mse: 31.4669\n",
      "Epoch 374/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.4435 - mse: 31.4435\n",
      "Epoch 375/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.4182 - mse: 31.4182\n",
      "Epoch 376/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.3993 - mse: 31.3993\n",
      "Epoch 377/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.3706 - mse: 31.3706\n",
      "Epoch 378/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.3532 - mse: 31.3532\n",
      "Epoch 379/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.3292 - mse: 31.3292\n",
      "Epoch 380/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 31.3099 - mse: 31.3099\n",
      "Epoch 381/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.3055 - mse: 31.3055\n",
      "Epoch 382/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.2735 - mse: 31.2735\n",
      "Epoch 383/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.2493 - mse: 31.2493\n",
      "Epoch 384/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.2290 - mse: 31.2290\n",
      "Epoch 385/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.2083 - mse: 31.2083\n",
      "Epoch 386/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1878 - mse: 31.1878\n",
      "Epoch 387/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1822 - mse: 31.1822\n",
      "Epoch 388/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1579 - mse: 31.1579\n",
      "Epoch 389/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1424 - mse: 31.1424\n",
      "Epoch 390/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1256 - mse: 31.1256\n",
      "Epoch 391/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.1053 - mse: 31.1053\n",
      "Epoch 392/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0882 - mse: 31.0882\n",
      "Epoch 393/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0764 - mse: 31.0764\n",
      "Epoch 394/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0565 - mse: 31.0565\n",
      "Epoch 395/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0418 - mse: 31.0418\n",
      "Epoch 396/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0371 - mse: 31.0371\n",
      "Epoch 397/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0229 - mse: 31.0229\n",
      "Epoch 398/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 31.0011 - mse: 31.0011\n",
      "Epoch 399/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9828 - mse: 30.9828\n",
      "Epoch 400/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9786 - mse: 30.9786\n",
      "Epoch 401/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9625 - mse: 30.9625\n",
      "Epoch 402/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.9500 - mse: 30.9500\n",
      "Epoch 403/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9428 - mse: 30.9428\n",
      "Epoch 404/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9252 - mse: 30.9252\n",
      "Epoch 405/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9169 - mse: 30.9169\n",
      "Epoch 406/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.9035 - mse: 30.9035\n",
      "Epoch 407/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.8932 - mse: 30.8932\n",
      "Epoch 408/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8851 - mse: 30.8851\n",
      "Epoch 409/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8710 - mse: 30.8710\n",
      "Epoch 410/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8620 - mse: 30.8620\n",
      "Epoch 411/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8550 - mse: 30.8550\n",
      "Epoch 412/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8447 - mse: 30.8447\n",
      "Epoch 413/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8322 - mse: 30.8322\n",
      "Epoch 414/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8229 - mse: 30.8229\n",
      "Epoch 415/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8228 - mse: 30.8228\n",
      "Epoch 416/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8053 - mse: 30.8053\n",
      "Epoch 417/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.8032 - mse: 30.8032\n",
      "Epoch 418/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7966 - mse: 30.7966\n",
      "Epoch 419/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7930 - mse: 30.7930\n",
      "Epoch 420/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7803 - mse: 30.7803\n",
      "Epoch 421/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7874 - mse: 30.7874\n",
      "Epoch 422/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7591 - mse: 30.7591\n",
      "Epoch 423/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7580 - mse: 30.7580\n",
      "Epoch 424/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7513 - mse: 30.7513\n",
      "Epoch 425/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7404 - mse: 30.7404\n",
      "Epoch 426/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7392 - mse: 30.7392\n",
      "Epoch 427/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7306 - mse: 30.7306\n",
      "Epoch 428/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7288 - mse: 30.7288\n",
      "Epoch 429/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7230 - mse: 30.7230\n",
      "Epoch 430/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7086 - mse: 30.7086\n",
      "Epoch 431/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7098 - mse: 30.7098\n",
      "Epoch 432/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.7042 - mse: 30.7042\n",
      "Epoch 433/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6927 - mse: 30.6927\n",
      "Epoch 434/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6915 - mse: 30.6915\n",
      "Epoch 435/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.7034 - mse: 30.7034\n",
      "Epoch 436/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6791 - mse: 30.6791\n",
      "Epoch 437/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6841 - mse: 30.6841\n",
      "Epoch 438/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.6834 - mse: 30.6834\n",
      "Epoch 439/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6938 - mse: 30.6938\n",
      "Epoch 440/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6640 - mse: 30.6640\n",
      "Epoch 441/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6590 - mse: 30.6590\n",
      "Epoch 442/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6608 - mse: 30.6608\n",
      "Epoch 443/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6607 - mse: 30.6607\n",
      "Epoch 444/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6477 - mse: 30.6477\n",
      "Epoch 445/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6450 - mse: 30.6450\n",
      "Epoch 446/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6415 - mse: 30.6415\n",
      "Epoch 447/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6378 - mse: 30.6378\n",
      "Epoch 448/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6327 - mse: 30.6327\n",
      "Epoch 449/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6291 - mse: 30.6291\n",
      "Epoch 450/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6341 - mse: 30.6341\n",
      "Epoch 451/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6287 - mse: 30.6287\n",
      "Epoch 452/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6203 - mse: 30.6203\n",
      "Epoch 453/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6200 - mse: 30.6200\n",
      "Epoch 454/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6215 - mse: 30.6215\n",
      "Epoch 455/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6135 - mse: 30.6135\n",
      "Epoch 456/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6145 - mse: 30.6145\n",
      "Epoch 457/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6070 - mse: 30.6070\n",
      "Epoch 458/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6096 - mse: 30.6096\n",
      "Epoch 459/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6038 - mse: 30.6038\n",
      "Epoch 460/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6012 - mse: 30.6012\n",
      "Epoch 461/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5976 - mse: 30.5976\n",
      "Epoch 462/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5957 - mse: 30.5957\n",
      "Epoch 463/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5945 - mse: 30.5945\n",
      "Epoch 464/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6025 - mse: 30.6025\n",
      "Epoch 465/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5983 - mse: 30.5983\n",
      "Epoch 466/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6006 - mse: 30.6006\n",
      "Epoch 467/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5861 - mse: 30.5861\n",
      "Epoch 468/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5959 - mse: 30.5959\n",
      "Epoch 469/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.6067 - mse: 30.6067\n",
      "Epoch 470/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5831 - mse: 30.5831\n",
      "Epoch 471/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5828 - mse: 30.5828\n",
      "Epoch 472/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5963 - mse: 30.5963\n",
      "Epoch 473/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5786 - mse: 30.5786\n",
      "Epoch 474/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5791 - mse: 30.5791\n",
      "Epoch 475/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5778 - mse: 30.5778\n",
      "Epoch 476/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5829 - mse: 30.5829\n",
      "Epoch 477/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5727 - mse: 30.5727\n",
      "Epoch 478/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5810 - mse: 30.5810\n",
      "Epoch 479/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5767 - mse: 30.5767\n",
      "Epoch 480/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5729 - mse: 30.5729\n",
      "Epoch 481/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5667 - mse: 30.5667\n",
      "Epoch 482/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5694 - mse: 30.5694\n",
      "Epoch 483/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5701 - mse: 30.5701\n",
      "Epoch 484/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5659 - mse: 30.5659\n",
      "Epoch 485/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5618 - mse: 30.5618\n",
      "Epoch 486/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5630 - mse: 30.5630\n",
      "Epoch 487/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5627 - mse: 30.5627\n",
      "Epoch 488/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5629 - mse: 30.5629\n",
      "Epoch 489/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5628 - mse: 30.5628\n",
      "Epoch 490/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5605 - mse: 30.5605\n",
      "Epoch 491/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5625 - mse: 30.5625\n",
      "Epoch 492/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5575 - mse: 30.5575\n",
      "Epoch 493/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5601 - mse: 30.5601\n",
      "Epoch 494/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5634 - mse: 30.5634\n",
      "Epoch 495/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5563 - mse: 30.5563\n",
      "Epoch 496/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5535 - mse: 30.5535\n",
      "Epoch 497/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5556 - mse: 30.5556\n",
      "Epoch 498/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5515 - mse: 30.5515\n",
      "Epoch 499/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5673 - mse: 30.5673\n",
      "Epoch 500/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5507 - mse: 30.5507\n",
      "Epoch 501/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5529 - mse: 30.5529\n",
      "Epoch 502/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5493 - mse: 30.5493\n",
      "Epoch 503/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5565 - mse: 30.5565\n",
      "Epoch 504/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5520 - mse: 30.5520\n",
      "Epoch 505/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5543 - mse: 30.5543\n",
      "Epoch 506/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5470 - mse: 30.5470\n",
      "Epoch 507/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5527 - mse: 30.5527\n",
      "Epoch 508/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5602 - mse: 30.5602\n",
      "Epoch 509/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5480 - mse: 30.5480\n",
      "Epoch 510/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5465 - mse: 30.5465\n",
      "Epoch 511/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5466 - mse: 30.5466\n",
      "Epoch 512/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5474 - mse: 30.5474\n",
      "Epoch 513/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5495 - mse: 30.5495\n",
      "Epoch 514/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5485 - mse: 30.5485\n",
      "Epoch 515/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5489 - mse: 30.5489\n",
      "Epoch 516/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5510 - mse: 30.5510\n",
      "Epoch 517/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5427 - mse: 30.5427\n",
      "Epoch 518/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5437 - mse: 30.5437\n",
      "Epoch 519/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5407 - mse: 30.5407\n",
      "Epoch 520/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5576 - mse: 30.5576\n",
      "Epoch 521/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5418 - mse: 30.5418\n",
      "Epoch 522/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5511 - mse: 30.5511\n",
      "Epoch 523/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5469 - mse: 30.5469\n",
      "Epoch 524/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5448 - mse: 30.5448\n",
      "Epoch 525/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5396 - mse: 30.5396\n",
      "Epoch 526/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5420 - mse: 30.5420\n",
      "Epoch 527/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5393 - mse: 30.5393\n",
      "Epoch 528/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5545 - mse: 30.5545\n",
      "Epoch 529/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5383 - mse: 30.5383\n",
      "Epoch 530/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5409 - mse: 30.5409\n",
      "Epoch 531/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5438 - mse: 30.5438\n",
      "Epoch 532/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5427 - mse: 30.5427\n",
      "Epoch 533/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5411 - mse: 30.5411\n",
      "Epoch 534/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5398 - mse: 30.5398\n",
      "Epoch 535/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5397 - mse: 30.5397\n",
      "Epoch 536/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5447 - mse: 30.5447\n",
      "Epoch 537/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5409 - mse: 30.5409\n",
      "Epoch 538/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5386 - mse: 30.5386\n",
      "Epoch 539/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 540/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 541/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5405 - mse: 30.5405\n",
      "Epoch 542/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5371 - mse: 30.5371\n",
      "Epoch 543/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5388 - mse: 30.5388\n",
      "Epoch 544/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 545/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5384 - mse: 30.5384\n",
      "Epoch 546/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5367 - mse: 30.5367\n",
      "Epoch 547/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5518 - mse: 30.5518\n",
      "Epoch 548/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5393 - mse: 30.5393\n",
      "Epoch 549/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 550/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5380 - mse: 30.5380\n",
      "Epoch 551/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5357 - mse: 30.5357\n",
      "Epoch 552/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 553/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5488 - mse: 30.5488\n",
      "Epoch 554/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5375 - mse: 30.5375\n",
      "Epoch 555/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5356 - mse: 30.5356\n",
      "Epoch 556/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 557/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5426 - mse: 30.5426\n",
      "Epoch 558/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5326 - mse: 30.5326\n",
      "Epoch 559/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 560/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 561/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5568 - mse: 30.5568\n",
      "Epoch 562/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5344 - mse: 30.5344\n",
      "Epoch 563/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5408 - mse: 30.5408\n",
      "Epoch 564/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5328 - mse: 30.5328\n",
      "Epoch 565/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5365 - mse: 30.5365\n",
      "Epoch 566/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5336 - mse: 30.5336\n",
      "Epoch 567/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5370 - mse: 30.5370\n",
      "Epoch 568/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5339 - mse: 30.5339\n",
      "Epoch 569/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5409 - mse: 30.5409\n",
      "Epoch 570/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5312 - mse: 30.5312\n",
      "Epoch 571/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5349 - mse: 30.5349\n",
      "Epoch 572/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5421 - mse: 30.5421\n",
      "Epoch 573/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5442 - mse: 30.5442\n",
      "Epoch 574/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5339 - mse: 30.5339\n",
      "Epoch 575/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5320 - mse: 30.5320\n",
      "Epoch 576/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 577/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 578/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 579/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5366 - mse: 30.5366\n",
      "Epoch 580/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5382 - mse: 30.5382\n",
      "Epoch 581/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5369 - mse: 30.5369\n",
      "Epoch 582/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5349 - mse: 30.5349\n",
      "Epoch 583/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5381 - mse: 30.5381\n",
      "Epoch 584/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5368 - mse: 30.5368\n",
      "Epoch 585/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 586/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5362 - mse: 30.5362\n",
      "Epoch 587/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5311 - mse: 30.5311\n",
      "Epoch 588/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 589/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5378 - mse: 30.5378\n",
      "Epoch 590/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5430 - mse: 30.5430\n",
      "Epoch 591/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5304 - mse: 30.5304\n",
      "Epoch 592/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5322 - mse: 30.5322\n",
      "Epoch 593/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5304 - mse: 30.5304\n",
      "Epoch 594/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5339 - mse: 30.5339\n",
      "Epoch 595/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5328 - mse: 30.5328\n",
      "Epoch 596/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5316 - mse: 30.5316\n",
      "Epoch 597/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5296 - mse: 30.5296\n",
      "Epoch 598/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5337 - mse: 30.5337\n",
      "Epoch 599/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 600/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5332 - mse: 30.5332\n",
      "Epoch 601/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5306 - mse: 30.5306\n",
      "Epoch 602/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 603/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5419 - mse: 30.5419\n",
      "Epoch 604/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 605/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5369 - mse: 30.5369\n",
      "Epoch 606/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5310 - mse: 30.5310\n",
      "Epoch 607/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5407 - mse: 30.5407\n",
      "Epoch 608/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5296 - mse: 30.5296\n",
      "Epoch 609/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5292 - mse: 30.5292\n",
      "Epoch 610/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5342 - mse: 30.5342\n",
      "Epoch 611/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5421 - mse: 30.5421\n",
      "Epoch 612/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5450 - mse: 30.5450\n",
      "Epoch 613/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5368 - mse: 30.5368\n",
      "Epoch 614/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5366 - mse: 30.5366\n",
      "Epoch 615/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5334 - mse: 30.5334\n",
      "Epoch 616/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 617/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5290 - mse: 30.5290\n",
      "Epoch 618/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 619/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5338 - mse: 30.5338\n",
      "Epoch 620/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 621/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5342 - mse: 30.5342\n",
      "Epoch 622/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5325 - mse: 30.5325\n",
      "Epoch 623/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5398 - mse: 30.5398\n",
      "Epoch 624/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5389 - mse: 30.5389\n",
      "Epoch 625/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5382 - mse: 30.5382\n",
      "Epoch 626/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5311 - mse: 30.5311\n",
      "Epoch 627/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 628/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5296 - mse: 30.5296\n",
      "Epoch 629/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 630/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 631/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5416 - mse: 30.5416\n",
      "Epoch 632/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5275 - mse: 30.5275\n",
      "Epoch 633/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 634/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 635/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5334 - mse: 30.5334\n",
      "Epoch 636/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 637/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 638/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 639/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 640/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 641/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5329 - mse: 30.5329\n",
      "Epoch 642/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5283 - mse: 30.5283\n",
      "Epoch 643/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5372 - mse: 30.5372\n",
      "Epoch 644/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5318 - mse: 30.5318\n",
      "Epoch 645/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5362 - mse: 30.5362\n",
      "Epoch 646/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5362 - mse: 30.5362\n",
      "Epoch 647/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5461 - mse: 30.5461\n",
      "Epoch 648/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 649/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 650/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5313 - mse: 30.5313\n",
      "Epoch 651/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5334 - mse: 30.5334\n",
      "Epoch 652/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 653/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 654/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5312 - mse: 30.5312\n",
      "Epoch 655/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5283 - mse: 30.5283\n",
      "Epoch 656/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5335 - mse: 30.5335\n",
      "Epoch 657/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 658/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 659/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 660/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5353 - mse: 30.5353\n",
      "Epoch 661/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5365 - mse: 30.5365\n",
      "Epoch 662/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5407 - mse: 30.5407\n",
      "Epoch 663/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 664/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5349 - mse: 30.5349\n",
      "Epoch 665/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5272 - mse: 30.5272\n",
      "Epoch 666/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 667/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5272 - mse: 30.5272\n",
      "Epoch 668/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5278 - mse: 30.5278\n",
      "Epoch 669/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 670/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 671/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 672/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 673/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 674/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 675/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5358 - mse: 30.5358\n",
      "Epoch 676/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5369 - mse: 30.5369\n",
      "Epoch 677/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5416 - mse: 30.5416\n",
      "Epoch 678/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 679/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5270 - mse: 30.5270\n",
      "Epoch 680/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5299 - mse: 30.5299\n",
      "Epoch 681/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5347 - mse: 30.5347\n",
      "Epoch 682/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 683/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5290 - mse: 30.5290\n",
      "Epoch 684/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 685/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 686/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 687/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 688/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 689/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 690/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 691/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5328 - mse: 30.5328\n",
      "Epoch 692/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5303 - mse: 30.5303\n",
      "Epoch 693/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5303 - mse: 30.5303\n",
      "Epoch 694/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5303 - mse: 30.5303\n",
      "Epoch 695/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5276 - mse: 30.5276\n",
      "Epoch 696/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5327 - mse: 30.5327\n",
      "Epoch 697/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 698/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5387 - mse: 30.5387\n",
      "Epoch 699/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 700/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5272 - mse: 30.5272\n",
      "Epoch 701/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 702/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 703/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 704/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 705/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 706/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 707/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 708/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 709/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5328 - mse: 30.5328\n",
      "Epoch 710/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 711/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5648 - mse: 30.5648\n",
      "Epoch 712/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 713/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5398 - mse: 30.5398\n",
      "Epoch 714/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 715/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 716/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 717/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5276 - mse: 30.5276\n",
      "Epoch 718/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 719/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5426 - mse: 30.5426\n",
      "Epoch 720/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 721/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 722/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5300 - mse: 30.5300\n",
      "Epoch 723/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5277 - mse: 30.5277\n",
      "Epoch 724/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5315 - mse: 30.5315\n",
      "Epoch 725/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5277 - mse: 30.5277\n",
      "Epoch 726/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 727/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 728/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5282 - mse: 30.5282\n",
      "Epoch 729/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5287 - mse: 30.5287\n",
      "Epoch 730/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5399 - mse: 30.5399\n",
      "Epoch 731/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5248 - mse: 30.5248\n",
      "Epoch 732/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 733/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 734/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5264 - mse: 30.5264\n",
      "Epoch 735/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5240 - mse: 30.5240\n",
      "Epoch 736/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5240 - mse: 30.5240\n",
      "Epoch 737/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 738/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 739/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5285 - mse: 30.5285\n",
      "Epoch 740/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5325 - mse: 30.5325\n",
      "Epoch 741/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5650 - mse: 30.5650\n",
      "Epoch 742/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5288 - mse: 30.5288\n",
      "Epoch 743/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5331 - mse: 30.5331\n",
      "Epoch 744/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 745/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 746/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 747/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 748/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5244 - mse: 30.5244\n",
      "Epoch 749/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 750/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5255 - mse: 30.5255\n",
      "Epoch 751/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 752/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5352 - mse: 30.5352\n",
      "Epoch 753/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5443 - mse: 30.5443\n",
      "Epoch 754/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5257 - mse: 30.5257\n",
      "Epoch 755/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5287 - mse: 30.5287\n",
      "Epoch 756/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5412 - mse: 30.5412\n",
      "Epoch 757/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 758/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 759/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5285 - mse: 30.5285\n",
      "Epoch 760/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5285 - mse: 30.5285\n",
      "Epoch 761/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 762/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5294 - mse: 30.5294\n",
      "Epoch 763/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5260 - mse: 30.5260\n",
      "Epoch 764/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5411 - mse: 30.5411\n",
      "Epoch 765/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 766/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 767/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 768/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 769/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 770/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 771/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5289 - mse: 30.5289\n",
      "Epoch 772/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 773/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 774/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5323 - mse: 30.5323\n",
      "Epoch 775/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5287 - mse: 30.5287\n",
      "Epoch 776/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 777/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5279 - mse: 30.5279\n",
      "Epoch 778/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 779/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 780/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5281 - mse: 30.5281\n",
      "Epoch 781/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5231 - mse: 30.5231\n",
      "Epoch 782/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5321 - mse: 30.5321\n",
      "Epoch 783/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5309 - mse: 30.5309\n",
      "Epoch 784/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5297 - mse: 30.5297\n",
      "Epoch 785/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 786/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5338 - mse: 30.5338\n",
      "Epoch 787/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5341 - mse: 30.5341\n",
      "Epoch 788/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 789/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5315 - mse: 30.5315\n",
      "Epoch 790/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5285 - mse: 30.5285\n",
      "Epoch 791/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5307 - mse: 30.5307\n",
      "Epoch 792/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 793/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 794/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 795/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 796/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5325 - mse: 30.5325\n",
      "Epoch 797/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 798/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5223 - mse: 30.5223\n",
      "Epoch 799/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5252 - mse: 30.5252\n",
      "Epoch 800/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 801/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 802/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 803/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5295 - mse: 30.5295\n",
      "Epoch 804/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5208 - mse: 30.5208\n",
      "Epoch 805/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 806/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 807/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 808/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 809/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 810/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 811/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5343 - mse: 30.5343\n",
      "Epoch 812/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 813/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5343 - mse: 30.5343\n",
      "Epoch 814/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5224 - mse: 30.5224\n",
      "Epoch 815/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5264 - mse: 30.5264\n",
      "Epoch 816/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 817/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 818/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5203 - mse: 30.5203\n",
      "Epoch 819/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 820/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 821/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 822/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5222 - mse: 30.5222\n",
      "Epoch 823/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 824/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 825/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5360 - mse: 30.5360\n",
      "Epoch 826/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 827/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 828/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 829/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 830/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5280 - mse: 30.5280\n",
      "Epoch 831/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 832/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5314 - mse: 30.5314\n",
      "Epoch 833/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 834/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 835/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 836/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5224 - mse: 30.5224\n",
      "Epoch 837/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 838/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5223 - mse: 30.5223\n",
      "Epoch 839/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 840/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5229 - mse: 30.5229\n",
      "Epoch 841/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 842/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5213 - mse: 30.5213\n",
      "Epoch 843/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 844/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5271 - mse: 30.5271\n",
      "Epoch 845/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5369 - mse: 30.5369\n",
      "Epoch 846/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 847/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5219 - mse: 30.5219\n",
      "Epoch 848/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 849/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5284 - mse: 30.5284\n",
      "Epoch 850/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5323 - mse: 30.5323\n",
      "Epoch 851/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 852/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 853/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5385 - mse: 30.5385\n",
      "Epoch 854/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 855/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 856/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 857/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 858/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 859/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5226 - mse: 30.5226\n",
      "Epoch 860/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5226 - mse: 30.5226\n",
      "Epoch 861/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5274 - mse: 30.5274\n",
      "Epoch 862/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 863/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5237 - mse: 30.5237\n",
      "Epoch 864/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 865/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5223 - mse: 30.5223\n",
      "Epoch 866/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5212 - mse: 30.5212\n",
      "Epoch 867/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 868/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5343 - mse: 30.5343\n",
      "Epoch 869/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5455 - mse: 30.5455\n",
      "Epoch 870/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5255 - mse: 30.5255\n",
      "Epoch 871/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5236 - mse: 30.5236\n",
      "Epoch 872/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5246 - mse: 30.5246\n",
      "Epoch 873/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5256 - mse: 30.5256\n",
      "Epoch 874/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5262 - mse: 30.5262\n",
      "Epoch 875/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5191 - mse: 30.5191\n",
      "Epoch 876/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5206 - mse: 30.5206\n",
      "Epoch 877/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 878/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5286 - mse: 30.5286\n",
      "Epoch 879/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 880/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5313 - mse: 30.5313\n",
      "Epoch 881/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5200 - mse: 30.5200\n",
      "Epoch 882/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 883/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 884/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5198 - mse: 30.5198\n",
      "Epoch 885/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 886/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5205 - mse: 30.5205\n",
      "Epoch 887/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5223 - mse: 30.5223\n",
      "Epoch 888/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5334 - mse: 30.5334\n",
      "Epoch 889/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5308 - mse: 30.5308\n",
      "Epoch 890/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 891/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 892/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 893/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 894/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5213 - mse: 30.5213\n",
      "Epoch 895/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5260 - mse: 30.5260\n",
      "Epoch 896/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 897/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5245 - mse: 30.5245\n",
      "Epoch 898/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 899/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 900/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 901/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5189 - mse: 30.5189\n",
      "Epoch 902/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5362 - mse: 30.5362\n",
      "Epoch 903/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5251 - mse: 30.5251\n",
      "Epoch 904/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5180 - mse: 30.5180\n",
      "Epoch 905/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5333 - mse: 30.5333\n",
      "Epoch 906/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5346 - mse: 30.5346\n",
      "Epoch 907/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5273 - mse: 30.5273\n",
      "Epoch 908/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 909/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5208 - mse: 30.5208\n",
      "Epoch 910/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5370 - mse: 30.5370\n",
      "Epoch 911/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 912/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5204 - mse: 30.5204\n",
      "Epoch 913/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 914/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5206 - mse: 30.5206\n",
      "Epoch 915/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 916/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5247 - mse: 30.5247\n",
      "Epoch 917/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 918/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 919/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5373 - mse: 30.5373\n",
      "Epoch 920/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 921/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 922/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 923/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5299 - mse: 30.5299\n",
      "Epoch 924/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 925/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5236 - mse: 30.5236\n",
      "Epoch 926/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5269 - mse: 30.5269\n",
      "Epoch 927/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5342 - mse: 30.5342\n",
      "Epoch 928/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5206 - mse: 30.5206\n",
      "Epoch 929/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 930/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5535 - mse: 30.5535\n",
      "Epoch 931/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5241 - mse: 30.5241\n",
      "Epoch 932/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 933/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 934/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5233 - mse: 30.5233\n",
      "Epoch 935/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5228 - mse: 30.5228\n",
      "Epoch 936/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5210 - mse: 30.5210\n",
      "Epoch 937/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 938/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5301 - mse: 30.5301\n",
      "Epoch 939/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5218 - mse: 30.5218\n",
      "Epoch 940/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5214 - mse: 30.5214\n",
      "Epoch 941/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 942/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5243 - mse: 30.5243\n",
      "Epoch 943/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 944/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5189 - mse: 30.5189\n",
      "Epoch 945/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5213 - mse: 30.5213\n",
      "Epoch 946/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5658 - mse: 30.5658\n",
      "Epoch 947/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5235 - mse: 30.5235\n",
      "Epoch 948/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5273 - mse: 30.5273\n",
      "Epoch 949/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5249 - mse: 30.5249\n",
      "Epoch 950/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 951/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5217 - mse: 30.5217\n",
      "Epoch 952/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5202 - mse: 30.5202\n",
      "Epoch 953/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5250 - mse: 30.5250\n",
      "Epoch 954/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5204 - mse: 30.5204\n",
      "Epoch 955/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5232 - mse: 30.5232\n",
      "Epoch 956/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 957/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5266 - mse: 30.5266\n",
      "Epoch 958/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5276 - mse: 30.5276\n",
      "Epoch 959/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5222 - mse: 30.5222\n",
      "Epoch 960/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5302 - mse: 30.5302\n",
      "Epoch 961/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5263 - mse: 30.5263\n",
      "Epoch 962/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5259 - mse: 30.5259\n",
      "Epoch 963/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5197 - mse: 30.5197\n",
      "Epoch 964/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5220 - mse: 30.5220\n",
      "Epoch 965/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5191 - mse: 30.5191\n",
      "Epoch 966/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 967/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5230 - mse: 30.5230\n",
      "Epoch 968/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5244 - mse: 30.5244\n",
      "Epoch 969/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 970/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5187 - mse: 30.5187\n",
      "Epoch 971/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5208 - mse: 30.5208\n",
      "Epoch 972/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5316 - mse: 30.5316\n",
      "Epoch 973/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5229 - mse: 30.5229\n",
      "Epoch 974/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5225 - mse: 30.5225\n",
      "Epoch 975/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5351 - mse: 30.5351\n",
      "Epoch 976/1000\n",
      "17/17 [==============================] - 0s 3ms/step - loss: 30.5568 - mse: 30.5568\n",
      "Epoch 977/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5163 - mse: 30.5163\n",
      "Epoch 978/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5267 - mse: 30.5267\n",
      "Epoch 979/1000\n",
      "17/17 [==============================] - 0s 4ms/step - loss: 30.5242 - mse: 30.5242\n",
      "Epoch 980/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5211 - mse: 30.5211\n",
      "Epoch 981/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5234 - mse: 30.5234\n",
      "Epoch 982/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5227 - mse: 30.5227\n",
      "Epoch 983/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5224 - mse: 30.5224\n",
      "Epoch 984/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5291 - mse: 30.5291\n",
      "Epoch 985/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5238 - mse: 30.5238\n",
      "Epoch 986/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5254 - mse: 30.5254\n",
      "Epoch 987/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5268 - mse: 30.5268\n",
      "Epoch 988/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5306 - mse: 30.5306\n",
      "Epoch 989/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5228 - mse: 30.5228\n",
      "Epoch 990/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5253 - mse: 30.5253\n",
      "Epoch 991/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5220 - mse: 30.5220\n",
      "Epoch 992/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5275 - mse: 30.5275\n",
      "Epoch 993/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5305 - mse: 30.5305\n",
      "Epoch 994/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5203 - mse: 30.5203\n",
      "Epoch 995/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5221 - mse: 30.5221\n",
      "Epoch 996/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5239 - mse: 30.5239\n",
      "Epoch 997/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5293 - mse: 30.5293\n",
      "Epoch 998/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5196 - mse: 30.5196\n",
      "Epoch 999/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5310 - mse: 30.5310\n",
      "Epoch 1000/1000\n",
      "17/17 [==============================] - 0s 2ms/step - loss: 30.5175 - mse: 30.5175\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd6ab8c3510>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "model = Sequential([\n",
    "    # 단 하나의 units 설정. input_shape는 2차원, 회귀이므로 activation은 설정하지 않음. \n",
    "    # weight와 bias 초기화는 kernel_inbitializer와 bias_initializer를 이용. \n",
    "    Dense(1, input_shape=(2, ), activation=None, kernel_initializer='zeros', bias_initializer='ones')\n",
    "])\n",
    "# Adam optimizer를 이용하고 Loss 함수는 Mean Squared Error, 성능 측정 역시 MSE를 이용하여 학습 수행. \n",
    "model.compile(optimizer=Adam(learning_rate=0.01), loss='mse', metrics=['mse'])\n",
    "\n",
    "# Keras는 반드시 Batch GD를 적용함. batch_size가 None이면 32를 할당. \n",
    "model.fit(scaled_features, bostonDF['PRICE'].values, batch_size=30, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "A17Yenrr1REc",
    "outputId": "e7649fa9-da53-473e-a358-95539a52ce85"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-04e3ee85-8993-4533-ac95-81a6cc47fecb\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>PRICE</th>\n",
       "      <th>PREDICTED_PRICE_BATCH_RANDOM</th>\n",
       "      <th>PREDICTED_PRICE_BATCH</th>\n",
       "      <th>KERAS_PREDICTED_PRICE_BATCH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>28.937588</td>\n",
       "      <td>28.819549</td>\n",
       "      <td>28.979647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>25.486589</td>\n",
       "      <td>25.364749</td>\n",
       "      <td>25.505798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>32.529370</td>\n",
       "      <td>32.513763</td>\n",
       "      <td>32.642754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "      <td>32.324713</td>\n",
       "      <td>32.269932</td>\n",
       "      <td>32.417938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "      <td>31.500316</td>\n",
       "      <td>31.485311</td>\n",
       "      <td>31.607723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.02985</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.430</td>\n",
       "      <td>58.7</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.12</td>\n",
       "      <td>5.21</td>\n",
       "      <td>28.7</td>\n",
       "      <td>28.081091</td>\n",
       "      <td>27.938726</td>\n",
       "      <td>28.106190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "      <td>21.356486</td>\n",
       "      <td>21.180895</td>\n",
       "      <td>21.324598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.14455</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.172</td>\n",
       "      <td>96.1</td>\n",
       "      <td>5.9505</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>396.90</td>\n",
       "      <td>19.15</td>\n",
       "      <td>27.1</td>\n",
       "      <td>17.775532</td>\n",
       "      <td>17.666026</td>\n",
       "      <td>17.753742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.21124</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>5.631</td>\n",
       "      <td>100.0</td>\n",
       "      <td>6.0821</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.63</td>\n",
       "      <td>29.93</td>\n",
       "      <td>16.5</td>\n",
       "      <td>8.140533</td>\n",
       "      <td>7.996101</td>\n",
       "      <td>8.043216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.17004</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.004</td>\n",
       "      <td>85.9</td>\n",
       "      <td>6.5921</td>\n",
       "      <td>5.0</td>\n",
       "      <td>311.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>386.71</td>\n",
       "      <td>17.10</td>\n",
       "      <td>18.9</td>\n",
       "      <td>18.286595</td>\n",
       "      <td>18.135869</td>\n",
       "      <td>18.248018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-04e3ee85-8993-4533-ac95-81a6cc47fecb')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-04e3ee85-8993-4533-ac95-81a6cc47fecb button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-04e3ee85-8993-4533-ac95-81a6cc47fecb');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM    AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575   65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421   78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185   61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998   45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147   54.2  6.0622  3.0  222.0   \n",
       "5  0.02985   0.0   2.18   0.0  0.458  6.430   58.7  6.0622  3.0  222.0   \n",
       "6  0.08829  12.5   7.87   0.0  0.524  6.012   66.6  5.5605  5.0  311.0   \n",
       "7  0.14455  12.5   7.87   0.0  0.524  6.172   96.1  5.9505  5.0  311.0   \n",
       "8  0.21124  12.5   7.87   0.0  0.524  5.631  100.0  6.0821  5.0  311.0   \n",
       "9  0.17004  12.5   7.87   0.0  0.524  6.004   85.9  6.5921  5.0  311.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  PRICE  PREDICTED_PRICE_BATCH_RANDOM  \\\n",
       "0     15.3  396.90   4.98   24.0                     28.937588   \n",
       "1     17.8  396.90   9.14   21.6                     25.486589   \n",
       "2     17.8  392.83   4.03   34.7                     32.529370   \n",
       "3     18.7  394.63   2.94   33.4                     32.324713   \n",
       "4     18.7  396.90   5.33   36.2                     31.500316   \n",
       "5     18.7  394.12   5.21   28.7                     28.081091   \n",
       "6     15.2  395.60  12.43   22.9                     21.356486   \n",
       "7     15.2  396.90  19.15   27.1                     17.775532   \n",
       "8     15.2  386.63  29.93   16.5                      8.140533   \n",
       "9     15.2  386.71  17.10   18.9                     18.286595   \n",
       "\n",
       "   PREDICTED_PRICE_BATCH  KERAS_PREDICTED_PRICE_BATCH  \n",
       "0              28.819549                    28.979647  \n",
       "1              25.364749                    25.505798  \n",
       "2              32.513763                    32.642754  \n",
       "3              32.269932                    32.417938  \n",
       "4              31.485311                    31.607723  \n",
       "5              27.938726                    28.106190  \n",
       "6              21.180895                    21.324598  \n",
       "7              17.666026                    17.753742  \n",
       "8               7.996101                     8.043216  \n",
       "9              18.135869                    18.248018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted = model.predict(scaled_features)\n",
    "bostonDF['KERAS_PREDICTED_PRICE_BATCH'] = predicted\n",
    "bostonDF.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ap84lX8c1REc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "gradient-descent-practice (1).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
